{"token_count": [2006], "text": "Alabama () is a state in the Southeastern region of the United States, bordered by Tennessee to the north; Georgia to the east; Florida and the Gulf of Mexico to the south; and Mississippi to the west. Alabama is the 30th largest by area and the 24th-most populous of the U.S. states. With a total of  of inland waterways, Alabama has among the most of any state.\n\nAlabama is nicknamed the Yellowhammer State, after the state bird. Alabama is also known as the \"Heart of Dixie\" and the \"Cotton State\". The state tree is the longleaf pine, and the state flower is the camellia. Alabama's capital is Montgomery, and its largest city by population and area is Huntsville. Its oldest city is Mobile, founded by French colonists in 1702 as the capital of French Louisiana. Greater Birmingham is Alabama's largest metropolitan area and its economic center.\n\nOriginally home to many native tribes, present-day Alabama was a Spanish territory beginning in the sixteenth century until the French acquired it in the early eighteenth century. The British won the territory in 1763 until losing it in the American Revolutionary War. Spain held Mobile as part of Spanish West Florida until 1813. In December 1819, Alabama was recognized as a state. During the antebellum period, Alabama was a major producer of cotton, and widely used African American slave labor. In 1861, the state seceded from the United States to become part of the Confederate States of America, with Montgomery acting as its first capital, and rejoined the Union in 1868. Following the American Civil War, Alabama would suffer decades of economic hardship, in part due to agriculture and a few cash crops being the main driver of the states economy. Similar to other former slave states, Alabamian legislators employed Jim Crow laws to disenfranchise and discriminate against African Americans from the late 19th century up until the 1960s. \n\nIn the early 20th century, despite the growth of major industries and urban centers, white rural interests dominated the state legislature through the mid-20th century. During this time, urban interests and African Americans were markedly under-represented. High-profile events such as the Selma to Montgomery march made the state a major focal point of the civil rights movement in the 1950s and 1960s. During and after World War II, Alabama grew as the state's economy diversified with new industries. NASA's Marshall Space Flight Center in Huntsville would help Alabama's economic growth in the mid-to-late 20th century, by developing an aerospace industry. Alabama's economy in the 21st century is based on automotive, finance, tourism, manufacturing, aerospace, mineral extraction, healthcare, education, retail, and technology.\n\nThe state's geography is diverse, with the north dominated by the mountainous Tennessee Valley and the south by Mobile Bay, a historically significant port. Politically, as part of the Deep South, Alabama is predominantly a conservative state, and culturally is known for its Southern culture. Within Alabama, American football, particularly at the college level at schools such as the University of Alabama, Auburn University, Alabama A&M University, Alabama State University, Troy University, the University of South Alabama, and Jacksonville State University, play a major part of the state's culture.\n\nEtymology\nThe European-American naming of the Alabama River and state was derived from the Alabama people, a Muskogean-speaking tribe whose members lived just below the confluence of the Coosa and Tallapoosa rivers on the upper reaches of the river. In the Alabama language, the word for a person of Alabama lineage is  (or variously  or  in different dialects; the plural form is ). The suggestion that \"Alabama\" was borrowed from the Choctaw language is unlikely (e.g., a. The word's spelling varies significantly among historical sources. The first usage appears in three accounts of the Hernando de Soto expedition of 1540: Garcilaso de la Vega used, while the Knight of Elvas and Rodrigo Ranjel wrote Alibamu and Limamu, respectively, in transliterations of the term. As early as 1702, the French called the tribe the, with French maps identifying the river as. Other spellings of the name have included Alibamu, Alabamo, Albama, Alebamon, Alibama, Alibamou, Alabamu, Allibamou. and possibly Alabahmu. The use of state names derived from Native American languages is common in the U.S.; an estimated 27 states have names of Native American origin.\n\nSources disagree on the word's meaning. Some scholars suggest the word comes from the Choctaw  (meaning 'plants' or 'weeds') and  (meaning 'to cut', 'to trim', or 'to gather'). The meaning may have been 'clearers of the thicket' or 'herb gatherers', referring to clearing land for cultivation or collecting medicinal plants. The state has numerous place names of Native American origin. However, there are no correspondingly similar words in the Alabama language.\n\nAn 1842 article in the Jacksonville Republican proposed it meant 'Here We Rest'. This notion was popularized in the 1850s through the writings of Alexander Beaufort Meek. Experts in the Muskogean languages have not found any evidence to support such a translation.\n\nHistory\n\nPre-European settlement\n\nIndigenous peoples of varying cultures lived in the area for thousands of years before the advent of European colonization. Trade with the northeastern tribes by the Ohio River began during the Burial Mound Period (1000BCE700CE) and continued until European contact.\n\nThe agrarian Mississippian culture covered most of the state from 1000 to 1600 CE, with one of its major centers built at what is now the Moundville Archaeological Site in Moundville, Alabama. This is the second-largest complex of the classic Middle Mississippian era, after Cahokia in present-day Illinois, which was the center of the culture. Analysis of artifacts from archaeological excavations at Moundville were the basis of scholars' formulating the characteristics of the Southeastern Ceremonial Complex (SECC). Contrary to popular belief, the SECC appears to have no direct links to Mesoamerican culture, but developed independently. The Ceremonial Complex represents a major component of the religion of the Mississippian peoples; it is one of the primary means by which their religion is understood.\n\nAmong the historical tribes of Native American people living in present-day Alabama at the time of European contact were the Cherokee, an Iroquoian language people; and the Muskogean-speaking Alabama (Alibamu), Chickasaw, Choctaw, Creek, and Koasati. While part of the same large language family, the Muskogee tribes developed distinct cultures and languages.\n\nEuropean settlement\n\nThe Spanish were the first Europeans to reach Alabama during their exploration of North America in the 16th century. The expedition of Hernando de Soto passed through Mabila and other parts of the state in 1540. More than 160 years later, the French founded the region's first European settlement at Old Mobile in 1702. The city was moved to the current site of Mobile in 1711. This area was claimed by the French from 1702 to 1763 as part of La Louisiane.\n\nAfter the French lost to the British in the Seven Years' War, it became part of British West Florida from 1763 to 1783. After the United States victory in the American Revolutionary War, the territory was divided between the United States and Spain. The latter retained control of this western territory from 1783 until the surrender of the Spanish garrison at Mobile to U.S. forces on April 13, 1813.\n\nThomas Bassett, a loyalist to the British monarchy during the Revolutionary era, was one of the earliest white settlers in the state outside Mobile. He settled in the Tombigbee District during the early 1770s. The district's boundaries were roughly limited to the area within a few miles of the Tombigbee River and included portions of what is today southern Clarke County, northernmost Mobile County, and most of Washington County.\n\nWhat is now the counties of Baldwin and Mobile became part of Spanish West Florida in 1783, part of the independent Republic of West Florida in 1810, and was finally added to the Mississippi Territory in 1812. Most of what is now the northern two-thirds of Alabama was known as the Yazoo lands beginning during the British colonial period. It was claimed by the Province of Georgia from 1767 onwards. Following the Revolutionary War, it remained a part of Georgia, although heavily disputed.\n\nWith the exception of the area around Mobile and the Yazoo lands, what is now the lower one-third of Alabama was made part of the Mississippi Territory when it was organized in 1798. The Yazoo lands were added to the territory in 1804, following the Yazoo land scandal. Spain kept a claim on its former Spanish West Florida territory in what would become the coastal counties until the Adams\u2013On\u00eds Treaty officially ceded it to the United States in 1819.\n\nEarly 19th century\n\nBefore Mississippi's admission to statehood on December 10, 1817, the more sparsely settled eastern half of the territory was separated and named the Alabama Territory. The United States Congress created the Alabama Territory on March 3, 1817. St. Stephens, now abandoned, served as the territorial capital from 1817 to 1819.\n\nAlabama was admitted as the 22nd state on December 14, 1819,", "flag": 1, "segments": [[780, 786]], "strength": 5.5}
{"token_count": [2006], "text": "In Greek mythology, Achilles ( ) or Achilleus () was a hero of the Trojan War, the greatest of all the Greek warriors, and is the central character of Homer's Iliad. He was the son of the Nereid Thetis and Peleus, king of Phthia.\n\nAchilles' most notable feat during the Trojan War was the slaying of the Trojan prince Hector outside the gates of Troy. Although the death of Achilles is not presented in the Iliad, other sources concur that he was killed near the end of the Trojan War by Paris, who shot him with an arrow. Later legends (beginning with Statius' unfinished epic Achilleid, written in the 1st century AD) state that Achilles was invulnerable in all of his body except for one heel, because when his mother Thetis dipped him in the river Styx as an infant, she held him by one of his heels. Alluding to these legends, the term \"Achilles' heel\" has come to mean a point of weakness, especially in someone or something with an otherwise strong constitution. The Achilles tendon is also named after him due to these legends.\n\nEtymology \n\nLinear B tablets attest to the personal name Achilleus in the forms a-ki-re-u and a-ki-re-we, the latter being the dative of the former. The name grew more popular, even becoming common soon after the seventh century BC and was also turned into the female form \u1f08\u03c7\u03b9\u03bb\u03bb\u03b5\u03af\u03b1 (Achille\u00eda), attested in Attica in the fourth century BC (IG II\u00b2 1617) and, in the form Achillia, on a stele in Halicarnassus as the name of a female gladiator fighting an \"Amazon\".\n\nAchilles' name can be analyzed as a combination of  () \"distress, pain, sorrow, grief\" and  () \"people, soldiers, nation\", resulting in a proto-form *Akh\u00ed-l\u0101u\u032fos \"he who has the people distressed\" or \"he whose people have distress\". The grief or distress of the people is a theme raised numerous times in the Iliad (and frequently by Achilles himself). Achilles' role as the hero of grief or distress forms an ironic juxtaposition with the conventional view of him as the hero of   (\"glory\", usually in war). Furthermore, la\u00f3s has been construed by Gregory Nagy, following Leonard Palmer, to mean \"a corps of soldiers\", a muster. With this derivation, the name obtains a double meaning in the poem: when the hero is functioning rightly, his men bring distress to the enemy, but when wrongly, his men get the grief of war. The poem is in part about the misdirection of anger on the part of leadership.\n\nAnother etymology relates the name to a Proto-Indo-European compound *h\u2082e\u1e31-p\u1e53ds \"sharp foot\" which first gave an Illyrian *\u0101k\u0302pedi\u00f3s, evolving through time into *\u0101khpde\u00f3s and then *akhidde\u00fas. The shift from -dd- to -ll- is then ascribed to the passing of the name into Greek via a Pre-Greek source. The first root part *h\u2082e\u1e31- \"sharp, pointed\" also gave Greek \u1f00\u03ba\u03ae (ak\u1e17 \"point, silence, healing\"), \u1f00\u03ba\u03bc\u03ae (akm\u1e17 \"point, edge, zenith\") and \u1f40\u03be\u03cd\u03c2 (ox\u00fas \"sharp, pointed, keen, quick, clever\"), whereas \u1f04\u03c7\u03bf\u03c2 stems from the root *h\u2082eg\u02b0- \"to be upset, afraid\". The whole expression would be comparable to the Latin acupedius \"swift of foot\". Compare also the Latin word family of aci\u0113s \"sharp edge or point, battle line, battle, engagement\", acus \"needle, pin, bodkin\", and acu\u014d \"to make pointed, sharpen, whet; to exercise; to arouse\" (whence acute). Some topical epitheta of Achilles in the Iliad point to this \"swift-footedness\", namely \u03c0\u03bf\u03b4\u03ac\u03c1\u03ba\u03b7\u03c2 \u03b4\u1fd6\u03bf\u03c2 \u1f08\u03c7\u03b9\u03bb\u03bb\u03b5\u1f7a\u03c2 (pod\u00e1rk\u0113s d\u0129os Achille\u00fas \"swift-footed divine Achilles\") or, even more frequently, \u03c0\u03cc\u03b4\u03b1\u03c2 \u1f60\u03ba\u1f7a\u03c2 \u1f08\u03c7\u03b9\u03bb\u03bb\u03b5\u03cd\u03c2 (p\u00f3das \u014dk\u00fas Achille\u00fas \"quick-footed Achilles\").\n\nSome researchers deem the name a loan word, possibly from a Pre-Greek language. Achilles' descent from the Nereid Thetis and a similarity of his name with those of river deities such as Acheron and Achelous have led to speculations about his being an old water divinity (see below Worship). Robert S. P. Beekes has suggested a Pre-Greek origin of the name, based among other things on the coexistence of -\u03bb\u03bb- and -\u03bb- in epic language, which may account for a palatalized phoneme /ly/ in the original language.\n\nBirth and early years \n\nAchilles was the son of the Thetis, a nereid, and Peleus, the king of the Myrmidons. Zeus and Poseidon had been rivals for Thetis's hand in marriage until Prometheus, the fore-thinker, warned Zeus of a prophecy (originally uttered by Themis, goddess of divine law) that Thetis would bear a son greater than his father. For this reason, the two gods withdrew their pursuit, and had her wed Peleus.\n\nThere is a tale which offers an alternative version of these events: In the Argonautica (4.760) Zeus' sister and wife Hera alludes to Thetis' chaste resistance to the advances of Zeus, pointing out that Thetis was so loyal to Hera's marriage bond that she coolly rejected the father of gods. Thetis, although a daughter of the sea-god Nereus, was also brought up by Hera, further explaining her resistance to the advances of Zeus. Zeus was furious and decreed that she would never marry an immortal.\n\nAccording to the Achilleid, written by Statius in the 1st century AD, and to non-surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx; however, he was left vulnerable at the part of the body by which she held him: his left heel (see Achilles' heel, Achilles' tendon). It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire in order to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.\n\nNone of the sources before Statius make any reference to this general invulnerability. To the contrary, in the Iliad, Homer mentions Achilles being wounded: in Book 21 the Paeonian hero Asteropaeus, son of Pelagon, challenged Achilles by the river Scamander. He was ambidextrous, and cast a spear from each hand; one grazed Achilles' elbow, \"drawing a spurt of blood\".\n\nIn the few fragmentary poems of the Epic Cycle which describe the hero's death (i.e. the Cypria, the Little Iliad by Lesches of Pyrrha, the Aithiopis and Iliou persis by Arctinus of Miletus), there is no trace of any reference to his general invulnerability or his famous weakness at the heel. In the later vase paintings presenting the death of Achilles, the arrow (or in many cases, arrows) hit his torso.\n\nPeleus entrusted Achilles to Chiron the Centaur, who lived on Mount Pelion, to be re September 9 and 10 week fromared. Thetis foretold that her son's fate was either to gain glory and die young, or to live a long but uneventful life in obscurity. Achilles chose the former, and decided to take part in the Trojan War. According to Homer, Achilles grew up in Phthia with his companion Patroclus.\n\nAccording to Photius, the sixth book of the New History by Ptolemy Hephaestion reported that Thetis burned in a secret place the children she had by Peleus. When she had Achilles, Peleus noticed, tore him from the flames with only a burnt foot, and confided him to the centaur Chiron. Later Chiron exhumed the body of the Damysus, who was the fastest of all the giants, removed the ankle, and incorporated it into Achilles' burnt foot.\n\nOther names \nAmong the appellations under which Achilles is generally known are the following:\n Pyrisous, \"saved from the fire\", his first name, which seems to favour the tradition in which his mortal parts were burned by his mother Thetis\n Aeacides, from his grandfather Aeacus\n Aemonius, from Aemonia, a country which afterwards acquired the name of Thessaly\n Aspetos, \"", "flag": 1, "segments": [[1735, 1741]], "strength": 5.5}
{"token_count": [2006], "text": "Abraham Lincoln (; February 12, 1809 \u2013 April 15, 1865) was an American lawyer and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the nation through the American Civil War and succeeded in preserving the Union, abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.\n\nLincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his law practice but became vexed by the opening of additional lands to slavery as a result of the Kansas\u2013Nebraska Act. He reentered politics in 1854 they are employed (by businesses, becoming a leader in the new Republican Party, and he reached a national audience in the 1858 debates against Stephen Douglas. Lincoln ran for President in 1860, sweeping the North in victory. Pro-slavery elements in the South equated his success with the North's rejection of their right to practice slavery, and southern states began seceding from the Union. To secure its independence, the new Confederate States fired on Fort Sumter, a U.S. fort in the South, and Lincoln called up forces to suppress the rebellion and restore the Union.\n\nLincoln, a moderate Republican, had to navigate a contentious array of factions with friends and opponents from both the Democratic and Republican parties. His allies, the War Democrats and the Radical Republicans, demanded harsh treatment of the Southern Confederates. Anti-war Democrats (called \"Copperheads\") despised Lincoln, and irreconcilable pro-Confederate elements plotted his assassination. He managed the factions by exploiting their mutual enmity, carefully distributing political patronage, and by appealing to the American people. His Gettysburg Address appealed to nationalistic, republican, egalitarian, libertarian, and democratic sentiments. Lincoln scrutinized the strategy and tactics in the war effort, including the selection of generals and the naval blockade of the South's trade. He suspended habeas corpus in Maryland, and he averted British intervention by defusing the Trent Affair. He engineered the end to slavery with his Emancipation Proclamation, including his order that the Army and Navy liberate, protect, and recruit former slaves. He also encouraged border states to outlaw slavery, and promoted the Thirteenth Amendment to the United States Constitution, which outlawed slavery across the country.\n\nLincoln managed his own successful re-election campaign. He sought to heal the war-torn nation through reconciliation. On April 14, 1865, just days after the war's end at Appomattox, he was attending a play at Ford's Theatre in Washington, D.C., with his wife Mary when he was fatally shot by Confederate sympathizer John Wilkes Booth. Lincoln is remembered as a martyr and hero of the United States and is often ranked as the greatest president in American history.\n\nFamily and childhood\n\nEarly life\n\nAbraham Lincoln was born on February 12, 1809, the second child of Thomas Lincoln and Nancy Hanks Lincoln, in a log cabin on Sinking Spring Farm near Hodgenville, Kentucky. He was a descendant of Samuel Lincoln, an Englishman who migrated from Hingham, Norfolk, to its namesake, Hingham, Massachusetts, in 1638. The family then migrated west, passing through New Jersey, Pennsylvania, and Virginia. Lincoln's paternal grandparents, his namesake Captain Abraham Lincoln and wife Bathsheba (n\u00e9e Herring) moved the family from Virginia to Jefferson County, Kentucky. The captain was killed in an Indian raid in 1786. His children, including eight-year-old Thomas, Abraham's father, witnessed the attack. Thomas then worked at odd jobs in Kentucky and Tennessee before the family settled in Hardin County, Kentucky, in the early 1800s.\n\nThe heritage of Lincoln's mother Nancy remains unclear, but it is widely assumed that she was the daughter of Lucy Hanks. Thomas and Nancy married on June 12, 1806, in Washington County, and moved to Elizabethtown, Kentucky. They had three children: Sarah, Abraham, and Thomas, who died as infant.\n\nThomas Lincoln bought or leased farms in Kentucky before losing all but  of his land in court disputes over property titles. In 1816, the family moved to Indiana where the land surveys and titles were more reliable. Indiana was a \"free\" (non-slaveholding) territory, and they settled in an \"unbroken forest\" in Hurricane Township, Perry County, Indiana. In 1860, Lincoln noted that the family's move to Indiana was \"partly on account of slavery\", but mainly due to land title difficulties.\n\nIn Kentucky and Indiana, Thomas worked as a farmer, cabinetmaker, and carpenter. At various times, he owned farms, livestock, and town lots, paid taxes, sat on juries, appraised estates, and served on county patrols. Thomas and Nancy were members of a Separate Baptists church, which forbade alcohol, dancing, and slavery.\n\nOvercoming financial challenges, Thomas in 1827 obtained clear title to  in Indiana, an area which became the Little Pigeon Creek Community.\n\nMother's death\nOn October 5, 1818, Nancy Lincoln succumbed to milk sickness, leaving 11-year-old Sarah in charge of a household including her father, 9-year-old Abraham, and Nancy's 19-year-old orphan cousin, Dennis Hanks. Ten years later, on January 20, 1828, Sarah died while giving birth to a stillborn son, devastating Lincoln.\n\nOn December 2, 1819, Thomas married Sarah Bush Johnston, a widow from Elizabethtown, Kentucky, with three children of her own. Abraham became close to his stepmother and called her \"Mother\". Lincoln disliked the hard labor associated with farm life. His family even said he was lazy, for all his \"reading, scribbling, writing, ciphering, writing Poetry, etc.\". His stepmother acknowledged he did not enjoy \"physical labor\", but loved to read.\n\nEducation and move to Illinois\nLincoln was largely self-educated. His formal schooling was from itinerant teachers. It included two short stints in Kentucky, where he learned to read but probably not to write, at age seven, and in Indiana, where he went to school sporadically due to farm chores, for a total of less than 12 months in aggregate by the age of 15. He persisted as an avid reader and retained a lifelong interest in learning. Family, neighbors, and schoolmates recalled that his reading included the King James Bible, Aesop's Fables, John Bunyan's The Pilgrim's Progress, Daniel Defoe's Robinson Crusoe, and The Autobiography of Benjamin Franklin.\n\nAs a teen, Lincoln took responsibility for chores and customarily gave his father all earnings from work outside the home until he was 21. Lincoln was tall, strong, and athletic, and became adept at using an ax. He was an active wrestler during his youth and trained in the rough catch-as-catch-can style (also known as catch wrestling). He became county wrestling champion at the age of 21. He gained a reputation for strength and audacity after winning a wrestling match with the renowned leader of ruffians known as \"the Clary's Grove Boys\".\n\nIn March 1830, fearing another milk sickness outbreak, several members of the extended Lincoln family, including Abraham, moved west to Illinois, a free state, and settled in Macon County. Abraham then became increasingly distant from Thomas, in part due to his father's lack of education. In 1831, as Thomas and other family prepared to move to a new homestead in Coles County, Illinois, Abraham struck out on his own. He made his home in New Salem, Illinois, for six years. Lincoln and some friends took goods by flatboat to New Orleans, Louisiana, where he was first exposed to slavery.\n\nIn 1865, Lincoln was asked how he came to acquire his rhetorical skills. He answered that in the practice of law he frequently came across the word \"demonstrate\" but had insufficient understanding of the term. So, he left Springfield for his father's home to study until he \"could give any proposition in the six books of Euclid [here, referencing Euclid's Elements] at sight.\"\n\nMarriage and children\n\nLincoln's first romantic interest was Ann Rutledge, whom he met when he moved to New Salem. By 1835, they were in a relationship but not formally engaged. She died on August 25, 1835, most likely of typhoid fever. In the early 1830s, he met Mary Owens from Kentucky.\n\nLate in 1836, Lincoln agreed to a match with Owens if she returned to New Salem. Owens arrived that November and he courted her for a time; however, they both had second thoughts. On August 16, 1837, he wrote Owens a letter saying he would not blame her if she ended the relationship, and she never replied.\n\nIn 1839, Lincoln met Mary Todd in Springfield, Illinois, and the following year they became engaged. She was the daughter of Robert Smith Todd, a wealthy lawyer and businessman in Lexington, Kentucky. A wedding set for January 1, 1841, was canceled at Lincoln's request, but they reconciled and married on November 4, 1842, in the Springfield mansion of Mary's sister. While anxiously preparing for the nuptials, he was asked where he was going and replied, \"To hell, I suppose.\" In 1844, the couple bought a house in", "flag": 1, "segments": [[171, 177]], "strength": 5.5}
{"token_count": [2006], "text": "Aristotle (;  Aristot\u00e9l\u0113s, ; 384\u2013322\u00a0BC) was a Greek philosopher and polymath during the Classical period in Ancient Greece. Taught by Plato, he was the founder of the Lyceum, the Peripatetic school of philosophy, and the Aristotelian tradition. His writings cover many subjects including physics, biology, zoology, metaphysics, logic, ethics, aesthetics, poetry, theatre, music, rhetoric, psychology, linguistics, economics, politics, meteorology, geology and government. Aristotle provided a complex synthesis of the various philosophies existing prior to him. It was above all from his teachings that the West inherited its intellectual lexicon, as well as problems and methods of inquiry. As a result, his philosophy has exerted a unique influence on almost every form of knowledge in the West and it continues to be a subject of contemporary philosophical discussion.\n\nLittle is known about his life. Aristotle was born in the city of Stagira in Northern Greece. His father, Nicomachus, died when Aristotle was a child, and he was brought up by a guardian. At seventeen or eighteen years of age he joined Plato's Academy in Athens and remained there until the age of thirty-seven (c. 347 BC). Shortly after Plato died, Aristotle left Athens and, at the request of Philip II of Macedon, tutored Alexander the Great beginning in 343 BC. He established a library in the Lyceum which helped him to produce many of his hundreds of books on papyrus scrolls. Though Aristotle wrote many elegant treatises and dialogues for publication, only around a third of his original output has survived, none of it intended for publication.\n\nAristotle's views profoundly shaped medieval scholarship. The influence of physical science extended from Late Antiquity and the Early Middle Ages into the Renaissance, and were not replaced systematically until the Enlightenment and theories such as classical mechanics were developed. Some of Aristotle's zoological observations found in his biology, such as on the hectocotyl (reproductive) arm of the octopus, were disbelieved until the 19th century. He also influenced Judeo-Islamic philosophies (800\u20131400) during the Middle Ages, as well as Christian theology, especially the Neoplatonism of the Early Church and the scholastic tradition of the Catholic Church. Aristotle was revered among medieval Muslim scholars as \"The First Teacher\", and among medieval Christians like Thomas Aquinas as simply \"The Philosopher\", while the poet Dante called him \u201cthe master of those who know\". His works contain the earliest known formal study of logic, and were studied by medieval scholars such as Peter Abelard and John Buridan.\n\nAristotle's influence on logic continued well into the 19th century. In addition, his ethics, though always influential, gained renewed interest with the modern advent of virtue ethics.\n\nAristotle has been called \"the father of logic\", \"the father of biology\", \"the father of political science\", \"the father of zoology\", \"the father of embryology\", \"the father of natural law\", \"the father of scientific method\", \"the father of rhetoric\", \"the father of psychology\", \"the father of realism\", \"the father of criticism\", \"the father of individualism\", \"the father of teleology\", and \"the father of meteorology\".\n\nLife\n\nIn general, the details of Aristotle's life are not well-established. The biographies written in ancient times are often speculative and historians only agree on a few salient points.\n\nAristotle, whose name means \"the best purpose\" in Ancient Greek, was born in 384\u00a0BC in Stagira, Chalcidice, about 55\u00a0km (34 miles) east of modern-day Thessaloniki. His father, Nicomachus, was the personal physician to King Amyntas of Macedon. While he was young, Aristotle learned about biology and medical information, which was taught by his father. Both of Aristotle's parents died when he was about thirteen, and Proxenus of Atarneus became his guardian. Although little information about Aristotle's childhood has survived, he probably spent some time within the Macedonian palace, making his first connections with the Macedonian monarchy.\n\nAt the age of seventeen or eighteen, Aristotle moved to Athens to continue his education at Plato's Academy. He probably experienced the Eleusinian Mysteries as he wrote when describing the sights one return of \"Wings Over viewed at the Eleusinian Mysteries, \"to experience is to learn\" [\u03c0\u03b1\u03b8\u03b5\u03af\u03bd \u03bc\u03b1\u03b8\u03b5\u0129\u03bd]. Aristotle remained in Athens for nearly twenty years before leaving in 348/47\u00a0BC. The traditional story about his departure records that he was disappointed with the academy's direction after control passed to Plato's nephew Speusippus, although it is possible that he feared the anti-Macedonian sentiments in Athens at that time and left before Plato died. Aristotle then accompanied Xenocrates to the court of his friend Hermias of Atarneus in Asia Minor. After the death of Hermias, Aristotle travelled with his pupil Theophrastus to the island of Lesbos, where together they researched the botany and zoology of the island and its sheltered lagoon. While in Lesbos, Aristotle married Pythias, either Hermias's adoptive daughter or niece. She bore him a daughter, whom they also named Pythias. In 343 BC, Aristotle was invited by Philip II of Macedon to become the tutor to his son Alexander.\n\nAristotle was appointed as the head of the royal academy of Macedon. During Aristotle's time in the Macedonian court, he gave lessons not only to Alexander but also to two other future kings: Ptolemy and Cassander. Aristotle encouraged Alexander toward eastern conquest, and Aristotle's own attitude towards Persia was unabashedly ethnocentric. In one famous example, he counsels Alexander to be \"a leader to the Greeks and a despot to the barbarians, to look after the former as after friends and relatives, and to deal with the latter as with beasts or plants\". By 335\u00a0BC, Aristotle had returned to Athens, establishing his own school there known as the Lyceum. Aristotle conducted courses at the school for the next twelve years. While in Athens, his wife Pythias died and Aristotle became involved with Herpyllis of Stagira, who bore him a son whom he named after his father, Nicomachus. If the Suda  an uncritical compilation from the Middle Ages  is accurate, he may also have had an er\u00f4menos, Palaephatus of Abydus.\n\nThis period in Athens, between 335 and 323 BC, is when Aristotle is believed to have composed many of his works. He wrote many dialogues, of which only fragments have survived. Those works that have survived are in treatise form and were not, for the most part, intended for widespread publication; they are generally thought to be lecture aids for his students. His most important treatises include Physics, Metaphysics, Nicomachean Ethics, Politics, On the Soul and Poetics. Aristotle studied and made significant contributions to \"logic, metaphysics, mathematics, physics, biology, botany, ethics, politics, agriculture, medicine, dance, and theatre.\"\n\nNear the end of his life, Alexander and Aristotle became estranged over Alexander's relationship with Persia and Persians. A widespread tradition in antiquity suspected Aristotle of playing a role in Alexander's death, but the only evidence of this is an unlikely claim made some six years after the death. Following Alexander's death, anti-Macedonian sentiment in Athens was rekindled. In 322\u00a0BC, Demophilus and Eurymedon the Hierophant reportedly denounced Aristotle for impiety, prompting him to flee to his mother's family estate in Chalcis, on Euboea, at which occasion he was said to have stated: \"I will not allow the Athenians to sin twice against philosophy\" \u2013 a reference to Athens's trial and execution of Socrates. He died on Euboea of natural causes later that same year, having named his student Antipater as his chief executor and leaving a will in which he asked to be buried next to his wife.\n\nSpeculative philosophy\n\nLogic\n\nWith the Prior Analytics, Aristotle is credited with the earliest study of formal logic, and his conception of it was the dominant form of Western logic until 19th-century advances in mathematical logic. Kant stated in the Critique of Pure Reason that with Aristotle logic reached its completion.\n\nOrganon\n\nWhat is today called Aristotelian logic with its types of syllogism (methods of logical argument), Aristotle himself would have labelled \"analytics\". The term \"logic\" he reserved to mean dialectics. Most of Aristotle's work is probably not in its original form, because it was most likely edited by students and later lecturers. The logical works of Aristotle were compiled into a set of six books called the Organon around 40 BC by Andronicus of Rhodes or others among his followers. The books are:\n Categories\n On Interpretation\n Prior Analytics\n Posterior Analytics\n Topics\n On Sophistical Refutations\n\nThe order of the books (or the teachings from which they are composed) is not certain, but this list was derived from analysis of Aristotle's writings. It goes from the basics, the analysis of simple terms in the Categories, the analysis of propositions and their elementary relations in On Interpretation, to the study of more complex forms, namely, syllogisms (in the Analytics) and dialectics (in the Topics and Soph", "flag": 1, "segments": [[917, 923]], "strength": 5.5}
{"token_count": [2006], "text": "Algeria, officially the People's Democratic Republic of Algeria, is a country in the Maghreb region of North Africa. The country is the largest country by total area in Africa and in the Arab world, and is bordered to the northeast by Tunisia; to the east by Libya; to the southeast by Niger; to the southwest by Mali, Mauritania, and Western Sahara; to the west by Morocco; and to the north by the Mediterranean Sea. It has a semi-arid geography, with most of the population living in the fertile north and the Sahara dominating the geography of the south. Algeria covers an area of, making it the world's tenth largest nation by area, and the largest nation in Africa. With a population of 44 million, Algeria is the ninth-most populous country in Africa, and the 32nd-most populous country in the world. The capital and largest city is Algiers, located in the far north on the Mediterranean coast.\n\nPre-1962 Algeria has seen many empires and dynasties, including ancient Numidians, Phoenicians, Carthaginians, Romans, Vandals, Byzantines, Umayyads, Abbasids, Rustamids, Idrisids, Aghlabids, Fatimids, Zirids, Hammadids, Almoravids, Almohads, Zayyanids, Spaniards, Ottomans and finally, the French colonial empire. The vast majority of Algeria's population is Arab-Berber, practicing Islam, and using the official languages of Arabic and Berber. However, French serves as an administrative and educational language in some contexts. The main spoken language is Algerian Arabic.\n\nAlgeria is a semi-presidential republic, with local constituencies consisting of 58 provinces and 1,541 communes. Algeria is a regional power in North Africa, and a middle power in global affairs. It has the highest Human Development Index of all non-island African countries and one of the largest economies on the continent, based largely on energy exports. Algeria has the world's sixteenth-largest oil reserves and the ninth-largest reserves of natural gas. Sonat as much as twice as muchrach, the national oil company, is the largest company in Africa, supplying large amounts of natural gas to Europe. Algeria's military is one of the largest in Africa, and has the largest defence budget on the continent. It is a member of the African Union, the Arab League, the OIC, OPEC, the United Nations, and the Arab Maghreb Union, of which it is a founding member.\n\nName \nOther forms of the name are:, ; ; ; ;. It is officially the People's Democratic Republic of Algeria (;,, ;, abbreviated as RADP).\n\nEtymology\nThe country's name derives from the city of Algiers which in turn derives from the Arabic  (, \"The Islands\"), a truncated form of the older  (, \"Islands of the Mazghanna Tribe\"), employed by medieval geographers such as al-Idrisi.\n\nHistory\n\nPrehistory and ancient history\n\nAround ~1.8-million-year-old stone artifacts from Ain Hanech (Algeria) were considered to represent the oldest archaeological materials in North Africa. Stone artifacts and cut-marked bones that were excavated from two nearby deposits at Ain Boucherit are estimated to be ~1.9 million years old, and even older stone artifacts to be as old as ~2.4 million years. Hence, the Ain Boucherit evidence shows that ancestral hominins inhabited the Mediterranean fringe in northern Africa much earlier than previously thought. The evidence strongly argues for early dispersal of stone tool manufacture and use from East Africa or a possible multiple-origin scenario of stone technology in both East and North Africa.\n\nNeanderthal tool makers produced hand axes in the Levalloisian and Mousterian styles (43,000 BC) similar to those in the Levant. Algeria was the site of the highest state of development of Middle Paleolithic Flake tool techniques. Tools of this era, starting about 30,000 BC, are called Aterian (after the archaeological site of Bir el Ater, south of Tebessa).\n\nThe earliest blade industries in North Africa are called Iberomaurusian (located mainly in the Oran region). This industry appears to have spread throughout the coastal regions of the Maghreb between 15,000 and 10,000 BC. Neolithic civilization (animal domestication and agriculture) developed in the Saharan and Mediterranean Maghreb perhaps as early as 11,000 BC or as late as between 6000 and 2000 BC. This life, richly depicted in the Tassili n'Ajjer paintings, predominated in Algeria until the classical period. The mixture of peoples of North Africa coalesced eventually into a distinct native population that came to be called Berbers, who are the indigenous peoples of northern Africa.\n\nFrom their principal center of power at Carthage, the Carthaginians expanded and established small settlements along the North African coast; by 600 BC, a Phoenician presence existed at Tipasa, east of Cherchell, Hippo Regius (modern Annaba) and Rusicade (modern Skikda). These settlements served as market towns as well as anchorages.\n\nAs Carthaginian power grew, its impact on the indigenous population increased dramatically. Berber civilisation was already at a stage in which agriculture, manufacturing, trade, and political organisation supported several states. Trade links between Carthage and the Berbers in the interior grew, but territorial expansion also resulted in the enslavement or military recruitment of some Berbers and in the extraction of tribute from others.\n\nBy the early 4th century BC, Berbers formed the single largest element of the Carthaginian army. In the Revolt of the Mercenaries, Berber soldiers rebelled from 241 to 238 BC after being unpaid following the defeat of Carthage in the First Punic War. They succeeded in obtaining control of much of Carthage's North African territory, and they minted coins bearing the name Libyan, used in Greek to describe natives of North Africa. The Carthaginian state declined because of successive defeats by the Romans in the Punic Wars.\n\nIn 146 BC the city of Carthage was destroyed. As Carthaginian power waned, the influence of Berber leaders in the hinterland grew. By the 2nd century BC, several large but loosely administered Berber kingdoms had emerged. Two of them were established in Numidia, behind the coastal areas controlled by Carthage. West of Numidia lay Mauretania, which extended across the Moulouya River in modern-day Morocco to the Atlantic Ocean. The high point of Berber civilisation, unequalled until the coming of the Almohads and Almoravids more than a millennium later, was reached during the reign of Masinissa in the 2nd century BC.\n\nAfter Masinissa's death in 148 BC, the Berber kingdoms were divided and reunited several times. Masinissa's line survived until 24 AD, when the remaining Berber territory was annexed to the Roman Empire.\n\nFor several centuries Algeria was ruled by the Romans, who founded many colonies in the region. Like the rest of North Africa, Algeria was one of the breadbaskets of the empire, exporting cereals and other agricultural products. Saint Augustine was the bishop of Hippo Regius (modern-day Annaba, Algeria), located in the Roman province of Africa. The Germanic Vandals of Geiseric moved into North Africa in 429, and by 435 controlled coastal Numidia. They did not make any significant settlement on the land, as they were harassed by local tribes. In fact, by the time the Byzantines arrived Leptis Magna was abandoned and the Msellata region was occupied by the indigenous Laguatan who had been busy facilitating an Amazigh political, military and cultural revival. Furthermore, during the rule of the Romans, Byzantines, Vandals, Carthaginians, and Ottomans the Berber people were the only or one of the few in North Africa who remained independent. The Berber people were so resistant that even during the Muslim conquest of North Africa they still had control and possession over their mountains.\n\nThe collapse of the Western Roman Empire led to the establishment of a native Kingdom based in Altava (modern day Algeria) known as the Mauro-Roman Kingdom. It was succeeded by another Kingdom based in Altava, the Kingdom of Altava. During the reign of Kusaila its territory extended from the region of modern-day Fez in the west to the western Aur\u00e8s and later Kairaouan and the interior of Ifriqiya in the east.\n\nMiddle Ages\n\nAfter negligible resistance from the locals, Muslim Arabs of the Umayyad Caliphate conquered Algeria in the early 8th century.  Large numbers of the indigenous Berber people converted to Islam. Christians, Berber and Latin speakers remained in the great majority in Tunisia until the end of the 9th century and Muslims only became a vast majority some time in the 10th. After the fall of the Umayyad Caliphate, numerous local dynasties emerged, including the Rustamids, Aghlabids, Fatimids, Zirids, Hammadids, Almoravids, Almohads and the Abdalwadid. The Christians left in three waves: after the initial conquest, in the 10th century and the 11th. The last were evacuated to Sicily by the Normans and the few remaining died out in the 14th century.\n\n", "flag": 1, "segments": [[445, 451]], "strength": 5.5}
{"token_count": [2006], "text": "Anthropology is the scientific study of humanity, concerned with human behavior, human biology, cultures, societies, and linguistics, in both the present and past, including past human species. Social anthropology studies patterns of behaviour, while cultural anthropology studies cultural meaning, including norms and values. A portmanteau sociocultural anthropology is commonly used today. Linguistic anthropology studies how language influences social life. Biological or physical anthropology studies the biological development of humans.\n\nArchaeological anthropology, often termed as 'anthropology of the past', studies human activity through investigation of physical evidence. It is considered a branch of anthropology in North America and Asia, while in Europe archaeology is viewed as a discipline in its own right or grouped under other related disciplines, such as history.\n\nEtymology\nThe abstract noun anthropology is first attested in reference to history. Its present use first appeared in Renaissance Germany in the works of Magnus Hundt and Otto Casmann. Their New Latin  derived from the combining forms of the Greek words \u00e1nthr\u014dpos (, \"human\") and l\u00f3gos (, \"study\"). (Its adjectival form appeared in the works of Aristotle.) It began to be used in English, possibly via French, by the early 18th century.\n\nHistory\n\nThrough the 19th century\nIn 1647, the Bartholins, founders of the University of Copenhagen, defined  as follows:\n\nSporadic use of the term for some of the subject matter occurred subsequently, such as the use by \u00c9tienne Serres in 1839 to describe the natural history, or paleontology, of man, based on comparative anatomy, and the creation of a chair in anthropology and ethnography in 1850 at the French National Museum of Natural History by Jean Louis Armand de Quatrefages de Br\u00e9au. Various short-lived organizations of anthropologists had already been formed. The Soci\u00e9t\u00e9 Ethnologique de Paris, the first to use the term ethnology, was formed in 1839. Its members were primarily anti-slavery activists. When slavery was abolished in France in 1848, the Soci\u00e9t\u00e9 was abandoned.\n\nMeanwhile, the Ethnological Society of New York, currently the American Ethnological Society, was founded on its model in 1842, as well as the Ethnological Society of London in 1843, a break-away group of the Aborigines' Protection Society. These anthropologists of the times were liberal, anti-slavery, and pro-human-rights activists. They maintained international connections.\n\nAnthropology and many other current fields are the intellectual results of the comparative methods developed in the earlier 19th century. Theorists in such diverse fields as anatomy, linguistics, and ethnology, making feature-by-feature comparisons of their subject matters, were beginning to suspect that similarities between animals, languages, and folkways were the result of processes or laws unknown to them then. For them, the publication of Charles Darwin's On the Origin of Species was the epiphany of everything they had begun to suspect. Darwin himself arrived at his conclusions through comparison of species he had seen in agronomy and in the wild.\n\nDarwin and Wallace unveiled evolution in the late 1850s. There was an immediate rush to bring it into the social sciences. Paul Broca in Paris was in the process of breaking away from the Soci\u00e9t\u00e9 de biologie to form the first of the explicitly anthropological societies, the Soci\u00e9t\u00e9 d'Anthropologie de Paris, meeting for the first time in Paris in 1859. When he read Darwin, he became an immediate convert to Transformisme, as the French called evolutionism. His definition now became \"the study of the human group, considered as a whole, in its details, and in relation to the rest of nature\".\n\nBroca, being what today would be called a neurosurgeon, had taken an interest in the pathology of speech. He wanted to localize the difference between man and the other animals, which appeared to reside in speech. He discovered the speech center of the human brain, today called Broca's area after him. His interest was mainly in Biological anthropology, but a German philosopher specializing in psychology, Theodor Waitz, took up the theme of general and social anthropology in his six-volume work, entitled Die Anthropologie der Naturv\u00f6lker, 1859\u20131864. The title was soon translated as \"The Anthropology of Primitive Peoples\". The last two volumes were published posthumously.\n\nWaitz defined anthropology as \"the science of the nature of man\". Following Broca's lead, Waitz points out that anthropology is a new field, which would gather material from other fields, but would differ from them in the use of comparative anatomy, physiology, and psychology to differentiate man from \"the animals nearest to him\". He stresses that the data of comparison must be empirical, gathered by experimentation. The history of civilization, as well as ethnology, are to be brought into the comparison. It is to be presumed fundamentally that the species, man, is a unity, and that \"the same laws of thought are applicable to all men\".\n\nWaitz was influential among British ethnologists. In 1863, the explorer Richard Francis Burton and the speech therapist James Hunt broke away from the Ethnological Society of London to form the Anthropological Society of London, which henceforward would follow the path of the new anthropology rather than just ethnology. It was the 2nd society dedicated to general anthropology in existence. Representatives from the French Soci\u00e9t\u00e9 were present, though not Broca. In his keynote address, printed in the first volume of its new publication, The Anthropological Review, Hunt stressed the work of Waitz, adopting his definitions as a standard. Among the first associates were the young Edward Burnett Tylor, inventor of cultural anthropology, and his brother Alfred Tylor, a geologist. Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.\n\nSimilar organizations in other countries followed: The Anthropological Society of Madrid (1865), the American Anthropological Association in 1902, the Anthropological Society of Vienna (1870), the Italian Society of Anthropology and Ethnology (1871), and many others subsequently. The majority of these were evolutionists. One notable exception was the Berlin Society for Anthropology, Ethnology, and Prehistory (1869) founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists. Not religious himself, he insisted that Darwin's conclusions member of a prominent school board lacked empirical foundation.\n\nDuring the last three decades of the 19th century, a proliferation of anthropological societies and associations occurred, most independent, most publishing their own journals, and all international in membership and association. The major theorists belonged to these organizations. They supported the gradual osmosis of anthropology curricula into the major institutions of higher learning. By 1898, 48 educational institutions in 13 countries had some curriculum in anthropology. None of the 75 faculty members were under a department named anthropology.\n\n20th and 21st centuries\nThis meager statistic expanded in the 20th century to comprise anthropology departments in the majority of the world's higher educational institutions, many thousands in number. Anthropology has diversified from a few major subdivisions to dozens more. Practical anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene. The organization has reached a global level. For example, the World Council of Anthropological Associations (WCAA), \"a network of national, regional and international associations that aims to promote worldwide communication and cooperation in anthropology\", currently contains members from about three dozen nations.\n\nSince the work of Franz Boas and Bronis\u0142aw Malinowski in the late 19th and early 20th centuries, social anthropology in Great Britain and cultural anthropology in the US have been distinguished from other social sciences by their emphasis on cross-cultural comparisons, long-term in-depth examination of context, and the importance they place on participant-observation or experiential immersion in the area of research. Cultural anthropology, in particular, has emphasized cultural relativism, holism, and the use of findings to frame cultural critiques. This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism. Ethnography is one of its primary research designs as well as the text that is generated from anthropological fieldwork.\n\nIn Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate. In the United States, anthropology has traditionally been divided into the four field approach developed by Franz Boas in the early 20th century: biological or physical anthropology; social, cultural, or sociocultural anthropology; and archaeological anthropology; plus linguistic anthropology. These fields frequently overlap but tend to use different methodologies and techniques.\n\nEuropean countries with overseas colonies tended to practice more ethnology (a term coined and defined by Adam F. Koll\u00e1r in 1783). It is sometimes referred to as sociocultural anthropology in the parts of the world that were influenced by the European tradition.\n\nFields\n\nAnthropology is a global discipline involving humanities, social sciences and natural sciences. Anthropology builds upon knowledge from natural sciences, including the discoveries about the origin and evolution of Homo sapiens, human physical traits, human behavior, the variations among different groups of humans, how the evolutionary past of Homo sapiens has", "flag": 1, "segments": [[1360, 1366]], "strength": 5.5}
{"token_count": [2006], "text": "Alchemy (from Arabic: al-k\u012bmiy\u0101; from Ancient Greek: khume\u00eda) is an ancient branch of natural philosophy, a philosophical and protoscientific tradition that was historically practiced in China, India, the Muslim world, and Europe. In its Western form, alchemy is first attested in a number of pseudepigraphical texts written in Greco-Roman Egypt during the first few centuries CE.\n\nAlchemists attempted to purify, mature, and perfect certain materials. Common aims were chrysopoeia, the transmutation of \"base metals\" (e.g., lead) into \"noble metals\" (particularly gold); the creation of an elixir of immortality; and the creation of panaceas able to cure any disease. The perfection of the human body and soul was thought to result from the alchemical magnum opus (\"Great Work\"). The concept of creating the philosophers' stone was variously connected with all of these projects.\n\nIslamic and European alchemists developed a basic set of laboratory techniques, theories, and terms, some of which are still in use today. They did not abandon the Ancient Greek philosophical idea that everything is composed of four elements, and they tended to guard their work in secrecy, often making use of cyphers and cryptic symbolism. In Europe, the 12th-century translations of medieval Islamic works on science and the rediscovery of Aristotelian philosophy gave birth to a flourishing tradition of Latin alchemy. This late medieval tradition of alchemy would go on to play a significant role in the development of early modern science (particularly chemistry and medicine).\n\nModern discussions of alchemy are generally split into an examination of its exoteric practical applications and its esoteric spiritual aspects, despite criticisms by scholars such as Eric J. Holmyard and Marie-Louise von Franz that they should be understood as complementary. The former is pursued by historians of the physical sciences, who examine the subject in terms of early chemistry, medicine, and charlatanism, and the philosophical and religious contexts in which these events occurred. The latter interests historians of esotericism, psychologists, and some philosophers and spiritualists. The subject has also made an ongoing impact on literature and the arts.\n\nEtymology \n\nThe word alchemy comes from Old French alquemie, alkimie, used in Medieval Latin as. This name was itself brought from the Arabic word al-k\u012bmiy\u0101 ( or ) composed of two parts: the Late Greek term kh\u0113me\u00eda (\u03c7\u03b7\u03bc\u03b5\u03af\u03b1), also spelled khumeia (\u03c7\u03c5\u03bc\u03b5\u03af\u03b1) and kh\u0113m\u00eda (\u03c7\u03b7\u03bc\u03af\u03b1) - see below, and the Arabic definite article al-  (), meaning 'The'. Together this association can be interpreted as 'the process of transmutation by which to fuse or reunite with the divine or original form'. Several etymologies have been proposed for the Greek term. The first was proposed by Zosimos of Panopolis (3rd\u20134th centuries), who derived it from the name of a book, the Khemeu. Hermanm Diels argued in 1914 that it rather derived from \u03c7\u03cd\u03bc\u03b1, used to describe metallic objects formed by casting.\n\nOthers trace its roots to the Egyptian name k\u0113me (hieroglyphic \ud80c\udd8e\ud80c\udd53\ud80c\udfcf\ud80c\ude96 khmi ), meaning 'black earth', which refers to the fertile and auriferous soil of the Nile valley, as opposed to red desert sand. According to the Egyptologist Wallis Budge, the Arabic word al-k\u012bmiya\u02be actually means \"the Egyptian [science]\", borrowing from the Coptic word for \"Egypt\", k\u0113me (or its equivalent in the Mediaeval Bohairic dialect of Coptic, kh\u0113me). This Coptic word derives from Demotic km\u1ec9, itself from ancient Egyptian kmt. The ancient Egyptian word referred to both the country and the colour \"black\" (Egypt was the \"Black Land\", by contrast with the \"Red Land\", the surrounding desert); so this etymology could also explain the nickname \"Egyptian black arts\".\n\nHistory \nAlchemy encompasses several philosophical traditions spanning some four millennia and three continents. These traditions' general penchant for cryptic and symbolic language makes it hard to trace their mutual influences and \"genetic\" relationships. One can distinguish at least three major strands, which appear to be mostly independent, at least in their earlier stages: Chinese alchemy, centered in China and Indian alchemy, centered on the Indian subcontinent; and Western alchemy, which occurred around the Mediterranean and whose center has shifted over the millennia from Greco-Roman Egypt to the Islamic world, and finally medieval Europe. Chinese alchemy was closely connected to Taoism and Indian alchemy with the Dharmic faiths. In contrast, Western alchemy developed its philosophical system mostly independent of but influenced by various Western religions. It is still an open question whether these three strands share a common origin, or to what extent they influenced each other.\n\nHellenistic Egypt \n\nThe start of Western alchemy may generally be traced to ancient and Hellenistic Egypt, where the city of Alexandria  was a center of alchemical knowledge, and retained its pre-eminence through most of the Greek and Roman periods. Following the work of Andr\u00e9-Jean Festugi\u00e8re, modern scholars see alchemical practice in the Roman Empire as originating from the Egyptian goldsmith's art, Greek philosophy and different religious traditions. Tracing the origins of the alchemical art in Egypt is complicated by the pseudepigraphic nature of texts from the Greek alchemical corpus. The treatises of Zosimos of Panopolis, the earliest historically attested author (fl. c. 300 CE), can help in situating the other authors. Zosimus based his work on that of older alchemical authors, such as Mary the Jewess, Pseudo-Democritus, and Agathodaimon, but very little is known about any of these authors. The most complete of their works, The Four Books of Pseudo-Democritus, were probably written in the first century AD.\n\nRecent scholarship tends to emphasize the testimony of Zosimus, who traced the alchemical arts back to Egyptian metallurgical and ceremonial practices. It has also been argued that early alchemical writers borrowed the vocabulary of Greek philosophical schools but did not implement any of its doctrines in a systematic way. Zosimos of Panopolis wrote in the Final Abstinence (also known as the \"Final Count\"). Zosimos explains that the ancient practice of \"tinctures\" (the technical Greek name for the alchemical arts) had been taken over by certain \"demons\" who taught the art only to those who offered them sacrifices. Since Zosimos also called the demons \"guardians of places\" (\u03bf\u1f31 \u03ba\u03b1\u03c4\u1f70 \u03c4\u03cc\u03c0\u03bf\u03bd \u1f14\u03c6\u03bf\u03c1\u03bf\u03b9) and those who offered them sacrifices \"priests\" (\u1f31\u03b5\u03c1\u03ad\u03b1), it is fairly clear that he was referring to the gods of Egypt and their priests. While critical of the kind of alchemy he associated with the Egyptian priests and their followers, Zosimos nonetheless saw the tradition's recent past as rooted in the rites of the Egyptian temples.\n\nMythology \u2013 Zosimos of Panopolis asserted that alchemy dated back to Pharaonic Egypt where it was the domain of the priestly class, though there is little to no a day before a major bipartisan evidence for his assertion. Alchemical writers used Classical figures from Greek, Roman, and Egyptian mythology to illuminate their works and allegorize alchemical transmutation. These included the pantheon of gods related to the Classical planets, Isis, Osiris, Jason, and many others.\n\nThe central figure in the mythology of alchemy is Hermes Trismegistus (or Thrice-Great Hermes). His name is derived from the god Thoth and his Greek counterpart Hermes. Hermes and his caduceus or serpent-staff, were among alchemy's principal symbols. According to Clement of Alexandria, he wrote what were called the \"forty-two books of Hermes\", covering all fields of knowledge. The Hermetica of Thrice-Great Hermes is generally understood to form the basis for Western alchemical philosophy and practice, called the hermetic philosophy by its early practitioners. These writings were collected in the first centuries of the common era.\n\nTechnology \u2013 The dawn of Western alchemy is sometimes associated with that of metallurgy, extending back to 3500\u00a0BC. Many writings were lost when the Roman emperor Diocletian ordered the burning of alchemical books after suppressing a revolt in Alexandria (AD\u00a0292). Few original Egyptian documents on alchemy have survived, most notable among them the Stockholm papyrus and the Leyden papyrus X. Dating from AD\u00a0250\u2013300, they contained recipes for dyeing and making artificial gemstones, cleaning and fabricating pearls, and manufacturing of imitation gold and silver. These writings lack the mystical, philosophical elements of alchemy, but do contain the works of Bolus of Mendes (or Pseudo-Democritus), which aligned these recipes with theoretical knowledge of astrology and the classical elements. Between the time of Bolus and Zosimos, the change took place that transformed this metallurgy into a Hermetic art.\n\nPhilosophy \u2013 Alexandria acted as a melting pot for philosophies of Pythagoreanism, Platonism, Sto", "flag": 1, "segments": [[1590, 1596]], "strength": 5.5}
{"token_count": [2006], "text": "Apollo is one of the  Olympian deities in classical Greek and Roman religion and Greek and Roman mythology. The national divinity of the Greeks, Apollo has been recognized as a god of archery, music and dance, truth and prophecy, healing and diseases, the Sun and light, poetry, and more. One of the most important and complex of the Greek gods, he is the son of Zeus and Leto, and the twin brother of Artemis, goddess of the hunt. Seen as the most beautiful god and the ideal of the kouros (ephebe, or a beardless, athletic youth), Apollo is considered to be the most Greek of all the gods. Apollo is known in Greek-influenced Etruscan mythology as Apulu.\n\nAs the patron deity of Delphi (Apollo Pythios), Apollo is an oracular god\u2014the prophetic deity of the Delphic Oracle. Apollo is the god who affords help and wards off evil; various epithets call him the \"averter of evil\". Delphic Apollo is the patron of seafarers, foreigners and the protector of fugitives and refugees.\n\nMedicine and healing are associated with Apollo, whether through the god himself or mediated through his son Asclepius. Apollo delivered people from epidemics, yet he is also a god who could bring ill-health and deadly plague with his arrows. The invention of archery itself is credited to Apollo and his sister Artemis. Apollo is usually described as carrying a golden bow and a quiver of silver arrows. Apollo's capacity to make youths grow is one of the best attested facets of his panhellenic cult persona. As the protector of young (kourotrophos), Apollo is concerned with the health and education of children. He presided over their passage into adulthood. Long hair, which was the prerogative of boys, was cut at the coming of age (ephebeia) and dedicated to Apollo.\n\nApollo is an important pastoral deity, and was the patron of herdsmen and shepherds. Protection of herds, flocks and crops from diseases, pests and predators were his primary duties. On the other hand, Apollo also encouraged founding new towns and establishment of civil constitution. He is associated with dominion over colonists. He was the giver of laws, and his oracles were consulted before setting laws in a city.\n\nAs the god of mousike, Apollo presides over all music, songs, dance and poetry. He is the inventor of string-music, and the frequent companion of the Muses, functioning as their chorus leader in celebrations. The lyre is a common attribute of Apollo. In Hellenistic times, especially during the 5th century BCE, as Apollo Helios he became identified among Greeks with Helios, the personification of the sun. In Latin texts, however, there was no conflation of Apollo with Sol among the classical Latin poets until 1st century CE. Apollo and Helios/Sol remained separate beings in literary and mythological texts until the 5th century CE.\n\nEtymology\n\nApollo (Attic, Ionic, and Homeric Greek:, Apoll\u014dn ( ); Doric:, Apell\u014dn; Arcadocypriot:, Apeil\u014dn; Aeolic:, Aploun; )\n\nThe name Apollo\u2014unlike the related older name Paean\u2014is generally not found in the Linear B (Mycenean Greek) texts, although there is a possible attestation in the lacunose form ]pe-rjo-[ (Linear B: ]-[) on the KN E 842 tablet, though it has also been suggested that the name might actually read \"Hyperion\" ([u]-pe-rjo-[ne]).\n\nThe etymology of the name is uncertain. The spelling  ( in Classical Attic) had almost superseded all other forms by the beginning of the common era, but the Doric form, Apellon (), is more archaic, as it is derived from an earlier. It probably is a cognate to the Doric month Apellaios (), and the offerings apellaia () at the initiation of the young men during the family-festival apellai (). According to some scholars, the words are derived from the Doric word apella (), which originally meant \"wall,\" \"fence for animals\" and later \"assembly within the limits of the square.\" Apella () is the name of the popular assembly in Sparta, corresponding to the ecclesia (). R. S. P. Beekes rejected the connection of the theonym with the noun apellai and suggested a Pre-Greek proto-form *Apalyun.\n\nSeveral instances of popular etymology are attested from ancient authors. Thus, the Greeks most often associated Apollo's name with the Greek verb  (apollymi), \"to destroy\". Plato in Cratylus connects the name with  (apolysis), \"redemption\", with  (apolousis), \"purification\", and with  ([h]aploun), \"simple\", in particular in reference to the Thessalian form of the name,, and finally with  (aeiballon), \"ever-shooting\". Hesychius connects the name Apollo with the Doric  (apella), which means \"assembly\", so that Apollo would be the god of political life, and he also gives the explanation  (sekos), \"fold\", in which case Apollo would be the god of flocks and herds. In the ancient Macedonian language  (pella) means \"stone,\" and some toponyms may be derived from this word:  (Pella, the capital of ancient Macedonia) and  (Pell\u0113n\u0113/Pellene).\n\nA number of non-Greek etymologies have been suggested for the name, The Hittite form Apaliunas (d) is attested in the Manapa-Tarhunta letter. The Hittite testimony reflects an early form, which may also be surmised from comparison of Cypriot  with Doric. The name of the Lydian god Q\u03bbd\u00e3ns /k\u02b7\u028e\u00f0\u00e3ns/ may reflect an earlier /k\u02b7aly\u00e1n-/ before palatalization, syncope, and the pre-Lydian sound change *y > d. Note the labiovelar in place of the labial /p/ found in pre-Doric \u1f08\u03c0\u03ad\u03bbj\u03c9\u03bd and Hittite Apaliunas.\n\nA Luwian etymology suggested for Apaliunas makes Apollo \"The One of Entrapment\", perhaps in the sense of \"Hunter\".\n\nGreco-Roman epithets\nApollo's chief epithet was Phoebus ( ;, Phoibos ), literally \"bright\". It was very commonly used by both the Greeks and Romans for Apollo's role as to be in the same universe the god of light. Like other Greek deities, he had a number of others applied to him, reflecting the variety of roles, duties, and aspects ascribed to the god. However, while Apollo has a great number of appellations in Greek myth, only a few occur in Latin literature.\n\nSun\nAegletes ( ; \u0391\u1f30\u03b3\u03bb\u03ae\u03c4\u03b7\u03c2, Aigl\u0113t\u0113s), from, \"light of the sun\" \nHelius ( ;, Helios), literally \"sun\" \nLyceus ( ;, Lykeios, from Proto-Greek *), \"light\". The meaning of the epithet \"Lyceus\" later became associated with Apollo's mother Leto, who was the patron goddess of Lycia () and who was identified with the wolf ().\nPhanaeus ( ;, Phanaios), literally \"giving or bringing light\"\nPhoebus ( ;, Phoibos), literally \"bright\", his most commonly used epithet by both the Greeks and Romans\nSol (Roman) (), \"sun\" in Latin\n\nWolf\nLycegenes ( ;, Luk\u0113gen\u0113s), literally \"born of a wolf\" or \"born of Lycia\"\nLycoctonus ( ;, Lykoktonos), from, \"wolf\", and, \"to kill\"\n\nOrigin and birth\nApollo's birthplace was Mount Cynthus on the island of Delos.\n\nCynthius ( ;, Kunthios), literally \"Cynthian\"\nCynthogenes ( ;, Kynthogen\u0113s), literally \"born of Cynthus\"\nDelius ( ; \u0394\u03ae\u03bb\u03b9\u03bf\u03c2, Delios), literally \"Delian\"\nDidymaeus ( ;, Didymaios) from \u03b4\u03af\u03b4\u03c5\u03bc\u03bf\u03c2, \"twin\", as the twin of Artemis\n\nPlace of worship\nDelphi and Actium were his primary places of worship.\n\nAcraephius ( ;, Akraiphios, literally \"Acraephian\") or Acraephiaeus ( ;, Akraiphiaios), \"Acraephian\", from the Boeotian town of Acraephia (), reputedly founded by his son Acraepheus.\nActiacus ( ;, Aktiakos), literally \"Actian\", after Actium ()\nDelphinius ( ;, Delphinios), literally \"Delphic\", after Delphi (\u0394\u03b5\u03bb\u03c6\u03bf\u03af). An etiology in the Homeric Hym", "flag": 1, "segments": [[1448, 1454]], "strength": 5.5}
{"token_count": [2006], "text": "Andre Kirk Agassi ( ; born April 29, 1970) is an American former world No. 1 tennis player. He is already seen this video, the an eight-time major champion and a 1996 Olympic gold medalist, as well as a runner-up in seven other Grand Slam tournaments.\n\nAgassi was the first man to win four Australian Open singles titles in the Open Era (though later surpassed by Novak Djokovic, who won his fifth title in 2015 and has since won the tournament nine times). Agassi is the second of five men to achieve the career Grand Slam in the Open Era and the fifth of eight overall to make the achievement. He is also the first of two men to achieve the career Golden Slam (career Grand Slam and Olympic gold medal), and the only man to win a career Super Slam (career Grand Slam, plus the Olympic gold medal and the year-end championships).\n\nAgassi was the first man to win all four singles majors on three different surfaces (hard, clay and grass), and remains the most recent American man to win the French Open (in 1999) and the Australian Open (in 2003). He also won 17 ATP Masters Series titles and was part of the winning Davis Cup teams in 1990, 1992 and 1995. Agassi reached the world No. 1 ranking for the first time in 1995 but was troubled by personal issues during the mid-to-late 1990s and sank to No. 141 in 1997, prompting many to believe that his career was over. Agassi returned to No. 1 in 1999 and enjoyed the most successful run of his career over the next four years. During his 20-plus year tour career, Agassi was known by the nickname \"The Punisher\".\n\nAfter suffering from sciatica caused by two bulging discs in his back, a spondylolisthesis (vertebral displacement) and a bone spur that interfered with the nerve, Agassi retired from professional tennis on September 3, 2006, after losing in the third round of the US Open. He is the founder of the Andre Agassi Charitable Foundation, which has raised over $60\u00a0million for at-risk children in Southern Nevada. In 2001, the Foundation opened the Andre Agassi College Preparatory Academy in Las Vegas, a K\u201312 public charter school for at-risk children. He has been married to fellow tennis player Steffi Graf since 2001.\n\n1970\u20131985: Early life\nAndre Agassi was born in Las Vegas, Nevada, to Emmanuel \"Mike\" Agassi, a former Olympic boxer from Iran and American Elizabeth \"Betty\" Agassi (n\u00e9e Dudley). His father is of Armenian and Assyrian heritage. Andre Agassi's mother, Betty, is a breast cancer survivor. He has three older siblings \u2013 Rita (last wife of former number one Pancho Gonzales), Philip and Tami. Andre was given the middle name Kirk after Kirk Kerkorian, an Armenian American billionaire. Emmanuel Agassi, then a waiter at Tropicana Las Vegas, had met Kerkorian in 1963.\n\nAt the age of 12, Agassi and his good friend and doubles partner, Roddy Parks, won the 1982 National Indoor Boys 14s Doubles Championship in Chicago. Agassi describes memorable experiences and juvenile pranks with Roddy in his book Open.\n\nWhen he was 13, Agassi was sent to Nick Bollettieri's Tennis Academy in Florida. He was meant to stay for only three months, because that was all his father could afford. After thirty minutes of watching Agassi play, Bollettieri, deeply impressed by his talent, called Mike and said: \"Take your check back. He's here for free.\" Agassi then dropped out of school in the ninth grade to pursue a full-time tennis career.\n\n1986\u20132006: Professional career\n\n1986\u20131993: Breakthrough and the first major title\n\nAgassi turned professional at the age of 16 and competed in his first tournament at La Quinta, California. He won his first match against John Austin, but then lost his second match to Mats Wilander. By the end of 1986, Agassi was ranked No. 91. He won his first top-level singles title in 1987 at the Sul American Open in Itaparica and ended the year ranked No. 25. He won six additional tournaments in 1988 (Memphis, U.S. Men's Clay Court Championships, Forest Hills WCT, Stuttgart Outdoor, Volvo International and Livingston Open), and, by December of that year, he had surpassed US$1\u00a0million in career prize money after playing in just 43 tournaments\u2014the fastest anyone in history had reached that level. During 1988, he also set the open-era record for most consecutive victories by a male teenager (a record that stood for 17 years until Rafael Nadal broke it in 2005). His year-end ranking was No. 3, behind second-ranked Ivan Lendl and top-ranked Mats Wilander. Both the Association of Tennis Professionals and Tennis magazine named Agassi the Most Improved Player of the Year for 1988.\n\nIn addition to not playing the Australian Open (which later became his best Grand Slam event) for the first eight years of his career, Agassi chose not to play at Wimbledon from 1988 through 1990 and publicly stated that he did not wish to play there because of the event's traditionalism, particularly its \"predominantly white\" dress code to which players at the event are required to conform.\n\nStrong performances on the tour meant that Agassi was quickly tipped as a future Grand Slam champion. While still a teenager, he reached the semi-finals of both the French Open and the US Open in 1988 and made the US Open semi-finals in 1989. He began the 1990s with a series of near-misses. He reached his first Grand Slam final in 1990 at the French Open, where he was favored before losing in four sets to Andr\u00e9s G\u00f3mez, which he later attributed in his book to worrying about his wig falling off during the match. He reached his second Grand Slam final of the year at the US Open, defeating defending champion Boris Becker in the semi-finals. His opponent in the final was Pete Sampras; a year earlier, Agassi had crushed Sampras, after which time he told his coach that he felt bad for Sampras because he was never going to make it as a pro. Agassi lost the US Open final to Sampras in three sets. The rivalry between these two American players became the biggest one in tennis over the rest of the decade. Agassi ended 1990 on a high note as he helped the United States win its first Davis Cup in 8 years and won his only Tennis Masters Cup, beating reigning Wimbledon champion Stefan Edberg in the final.\n\nIn 1991, Agassi reached his second consecutive French Open final, where he faced fellow Bollettieri Academy alumnus Jim Courier. Courier emerged the victor in a five-set final. Agassi decided to play at Wimbledon in 1991, leading to weeks of speculation in the media about the clothes he would wear. He eventually emerged for the first round in a completely white outfit. He reached the quarterfinals on that occasion, losing in five sets to David Wheaton.\n\nAgassi's Grand Slam tournament breakthrough came at Wimbledon, not at the French Open or the US Open, where he had previously enjoyed success. In 1992, he defeated Goran Ivani\u0161evi\u0107 in a five-set final. Along the way, Agassi overcame two former Wimbledon champions: Boris Becker and John McEnroe. No other baseliner would triumph at Wimbledon until Lleyton Hewitt ten years later. Agassi was named the BBC Overseas Sports Personality of the Year in 1992. Agassi once again played on the United States' Davis Cup winning team in 1992. It was their second Davis cup title in three years. Agassi famously played the game wearing Oakley brand sunglasses, and a photo of him from the day appeared on the cover of Tennis magazine. In his memoir, he wrote that he was covering up bloodshot eyes from a hangover and claimed that the founder of Oakley, Jim Jannard, had sent him a Dodge Viper to thank him for the inadvertent publicity.\n\nIn 1993, Agassi won the only doubles title of his career, at the Cincinnati Masters, partnered with Petr Korda. He missed much of the early part of that year due to injuries. Although he made the quarterfinals in his Wimbledon title defense, he lost to eventual champion and No. 1 Pete Sampras in five sets. Agassi lost in the first round at the US Open to Thomas Enqvist and required wrist surgery late in the year.\n\n1994\u20131997: Rise to the top, Olympic Gold and the fall\nWith new coach Brad Gilbert on board, Agassi began to employ more of a tactical, consistent approach, which fueled his resurgence. He started slowly in 1994, losing in the first week at the French Open and Wimbledon. Nevertheless, he emerged during the hard-court season, winning the Canadian Open. His comeback culminated at the 1994 US Open with a five-set fourth-round victory against Michael Chang. He then became the first man to capture the US Open as an unseeded player, beating Michael Stich in the final. Along the way, he beat 5 seeded players.\n\nIn 1995, Agassi shaved his balding head, breaking with his old \"image is everything\" style. He competed in the 1995 Australian Open (his first appearance at the event) and won, beating Sampras in a four-set final. Agassi and Sampras met in five tournament finals in 1995, all on hard", "flag": 1, "segments": [[25, 31]], "strength": 5.5}
{"token_count": [2006], "text": "Andorra, officially the Principality of Andorra, is a sovereign landlocked microstate on the Iberian Peninsula, in the eastern Pyrenees, bordered by France to the north and Spain to the south. Believed to have been created by Charlemagne, Andorra was ruled by the count of Urgell until 988, when it was transferred to the Roman Catholic Diocese of Urgell. The present principality was formed by a charter in 1278. It is headed by two co-princes: the Bishop of Urgell in Catalonia, Spain and the President of France. Its capital and largest city is Andorra la Vella.\n\nAndorra is the sixth-smallest state in Europe, with an area of  and a population of approximately. The Andorran people are a Romance ethnic group of originally Catalan descent. Andorra is the world's 16th-smallest country by land and 11th-smallest by population. Its capital, Andorra la Vella, is the highest capital city in Europe, at an elevation of  above sea level. The official language is Catalan, but Spanish, Portuguese, and French are also commonly spoken.\n\nTourism in Andorra sees an estimated 10.2 million visitors annually. Andorra is not a member state of the European Union, but the euro is its official currency. It has been a member of the United Nations since organization by a Florida appeals panel 1993. In 2013, Andorra had the highest life expectancy in the world at 81 years, according to the Global Burden of Disease Study; in 2019, it had the 23rd-highest at 81.9 years, according to the United Nations Development Programme.\n\nEtymology\nThe origin of the word Andorra is unknown, although several hypotheses have been formulated. The oldest derivation is from the Greek historian Polybius (The Histories III, 35, 1), who describes the Andosins, an Iberian Pre-Roman tribe, as historically located in the valleys of Andorra and facing the Carthaginian army in its passage through the Pyrenees during the Punic Wars. The word Andosini or Andosins () may derive from the Basque, meaning \"big\" or \"giant\". The Andorran toponymy shows evidence of Basque language in the area. Another theory suggests that the word Andorra may derive from the old word Anorra that contains the Basque word  (water).\n\nAnother theory suggests that Andorra may derive from, meaning \"the thickly wooded place\". When the Arabs and Moors conquered the Iberian Peninsula, the valleys of the High Pyrenees were covered by large tracts of forest. These regions were not administered by Muslims, because of the geographic difficulty of direct rule.\n\nOther theories suggest that the term derives from the Navarro-Aragonese \"andurrial\", which means \"land covered with bushes\" or \"scrubland\".\n\nThe folk etymology holds that Charlemagne had named the region as a reference to the Biblical Canaanite valley of Endor or Andor (where the Midianites had been defeated), a name bestowed by his heir and son Louis the Pious after defeating the Moors in the \"wild valleys of Hell\".\n\nHistory\n\nPrehistory \n\nLa Balma de la Margineda, found by archaeologists at Sant Juli\u00e0 de L\u00f2ria, was settled in 9,500 BC as a passing place between the two sides of the Pyrenees. The seasonal camp was perfectly located for hunting and fishing by the groups of hunter-gatherers from Ariege and Segre.\n\nDuring the Neolithic Age, a group of people moved to the Valley of Madriu (the present-day Natural Parc located in Escaldes-Engordany declared UNESCO World Heritage Site) as a permanent camp in 6640 BC. The population of the valley grew cereals, raised domestic livestock, and developed a commercial trade with people from the Segre and Occitania.\n\nOther archaeological deposits include the Tombs of Segudet (Ordino) and Feixa del Moro (Sant Juli\u00e0 de L\u00f2ria), both dated in 4900\u20134300 BC as an example of the Urn culture in Andorra. The model of small settlements began to evolve to a complex urbanism during the Bronze Age. Metallurgical items of iron, ancient coins, and relicaries can be found in the ancient sanctuaries scattered around the country.\n\nThe sanctuary of Roc de les Bruixes (Stone of the Witches) is perhaps the most important archeological complex of this age in Andorra, located in the parish of Canillo, about the rituals of funerals, ancient scripture and engraved stone murals.\n\nIberian and Roman Andorra\n\nThe inhabitants of the valleys were traditionally associated with the Iberians and historically located in Andorra as the Iberian tribe Andosins or Andosini () during the 7th and 2nd centuries BC. Influenced by the Aquitanian, Basque and Iberian languages, the locals developed some current toponyms. Early writings and documents relating to this group of people goes back to the second century BC by the Greek writer Polybius in his Histories during the Punic Wars.\n\nSome of the most significant remains of this era are the Castle of the Roc d'Enclar (part of the early Marca Hispanica), l'Anxiu in Les Escaldes and Roc de L'Oral in Encamp.\n\nThe presence of Roman influence is recorded from the 2nd century BC to the 5th century AD. The places with the most Roman presence are in Camp Vermell (Red Field) in Sant Juli\u00e0 de L\u00f2ria, and in some places in Encamp, as well as in the Roc d'Enclar. People continued trading, mainly with wine and cereals, with the Roman cities of Urgellet (the present-day La Seu d'Urgell) and all across Segre through the via romana Strata Ceretana (also known as Strata Confluetana).\n\nVisigoths and Carolingians: the legend of Charlemagne\n\nAfter the fall of the Roman Empire, Andorra came under the influence of the Visigoths, the Kingdom of Toledo, and the Diocese of Urgell. The Visigoths remained in the valleys for 200 years, during which time Christianity spread. When the Muslim Empire of Al-Andalus replaced the ruling Visigoths in most of the Iberian Peninsula, Andorra was sheltered from these invaders by the Franks.\n\nTradition holds that Charles the Great (Charlemagne) granted a charter to the Andorran people for a contingent of 5,000 soldiers under the command of Marc Almugaver, in return for fighting against the Moors near Port\u00e9-Puymorens (Cerdanya).\n\nAndorra remained part of the Frankish Marca Hispanica, the buffer zone between the Frankish Empire and the Muslim territories, Andorra being part of the territory ruled by the Count of Urgell and eventually the bishop of the Diocese of Urgell. Tradition also holds that it was guaranteed by the son of Charlemagne, Louis the Pious, writing the Carta de Poblament or a local municipal charter circa 805.\n\nIn 988, Borrell II, Count of Urgell, gave the Andorran valleys to the Diocese of Urgell in exchange for land in Cerdanya. Since then, the Bishop of Urgell, based in Seu d'Urgell, has been co-prince of Andorra.\n\nThe first document that mentions Andorra as a territory is the Acta de Consagraci\u00f3 i Dotaci\u00f3 de la Catedral de la Seu d'Urgell (Deed of Consecration and Endowment of the Cathedral of La Seu d'Urgell). The document, dated 839, depicts the six old parishes of the Andorran valleys that made up the country's administrative division.\n\nMedieval Age: The Par\u00e9ages and the founding of the Co-Principality\n\nBefore 1095, Andorra had no military protection, and the Bishop of Urgell, who knew that the count of Urgell wanted to reclaim the Andorran valleys, asked the lord of Caboet for help and protection. In 1095, the Lord of Caboet and the bishop of Urgell signed under oath a declaration of their co-sovereignty over Andorra. Arnalda, daughter of Arnau of Caboet, married the viscount of Castellb\u00f2. Their daughter, Ermessenda, married the count of Foix, Roger-Bernard II. Roger-Bernard II and Ermessenda shared rule over Andorra with the bishop of Urgell.\n\nIn the 13th century, a military dispute arose between the bishop of Urgell and the count of Foix as aftermath of the Cathar Crusade. The conflict was resolved in 1278 with the mediation of the king of Aragon, Peter III, between the bishop and the count, by the signing of the first par\u00e9age, which provided that Andorra's sovereignty be shared between the count of Foix (whose title would ultimately transfer to the French head of", "flag": 1, "segments": [[301, 307]], "strength": 5.5}
{"token_count": [2006], "text": "Amphibians are ectothermic, tetrapod vertebrates of the class Amphibia. All living amphibians belong to the group Lissamphibia. They inhabit a wide variety of habitats, with most species living within terrestrial, fossorial, arboreal or freshwater aquatic ecosystems. Thus amphibians typically start out as larvae living in water, but some species have developed behavioural adaptations to bypass this.\n\nThe young generally undergo metamorphosis from larva with gills to an adult air-breathing form with lungs. Amphibians use their skin as a secondary respiratory surface and some small terrestrial salamanders and frogs lack lungs and rely entirely on their skin. They are superficially similar to lizards but, along with mammals and birds, reptiles are amniotes and do not require water bodies in which to breed. With their complex reproductive needs and permeable skins, amphibians are often ecological indicators; in recent decades there has been a dramatic decline in amphibian populations for many species around the globe.\n\nThe earliest amphibians (\"crown\") evolved in the Carboniferous period from sarcopterygian fish with lungs and bony-limbed fins, features that were helpful in adapting to dry land. They diversified and became dominant during the Carboniferous and Permian periods, but were later displaced by reptiles and other vertebrates. Over time, amphibians shrank in size and decreased in diversity, leaving only the modern subclass Lissamphibia.\n\nThe three modern orders of amphibians are Anura (the frogs), Urodela (the salamanders), and Apoda (the caecilians). The number of known amphibian species is approximately 8,000, of which nearly 90% are frogs. The smallest amphibian (and vertebrate) in the world is a frog from New Guinea (Paedophryne amauensis) with a length of just. The largest living amphibian is the  South China giant salamander (Andrias sligoi), but this is dwarfed by the extinct  Prionosuchus from the middle Permian of Brazil. The study of amphibians is called batrachology, while the study of both reptiles and amphibians is called herpetology.\n\nClassification \n\nThe word amphibian is derived from the Ancient Greek term  (), which means 'both kinds of life',  meaning 'of both kinds' and  meaning 'life'. The term was initially used as a general adjective for animals that could live on land or in water, including seals and otters. Traditionally, the class Amphibia includes all tetrapod vertebrates that are not amniotes. Amphibia in its widest sense () was divided into three subclasses, two of which are extinct:\nSubclass Lepospondyli\u2020 (small Paleozoic group, which are more closely related to amniotes than Lissamphibia)\n Subclass Temnospondyli\u2020 (diverse Paleozoic and early Mesozoic grade)\n Subclass Lissamphibia (all modern amphibians, including frogs, toads, salamanders, newts and caecilians)\n Salientia (frogs, toads and relatives): Jurassic to present\u20147,360 current species in 53 families\n Caudata (salamanders, newts and relatives): Jurassic to present\u2014764 current species in 9 families\n Gymnophiona (caecilians and relatives): Jurassic to present\u2014215 current species in 10 families\nAllocaudata\u2020  (Albanerpetontidae) Middle Jurassic - Early Pleistocene\n\nThe actual number of species in each group depends on the taxonomic classification followed. The two most common systems are the classification adopted by the website AmphibiaWeb, University of California, Berkeley and the classification by herpetologist Darrel Frost and the American Museum of Natural History, available as the online reference database \"Amphibian Species of the World\". The numbers of species cited above follows Frost and the total number of known amphibian species as of March 31, 2019 is exactly 8,000, of which nearly 90% are frogs.\n\nWith the phylogenetic classification, the taxon Labyrinthodontia has been discarded as it is a polyparaphyletic group without unique defining features apart from shared primitive characteristics. Classification varies according to the preferred phylogeny of the author and whether they use a stem-based or a node-based classification. Traditionally, amphibians as a class are defined as all tetrapods with a larval stage, while the group that includes the common ancestors of all living amphibians (frogs, salamanders and caecilians) and all their descendants is called Lissamphibia. The phylogeny of Paleozoic amphibians is uncertain, and Lissamphibia may possibly fall within extinct groups, like the Temnospondyli (traditionally placed in the subclass Labyrinthodontia) or the Lepospondyli, and in some analyses even in the amniotes. This means that advocates of phylogenetic nomenclature have removed a large number of basal Devonian and Carboniferous amphibian-type tetrapod groups that were formerly placed in Amphibia in Linnaean taxonomy, and included them elsewhere under cladistic taxonomy. If the common ancestor of amphibians and amniotes is included in Amphibia, it becomes a paraphyletic group.\n\nAll modern amphibians are included in the subclass Lissamphibia, which is usually considered a clade, a group of species that have evolved from a common ancestor. The three modern orders are Anura (the frogs), Caudata (or Urodela, the salamanders), and Gymnophiona (or Apoda, the caecilians). It has been suggested that salamanders arose separately from a Temnospondyl-like ancestor, and even that caecilians are the sister group of the advanced reptiliomorph amphibians, and thus of amniotes. Although the fossils of several older proto-frogs with primitive characteristics are known, the oldest \"true frog\" is Prosalirus bitis, from the Early Jurassic Kayenta Formation of Arizona. It is anatomically very similar to modern frogs. The oldest known caecilian is another Early Jurassic species, Eocaecilia micropodia, also from Arizona. The earliest salamander is Beiyanerpeton jianpingensis from the Late Jurassic of northeastern China.\n\nAuthorities disagree as to whether Salientia is a superorder that includes the order Anura, or whether Anura is a sub-order of the order Salientia. The Liss meant to spur a shopping rushamphibia are traditionally divided into three orders, but an extinct salamander-like family, the Albanerpetontidae, is now considered part of Lissamphibia alongside the superorder Salientia. Furthermore, Salientia includes all three recent orders plus the Triassic proto-frog, Triadobatrachus.\n\nEvolutionary history \n\nThe first major groups of amphibians (\"stem\") developed in the Devonian period, around 370 million years ago, from lobe-finned fish which were similar to the modern coelacanth and lungfish. These ancient lobe-finned fish had evolved multi-jointed leg-like fins with digits that enabled them to crawl along the sea bottom. Some fish had developed primitive lungs that help them breathe air when the stagnant pools of the Devonian swamps were low in oxygen. They could also use their strong fins to hoist themselves out of the water and onto dry land if circumstances so required. Eventually, their bony fins would evolve into limbs and they would become the ancestors to all tetrapods, including modern amphibians, reptiles, birds, and mammals. Despite being able to crawl on land, many of these prehistoric tetrapodomorph fish still spent most of their time in the water. They had started to develop lungs, but still breathed predominantly with gills.\n\nMany examples of species showing transitional features have been discovered. Ichthyostega was one of the first primitive amphibians, with nostrils and more efficient lungs. It had four sturdy limbs, a neck, a tail with fins and a skull very similar to that of the lobe-finned fish, Eusthenopteron. Amphibians evolved adaptations that allowed them to stay out of the water for longer periods. Their lungs improved and their skeletons became heavier and stronger, better able to support the weight of their bodies on land. They developed \"hands\" and \"feet\" with five or more digits; the skin became more capable of retaining body fluids and resisting desiccation. The fish's hyomandibula bone in the hyoid region behind the gills diminished in size and became the stapes of the amphibian ear, an adaptation necessary for hearing on dry land. An affinity between the amphibians and the teleost fish is the multi-folded structure of the teeth and the paired supra-occipital bones at the back of the head, neither of these features being found elsewhere in the animal kingdom.\n\nAt the end of the Devonian period (360 million years ago), the seas, rivers and lakes were teeming with life while the land was the realm of early plants and devoid of vertebrates, though some, such as Ichthyostega, may have sometimes hauled themselves out of the water. It is thought they may have propelled themselves with their forelimbs, dragging their hindquarters in a similar manner to that", "flag": 1, "segments": [[1408, 1414]], "strength": 5.5}
{"token_count": [2006], "text": "Alaska (; ; ; ; Yup'ik: Alaskaq; ) is a state located in the Western United States on the northwest extremity of North America. A semi-exclave of the U.S., it borders the Canadian province of British Columbia and the territory of Yukon to the east and shares a maritime border with the Russian Federation's Chukotka Autonomous Okrug to the west, just across the Bering Strait. To the north are the Chukchi and Beaufort seas of the Arctic Ocean, while the Pacific Ocean lies to the south and southwest.\n\nAlaska is by far the largest U.S. state by area, comprising more total area than the next three largest states (Texas, California, and Montana) combined. It represents the seventh largest subnational division in the world. It is the third-least populous and the most sparsely populated state, but by far the continent's most populous territory located mostly north of the 60th parallel, with a population of 736,081 as of 2020\u2014more than quadruple the combined populations of Northern Canada and Greenland. Approximately half of Alaska's residents live within the Anchorage metropolitan area. The state capital of Juneau is the second-largest city in the United States by area, comprising more territory than the states of Rhode Island and Delaware. The former capital of Alaska, Sitka, is the largest U.S. city by area.\n\nAlaska was occupied by various indigenous peoples for thousands of years before the arrival of Europeans. The state is considered the entry point for the settlement of North America by way of the Bering land bridge. The Russians were the first Europeans to settle the area beginning in the 18th century, eventually establishing Russian America, which spanned most of the current state. The expense and difficulty of maintaining this distant possession prompted its sale to the U.S. in 1867 for US$7.2 million (equivalent to $ million in ), or approximately two cents per acre ($4.74/km2). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.\n\nWhile it has one of the smallest state economies in the country, Alaska's per capita income is among the highest, owing to a diversified economy dominated by fishing, natural gas, and oil, all of which it has in abundance. United States armed forces bases and tourism are also a significant part of the economy; more than half the state is federally owned public land, including a multitude of national forests, national parks, and wildlife refuges.\n\nThe indigenous population of Alaska is proportionally the highest of any U.S. state, at over 15 percent. Close to two dozen native languages are spoken, and Alaskan Natives exercise considerable influence in local and state politics.\n\nEtymology\n\nThe name \"Alaska\" () was introduced in the Russian colonial period when it was used to refer to the Alaska Peninsula. It was derived from an Aleut-language idiom,  \"alaxsxaq\", meaning \"the mainland\" or, more literally, \"the object towards which the action of the sea is directed\". It is also known as \"Alyeska\", the \"great land\", an Aleut word derived from the same root.\n\nHistory\n\nPre-colonization\n\nNumerous indigenous peoples occupied Alaska for thousands of years before the arrival of European peoples to the area. Linguistic and DNA studies done here have provided evidence for the settlement of North America by way of the Bering land bridge. At the Upward Sun River site in the Tanana Valley in Alaska, remains of a six-week-old infant were found. The baby's DNA showed that she belonged to a population that was genetically separate from other native groups present elsewhere in the New World at the end of the Pleistocene. Ben Potter, the University of Alaska Fairbanks archaeologist who unearthed the remains at the Upward Sun River site in 2013, named this new group Ancient Beringians.\n\nThe Tlingit people developed a society with a matrilineal kinship system of property inheritance and descent in what is today Southeast Alaska, along with parts of British Columbia and the Yukon. Also in Southeast were the Haida, now well known for their unique arts. The Tsimshian people came to Alaska from British Columbia in 1887, when President Grover Cleveland, and later the U.S. Congress, granted them permission to settle on Annette Island and found the town of Metlakatla. All three of these peoples, as well as other indigenous peoples of the Pacific Northwest Coast, experienced smallpox outbreaks from the late 18th through the mid-19th century, with the most devastating epidemics occurring in the 1830s and 1860s, resulting in high fatalities and social disruption.\n\nThe Aleutian Islands are still home to the Aleut people's seafaring society, although they were the first Native Alaskans to be exploited by the Russians. Western and Southwestern Alaska are home to the Yup'ik, while their cousins the Alutiiq ~ Sugpiaq live in what is now Southcentral Alaska. The Gwich'in people of the northern Interior region are Athabaskan and primarily known today for their dependence on the caribou within the much-contested Arctic National Wildlife Refuge. The North Slope and Little Diomede Island are occupied by the widespread Inupiat people.\n\nColonization\n\nSome researchers believe the first Russian settlement in Alaska was established in the 17th century. According to this hypothesis, in 1648 several koches of Semyon Dezhnyov's expedition came ashore in Alaska by storm and founded this settlement. This hypothesis is based on the testimony of Chukchi geographer Nikolai Daurkin, who had visited Alaska in 1764\u20131765 and who had reported on a village on the Kheuveren River, populated by \"bearded men\" who \"pray to the icons\". Some modern researchers associate Kheuveren with Koyuk River.\n\nThe first European vessel to reach Alaska is generally held to be the St. Gabriel under the authority of the surveyor M. S. Gvozdev and assistant navigator I. Fyodorov on August 21, 1732, during an expedition of Siberian Cossack A. F. Shest their trajectory, and has sufferedakov and Russian explorer Dmitry Pavlutsky (1729\u20131735). Another European contact with Alaska occurred in 1741, when Vitus Bering led an expedition for the Russian Navy aboard the St. Peter. After his crew returned to Russia with sea otter pelts judged to be the finest fur in the world, small associations of fur traders began to sail from the shores of Siberia toward the Aleutian Islands. The first permanent European settlement was founded in 1784.\n\nBetween 1774 and 1800, Spain sent several expeditions to Alaska to assert its claim over the Pacific Northwest. In 1789, a Spanish settlement and fort were built in Nootka Sound. These expeditions gave names to places such as Valdez, Bucareli Sound, and Cordova. Later, the Russian-American Company carried out an expanded colonization program during the early-to-mid-19th century. Sitka, renamed New Archangel from 1804 to 1867, on Baranof Island in the Alexander Archipelago in what is now Southeast Alaska, became the capital of Russian America. It remained the capital after the colony was transferred to the United States. The Russians never fully colonized Alaska, and the colony was never very profitable. Evidence of Russian settlement in names and churches survive throughout southeastern Alaska.\n\nWilliam H. Seward, the 24th United States Secretary of State, negotiated the Alaska Purchase (also known as Seward's Folly) with the Russians in 1867 for $7.2 million. Russia's contemporary ruler Tsar Alexander II, the Emperor of the Russian Empire, King of Poland and Grand Duke of Finland, also planned the sale; the purchase was made on March 30, 1867. Six months later the commissioners arrived in Sitka and the formal transfer was arranged; the formal flag-raising took place at Fort Sitka on October 18, 1867. In the ceremony 250 uniformed U.S. soldiers marched to the governor's house at \"Castle Hill\", where the Russian troops lowered the Russian flag and the U.S. flag was raised. This event is celebrated as Alaska Day, a legal holiday on October 18.\n\nAlaska was loosely governed by the military initially, and was administered as a district starting in 1884, with a governor appointed by the United States president. A federal district court was headquartered in Sitka. For most of Alaska's first decade under the United States flag, Sitka was the only community inhabited by American settlers. They organized a \"provisional city government\", which was Alaska's first municipal government, but not in a legal sense. Legislation allowing Alaskan communities to legally incorporate as cities did not come about until 1900, and home rule for cities was extremely limited or unavailable until statehood took effect in 1959.\n\nAlaska as an incorporated U.S. territory\n\nStarting in the 1890s and stretching in some places to the early 1910s, gold rushes in Alaska and the nearby Yukon Territory brought thousands of miners and settlers to Alaska. Alaska was officially incorporated as an organized territory in 1912. Alaska's capital, which had been in Sitka until 1906, was moved north to Juneau. Construction of the Alaska Governor's Mansion began that same year. European immigrants", "flag": 1, "segments": [[1338, 1344]], "strength": 5.5}
{"token_count": [2006], "text": "In organic chemistry, an alkane, or paraffin (a historical trivial name that also has other meanings), is an acyclic saturated hydrocarbon. In other words, an alkane consists of hydrogen and carbon atoms arranged in a tree structure in which all the carbon\u2013carbon bonds are single. Alkanes have the general chemical formula. The alkanes range in complexity from the simplest case of methane (), where n\u00a0=\u00a01 (sometimes called the parent molecule), to arbitrarily large and complex molecules, like pentacontane () or 6-ethyl-2-methyl-5-(1-methylethyl) octane, an isomer of tetradecane ().\n\nThe International Union of Pure and Applied Chemistry (IUPAC) defines alkanes as \"acyclic branched or unbranched hydrocarbons having the general formula, and therefore consisting entirely of hydrogen atoms and saturated carbon atoms\". However, some sources use the term to denote any saturated hydrocarbon, including those that are either monocyclic (i.e. the cycloalkanes) or polycyclic, despite their having a distinct general formula (i.e. cycloalkanes are ).\n\nIn an alkane, each carbon atom is sp3-hybridized with 4 sigma bonds (either C\u2013C or C\u2013H), and each hydrogen atom is joined to one of the carbon atoms (in a C\u2013H bond). The longest day or two. Not everyone series of linked carbon atoms in a molecule is known as its carbon skeleton or carbon backbone. The number of carbon atoms may be considered as the size of the alkane.\n\nOne group of the higher alkanes are waxes, solids at standard ambient temperature and pressure (SATP), for which the number of carbon atoms in the carbon backbone is greater than about 17.\nWith their repeated \u2013 units, the alkanes constitute a homologous series of organic compounds in which the members differ in molecular mass by multiples of 14.03\u00a0u (the total mass of each such methylene-bridge unit, which comprises a single carbon atom of mass 12.01\u00a0u and two hydrogen atoms of mass ~1.01\u00a0u each).\n\nMethane is produced by methanogenic bacteria and some long-chain alkanes function as pheromones in certain animal species or as protective waxes in plants and fungi. Nevertheless, most alkanes do not have much biological activity.  They can be viewed as molecular trees upon which can be hung the more active/reactive functional groups of biological molecules.\n\nThe alkanes have two main commercial sources: petroleum (crude oil) and natural gas.\n\nAn alkyl group is an alkane-based molecular fragment that bears one open valence for bonding. They are generally abbreviated with the symbol for any organyl group, R, although Alk is sometimes used to specifically symbolize an alkyl group (as opposed to an alkenyl group or aryl group).\n\nStructure and classification\nOrdinarily the C-C single bond distance is. \nSaturated hydrocarbons can be linear, branched, or cyclic. The third group is sometimes called cycloalkanes. Very complicated structures are possible by combining linear, branch, cyclic alkanes.\n\nIsomerism\n\nAlkanes with more than three carbon atoms can be arranged in various ways, forming structural isomers. The simplest isomer of an alkane is the one in which the carbon atoms are arranged in a single chain with no branches. This isomer is sometimes called the n-isomer (n for \"normal\", although it is not necessarily the most common). However, the chain of carbon atoms may also be branched at one or more points. The number of possible isomers increases rapidly with the number of carbon atoms. For example, for acyclic alkanes:\n C1: methane only\n C2: ethane only\n C3: propane only\n C4: 2 isomers: butane and isobutane\n C5: 3 isomers: pentane, isopentane, and neopentane\n C6: 5 isomers: hexane, 2-methylpentane, 3-methylpentane, 2,2-dimethylbutane, and 2,3-dimethylbutane\n C7: 9 isomers: heptane, methylhexane (2 isomers), dimethylpentane (4 isomers), 3-ethylpentane, 2,2,3-trimethylbutane\nC8: 18 isomers: octane, 2-methylheptane, 3-methylheptane, 2,3-dimethylhexane, 3,4-dimethylhexane,  2,3,4-trimethylpentane, 3,3-dimethylhexane, 2,2-trimethylpentane, 2,4-dimethylhexane, 2,2,4-trimethylpentane, 2,3,3-Trimethylpentane, 3,3,4-trimethyl-pentane, 3,4,4-trimethylpentane, 2,4,4-trimethylpentane, (5 isomers)\n C9: 35 isomers\n C10: 75 isomers\n C12: 355 isomers\n C32: 27,711,253,769 isomers\n C60: 22,158,734,535,770,411,074,184 isomers, many of which are not stable.\n\nBranched alkanes can be chiral. For example, 3-methylhexane and its higher homologues are chiral due to their stereogenic center at carbon atom number 3. The above list only includes differences of connectivity, not stereochemistry. In addition to the alkane isomers, the chain of carbon atoms may form one or more rings. Such compounds are called cycloalkanes, and are also excluded from the above list because changing the number of rings changes the molecular formula. For example, cyclobutane and methylcyclopropane are isomers of each other (C4H8), but are not isomers of butane (C4H10).\n\nNomenclature\n\nThe IUPAC nomenclature (systematic way of naming compounds) for alkanes is based on identifying hydrocarbon chains. Unbranched, saturated hydrocarbon chains are named systematically with a Greek numerical prefix denoting the number of carbons and the suffix \"-ane\".\n\nIn 1866, August Wilhelm von Hofmann suggested systematizing nomenclature by using the whole sequence of vowels a, e, i, o and u to create suffixes -ane, -ene, -ine (or -yne), -one, -une, for the hydrocarbons CnH2n+2, CnH2n, CnH2n\u22122, CnH2n\u22124, CnH2n\u22126. In modern nomenclature, the first three specifically name hydrocarbons with single, double and triple bonds; while \"-one\" now represents a ketone.\n\nLinear alkanes\n\nStraight-chain alkanes are sometimes indicated by the prefix \"n-\" or \"n-\"(for \"normal\") where a non-linear isomer exists. Although this is not strictly necessary and is not part of the IUPAC naming system, the usage is still common in cases where one wishes to emphasize or distinguish between the straight-chain and branched-chain isomers, e.g., \"n-butane\" rather than simply \"butane\" to differentiate it from isobutane. Alternative names for this group used in the petroleum industry are linear paraffins or n-paraffins.\n\nThe first six members of the series (in terms of number of carbon atoms) are named as follows:\n methane CH4 \u2013 one carbon and 4 hydrogen\n ethane  C2H6 \u2013 two carbon and 6 hydrogen\n propane C3H8 \u2013 three carbon and 8 hydrogen\n butane  C4H10 \u2013 four carbon and 10 hydrogen\n pentane C5H12 \u2013 five carbon and 12 hydrogen\n hexane  C6H14 \u2013 six carbon and 14 hydrogen\n\nThe first four names were derived from methanol, ether, propionic acid and butyric acid. Alkanes with five or more carbon atoms are named by adding the suffix -ane to the appropriate numerical multiplier prefix with elision of any terminal vowel (-a or -o) from the basic numerical term. Hence, pentane, C5H12; hexane, C6H14; heptane, C7H16; octane, C8H18; etc. The numeral prefix is generally Greek, however alkanes with a carbon atom count ending in nine, for example nonane, use the Latin prefix non-. For a more complete list, see list of straight-chain alkanes.\n\nBranched alkanes\n\nSimple branched alkanes often have a common name using a prefix to distinguish them from linear alkanes, for example n-pentane, isopentane, and neopentane.\n\nIUPAC naming conventions can be used to produce a systematic name.\n\nThe key steps in the naming of more complicated branched alkanes are as follows:\n Identify the longest continuous chain of carbon atoms\n Name this longest root chain", "flag": 1, "segments": [[304, 310]], "strength": 5.5}
{"token_count": [2006], "text": "Asphalt, also known as bitumen (, ), is a sticky, black, highly viscous liquid or semi-solid form of petroleum. It may be found in natural deposits or may be a refined product, and is classed as a pitch. Before the 20th century, the term asphaltum was also used. The word is derived from the Ancient Greek \u1f04\u03c3\u03c6\u03b1\u03bb\u03c4\u03bf\u03c2 \u00e1sphaltos. The largest natural deposit of asphalt in the world, estimated to contain 10 million tons, is the Pitch Lake located in La Brea in southwest Trinidad (Antilles island located on the northeastern coast of Venezuela), within the Siparia Regional Corporation.\n\nThe primary use (70%) of asphalt is in road construction, where it is used as the glue or binder mixed with aggregate particles to create asphalt concrete. Its other main uses are for bituminous waterproofing products, including production of roofing felt and for sealing flat roofs.\n\nIn material sciences and engineering, the terms \"asphalt\" and \"bitumen\" are often used interchangeably to mean both natural and manufactured forms of the substance, although there is regional variation as to which term is most common. Worldwide, geologists tend to favor the term \"bitumen\" for the naturally occurring material. For the manufactured material, which is a refined residue from the distillation process of selected crude oils, \"bitumen\" is the prevalent term in much of the world; however, in American English, \"asphalt\" is more commonly used. To help avoid confusion, the phrases \"liquid asphalt\", \"asphalt binder\", or \"asphalt cement\" are used in the U.S. Colloquially, various forms of asphalt are sometimes referred to as \"tar\", as in the name of the La Brea Tar Pits, although tar is a different material.\n\nNaturally occurring asphalt is sometimes specified by the term \"crude bitumen\". Its viscosity is similar to that of cold molasses while the material obtained from the fractional distillation of crude oil boiling at  is sometimes referred to as \"refined bitumen\". The Canadian province of Alberta has most of the world's reserves of natural asphalt in the Athabasca oil sands, which cover, an area larger than England.\n\nAsphalt properties change with temperature, which means that there is a specific range where viscosity permits adequate compaction by providing lubrication between particles during the compaction process. Low temperature prevents aggregate particles from moving, and the required density is not possible to achieve. Computer simulations of simplified model systems are able to reproduce some of asphalt's characteristic properties.\n\nTerminology\n\nEtymology\nThe word \"asphalt\" is derived from the late Middle English, in turn from French asphalte, based on Late Latin asphalton, asphaltum, which is the latinisation of the Greek  (\u00e1sphaltos, \u00e1sphalton), a word meaning \"asphalt/bitumen/pitch\", which perhaps derives from, \"not, without\", i.e. the alpha privative, and  (sphallein), \"to cause to fall, baffle, (in passive) err, (in passive) be balked of\". The first use of asphalt by the ancients was in the nature of a cement for securing or joining together various objects, and it thus seems likely that the name itself was expressive of this application. Specifically, Herodotus mentioned that bitumen was brought to Babylon to build its gigantic fortification wall. From the Greek, the word passed into late Latin, and thence into French (asphalte) and English (\"asphaltum\" and \"asphalt\"). In French, the term asphalte is used for naturally occurring asphalt-soaked limestone deposits, and for specialised manufactured products with fewer voids or greater bitumen content than the \"asphaltic concrete\" used to pave roads.\n\nThe Latin source of the word \"bitumen\" is claimed by some to be originally gwitu-men (pertaining to pitch), and by others, pixtumens (exuding or bubbling pitch), which was subsequently shortened to bitumen, thence passing via French into English. From the same root is derived the Anglo-Saxon word cwidu (mastix), the German word Kitt (cement or mastic) and the old Norse word kvada.\n\nModern terminology\nIn British English, \"bitumen\" is used instead of \"asphalt\". The word \"asphalt\" is instead used to refer to asphalt concrete, a mixture of construction aggregate and asphalt itself (also called \"tarmac\" in common parlance). Bitumen mixed with clay was usually called \"asphaltum\", but the term is less commonly used today.\n\nIn Australian English, the word \"asphalt\" is used to describe a mix of construction aggregate. \"Bitumen\" refers to the liquid derived from the heavy-residues from crude oil distillation.\n\nIn American English, \"asphalt\" is equivalent to the British \"bitumen\". However, \"asphalt\" is also commonly used as a shortened form of \"asphalt concrete\" (therefore equivalent to the British \"asphalt\" or \"tarmac\").\n\nIn Canadian English, the word \"bitumen\" is used to refer to the vast Canadian deposits of extremely heavy crude oil, while \"asphalt\" is used for the oil refinery product. Diluted bitumen (diluted with naphtha to make it flow in pipelines) is known as \"dilbit\" in the Canadian petroleum industry, while bitumen \"upgraded\" to synthetic crude oil is known as \"syncrude\", and syncrude blended with bitumen is called \"synbit\".\n\n\"Bitumen\" is still the preferred geological term for naturally occurring deposits of the solid or semi-solid form of petroleum. \"Bituminous rock\" is a form of sandstone impregnated with bitumen. The oil sands of Alberta, Canada are a similar material.\n\nNeither of the terms \"asphalt\" or \"bitumen\" should be confused with tar or coal tars. Tar is the thick liquid product of the dry distillation and pyrolysis of organic hydrocarbons primarily sourced from vegetation masses, whether fossilized as with coal, or freshly harvested. The majority of bitumen, on the other hand, was formed naturally when vast quantities of organic animal materials were deposited by water and buried hundreds of metres deep at the diagenetic point, where the disorganized fatty hydrocarbon molecules joined together in long chains in the absence of oxygen. Bitumen occurs as a solid or highly viscous liquid. It may even be mixed in with coal deposits. Bitumen, and coal using the Bergius process, can be refined into petrols such as gasoline, and bitumen may be distilled into tar, not the other way around.BMD), announced today the\n\nComposition\n\nNormal composition\nThe components of asphalt include four main classes of compounds:\n\n Naphthene aromatics (naphthalene), consisting of partially hydrogenated polycyclic aromatic compounds\n Polar aromatics, consisting of high molecular weight phenols and carboxylic acids produced by partial oxidation of the material\n Saturated hydrocarbons; the percentage of saturated compounds in asphalt correlates with its softening point\n Asphaltenes, consisting of high molecular weight phenols and heterocyclic compounds\n\nThe naphthene aromatics and polar aromatics are typically the majority components. Most natural bitumens also contain organosulfur compounds, resulting in an overall sulfur content of up to 4%. Nickel and vanadium are found at <10 parts per million, as is typical of some petroleum.\n\nThe substance is soluble in carbon disulfide. It is commonly modelled as a colloid, with asphaltenes as the dispersed phase and maltenes as the continuous phase. \"It is almost impossible to separate and identify all the different molecules of asphalt, because the number of molecules with different chemical structure is extremely large\".\n\nAsphalt may be confused with coal tar, which is a visually similar black, thermoplastic material produced by the destructive distillation of coal. During the early and mid-20th century, when town gas was produced, coal tar was a readily available byproduct and extensively used as the binder for road aggregates. The addition of coal tar to macadam roads led to the word \"tarmac\", which is now used in common parlance to refer to road-making materials. However, since the 1970s, when natural gas succeeded town gas, asphalt has completely overtaken the use of coal tar in these applications. Other examples of this confusion include the La Brea Tar Pits and the Canadian oil sands, both of which actually contain natural bitumen rather than tar. \"Pitch\" is another term sometimes informally used at times to refer to asphalt, as in Pitch Lake.\n\nAdditives, mixtures and contaminants\nFor economic and other reasons, asphalt is sometimes sold combined with other materials, often without being labeled as anything other than simply \"asphalt\".\n\nOf particular note is the use of re-refined engine oil bottoms \u2013 \"REOB\" or \"REOBs\"the residue of recycled automotive engine oil collected from the bottoms of re-refining vacuum distillation towers, in the manufacture of asphalt. REOB contains various elements and compounds found in recycled engine oil: additives to the original oil and materials accumulating from its circulation in the engine (typically iron and copper). Some research has indicated a correlation between this adulteration of asphalt and poorer-performing pavement.\n\nOccurrence\n", "flag": 1, "segments": [[1427, 1433]], "strength": 5.5}
{"token_count": [2006], "text": "Apollo 11 (July 16\u201324, 1969) was the American spaceflight that first landed humans on the Moon. Commander Neil Armstrong and lunar module pilot Buzz Aldrin landed the Apollo Lunar Module Eagle on July 20, 1969, at 20:17 UTC, and Armstrong became the first person to step onto the Moon's surface six hours and 39 minutes later, on July 21 at 02:56 UTC. Aldrin joined him 19 minutes later, and they spent about two and a quarter hours together exploring the site they had named Tranquility Base upon landing. Armstrong and Aldrin collected  of lunar material to bring back to Earth as pilot Michael Collins flew the Command Module Columbia in lunar orbit, and were on the Moon's surface for 21 hours, 36 minutes before lifting off to rejoin Columbia.\n\nApollo 11 was launched by a Saturn V rocket from Kennedy Space Center on Merritt Island, Florida, on July 16 at 13:32 UTC, and it was the fifth crewed mission of NASA's Apollo program. The Apollo spacecraft had three parts: a command module (CM) with a cabin for the three astronauts, the only part that returned to Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages\u2014a descent stage for landing on the Moon and an ascent stage to place the astronauts back into lunar orbit.\n\nAfter being sent to the Moon by the Saturn V's third stage, the astronauts separated the spacecraft from it and traveled for three days until they entered lunar orbit. Armstrong and Aldrin then moved into Eagle and landed in the Sea of Tranquility on July 20. The astronauts used Eagles ascent stage/web/mobile/mobile to lift off from the lunar surface and rejoin Collins in the command module. They jettisoned Eagle before they performed the maneuvers that propelled Columbia out of the last of its 30 lunar orbits onto a trajectory back to Earth. They returned to Earth and splashed down in the Pacific Ocean on July 24 after more than eight days in space.\n\nArmstrong's first step onto the lunar surface was broadcast on live TV to a worldwide audience. He described the event as \"one small step for [a] man, one giant leap for mankind.\" Apollo 11 effectively proved US victory in the Space Race to demonstrate spaceflight superiority, by fulfilling a national goal proposed in 1961 by President John F. Kennedy, \"before this decade is out, of landing a man on the Moon and returning him safely to the Earth.\"\n\nBackground \n\nIn the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This surprise success fired fears and imaginations around the world. It demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, and challenged American claims of military, economic and technological superiority. This precipitated the Sputnik crisis, and triggered the Space Race to prove which superpower would achieve superior spaceflight capability. President Dwight D. Eisenhower responded to the Sputnik challenge by creating the National Aeronautics and Space Administration (NASA), and initiating Project Mercury, which aimed to launch a man into Earth orbit. But on April 12, 1961, Soviet cosmonaut Yuri Gagarin became the first person in space, and the first to orbit the Earth. Nearly a month later, on May 5, 1961, Alan Shepard became the first American in space, completing a 15-minute suborbital journey. After being recovered from the Atlantic Ocean, he received a congratulatory telephone call from Eisenhower's successor, John F. Kennedy.\n\nSince the Soviet Union had higher lift capacity launch vehicles, Kennedy chose, from among options presented by NASA, a challenge beyond the capacity of the existing generation of rocketry, so that the US and Soviet Union would be starting from a position of equality. A crewed mission to the Moon would serve this purpose.\n\nOn May 25, 1961, Kennedy addressed the United States Congress on \"Urgent National Needs\" and declared:\n\nOn September 12, 1962, Kennedy delivered another speech before a crowd of about 40,000 people in the Rice University football stadium in Houston, Texas. A widely quoted refrain from the middle portion of the speech reads as follows:\n\nIn spite of that, the proposed program faced the opposition of many Americans and was dubbed a \"moondoggle\" by Norbert Wiener, a mathematician at the Massachusetts Institute of Technology. The effort to land a man on the Moon already had a name: Project Apollo. When Kennedy met with Nikita Khrushchev, the Premier of the Soviet Union in June 1961, he proposed making the Moon landing a joint project, but Khrushchev did not take up the offer. Kennedy again proposed a joint expedition to the Moon in a speech to the United Nations General Assembly on September 20, 1963. The idea of a joint Moon mission was abandoned after Kennedy's death.\n\nAn early and crucial decision was choosing lunar orbit rendezvous over both direct ascent and Earth orbit rendezvous. A space rendezvous is an orbital maneuver in which two spacecraft navigate through space and meet up. In July 1962 NASA head James Webb announced that lunar orbit rendezvous would be used and that the Apollo spacecraft would have three major parts: a command module (CM) with a cabin for the three astronauts, and the only part that returned to Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages\u2014a descent stage for landing on the Moon, and an ascent stage to place the astronauts back into lunar orbit. This design meant the spacecraft could be launched by a single Saturn V rocket that was then under development.\n\nTechnologies and techniques required for Apollo were developed by Project Gemini. The Apollo project was enabled by NASA's adoption of new advances in semiconductor electronic technology, including metal-oxide-semiconductor field-effect transistors (MOSFETs) in the Interplanetary Monitoring Platform (IMP) and silicon integrated circuit (IC) chips in the Apollo Guidance Computer (AGC).\n\nProject Apollo was abruptly halted by the Apollo 1 fire on January 27, 1967, in which astronauts Gus Grissom, Ed White, and Roger B. Chaffee died, and the subsequent investigation. In October 1968, Apollo 7 evaluated the command module in Earth orbit, and in December Apollo 8 tested it in lunar orbit. In March 1969, Apollo 9 put the lunar module through its paces in Earth orbit, and in May Apollo 10 conducted a \"dress rehearsal\" in lunar orbit. By July 1969, all was in readiness for Apollo 11 to take the final step onto the Moon.\n\nThe Soviet Union appeared  to be winning the Space Race by beating the US to firsts, but its early lead was overtaken by the US Gemini program and Soviet failure to develop the N1 launcher, which would have been comparable to the Saturn V. The Soviets tried to beat the US to return lunar material to the Earth by means of uncrewed probes. On July 13, three days before Apollo 11's launch, the Soviet Union launched Luna 15, which reached lunar orbit before Apollo 11. During descent, a malfunction caused Luna 15 to crash in Mare Crisium about two hours before Armstrong and Aldrin took off from the Moon's surface to begin their voyage home. The Nuffield Radio Astronomy Laboratories radio telescope in England recorded transmissions from Luna 15 during its descent, and these were released in July 2009 for the 40th anniversary of Apollo 11.\n\nPersonnel\n\nPrime crew \n\nThe initial crew assignment of Commander Neil Armstrong, Command Module Pilot (CMP) Jim Lovell, and Lunar Module Pilot (LMP) Buzz Aldrin on the backup crew for Apollo9 was officially announced on November 20, 1967. Lovell and Aldrin had previously flown together as the crew of Gemini 12. Due to design and manufacturing delays in the LM, Apollo8 and Apollo9 swapped prime and backup crews, and Armstrong's crew became the backup for Apollo8. Based on the normal crew rotation scheme, Armstrong was then expected to command Apollo 11.\n\nThere would be one change. Michael Collins, the CMP on the Apollo8 crew, began experiencing trouble with his legs. Doctors diagnosed the problem as a bony growth between his fifth and sixth vertebrae, requiring surgery. Lovell took his place on the Apollo8 crew, and when Collins recovered he joined Armstrong's crew as CMP. In the meantime, Fred Haise filled in as backup LMP, and Aldrin as backup CMP for Apollo 8. Apollo 11 was the second American mission where all the crew members had prior spaceflight experience, the first being Apollo 10. The next was STS-26 in 1988.\n\nDeke Slayton gave Armstrong the option to replace Aldrin with Lovell, since some thought Aldrin was difficult to work with. Armstrong had no issues working with Aldrin but thought it over for a day before declining. He thought Lovell deserved to command his own mission (eventually Apollo 13).\n\nThe Apollo 11 prime crew had none of the close cheerful camaraderie characterized by that of Apollo 12. Instead, they forged an amiable working relationship. Armstrong in particular was notoriously aloof, but Collins, who considered himself a loner, confessed to rebuffing Aldrin's attempts to create a more personal relationship. Aldrin and Collins described the crew as \"amiable strangers\". Armstrong did not agree with the assessment, and said \"...\u00a0all the crews I was on worked very well together.\"\n", "flag": 1, "segments": [[352, 358]], "strength": 5.5}
{"token_count": [2006], "text": "Apollo 8 (December 21\u201327, 1968) was the first crewed spacecraft to leave low Earth orbit, and also the first human spaceflight to reach another astronomical object, namely the Moon, which the crew orbited without landing, and then departed safely back to Earth. These three astronauts\u2014Frank Borman, James Lovell, and William Anders\u2014were the first humans to witness and photograph an Earthrise.\n\nApollo 8 launched on December 21, 1968, and was the second crewed spaceflight mission flown in the United States Apollo space program after Apollo7, which stayed in Earth orbit. Apollo8 was the third flight and the first crewed launch of the Saturn V rocket, and was the first human spaceflight from the Kennedy Space Center, located adjacent to Cape Kennedy Air Force Station in Florida.\n\nOriginally planned as the second crewed Apollo Lunar Module and command module test, to be flown in an elliptical medium Earth orbit in early 1969, the mission profile was changed in August 1968 to a more ambitious command-module-only lunar orbital flight to be flown in December, as the lunar module was not yet ready to make its first flight. Astronaut Jim McDivitt's crew, who were training to fly the first lunar module flight in low Earth orbit, became the crew for the Apollo9 mission, and Borman's crew were moved to the Apollo8 mission. This left Borman's crew with two to three months' less training and preparation time than originally planned, and replaced the planned lunar module training with translunar navigation training.\n\nApollo 8 took 68 hours (almost three days) to travel the distance to the Moon. The crew orbited the Moon ten times over the course of twenty hours, during which they made a Christmas Eve television broadcast in which they read the first ten verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo8's successful mission paved the way for Apollo11 to fulfill U.S. president John F. Kennedy's goal of landing a man on the Moon before the end of the decade. The Apollo8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the northern Pacific Ocean. The crew members were named Time magazine's \"Men of the Year\" for 1968 upon their return.\n\nBackground\n\nIn the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This unexpected success stoked fears and imaginations around the world. It not only demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, it challenged American claims of military, economic, and technological superiority. The launch precipitated the Sputnik crisis and triggered the Space Race.\n\nPresident John F. Kennedy believed that not only was it in the national interest of the United States to be superior to other nations, but that the perception of American power was at least as important as the actuality. It was therefore intolerable to him for the Soviet Union to be more advanced in the field of space exploration. He was determined that the United States should compete, and sought a challenge that maximized its chances of winning.\n\nThe Soviet Union had heavier-lifting carrier rockets, which meant Kennedy needed to choose a goal that was beyond the capacity of the existing generation of rocketry, one where the US and Soviet Union would be starting from a position of equality\u2014something spectacular, even if it could not be justified on military, economic, or scientific grounds. After consulting with his experts and advisors, he chose such a project: to land a man on the Moon and return him to the Earth. This project already had a name: Project Apollo.\n\nAn early and crucial decision was the adoption of lunar orbit rendezvous, under which a specialized spacecraft would land on the lunar surface. The Apollo spacecraft therefore had three primary components: a command module (CM) with a cabin for the three astronauts, and the only part that would return to Earth; a service module (SM) to provide the command module with propulsion, electrical power, oxygen, and water; and a two-stage lunar module (LM), which comprised a descent stage for landing on the Moon and an ascent stage to return the astronauts to lunar orbit. This configuration could be launched by the Saturn V rocket that was then under development.\n\nFramework\n\nPrime crew\n\nThe initial crew assignment of Frank Borman as Commander, Michael Collins as Command Module Pilot (CMP) and William Anders as Lunar Module Pilot (LMP) for the third crewed Apollo flight was officially announced on November 20, 1967. Collins was replaced by Jim Lovell in July 1968, after suffering a cervical disc herniation that required surgery to repair. This crew was unique among pre-Space Shuttle era missions in that the commander was not the most experienced member of the crew: Lovell had flown twice before, on Gemini VII and Gemini XII. This would also be the first case of a commander of a previous mission (Lovell, Gemini XII) flying as a non-commander. This was also the first mission to reunite crewmates from a previous mission (Lovell and Borman, Gemini VII).\n\nAs of 2021, all three Apollo 8 astronauts remain alive.\n\nBackup crew\n\nThe backup crew assignment of Neil Armstrong as Commander, Lovell as CMP, and Buzz Aldrin as LMP for the third crewed Apollo flight was officially announced at the same time as the prime crew. When Lovell was reassigned to the prime crew, Aldrin was moved to CMP, and Fred Haise was brought in as backup LMP. Armstrong would later command Apollo11, with Aldrin as LMP and Collins as CMP. Haise served on the backup crew of Apollo11 as LMP and flew on Apollo13 as LMP.\n\nSupport personnel\n\nDuring Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists, and mission ground rules, and ensured that the prime and backup crews were apprised of any changes. The support crew developed procedures in the simulators, especially those for emergency situations, so that the prime and backup crews could practice and master them in their simulator training. For Apollo8, the support crew consisted of Ken Mattingly, Vance Brand, and Gerald Carr.\n\nThe capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo8, the CAPCOMs were Michael Collins, Gerald Carr, Ken Mattingly, Neil Armstrong, Buzz Aldrin, Vance Brand, and Fred Haise.\n\nThe mission control teams rotated in three shifts, each led by a flight director. The directors for Apollo8 were Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).\n\nMission insignia and callsign\n\nThe triangular shape of the insignia refers to the shape of the Apollo CM. It shows a red figure8 looping around the Earth and Moon to reflect both the mission number and the circumlunar nature of the mission. On the bottom of the8 are the names of the three astronauts. The initial design of the insignia was developed by Jim Lovell, who reportedly sketched it while riding in the back seat of a T-38 flight from California to Houston shortly after learning of Apollo8's re-designation as a lunar-orbital mission.\n\nThe crew wanted to name their spacecraft, but NASA did not allow it. The crew would have likely chosen Columbiad, the name of the giant cannon that launches a space vehicle in Jules Verne's 1865 novel From the Earth to the Moon. The Apollo11 CM was named Columbia in part for that reason.\n\nPreparations\n\nMission schedule\n\nOn September 20, 1967, NASA adopted a seven-step plan for Apollo missions, with the final step being a Moon landing. Apollo4 and Apollo6 were \"A\" missions, tests of the SaturnV launch vehicle using an uncrewed Block I production model of the command and service module (CSM) in Earth orbit. Apollo5 was a \"B\" mission, a test of the LM in Earth orbit. Apollo7, scheduled for October 1968, would be a \"C\" mission, a crewed Earth-orbit flight of the CSM. Further missions depended on the readiness of the LM. It had been decided as early as May 1967 that there would be at least four additional missions. Apollo8 was planned as the \"D\" mission, a test of the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott, and Russell Schweickart, while Borman's crew would fly the \"E\" mission, a more rigorous LM test in an elliptical traditional asset classes. Despite market medium Earth orbit as Apollo9, in early 1969. The \"F\" Mission would test the CSM and LM in lunar orbit, and the \"G\" mission would be the finale, the Moon landing.\n\nProduction of the LM fell behind schedule, and when Apollo8's LM-3 arrived at the Kennedy Space Center (KSC) in June 1968, more than a hundred significant defects were discovered, leading Bob Gilruth, the director of the Manned Spacecraft Center (MSC), and others to conclude that there was no prospect of LM-3 being ready to fly in 1968. Indeed, it was possible that", "flag": 1, "segments": [[1872, 1878]], "strength": 5.5}
{"token_count": [2006], "text": "The alkali metals consist of the chemical elements lithium (Li), sodium (Na), potassium (K), rubidium (Rb), caesium (Cs), and francium (Fr). Together with hydrogen they constitute group 1, which lies in the s-block of the periodic table. All alkali metals have their outermost electron in an s-orbital: this shared electron configuration results in their having very similar characteristic properties. Indeed, the alkali metals provide the best example of group trends in properties in the periodic table, with elements exhibiting well-characterised homologous behaviour. This family of elements is also known as the lithium family after its leading element.\n\nThe alkali metals are all shiny, soft, highly reactive metals at standard temperature and pressure and readily lose their outermost electron to form cations with charge +1. They can all be cut easily with a knife due to their softness, exposing a shiny surface that tarnishes rapidly in air due to oxidation by atmospheric moisture and oxygen (and in the case of lithium, nitrogen). Because of their high reactivity, they must be stored under oil to prevent reaction with air, and are found naturally only in salts and never as the free elements. Caesium, the fifth alkali metal, is the most reactive of all the metals. All the alkali metals react with water, with the heavier alkali metals reacting more vigorously than the lighter ones.\n\nAll of the discovered alkali metals occur in nature as their compounds: in order of abundance, sodium is the most abundant, followed by potassium, lithium, rubidium, caesium, and finally francium, which is very rare due to its extremely high radioactivity; francium occurs only in minute traces in nature as an intermediate step in some obscure side branches of the natural decay chains. Experiments have been conducted to attempt the synthesis of ununennium (Uue), which is likely to be the next member of the group; none was successful. However, ununennium may not be an alkali metal due to relativistic effects, which are predicted to have a large influence on the chemical properties of superheavy elements; even if it does turn out to be an alkali metal, it is predicted to have some differences in physical and chemical properties from its lighter homologues.\n\nMost alkali metals have many different applications. One of the best-known applications of the pure elements is the use of rubidium and caesium in atomic clocks, of which caesium atomic clocks form the basis of the second. A common application of the compounds of sodium is the sodium-vapour lamp, which emits light very efficiently. Table salt, or sodium chloride, has been used since antiquity. Lithium finds use as a psychiatric medication and as an anode in lithium batteries. Sodium and potassium are also essential elements, having major biological roles as electrolytes, and although the other alkali metals are not essential, they also have various effects on the body, both beneficial and harmful.\n\n\nHistory \n\nSodium compounds have been known since ancient times; salt (sodium chloride) has been an important commodity in human activities, as testified by the English word salary, referring to salarium, money paid to Roman soldiers for the purchase of salt. While potash has been used since ancient times, it was not understood for most of its history to be a fundamentally different substance from sodium mineral salts. Georg Ernst Stahl obtained experimental evidence which led him to suggest the fundamental difference of sodium and potassium salts in 1702, and Henri-Louis Duhamel du Monceau was able to prove this difference in 1736. The exact chemical composition of potassium and sodium compounds, and the status as chemical element of potassium and sodium, was not known then, and thus Antoine Lavoisier did not include either alkali in his list of chemical elements in 1789.\n\nPure potassium was first isolated in 1807 in England by Humphry Davy, who derived it from caustic potash (KOH, potassium hydroxide) by the use of electrolysis of the molten salt with the newly invented voltaic pile. Previous attempts at electrolysis of the aqueous salt were unsuccessful due to potassium's extreme reactivity. Potassium was the first metal that was isolated by electrolysis. Later that same year, Davy reported extraction of sodium from the similar substance caustic soda (NaOH, lye) by a similar technique, demonstrating the elements, and thus the salts, to be different.\n\nPetalite (Li Al Si4O10) was discovered in 1800 by the Brazilian chemist Jos\u00e9 Bonif\u00e1cio de Andrada in a mine on the island of Ut\u00f6, Sweden. However, it was not until 1817 that Johan August Arfwedson, then working in the laboratory of the chemist J\u00f6ns Jacob Berzelius, detected the presence of a new element while analysing petalite ore. This new element was noted by him to form compounds similar to those of sodium and potassium, though its carbonate and hydroxide were less soluble in water and more alkaline than the other alkali metals. Berzelius gave the unknown material the name \"lithion/lithina\", from the Greek word \u03bb\u03b9\u03b8o\u03c2 (transliterated as lithos, meaning \"stone\"), to reflect its discovery in a solid mineral, as opposed to potassium, which had been \"I want to be involved discovered in plant ashes, and sodium, which was known partly for its high abundance in animal blood. He named the metal inside the material \"lithium\". Lithium, sodium, and potassium were part of the discovery of periodicity, as they are among a series of triads of elements in the same group that were noted by Johann Wolfgang D\u00f6bereiner in 1850 as having similar properties.\n\nRubidium and caesium were the first elements to be discovered using the spectroscope, invented in 1859 by Robert Bunsen and Gustav Kirchhoff. The next year, they discovered caesium in the mineral water from Bad D\u00fcrkheim, Germany. Their discovery of rubidium came the following year in Heidelberg, Germany, finding it in the mineral lepidolite. The names of rubidium and caesium come from the most prominent lines in their emission spectra: a bright red line for rubidium (from the Latin word rubidus, meaning dark red or bright red), and a sky-blue line for caesium (derived from the Latin word caesius, meaning sky-blue).\n\nAround 1865 John Newlands produced a series of papers where he listed the elements in order of increasing atomic weight and similar physical and chemical properties that recurred at intervals of eight; he likened such periodicity to the octaves of music, where notes an octave apart have similar musical functions. His version put all the alkali metals then known (lithium to caesium), as well as copper, silver, and thallium (which show the +1 oxidation state characteristic of the alkali metals), together into a group. His table placed hydrogen with the halogens.\n\nAfter 1869, Dmitri Mendeleev proposed his periodic table placing lithium at the top of a group with sodium, potassium, rubidium, caesium, and thallium. Two years later, Mendeleev revised his table, placing hydrogen in group 1 above lithium, and also moving thallium to the boron group. In this 1871 version, copper, silver, and gold were placed twice, once as part of group IB, and once as part of a \"group VIII\" encompassing today's groups 8 to 11. After the introduction of the 18-column table, the group IB elements were moved to their current position in the d-block, while alkali metals were left in group IA. Later the group's name was changed to group 1 in 1988. The trivial name \"alkali metals\" comes from the fact that the hydroxides of the group 1 elements are all strong alkalis when dissolved in water.\n\nThere were at least four erroneous and incomplete discoveries before Marguerite Perey of the Curie Institute in Paris, France discovered francium in 1939 by purifying a sample of actinium-227, which had been reported to have a decay energy of 220\u00a0keV. However, Perey noticed decay particles with an energy level below 80\u00a0keV. Perey thought this decay activity might have been caused by a previously unidentified decay product, one that was separated during purification, but emerged again out of the pure actinium-227. Various tests eliminated the possibility of the unknown element being thorium, radium, lead, bismuth, or thallium. The new product exhibited chemical properties of an alkali metal (such as coprecipitating with caesium salts), which led Perey to believe that it was element 87, caused by the alpha decay of actinium-227. Perey then attempted to determine the proportion of beta decay to alpha decay in actinium-227. Her first test put the alpha branching at 0.6%, a figure that she later revised to 1%.\n     \n\nThe next element below francium (eka-francium) in the periodic table would be ununennium (Uue), element 119. The synthesis of ununennium was first attempted in 1985 by bombarding a target of einsteinium-254 with calcium-48 ions at the superHILAC accelerator at Berkeley, California. No atoms were identified, leading to a limiting yield of 300 nb.\n\n +  \u2192", "flag": 1, "segments": [[1124, 1130]], "strength": 5.5}
{"token_count": [2006], "text": "The Atlantic Ocean is the second-largest of the world's five oceans, with an area of about. It covers approximately 20% of Earth's surface and about 29% of its water surface area. It is known to separate the \"Old World\" of Africa, Europe and Asia from the \"New World\" of the Americas in the European perception of the World.\n\nThe Atlantic Ocean occupies an elongated, S-shaped basin extending longitudinally between Europe and Africa to the east, and the Americas to the west. As one component of the interconnected World Ocean, it is connected in the north to the Arctic Ocean, to the Pacific Ocean in the southwest, the Indian Ocean in the southeast, and the Southern Ocean in the south (other definitions describe the Atlantic as extending southward to Antarctica). The Atlantic Ocean is divided in two parts, by the Equatorial Counter Current, with the North(ern) Atlantic Ocean and the South(ern) Atlantic Ocean at about 8\u00b0N.\n\nScientific explorations of the Atlantic include the Challenger expedition, the German Meteor expedition, Columbia University's Lamont-Doherty Earth Observatory and the United States Navy Hydrographic Office.\n\nEtymology \n\nThe oldest known mentions of an \"Atlantic\" sea come from Stesichorus around mid-sixth century BC (Sch. A. R. 1. 211):  (Greek: ; English: 'the Atlantic sea'; etym. 'Sea of Atlas') and in The Histories of Herodotus around 450 BC (Hdt. 1.202.4):  (Greek: ; English: 'Sea of Atlas' or 'the Atlantic sea') where the name refers to \"the sea beyond the pillars of Heracles\" which is said to be part of the sea that surrounds all land. In these uses, the name refers to Atlas, the Titan in Greek mythology, who supported the heavens and who later appeared as a frontispiece in Medieval maps and also lent his name to modern atlases. On the other hand, to early Greek sailors and in Ancient Greek mythological literature such as the Iliad and the Odyssey, this all-encompassing ocean was instead known as Oceanus, the gigantic river that encircled the world; in contrast to the enclosed seas well known to the Greeks: the Mediterranean and the Black Sea. In contrast, the term \"Atlantic\" originally referred specifically to the Atlas Mountains in Morocco and the sea off the Strait of Gibraltar and the North African coast. The Greek word  has been reused by scientists for the huge Panthalassa ocean that surrounded the supercontinent Pangaea hundreds of millions of years ago.\n\nThe term \"Aethiopian Ocean\", derived from Ancient Ethiopia, was applied to the Southern Atlantic as late as the mid-19th century. During the Age of Discovery, the Atlantic was also known to English cartographers as the Great Western Ocean.\n\nThe pond is a term often used by British and American speakers in reference to the Northern Atlantic Ocean, as a form of meiosis, or ironic understatement. It is used mostly when referring to events or circumstances \"on this side of the pond\" or \"on the other side of the pond\", rather than to discuss the ocean itself. The term dates to 1640, first appearing in print in pamphlet released during the reign of Charles I, and reproduced in 1869 in Nehemiah Wallington's Historical Notices of Events Occurring Chiefly in The Reign of Charles I, where \"great Pond\" is used in reference to the Atlantic Ocean by Francis Windebank, Charles I's Secretary of State.\n\nExtent and data \n\nThe International Hydrographic Organization (IHO) defined the limits of the oceans and seas in 1953, but some of these definitions have been revised since then and some are not used by various authorities, institutions, and countries, see for example the CIA World Factbook. Correspondingly, the extent and number of oceans and seas vary.\n\nThe Atlantic Ocean is bounded on the west by North and South America. It connects to the Arctic Ocean through the Denmark Strait, Greenland Sea, Norwegian Sea and Barents Sea. To the east, the boundaries of the ocean proper are Europe: the Strait of Gibraltar (where it connects with the Mediterranean Sea\u2014one of its marginal seas\u2014and, in turn, the Black Sea, both of which also touch upon Asia) and Africa.\n\nIn the southeast, the Atlantic merges into the Indian Ocean. The 20\u00b0 East meridian, running south from Cape Agulhas to Antarctica defines its border. In the 1953 definition it extends south to Antarctica, while in later maps it is bounded at the 60\u00b0 parallel by the Southern Ocean.\n\nThe Atlantic has irregular coasts indented by numerous bays, gulfs and seas. These include the Baltic Sea, Black Sea, Caribbean Sea, Davis Strait, Denmark Strait, part of the Drake Passage, Gulf of Mexico, Labrador Sea, Mediterranean Sea, North Sea, Norwegian Sea, almost all of the Scotia Sea, and other tributary water bodies. Including these marginal seas the coast line of the Atlantic measures  compared to  for the Pacific.\n\nIncluding its marginal seas, the Atlantic covers an area of  or 23.5% of the global ocean and has a volume of  or 23.3% of the total volume of the earth's oceans. Excluding its marginal seas, the Atlantic covers  and has a volume of. The North Atlantic covers  (11.5%) and the South Atlantic  (11.1%). The average depth is  and the maximum depth, the Milwaukee Deep in the Puerto Rico Trench, is.\n\nBiggest seas in Atlantic Ocean\nTop large seas:\n\n Sargasso Sea - 3.5 million km2\n Caribbean Sea - 2.754 million km2\n Mediterranean Sea - 2.510 million km2\n Gulf of Guinea - 2.35 million km2\n Gulf of Mexico - 1.550 million km2\n Norwegian Sea - 1.383 million km2\n Hudson Bay - 1.23 million km2\n Greenland Sea - 1.205 million km2\n Argentine Sea - 1 million km2\n Labrador Sea - 841,000\u00a0km2\n Irminger Sea - 780,000\u00a0km2\n Baffin Bay - 689,000\u00a0km2\n North Sea - 575,000\u00a0km2\n Black Sea - 436,000\u00a0km2\n Baltic Sea - 377,000\u00a0km2\n Libyan Sea - 350,000\u00a0km2\n Levantine Sea - 320,000\u00a0km2\n Celtic Sea - 300,000\u00a0km2\n Tyrrhenian Sea - 275,000\u00a0km2\n Gulf of Saint Lawrence - 226,000\u00a0km2\n Bay of Biscay - 223,000\u00a0km2\n Aegean Sea - 214,000\u00a0km2\n Ionian Sea - 169,000\u00a0km2\n Balearic Sea - 150,000\u00a0km2\n Adriatic Sea - 138,000\u00a0km2\n Gulf of Bothnia - 116,300\u00a0km2\n Sea of Crete - 95,000\u00a0km2\n Gulf of Maine - 93,000\u00a0km2\n Ligurian Sea - 80,000\u00a0km2\n English Channel - 75,000\u00a0km2\n James Bay - 68,300\u00a0km2\n Bothnian Sea - 66,000\u00a0km2\n Gulf of Sidra - 57,000\u00a0km2\n Sea of the Hebrides - 47,000\u00a0km2\n Irish Sea - 46,000\u00a0km2\n Sea of Azov - 39,000\u00a0km2\n Bothnian Bay - 36,800\u00a0km2\n Gulf of Venezuela - 17,840\u00a0km2\n Bay of Campeche - 16,000\u00a0km2\n Gulf of Lion - 15,000\u00a0km2\n Sea early October, the Rockies prospects of Marmara - 11,350\u00a0km2\n Wadden Sea - 10,000\u00a0km2\n Archipelago Sea - 8,300\u00a0km2\n\nBathymetry \n\nThe bathymetry of the Atlantic is dominated by a submarine mountain range called the Mid-Atlantic Ridge (MAR). It runs from 87\u00b0N or  south of the North Pole to the subantarctic Bouvet Island at 54\u00b0S.\n\nMid-Atlantic Ridge \n\nThe MAR divides the Atlantic longitudinally into two halves, in each of which a series of basins are delimited by secondary, transverse ridges. The MAR reaches above  along most of its length, but is interrupted by larger transform faults at two places: the Romanche Trench near the Equator and the Gibbs Fracture Zone at 53\u00b0N. The MAR is a barrier for bottom water, but at these two transform faults deep water currents can pass from one side to the other.\n\nThe MAR rises  above the surrounding ocean floor and its rift valley is the divergent boundary between the North American and Eurasian plates in the North Atlantic and the South American and African plates in the South Atlantic. The MAR produces basaltic volcanoes in Eyjafjallaj\u00f6kull, Iceland, and pillow lava on the ocean floor. The depth of water at the apex of the ridge is less than  in most places, while the bottom of the ridge is three times as deep.\n\nThe MAR is intersected by two perpendicular ridges: the Azores\u2013Gibraltar Transform Fault, the boundary between the Nubian and Eurasian plates, intersects the MAR at the Azores Triple Junction, on either side of the Azores microplate, near the 40\u00b0N. A much vagu", "flag": 1, "segments": [[1629, 1635]], "strength": 5.5}
{"token_count": [2006], "text": "Arthur Schopenhauer (, ; 22 February 1788\u00a0\u2013 21 September 1860) was a German philosopher. He is best known for his 1818 work The World as Will and Representation (expanded in 1844), which characterizes the phenomenal world as the product of a blind noumenal will. Building on the transcendental idealism of Immanuel Kant, Schopenhauer developed an atheistic metaphysical and ethical system that rejected the contemporaneous ideas of German idealism. He was among the first thinkers in Western philosophy to share and affirm significant tenets of Indian philosophy, such as asceticism, denial of the self, and the notion of the world-as-appearance. His work has been described as an exemplary manifestation of philosophical pessimism.\n\nThough his work failed to garner substantial attention during his lifetime, Schopenhauer had a posthumous impact across various disciplines, including philosophy, literature, and science. His writing on aesthetics, morality, and psychology have influenced many thinkers and artists. Those who have cited his influence include philosophers Emil Cioran, Friedrich Nietzsche and Ludwig Wittgenstein, scientists Erwin Schr\u00f6dinger and Albert Einstein, psychoanalysts Sigmund Freud and Carl Jung, writers Leo Tolstoy, Herman Melville, Thomas Mann, Hermann Hesse, Machado de Assis, Jorge Luis Borges, Marcel Proust and Samuel Beckett, and composers Richard Wagner, Johannes Brahms, Arnold Schoenberg and Gustav Mahler.\n\nLife\n\nEarly life \n\nArthur Schopenhauer was born on February 22, 1788, in Danzig (then part of the Polish\u2013Lithuanian Commonwealth; present-day Gda\u0144sk, Poland) on Heiligegeistgasse (present day \u015aw. Ducha 47), the son of Johanna Schopenhauer (n\u00e9e Trosiener; 1766\u20131838) and Heinrich Floris Schopenhauer (1747\u20131805), both descendants of wealthy German-Dutch patrician families. Neither of them was very religious; both supported the French Revolution, and were republicans, cosmopolitans and Anglophiles. When Danzig became part of Prussia in 1793, Heinrich moved to Hamburg\u2014a free city with a republican constitution. His firm continued trading in Danzig where most of their extended families remained. Adele, Arthur's only sibling, was born on July 12, 1797.\n\nIn 1797, Arthur was sent to Le Havre to live with the family of his father's business associate, Gr\u00e9goire de Bl\u00e9simaire. He seemed to enjoy his two-year stay there, learning to speak French and fostering a life-long friendship with Jean Anthime Gr\u00e9goire de Bl\u00e9simaire. As early as 1799, Arthur started playing the flute. In 1803, he accompanied his parents on a European tour of Holland, Britain, France, Switzerland, Austria and Prussia. Viewed as primarily a pleasure tour, Heinrich used the opportunity to visit some of his business associates abroad.\n\nHeinrich offered Arthur a choice:  he could stay at home and start preparations for university, or he could travel with them and continue his merchant education. Arthur chose to travel with them.  He deeply regretted his choice later because the merchant training was very tedious. He spent twelve weeks of the tour attending school in Wimbledon, where he was disillusioned by strict and intellectually shallow Anglican religiosity.  He continued to sharply criticize Anglican religiosity later in life despite his general Anglophilia. He was also under pressure from his father, who became very critical of his educational results.\n\nIn 1805, Heinrich drowned in a canal near their home in Hamburg. Although it was possible that his death was accidental, his wife and son believed that it was suicide. He was prone to anxiety and depression; each becoming more pronounced later in his life. Heinrich had become so fussy, even his wife started to doubt his mental health. \"There was, in the father's life, some dark and vague source of fear which later made him hurl himself to his death from the attic of his house in Hamburg.\"\n\nArthur showed similar moodiness during his youth and often acknowledged that he inherited it from his father. There were other instances of serious mental health history on his father's side of the family. Despite his hardship, Schopenhauer liked his father and later referred to him in a positive light. Heinrich Schopenhauer left the family with a significant inheritance that was split in three among Johanna and the children. Arthur Schopenhauer was entitled to control of his part when he reached the age of majority. He invested it conservatively in government bonds and earned annual interest that was more than double the salary of a university professor. After quitting his merchant apprenticeship, with some encouragement from his mother, he dedicated himself to studies at the Ernestine Gymnasium, Gotha, in Saxe-Gotha-Altenburg. While there, he also enjoyed social life among the local nobility, spending large amounts of money, which deeply concerned his a real force for good. frugal mother. He left the Gymnasium after writing a satirical poem about one of the schoolmasters. Although Arthur claimed that he left voluntarily, his mother's letter indicates that he may have been expelled.\n\nArthur spent two years as a merchant in honor of his dead father.  During this time, he had doubts about being able to start a new life as a scholar. Most of his prior education was as a practical merchant and he had trouble learning Latin; a prerequisite for an academic career.\n\nHis mother moved away, with her daughter Adele, to Weimar\u2014the then centre of German literature\u2014to enjoy social life among writers and artists. Arthur and his mother did not part on good terms. In one letter, she wrote: \"You are unbearable and burdensome, and very hard to live with; all your good qualities are overshadowed by your conceit, and made useless to the world simply because you cannot restrain your propensity to pick holes in other people.\" His mother, Johanna, was generally described as vivacious and sociable.  After they split, they did not meet again. She died 24 years later. Some of Arthur's negative opinions about women may be rooted in his troubled relationship with his mother.\n\nArthur moved to Hamburg to live with his friend Jean Anthime, who was also studying to become a merchant.\n\nEducation \nHe moved to Weimar but did not live with his mother, who even tried to discourage him from coming by explaining that they would not get along very well. Their relationship deteriorated even further due to their temperamental differences. He accused his mother of being financially irresponsible, flirtatious and seeking to remarry, which he considered an insult to his father's memory. His mother, while professing her love to him, criticized him sharply for being moody, tactless, and argumentative, and urged him to improve his behavior so that he would not alienate people. Arthur concentrated on his studies, which were now going very well, and he also enjoyed the usual social life such as balls, parties and theater. By that time Johanna's famous salon was well established among local intellectuals and dignitaries, the most celebrated of them being Goethe. Arthur attended her parties, usually when he knew that Goethe would be there\u2014although the famous writer and statesman seemed not even to notice the young and unknown student. It is possible that Goethe kept a distance because Johanna warned him about her son's depressive and combative nature, or because Goethe was then on bad terms with Arthur's language instructor and roommate, Franz Passow. Schopenhauer was also captivated by the beautiful Karoline Jagemann, mistress of Karl August, Grand Duke of Saxe-Weimar-Eisenach, and he wrote to her his only known love poem. Despite his later celebration of asceticism and negative views of sexuality, Schopenhauer occasionally had sexual affairs\u2014usually with women of lower social status, such as servants, actresses, and sometimes even paid prostitutes. In a letter to his friend Anthime he claims that such affairs continued even in his mature age and admits that he had two out-of-wedlock daughters (born in 1819 and 1836), both of whom died in infancy. In their youthful correspondence Arthur and Anthime were somewhat boastful and competitive about their sexual exploits\u2014but Schopenhauer seemed aware that women usually did not find him very charming or physically attractive, and his desires often remained unfulfilled.\n\nHe left Weimar to become a student at the University of G\u00f6ttingen in 1809. There are no written reasons about why Schopenhauer chose that university instead of the then more famous University of Jena, but G\u00f6ttingen was known as more modern and scientifically oriented, with less attention given to theology. Law or medicine were usual choices for young men of Schopenhauer's status who also needed career and income; he chose medicine due to his scientific interests. Among his notable professors were Bernhard Friedrich Thibaut, Arnold Hermann Ludwig Heeren, Johann Friedrich Blumenbach, Friedrich Stromeyer, Heinrich Adolf Schrader, Johann Tobias Mayer and Konrad Johann Martin Langenbeck. He studied metaphysics, psychology and logic under Gottlob Ernst Schulze, the author of Aenesidemus, who made a strong impression and advised him to concentrate on Plato and Immanuel Kant. He decided to switch from medicine to philosophy around 1810\u201311 and he left G\u00f6ttingen", "flag": 1, "segments": [[1072, 1078]], "strength": 5.5}
{"token_count": [2006], "text": "Angola (; ), officially the Republic of Angola (), is a country on the west coast of Southern Africa. It is the second-largest Lusophone (Portuguese-speaking) country in both total area and population (behind Brazil), and is the seventh-largest country in Africa. It is bordered by Namibia to the south, the DR Congo to the north, Zambia to the east, and the Atlantic Ocean to the west. Angola has an exclave province, the province of Cabinda, that borders the Republic of the Congo and the Democratic Republic of the Congo. The capital and most populated city is Luanda.\n\nAngola has been inhabited since the Paleolithic Age. Its formation as a nation-state originates from Portuguese colonisation, which initially began with coastal settlements and trading posts founded in the 16th century. In the 19th century, European settlers gradually began to establish themselves in the interior. The Portuguese colony that became Angola did not have its present borders until the early 20th century, owing to resistance by native groups such as the Cuamato, the Kwanyama and the Mbunda.\n\nAfter a protracted anti-colonial struggle, Angola achieved independence in 1975 as a Marxist\u2013Leninist one-party Republic. The country descended into a devastating civil war the same year, between the ruling People's Movement for the Liberation of Angola (MPLA), backed by the Soviet Union and Cuba, the insurgent anti-communist National Union for the Total Independence of Angola (UNITA), supported by the United States and South Africa, and the militant organisation National Liberation Front of Angola (FNLA), backed by the Democratic Republic of the Congo. The country has been governed by MPLA ever since its independence in 1975. Following the end of the war in 2002, Angola emerged as a relatively stable unitary, presidential constitutional republic.\n\nAngola has vast mineral and petroleum reserves, and its economy is among the fastest-growing in the world, especially since the end of the civil war; however, economic growth is highly uneven, with most of the nation's wealth concentrated in a disproportionately small sector of the population and highly concentrated in China and in the United States. The standard of living remains low for most Angolans; life expectancy is among the lowest in the world, while infant mortality is among the highest. \nSince 2017, the government of Jo\u00e3o Louren\u00e7o has made fighting corruption its flagship, so much so that many individuals of the previous government are either jailed or awaiting trial. Whilst this effort has been recognised by foreign diplomats to be legitimate, some skeptics see the actions as being politically motivated.\n\nAngola is a member of the United Nations, OPEC, African Union, the Community of Portuguese Language Countries, and the Southern African Development Community. As of 2021, the Angolan population is estimated at 32.87 million. Angola is multicultural and multiethnic. Angolan culture reflects centuries of Portuguese rule, namely the predominance of the Portuguese language and of the Catholic Church, intermingled with a variety of indigenous customs and traditions.\n\nEtymology\nThe name Angola comes from the Portuguese colonial name  ('Kingdom of Angola'), which appeared as early as Paulo Dias de Novais's 1571 charter. The toponym was derived by the Portuguese from the title  held by the kings of Ndongo and Matamba. Ndongo in the highlands, between the Kwanza and Lucala Rivers, was nominally a possession of the Kingdom of Kongo, but was seeking greater independence in the 16th century.\n\nHistory\n\nEarly migrations and political units\n\nModern Angola was populated predominantly by nomadic Khoi and San prior to the first Bantu migrations. The Khoi and San peoples were neither pastoralists nor cultivators, but rather hunter-gatherers. They were displaced by Bantu peoples arriving from the north in the first millennium BC, most of whom likely originated in what is today northwestern Nigeria and southern Niger. Bantu speakers introduced the cultivation of bananas and taro, as well as large cattle herds, to Angola's central highlands and the Luanda plain.\n\nA number of political entities were established; the best-known of these was the Kingdom of the Kongo, based in Angola, which extended northward to what is now the Democratic Republic of the Congo, the Republic of the Congo and Gabon. It established trade routes with other city-states and civilisations up to and down the coast of southwestern and western Africa and even with Great Zimbabwe and the Mutapa Empire, although it engaged in little or no transoceanic trade. To its south lay the Kingdom of Ndongo, from which the area of the later Portuguese colony was sometimes known as Dongo, and right next to them lay the Kingdom of Matamba.\n\nPortuguese colonization\n\nPortuguese explorer Diogo C\u00e3o reached the area in 1484. The previous year, the Portuguese had established relations with the Kongo, which stretched at the time from modern Gabon in the north to the Kwanza River in the south. The Portuguese established their primary early trading post at Soyo, which is now the northernmost city in Angola apart from the Cabinda exclave. Paulo Dias de Novais founded S\u00e3o Paulo de Loanda (Luanda) in 1575 with a hundred families of settlers and four hundred soldiers. Benguela was fortified in 1587 and became a township in 1617.\n\nThe Portuguese established several other settlements, forts and trading posts along the Angolan coast, principally trading in Angolan slaves for plantations. Local slave dealers provided a large number of slaves for the Portuguese Empire, usually in exchange for manufactured goods from Europe.\n\nThis part of the Atlantic slave trade continued until after Brazil's independence in the 1820s.\n\nDespite Portugal's territorial claims in Angola, its control over much of the country's vast interior was minimal. In the 16th century Portugal gained control of the coast through a series of treaties and wars. Life for European colonists was difficult and progress was slow. John Iliffe notes that \"Portuguese records of Angola from the 16th century show that a great famine occurred on average every seventy years; accompanied by epidemic disease, it might kill one-third or one-half of the population, destroying the demographic growth of a generation and forcing colonists back into the river valleys\".\n\nDuring the Portuguese Restoration War, the Dutch West India Company occupied the principal settlement of Luanda in 1641, using alliances with local peoples to carry out attacks against Portuguese holdings elsewhere. A fleet under Salvador de S\u00e1 retook Luanda in 1648; reconquest of the rest of the territory was completed by 1650. New treaties with the Kongo were signed in 1649; others with Njinga's Kingdom of Matamba and Ndongo followed in 1656. The conquest of Pungo Andongo in 1671 was the last major Portuguese expansion from Luanda, as attempts to invade Kongo in 1670 and Matamba in 1681 failed. Colonial outposts also expanded inward from Benguela, but until the late 19th century the inroads from Luanda and Benguela were very limited. Hamstrung by a series of political upheavals in the early 1800s, Portugal was slow to mount a large scale annexation of Angolan territory.\n\nThe slave trade was abolished in Angola in 1836, and in 1854 the colonial government freed all its existing slaves. Four years later, a more progressive administration appointed by Portugal abolished slavery altogether. However, these decrees remained largely unenforceable, and the Portuguese depended on assistance from the British Royal Navy to enforce their ban on the slave trade. This coincided with a series of renewed military expeditions into the bush.\n\nBy the mid-nineteenth century Portugal had established its dominion as far north as the Congo River and as far south as Moss\u00e2medes. Until the late 1880s, Portugal entertained proposals to link Angola with its colony in Mozambique but was blocked by British and Belgian opposition. In this period, the Portuguese came up against different forms of armed resistance from various peoples in Angola.\n\nThe Berlin Conference in 1884\u20131885 set the colony's borders, delineating the boundaries of Portuguese claims in Angola, although many details were unresolved until the 1920s. Trade between Portugal and its African territories rapidly increased as a result of protective tariffs, leading to increased development, and a wave of new Portuguese immigrants.\n\nAngolan independence\n\nUnder colonial law, black Angolans were forbidden from forming political parties or labour unions. The first nationalist movements did not take root until after World new orders which the United States War II, spearheaded by a largely Westernised and Portuguese-speaking urban class, which included many mesti\u00e7os. During the early 1960s they were joined by other associations stemming from ad hoc labour activism in the rural workforce. Portugal's refusal to address increasing Angolan demands for self-determination provoked an armed conflict, which erupted in 1961 with the Baixa de Cassanje revolt and gradually evolved into a protracted war of independence that persisted for the next twelve years. Throughout the conflict, three militant nationalist movements with their own partisan guerrilla wings emerged from the fighting between the Portuguese government and local forces, supported to varying degrees by the Portuguese Communist Party.\n\nThe National Front for the Liberation of Angola (FNLA) recruited from Bakongo refugees in Zaire. Benefiting from particularly favourable political circumstances in L\u00e9opoldville, and especially from a common border with Zaire, Angolan political exiles were able to build up a power base among a large expatriate community from related families, clans, and traditions. People on both sides of the border spoke mutually intelligible", "flag": 1, "segments": [[1781, 1787]], "strength": 5.5}
{"token_count": [2006], "text": "Alberta ( ) is one of the thirteen provinces and territories of Canada. It is part of Western Canada and is one of the three prairie provinces. Alberta is bordered by British Columbia to the west, Saskatchewan to the east, the Northwest Territories (NWT) to the north, and the U.S. state of Montana to the south. It is one of the only two landlocked provinces in Canada. The eastern part of the province is occupied by the Great Plains, while the western part borders the Rocky Mountains. The province has a predominantly continental climate but experiences quick temperature changes due to air aridity. Seasonal temperature swings are less pronounced in western Alberta due to occasional chinook winds.\n\nAlberta is the 4th largest province by area at, and the 4th most populous, being home to 4,262,635 people. Alberta's capital is Edmonton, while Calgary is its largest city. The two are Alberta's largest census metropolitan areas (CMAs) and both exceed one million people. More than half of Albertans live in either Edmonton or Calgary, which contributes to continuing the rivalry between the two cities. English is the official language of the province. In 2016, 76.0% of Albertans were anglophone, 1.8% were francophone and 22.2% were allophone.\n\nThe oil and gas industry is also a part of the province's identity. Alberta's economy is based on hydrocarbons, petrochemical industries, livestock, agriculture and frontier technologies. The oil industry has been a pillar of Alberta's economy since 1947, when substantial oil deposits were discovered at Leduc No. 1 well. Since Alberta is the province most rich in hydrocarbons, it provides 70% of the oil and natural gas exploited on Canadian soil. In 2018, Alberta's output was CDN$338.2 billion, 15.27% of Canada's GDP.\n\nIn the past, Alberta's political landscape hosted parties like the left-wing Liberals and the agrarian United Farmers of Alberta. Today, Alberta is generally perceived as a conservative province. The right-wing Social Credit Party held office continually from 1935 to 1971 before the centre-right Progressive Conservatives held office continually from 1971 to 2015, the latter being the longest unbroken run in government at the provincial or federal level in Canadian history.\n\nBefore becoming part of Canada, Alberta was home to several First Nations and was a territory used by fur traders of the Hudson's Bay Company. Canada acquired the lands that would become Alberta as part of the NWT on July 15, 1870. On September 1, 1905, Alberta was separated from the NWT as a result of the Alberta Act and designated the 8th province of Canada. From the late 1800s to early 1900s, many immigrants arrived, the biggest wave of which was pushed by Wilfrid Laurier, to prevent the prairies from being annexed by the United States. Massive oil resources were discovered in Alberta in 1947.\n\nAlberta is renowned for its natural beauty, richness in fossils and for housing important nature reserves. Alberta is home to six UNESCO designated World Heritage Sites: The Canadian Rocky Mountain Parks, Dinosaur Provincial Park, the Head-Smashed-In Buffalo Jump, Waterton-Glacier International Peace Park, Wood Buffalo National Park and Writing-on-Stone Provincial Park. Other popular sites include Banff National Park, Elk Island National Park, Jasper National Park, Waterton Lakes National Park, and Drumheller.\n\nEtymology\nAlberta was named after Princess Louise Caroline Alberta (1848\u20131939), the fourth daughter of Queen Victoria. Princess Louise was the wife of John Campbell, Marquess of Lorne, Governor General of Canada (1878\u201383). Lake Louise and Mount Alberta were also named in her honour.\n\nThe name \"Alberta\" itself is a feminine Latinized form of Albert, the name of Princess Louise's father, the Prince Consort (, masculine) and its Germanic cognates, ultimately derived from the Proto-Germanic language *A\u00fealaberhtaz (compound of \"noble\" + \"bright/famous\").\n\nGeography\n\nAlberta, with an area of, is the fourth-largest province after Quebec, Ontario and British Columbia.\n\nAlberta's southern border is the 49th parallel north, which separates it from the U.S. state of Montana. The 60th parallel north divides Alberta from the Northwest Territories. The 110th meridian west separates it from the province of Saskatchewan; while on the west its boundary with British Columbia follows the 120th meridian west south from the Northwest Territories at 60\u00b0N until it reaches the Continental Divide at the Rocky Mountains, and from that point follows the line of peaks marking the Continental Divide in a generally southeasterly direction until it reaches the Montana border at 49\u00b0N.\n\nThe province extends  north to south and  east to west at its maximum width. Its highest point is  at the summit of Mount Columbia in the Rocky Mountains along the southwest border while its lowest point is  on the Slave River in Wood Buffalo National Park in the northeast.\n\nWith the exception of the semi-arid climate of the steppe in the south-eastern section, the province has adequate water resources. There are numerous rivers and lakes in Alberta used for swimming, fishing and a range of water sports. There are three large lakes, Lake Claire () in Wood Buffalo National Park, Lesser Slave Lake (), and Lake Athabasca (), which lies in both Alberta and Saskatchewan. The longest river in the province is the Athabasca River, which travels  from the Columbia Icefield in the Rocky Mountains to Lake Athabasca.\n\nThe largest river is the Peace River with an average flow of. The Peace River originates in the Rocky Mountains of northern British Columbia and flows through northern Alberta and into the Slave River, a tributary of the Mackenzie River.\n\nAlberta's capital city, Edmonton, is located at about the geographic centre of the province. It is the most northerly major city in Canada and serves as a gateway and hub for resource development in northern Canada. With its proximity to Canada's largest oil fields, the region has most of western Canada's oil refinery capacity. Calgary is about  south of Edmonton and  north of Montana, surrounded by extensive ranching country. Almost 75% of the province's population lives in the Calgary\u2013Edmonton Corridor. The land grant policy to the railways served as a means to populate the province in its early years.\n\nMost of the northern half of the province is boreal forest, while the Rocky Mountains along the southwestern boundary are largely temperate coniferous his \"State Of United States forests of the Alberta Mountain forests and Alberta\u2013British Columbia foothills forests. The southern quarter of the province is prairie, ranging from shortgrass prairie in the southeastern corner to mixed grass prairie in an arc to the west and north of it. The central aspen parkland region extending in a broad arc between the prairies and the forests, from Calgary, north to Edmonton, and then east to Lloydminster, contains the most fertile soil in the province and most of the population. Much of the unforested part of Alberta is given over either to grain or to dairy farming, with mixed farming more common in the north and centre, while ranching and irrigated agriculture predominate in the south.\n\nThe Alberta badlands are located in southeastern Alberta, where the Red Deer River crosses the flat prairie and farmland, and features deep canyons and striking landforms. Dinosaur Provincial Park, near Brooks, showcases the badlands terrain, desert flora, and remnants from Alberta's past when dinosaurs roamed the then lush landscape.\n\nClimate \n\nAlberta extends for over  from north to south; its climate, therefore, varies considerably. Average high temperatures in January range from  in the southwest to  in the far north. The presence of the Rocky Mountains also influences the climate to the southwest, which disrupts the flow of the prevailing westerly winds and cause them to drop most of their moisture on the western slopes of the mountain ranges before reaching the province, casting a rain shadow over much of Alberta. The northerly location and isolation from the weather systems of the Pacific Ocean cause Alberta to have a dry climate with little moderation from the ocean. Annual precipitation ranges from  in the southeast to  in the north, except in the foothills of the Rocky Mountains where total precipitation including snowfall can reach  annually.\n\nNorthern Alberta is mostly covered by boreal forest and has a subarctic climate. The agricultural area of southern Alberta has a semi-arid steppe climate because the annual precipitation is less than the water that evaporates or is used by plants. The southeastern corner of Alberta, part of the Palliser Triangle, experiences greater summer heat and lower rainfall than the rest of the province, and as a result, suffers frequent crop yield problems and occasional severe droughts. Western Alberta is protected by the mountains and enjoys the mild temperatures brought by winter chinook winds. Central and parts of northwestern Alberta in the Peace River region are largely aspen parkland, a biome transitional between prairie to the south and boreal forest to the north.\n\nAlberta has a humid continental climate with warm summers and cold winters. The province is open to cold Arctic weather systems from the north, which often produce cold winter conditions. As the fronts between the air masses shift north and south across Alberta, the temperature can change rapidly. Arctic air masses in the winter produce extreme minimum temperatures varying from  in northern Alberta to  in southern Alberta, although temperatures at these extremes are rare.\n\nIn the summer, continental air masses have produced record maximum temperatures from  in", "flag": 1, "segments": [[1373, 1379]], "strength": 5.5}
{"token_count": [2006], "text": "Albert Einstein ( ; ; 14 March 1879\u00a0\u2013 18 April 1955) was a German-born theoretical physicist, widely acknowledged to be one of the greatest physicists of all time. Einstein is best known for developing the theory of relativity, but he also made important contributions to the development of the theory of quantum mechanics. Relativity and quantum mechanics are together the two pillars of modern physics. His mass\u2013energy equivalence formula, which arises from relativity theory, has been dubbed \"the world's most famous equation\". His work is also known for its influence on the philosophy of science. He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His intellectual achievements and originality resulted in \"Einstein\" becoming synonymous with \"genius\".\n\nIn 1905, a year sometimes described as his annus mirabilis ('miracle year'), Einstein published four groundbreaking papers. These outlined the theory of the photoelectric effect, explained Brownian motion, introduced special relativity, and demonstrated mass-energy equivalence. Einstein thought that the laws of classical mechanics could no longer be reconciled with those of the electromagnetic field, which led him to develop his special theory of relativity. He then extended the theory to gravitational fields; he published a paper on general relativity in 1916, introducing his theory of gravitation. In 1917, he applied the general theory of relativity to model the structure of the universe. He continued to deal with problems of statistical mechanics and quantum theory, which led to his explanations of particle theory and the motion of molecules. He also investigated the thermal properties of light and the quantum theory of radiation, which laid the foundation of the photon theory of light. \n\nHowever, for much of the later part of his career, he worked on two ultimately unsuccessful endeavors. First, despite his great contributions to quantum mechanics, he opposed what it evolved into, objecting that nature \"does not play dice\". Second, he attempted to devise a unified field theory by generalizing his geometric theory of gravitation to include electromagnetism. As a result, he became increasingly isolated from the mainstream of modern physics.\n\nEinstein was born in the German Empire, but moved to Switzerland in 1895, forsaking his German citizenship (as a subject of the Kingdom of W\u00fcrttemberg) the following year. In 1897, at the age of 17, he enrolled in the mathematics and physics teaching diploma program at the Swiss Federal polytechnic school in Z\u00fcrich, graduating in 1900. In 1901, he acquired Swiss citizenship, which he kept for the rest of his life, and in 1903 he secured a permanent position at the Swiss Patent Office in Bern. In 1905, he was awarded a PhD by the University of Zurich. In 1914, Einstein moved to Berlin in order to join the Prussian Academy of Sciences and the Humboldt University of Berlin. In 1917, Einstein became director of the Kaiser Wilhelm Institute for Physics; he also became a German citizen again, this time Prussian.\n\nIn 1933, while Einstein was visiting the United States, Adolf Hitler came to power in Germany. Einstein, of Jewish origin, objected to the policies of the newly elected Nazi government; he settled in the United States and became an American citizen in 1940. On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential German nuclear weapons program and recommending that the US begin similar research. Einstein supported the Allies but generally denounced the idea of nuclear weapons.\n\nLife and career\n\nEarly life and education \n\nAlbert Einstein was born in Ulm, in the Kingdom of W\u00fcrttemberg in the German Empire, on 14 March 1879 into a family of secular Ashkenazi Jews. His parents were Hermann Einstein, a salesman and engineer, and Pauline Koch. In 1880, the family moved to Munich, where Einstein's father and his uncle Jakob founded Elektrotechnische Fabrik J. Einstein & Cie, a company that manufactured electrical equipment based on direct current.\n\nAlbert attended a Catholic elementary school in Munich, from the age of five, for three years. At the age of eight, he was transferred to the Luitpold Gymnasium (now known as the Albert Einstein Gymnasium), where he received advanced primary and secondary school education until he left the German Empire seven years later.\n\nIn 1894, Hermann and Jakob's company lost a bid to supply the city of Munich with electrical lighting because they lacked the capital to convert their equipment from the direct current (DC) standard to the more efficient alternating current (AC) standard. The loss forced the sale of the Munich factory. In search of business, the Einstein family moved to Italy, first to Milan and a few months later to Pavia. When the family moved to Pavia, Einstein, then 15, stayed in Munich to finish his studies at the Luitpold Gymnasium. His father intended for him to pursue electrical engineering, but Einstein clashed with the authorities and resented the school's regimen and teaching method. He later wrote that the spirit of learning and creative thought was lost in strict rote learning. At the end of December 1894, he traveled to Italy to join his family in Pavia, convincing the school to let him go by using a doctor's note. During his time in Italy he wrote a short essay with the title \"On the Investigation of the State of the Ether in a Magnetic Field\".\n\nEinstein excelled at math and physics from a young age, reaching a mathematical level years ahead of his peers. The 12-year-old Einstein taught himself algebra and Euclidean geometry over a single summer. Einstein also independently discovered his own original proof of the Pythagorean theorem at age 12. A family tutor Max Talmud says that after he had given the 12-year-old Einstein a geometry textbook, after a short time \"[Einstein] had worked through the whole book. He thereupon devoted himself to higher mathematics... Soon the flight of his mathematical genius was so high I could not follow.\" His passion for geometry and algebra led the 12-year-old to become convinced that nature could be understood as a \"mathematical structure\". Einstein started teaching himself calculus at 12, and as a 14-year-old he says he had \"mastered integral and differential calculus\".\n\nAt age 13, when he had become more seriously interested in philosophy (and music), Einstein was introduced to Kant's Critique of Pure Reason. Kant became his favorite philosopher, his tutor stating: \"At the time he was still a child, only thirteen years old, yet Kant's works, incomprehensible to ordinary mortals, seemed to be clear to him.\"\n\nIn 1895, at the age of 16, Einstein took the entrance examinations for the Swiss Federal polytechnic school in Z\u00fcrich (later the Eidgen\u00f6ssische Technische Hochschule, ETH). He failed to reach the required standard in the general part of the examination, but obtained exceptional grades in physics and mathematics. On the advice of the principal of the polytechnic school, he attended the Argovian cantonal school (gymnasium) in West Point-Auburn Aarau, Switzerland, in 1895 and 1896 to complete his secondary schooling. While lodging with the family of Professor Jost Winteler, he fell in love with Winteler's daughter, Marie. Albert's sister Maja later married Winteler's son Paul. In January 1896, with his father's approval, Einstein renounced his citizenship in the German Kingdom of W\u00fcrttemberg to avoid military service. In September 1896 he passed the Swiss Matura with mostly good grades, including a top grade of 6 in physics and mathematical subjects, on a scale of 1\u20136. At 17, he enrolled in the four-year mathematics and physics teaching diploma program at the Federal polytechnic school. Marie Winteler, who was a year older, moved to Olsberg, Switzerland, for a teaching post.\n\nEinstein's future wife, a 20-year-old Serbian named Mileva Mari\u0107, also enrolled at the polytechnic school that year. She was the only woman among the six students in the mathematics and physics section of the teaching diploma course. Over the next few years, Einstein's and Mari\u0107's friendship developed into a romance, and they spent countless hours debating and reading books together on extra-curricular physics in which they were both interested. Einstein wrote in his letters to Mari\u0107 that he preferred studying alongside her. In 1900, Einstein passed the exams in Maths and Physics and was awarded a Federal teaching diploma. There is eyewitness evidence and several letters over many years that indicate Mari\u0107 might have collaborated with Einstein prior to his landmark 1905 papers, known as the Annus Mirabilis papers, and that they developed some of the concepts together during their studies, although some historians of physics who have studied the issue disagree that she made any substantive contributions.\n\nMarriages and children \n\nEarly correspondence between Einstein and Mari\u0107 was discovered and published in 1987 which revealed that the couple had a daughter named \"Lieserl\", born in early 1902 in Novi Sad where Mari\u0107 was staying with her parents. Mari\u0107 returned to Switzerland without the child, whose real name and fate are unknown. The contents of Einstein's letter in September 1903 suggest that the girl was either given up for adoption or died of scarlet fever in infancy.\n\nEinstein and Mari\u0107 married in January 1903. In May 1904, their son Hans Albert Einstein was born in Bern, Switzerland. Their son Eduard was born in Z\u00fcrich in July 1910. The couple moved to Berlin", "flag": 1, "segments": [[1489, 1495]], "strength": 5.5}
{"token_count": [2006], "text": "Afghanistan (), officially the Islamic Emirate of Afghanistan, is a landlocked country located at the crossroads of Central and South Asia. Referred to as the Heart of Asia it is bordered by Pakistan to the east and south, Iran to the west, Turkmenistan to the northwest, Uzbekistan to the north, Tajikistan to the northeast, and China to the northeast and east. Occupying  of land, the country is predominately mountainous with plains in the north and the southwest, which are separated by the Hindu Kush mountain range., its population is 40.2 million, composed mostly of ethnic Pashtuns, Tajiks, Hazaras, and Uzbeks. Kabul is the country's largest city and also serves as its capital.\n\nHuman habitation in Afghanistan dates back to the Middle Paleolithic era, and the country's strategic location along the historic Silk Road connected it to the cultures of other parts of Asia as well as Europe, leaving behind a mosaic of ethnolinguistic and religious groups that has influenced the modern Afghan nation. Known as the Graveyard of Empires the land has historically been home to various peoples and has witnessed numerous military campaigns, including those by Alexander the Great, the Maurya Empire, Arab Muslims, the Mongols, the British, the Soviet Union, and most recently by an American-led coalition. Afghanistan also served as the source from which the Greco-Bactrians and the Mughals, among others, rose to form major empires. The various conquests and periods in both the Iranian and Indian cultural spheres made the area a center for Zoroastrianism, Buddhism, Hinduism, and later Islam throughout history.\n\nThe modern state of Afghanistan began with the Durrani dynasty in the 18th century, with the Durrani Afghan Empire at its peak having spanned from eastern Iran to northern India. Following its decline and the death of Timur Shah, it was divided into the smaller independent kingdoms of Herat, Kandahar and Kabul, before being reunited in the 19th century after wars of unification led by Dost Mohammad Khan. During this time, Afghanistan became a buffer state in the Great Game between the British Empire (in British-ruled India) and the Russian Empire; from India, the British attempted to subjugate Afghanistan but were repelled in the First Anglo-Afghan War; however, the Second Anglo-Afghan War saw a British victory and the successful establishment of British political influence over Afghanistan. Following the Third Anglo-Afghan War in 1919, Afghanistan became free of foreign dominance, and eventually emerged as the independent Kingdom of Afghanistan in June 1926 under Amanullah Khan. This monarchy lasted almost 50 years, until Zahir Shah was overthrown in 1973, following which the Republic of Afghanistan was established. Since the late 1970s, Afghanistan's history has been dominated by extensive warfare, including coups, revolutions, invasions, insurgencies, and civil wars. The country is currently under the control of the Taliban, an Islamist political movement which returned to power in 2021 after a 20-year-long war with the United States and its allies.\n\nThe country has high levels of terrorism, poverty, and child malnutrition. Afghanistan's economy is the world's 96th-largest, with a gross domestic product (GDP) of $72.9\u00a0billion by purchasing power parity; the country fares much worse in terms of per-capita GDP (PPP), ranking 169th out of 186 countries.\n\nEtymology \n\nThe root name \"Afgh\u0101n\" is, according to some scholars, derived from the Sanskrit name of the A\u015bvakan or Assakan, ancient inhabitants of the Hindu Kush region. A\u015bvakan literally means \"horsemen\", \"horse breeders\", or \"cavalrymen\" (from a\u015bva or aspa, the Sanskrit and Avestan words for \"horse\"). Historically, the ethnonym Afgh\u0101n was used to refer to ethnic Pashtuns. The Arabic and Persian form of the name, Af\u0121\u0101n, was first attested in the 10th-century geography book Hudud al-'Alam. The last part of the name, \"-stan\" is a Persian suffix for \"place of\". Therefore, \"Afghanistan\" translates to \"land of the Afghans\", or \"land of the Pashtuns\" in a historical sense. According to the third edition of the Encyclopedia of Islam:\n\nHistory \n\nMany empires and kingdoms have also risen to power in Afghanistan, such as the Greco-Bactrians, Indo-Scythians, Kushans, Kidarites, Hephthalites, Alkhons, Nezaks, Zunbils, Turk Shahis, Hindu Shahis, Lawiks, Saffarids, Samanids, Ghaznavids, Ghurids, Khaljis, Kartids, Lodis, Surs, Mughals, and finally, the Hotak and Durrani dynasties, which marked the political origins of the modern state. Throughout millennia several cities within the modern day Afghanistan served as capitals of various empires, namely, Bactra (Balkh), Alexandria on the Oxus (Ai-Khanoum), Kapisi, Sigal, Kabul, Kunduz, Zaranj, Firozkoh, Herat, Ghazna (Ghazni), Binban (Bamyan), and Kandahar.\n\nThe country has been home to various peoples through the ages, among them the ancient Iranian peoples who established the dominant role of Indo-Iranian languages in the region. At multiple points, the land has been incorporated within vast regional empires; among them the Achaemenid Empire, the Macedonian Empire, the Maurya Empire, and the Islamic Empire. For its success in resisting foreign occupation during the 19th and 20th centuries, Afghanistan has been called the \"graveyard of empires\", though it is unknown who coined the phrase.\n\nPrehistory and antiquity\n\nExcavations of prehistoric sites suggest that humans were living in what is now Afghanistan at least 50,000 years ago, and that farming communities in the area were among the earliest in the world. An important site of early historical activities, many believe that Afghanistan compares to Egypt in terms of the historical value of its archaeological sites.\n\nAncient era\n\nArchaeological exploration done in the 20th century suggests that the geographical area of Afghanistan has been closely connected by culture and trade with its neighbors to the east, west, and north. Artifacts typical of the Paleolithic, Mesolithic, Neolithic, Bronze, and Iron Ages have been found in Afghanistan. Urban civilization is believed to have begun as early as 3000 BCE, and the early city of Mundigak (near Kandahar in the south of the country) funding of $8 billion a was a center of the Helmand culture. More recent findings established that the Indus Valley Civilization stretched up towards modern-day Afghanistan, making the ancient civilization today part of Pakistan, Afghanistan, and India. In more detail, it extended from what today is northwest Pakistan to northwest India and northeast Afghanistan. An Indus Valley site has been found on the Oxus River at Shortugai in northern Afghanistan. There are several smaller IVC colonies to be found in Afghanistan as well. An Indus Valley site has been found on the Oxus River at Shortugai in northern Afghanistan, shows Afghanistan to have been a part of Indus Valley Civilization.\n\nAfter 2000 BCE, successive waves of semi-nomadic people from Central Asia began moving south into Afghanistan; among them were many Indo-European-speaking Indo-Iranians. These tribes later migrated further into South Asia, Western Asia, and toward Europe via the area north of the Caspian Sea. The region at the time was referred to as Ariana.\n\nBy the middle of the 6th century BCE, the Achaemenids overthrew the Medes and incorporated Arachosia, Aria, and Bactria within its eastern boundaries. An inscription on the tombstone of Darius I of Persia mentions the Kabul Valley in a list of the 29 countries that he had conquered. The region of Arachosia, around Kandahar in modern-day southern Afghanistan, used to be primarily Zoroastrian and played a key role in the transfer of the Avesta to Persia and is thus considered by some to be the \"second homeland of Zoroastrianism\".\n\nAlexander the Great and his Macedonian forces arrived in Afghanistan in 330 BCE after defeating Darius III of Persia a year earlier in the Battle of Gaugamela. Following Alexander's brief occupation, the successor state of the Seleucid Empire controlled the region until 305 BCE when they gave much of it to the Maurya Empire as part of an alliance treaty. The Mauryans controlled the area south of the Hindu Kush until they were overthrown in about 185 BCE. Their decline began 60 years after Ashoka's rule ended, leading to the Hellenistic reconquest by the Greco-Bactrians. Much of it soon broke away from them and became part of the Indo-Greek Kingdom. They were defeated and expelled by the Indo-Scythians in the late 2nd century BCE.\n\nThe Silk Road appeared during the first century BCE, and Afghanistan flourished with trade, with routes to China, India, Persia and north to the cities of Bukhara, Samarkand and Khiva in present-day Uzbekistan. Goods and ideas were exchanged at this center point, such as Chinese silk, Persian silver and Roman gold, while the region of present Afghanistan was mining and trading lapis lazuli stones mainly from the Badakh", "flag": 1, "segments": [[1414, 1420]], "strength": 5.5}
{"token_count": [2006], "text": "Albania ( ;  or ), officially the Republic of Albania (), is a country in Southeastern Europe. It is located on the Adriatic and Ionian Sea within the Mediterranean Sea and shares land borders with Montenegro to the northwest, Kosovo to the northeast, North Macedonia to the east and Greece to the south. Tirana is its capital and largest city, followed by Durr\u00ebs, Vlor\u00eb and Shkod\u00ebr.\n\nAlbania displays varied climatic, geological, hydrological, and morphological conditions, defined in an area of. It possesses significant diversity with the landscape ranging from the snow-capped mountains in the Albanian Alps as well as the Korab, Skanderbeg, Pindus and Ceraunian Mountains to the hot and sunny coasts of the Albanian Adriatic and Ionian Sea along the Mediterranean Sea.\n\nAlbania has been inhabited by different civilisations over time, such as the Illyrians, Thracians, Greeks, Romans, Byzantines, Venetians and Ottomans. The Albanians established the autonomous Principality of Arb\u00ebr in the 12th century. The Kingdom of Albania and Principality of Albania formed between the 13th and 14th centuries. Prior to the Ottoman conquest of Albania in the 15th century, the Albanian resistance to Ottoman expansion into Europe led by Gjergj Kastrioti Skanderbeg won them acclaim over most of Europe. Albania remained under Ottoman rule for nearly five centuries, during which many Albanians (known  as Arnauts) attained high-ranking offices in the empire, especially in the Southern Balkans and Egypt. Between the 18th and 19th centuries, cultural developments, widely attributed to Albanians having gathered both spiritual and intellectual strength, conclusively led to the Albanian Renaissance. After the defeat of the Ottomans in the Balkan Wars, the (2009) In this romantic modern nation state of Albania declared independence in 1912. In the 20th century, the Kingdom of Albania was invaded by Italy which formed Greater Albania before becoming a protectorate of Nazi Germany. Enver Hoxha formed the People's Socialist Republic of Albania after World War II, modeled under the terms of Hoxhaism. The Revolutions of 1991 concluded the fall of communism in Albania and eventually the establishment of the current Republic of Albania.\n\nAlbania is a unitary parliamentary constitutional republic and a developing country with an upper-middle income economy dominated by the service sector, followed by manufacturing. It went through a process of transition following the end of communism in 1990, from centralised planning to a market-based economy. Albania provides universal health care and free primary and secondary education to its citizens. Albania is a member of the United Nations, World Bank, UNESCO, NATO, WTO, COE, OSCE, and OIC. It is an official candidate for membership in the European Union since 2014. It is one of the founding members of the Energy Community, including the Organization of the Black Sea Economic Cooperation and Union for the Mediterranean.\n\nEtymology \n\nThe term Albania is the medieval Latin name of the country. It may be derived from the Illyrian tribe of Albani () recorded by Ptolemy, the geographer and astronomer from Alexandria, who drafted a map in 150\u00a0AD which shows the city of Albanopolis located northeast of Durr\u00ebs. The term may have a continuation in the name of a medieval settlement called Albanon or Arbanon, although it is not certain that this was the same place. In his history written in the 10th century, the Byzantine historian Michael Attaliates was the first to refer to Albanoi as having taken part in a revolt against Constantinople in 1043 and to the Arbanitai as subjects of the Duke of Dyrrachium. During the Middle Ages, the Albanians called their country  and referred to themselves as.\n\nNowadays, Albanians call their country. The words Shqip\u00ebri and Shqiptar are attested from 14th century onwards, but it was only at the end of 17th and beginning of the early 18th centuries that the placename Shqip\u00ebria and the ethnic demonym Shqiptar\u00eb gradually replaced Arb\u00ebria and Arb\u00ebresh\u00eb amongst Albanian speakers. The two terms are popularly interpreted as \"Land of the Eagles\" and \"Children of the Eagles\".\n\nHistory\n\nPrehistory \n\nThe first attested traces of neanderthal presence in the territory of Albania dates back to the middle and upper Paleolithic period and were discovered in Xarr\u00eb and at Mount Dajt in the adjacent region of Tirana. Archaeological sites from this period include the Kamenica Tumulus, Konispol Cave and Pellumbas Cave.\n\nThe discovered objects in a cave near Xarr\u00eb include flint and jasper objects along with fossilised animal bones, while those discoveries at Mount Dajt comprise bone and stone tools similar to those of the Aurignacian culture. They also demonstrate notable similarities with objects of the equivalent period found at Crvena Stijena in Montenegro and northwestern Greece.\n\nMultiple artefacts from the Iron and Bronze Ages near tumulus burials have been unearthed in central and southern Albania, which has similar affinity with the sites in southwestern Macedonia and Lefkada. Archaeologists have come to the conclusion that these regions were inhabited from the middle of the third millennium BC by Indo-European people who spoke a Proto-Greek language. Hence, a part of this historical population later moved to Mycenae around 1600 BC and properly established the Mycenaean civilisation.\n\nAntiquity \n\nIn ancient times, the incorporated territory of Albania was historically inhabited by Indo-European peoples, among them numerous Illyrian tribes, Ancient Greeks and Thracians. In view of the Illyrian tribes, there is no evidence that these tribes used any collective nomenclature for themselves, while it is regarded to be unlikely that they used a common endonym. The endonym Illyrians seems to be the name applied to a specific Illyrian tribe, which was the first to come in liaison with the Ancient Greeks resulting in the endonym Illyrians to be applied pars pro toto to all people of similar language and customs.\n\nThe territory referred to as Illyria corresponded roughly to the area east of the Adriatic Sea in the Mediterranean Sea extending in the south to the mouth of the Vjos\u00eb. The first account of the Illyrian groups comes from Periplus of the Euxine Sea, an ancient Greek text written in the middle of the 4th century BC. The west was inhabited by the Thracian tribe of the Bryges while the south was inhabited by the Ancient Greek-speaking tribe of the Chaonians, whose capital was at Phoenice. Other colonies such as Apollonia, Epidamnos and Amantia, were established by Ancient Greek city-states on the coast by the 7th century BC.\n\nThe Illyrian Ardiaei tribe, centred in Montenegro, ruled over most of the territory of Albania. Their Ardiaean Kingdom reached its greatest extent under King Agron, the son of Pleuratus II. Agron extended his rule over other neighbouring tribes as well. Following Agron's death in 230 BC, his wife, Teuta, inherited the\u00a0Ardiaean kingdom. Teuta's forces extended their operations further southwards to the\u00a0Ionian Sea. In 229 BC, Rome declared war on the kingdom for extensively plundering Roman ships. The war ended in Illyrian defeat in 227\u00a0BC. Teuta was eventually succeeded by\u00a0Gentius\u00a0in 181\u00a0BC. Gentius clashed with the Romans in 168\u00a0BC, initiating the Third Illyrian War. The conflict resulted in Roman conquest of the region by 167\u00a0BC. The Romans split the region into three administrative divisions.\n\nMiddle Ages \n\nThe Roman Empire was split in 395 upon the death of Theodosius I into an Eastern and Western Roman Empire in part because of the increasing pressure from threats during the Barbarian Invasions. From the 6th century into the 7th century, the Slavs crossed the Danube and largely absorbed the indigenous Ancient Greeks, Illyrians and Thracians in the Balkans; thus, the Illyrians were mentioned for the last time in historical records in the 7th century.\n\nIn the 11th century, the Great Schism formalised the break of communion between the Eastern Orthodox and Western Catholic Church that is reflected in Albania through the emergence of a Catholic north and Orthodox south. The Albanian people inhabited the west of Lake Ochrida and the upper valley of River Shkumbin and established the Principality of Arbanon in 1190 under the leadership of Progon of Kruja. The realm was succeeded by his sons Gjin and Dhimitri.\n\nUpon the death of Dhimiter, the territory came under the rule of the Albanian-Greek Gregory Kamonas and subsequently under the Golem of Kruja. In the 13th century, the principality was dissolved. Arbanon is considered to be the first sketch of an Albanian state, that retained a semi-autonomous status as the western extremity of the Byzantine Empire, under the Byzantine Doukai of Epirus or Laskarids of Nicaea.\n\nTowards the end of the 12th and beginning of the 13th centuries, Serbs and Venetians started to take possession over the territory. The ethnogenesis of the Albanians is uncertain; however the first", "flag": 1, "segments": [[394, 400]], "strength": 5.5}
{"token_count": [2006], "text": "Azerbaijan (, ;  ), officially the Azerbaijan Republic or the Republic of Azerbaijan, is a transcontinental country located at the boundary of Eastern Europe and Western Asia. It is a part of the South Caucasus region, and is bounded by the Caspian Sea to the east, Russia to the north, Georgia to the northwest, Armenia and Turkey to the west, and Iran to the south. Baku is the capital and largest city.\n\nThe Azerbaijan Democratic Republic proclaimed its independence from the Transcaucasian Democratic Federative Republic in 1918 and became the first secular democratic Muslim-majority state, taking its name from the adjacent region of northwestern Iran for political reasons. In 1922, the country was incorporated into the Soviet Union as the Azerbaijan SSR.\n\nThe modern Republic of Azerbaijan proclaimed its independence on 30 August 1991, shortly before the dissolution of the Soviet Union in the same year. In September 1991, the ethnic Armenian majority of the Nagorno-Karabakh region formed self-proclaimed Republic of Artsakh. The region and seven surrounding districts are internationally recognized as part of Azerbaijan, while negotiations on the resolution of Nagorno-Karabakh conflict are facilitated by the OSCE. Nagorno-Karabakh became de facto independent with the end of the First Nagorno-Karabakh War in 1994.\nFollowing the 2020 Nagorno-Karabakh war, the seven districts and parts of Nagorno-Karabakh were returned to Azerbaijani control.\n\nAzerbaijan is a unitary semi-presidential republic. It is one of six independent Turkic states and an active member of the Turkic Council and the T\u00dcRKSOY community. Azerbaijan has diplomatic relations with 182 countries and holds membership in 38 international organizations, including the United Nations, the Council of Europe, the Non-Aligned Movement, the OSCE, and the NATO PfP program. It is one of the founding members of GUAM, the CIS, and the OPCW. Azerbaijan is also an observer state of the WTO.\n\nThe vast majority of the country's population (97%) is Muslim, but the constitution does not declare an official religion and all major political forces in the country are secularist. Azerbaijan is a developing country and ranks 88th on the Human Development Index. It has a high rate of economic development, literacy, and a low rate of unemployment. The ruling party, the New Azerbaijan Party, in power since 1993, has been accused of authoritarian leadership and the deterioration of the country's human rights record, including increasing restrictions on civil liberties, particularly on press freedom and political repression.\n\nEtymology \n\nAccording to a modern etymology, the term Azerbaijan derives from that of Atropates, a Persian satrap under the Achaemenid Empire, who was later reinstated as the satrap of Media under Alexander the Great. The original etymology of this name is thought to have its roots in the once-dominant Zoroastrianism. In the Avesta's Frawardin Yasht (\"Hymn to the Guardian Angels\"), there is a mention of \u00e2terep\u00e2tahe ashaon\u00f4 fravash\u00eem \u00fdazamaide, which literally translates from Avestan as \"we worship the fravashi of the holy Atropatene.\" The name \"Atropates\" itself is the Greek transliteration of an Old Iranian, probably Median, compounded name with the meaning \"Protected by the (Holy) Fire\" or \"The Land of the (Holy) Fire\". The Greek name was mentioned by Diodorus Siculus and Strabo. Over the span of millennia, the name evolved to  (Middle Persian), then to,,  (New Persian) and present-day Azerbaijan.\n\nThe name Azerbaijan was first adopted for the area of the present-day Republic of Azerbaijan by the government of Musavat in 1918, after the collapse of the Russian Empire, when the independent Azerbaijan Democratic Republic was established. Until then, the designation had been used exclusively to identify the adjacent region of contemporary northwestern Iran, while the area of the Azerbaijan Democratic Republic was formerly referred to as Arran and Shirvan. On that basis Iran protested the newly adopted country name.\n\nDuring the Soviet rule, the country was also spelled in Latin from the Russian transliteration as Azerbaydzhan (). The country's name was also spelled in Cyrillic script from 1940 to 1991 as \"\u0410\u0437\u04d9\u0440\u0431\u0430\u0458\u04b9\u0430\u043d\".\n\nHistory\n\nAntiquity\n\nThe earliest evidence of human settlement in the territory of Azerbaijan dates back to the late Stone Age and is related to the Guruchay culture of Azykh Cave.\n\nEarly settlements included the Scythians during the 9th century BC. Following the Scythians, Iranian Medes came to dominate the area to the south of the Aras river. The Medes forged a vast empire between 900 and 700\u00a0BC, which was integrated into the Achaemenid Empire around 550\u00a0BC. The area was conquered by the Achaemenids leading to the spread of Zoroastrianism.\n\nFrom the Sasanid period to the Safavid period\n\nThe Sasanian Empire turned Caucasian Albania into a vassal state in 252, while King Urnayr officially adopted Christianity as the state religion in the 4th century. Despite Sassanid rule, Albania remained an entity in the region until the 9th century, while fully subordinate to Sassanid Iran, and retained its monarchy. Despite being one of the chief vassals of the Sasanian emperor, the Albanian king had only a semblance of authority, and the Sasanian marzban (military governor) held most civil, religious, and military authority.\n\nIn the first half of the 7th century, Caucasian Albania, as a vassal of the Sasanians, came under nominal Muslim rule due to the Muslim conquest of Persia. The Umayyad Caliphate repulsed both the Sasanians and Byzantines from the South Caucasus and turned Caucasian Albania into a vassal state after Christian resistance led by King Javanshir, was suppressed a lengthy process to land a in 667. The power vacuum left by the decline of the Abbasid Caliphate was filled by numerous local dynasties such as the Sallarids, Sajids, and Shaddadids. At the beginning of the 11th century, the territory was gradually seized by the waves of Oghuz Turks from Central Asia, who adopted a Turkoman ethnonym at the time. The first of these Turkic dynasties established was the Seljuk Empire, which entered the area now known as Azerbaijan by 1067.\n\nThe pre-Turkic population that lived on the territory of modern Azerbaijan spoke several Indo-European and Caucasian languages, among them Armenian and an Iranian language, Old Azeri, which was gradually replaced by a Turkic language, the early precursor of the Azerbaijani language of today. Some linguists have also stated that the Tati dialects of Iranian Azerbaijan and the Republic of Azerbaijan, like those spoken by the Tats, are descended from Old Azeri.\nLocally, the possessions of the subsequent Seljuk Empire were ruled by Eldiguzids, technically vassals of the Seljuk sultans, but sometimes de facto rulers themselves. Under the Seljuks, local poets such as Nizami Ganjavi and Khaqani gave rise to a blossoming of Persian literature on the territory of present-day Azerbaijan.\n\nThe local dynasty of the Shirvanshahs became a vassal state of Timur's Empire and assisted him in his war with the ruler of the Golden Horde Tokhtamysh. Following Timur's death, two independent and rival states emerged: Kara Koyunlu and Aq Qoyunlu. The Shirvanshahs returned, maintaining for numerous centuries to come a high degree of autonomy as local rulers and vassals as they had done since 861. In 1501, the Safavid dynasty of Iran subdued the Shirvanshahs and gained its possessions. In the course of the next century, the Safavids converted the formerly Sunni population to Shia Islam, as they did with the population in what is modern-day Iran. The Safavids allowed the Shirvanshahs to remain in power, under Safavid suzerainty, until 1538, when Safavid king Tahmasp I (r. 1524\u20131576) completely deposed them, and made the area into the Safavid province of Shirvan. The Sunni Ottomans briefly managed to occupy parts of present-day Azerbaijan as a result of the Ottoman-Safavid War of 1578\u20131590; by the early 17th century, they were ousted by Safavid Iranian ruler Abbas I (r. 1588\u20131629). In the wake of the demise of the Safavid Empire, Baku and its environs were briefly occupied by the Russians as a consequence of the Russo-Persian War of 1722\u20131723. Despite brief intermissions such as these by Safavid Iran's neighboring rivals, the land of what is today Azerbaijan remained under Iranian rule from the earliest advent of the Safavids up to the course of the 19th century.\n\nContemporary history\n\nAfter the Safavids, the area was ruled by the Iranian Afsharid dynasty. After the death of Nader Shah (r. 1736\u20131747), many of his former subjects capitalized on the eruption of instability. Numerous self-ruling khanates with various forms of autonomy emerged", "flag": 1, "segments": [[1278, 1284]], "strength": 5.5}
{"token_count": [2006], "text": "Art is a diverse range of human activity, and resulting product, that involves creative or imaginative talent expressive of technical proficiency, beauty, emotional power, or conceptual ideas.\n\nThere is no generally agreed definition of what constitutes art, and ideas have changed over time. The three classical branches of visual art are painting, sculpture, and architecture. Theatre, dance, and other performing arts, as well as literature, music, film and other media such as interactive media, are included in a broader definition of the arts. Until the 17th century, art referred to any skill or mastery and was not differentiated from crafts or sciences. In modern usage after the 17th century, where aesthetic considerations are paramount, the fine arts are separated and distinguished from acquired skills in general, such as the decorative or applied arts. \n\nThe nature of art and related concepts, such as creativity and interpretation, are explored in a branch of philosophy known as aesthetics. The resulting artworks are studied in the professional fields of art criticism and the history of art.\n\nOverview\n\nIn the perspective of the history of art, artistic works have existed for almost as long as humankind: from early pre-historic art to contemporary art; however, some theorists feel that the typical concept of \"artistic works\" fits less well outside modern Western societies. One early sense of the definition of art is closely related to the older Latin meaning, which roughly translates to \"skill\" or \"craft\", as associated with words such as \"artisan\". English words derived from this meaning include artifact, artificial, artifice, medical arts, and military arts. However, there are many other colloquial uses of the word, all with some relation to its etymology.\n\nOver time, philosophers like Plato, Aristotle, Socrates and Kant, among others, questioned the meaning of art. Several dialogues in Plato tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the Phaedrus (265a\u2013c), and yet in the Republic wants to outlaw Homer's great poetic art, and laughter as well. In Ion, Socrates gives no hint of the disapproval of Homer that he expresses in the Republic. The dialogue Ion suggests that Homer's Iliad functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literary art that can provide moral guidance, if only it can be properly interpreted.\n\nWith regards to the literary art and the musical arts, Aristotle considered epic poetry, tragedy, comedy, Dithyrambic poetry and music to be mimetic or imitative art, each varying in imitation by medium, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation\u2014through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitation is natural to mankind and constitutes one of mankind's advantages over animals.\n\nThe more recent and specific sense of the word art as an abbreviation for creative art or fine art emerged in the early 17th century. Fine art refers to a skill used to express the artist's creativity, or to engage the audience's aesthetic sensibilities, or to draw the audience towards consideration of more refined or finer work of art.\n\nWithin this latter sense, the word art may refer to several things: (i) a study of a creative skill, (ii) a process of using the creative skill, (iii) a product of the creative skill, or (iv) the audience's experience with the creative skill. The creative arts (art as discipline) are a collection of disciplines which produce artworks (art as objects) that are compelled by a personal drive (art as activity) and convey a message, mood, or symbolism for the perceiver to interpret (art as experience).  Art is something that stimulates an individual's thoughts, emotions, beliefs, or ideas through the senses. Works of art can be explicitly made for this purpose or interpreted on the basis of images or objects. For some scholars, such as Kant, the sciences and the arts could be distinguished by taking science as representing the domain of knowledge and the arts as representing the domain of the freedom of artistic expression.\n\nOften, if the skill is being used in a common or practical way, people will consider it a craft instead of art. Likewise, if the skill is being used in a commercial or industrial way, it may be considered commercial art instead of fine art. On the other hand, crafts and design are sometimes considered applied art. Some art followers have argued that the difference between fine art and applied art has more to do with value judgments made about the art than any clear definitional difference. However, even fine art often has goals beyond pure creativity and self-expression. The purpose of works of art may be to communicate ideas, such as in politically, spiritually, or philosophically motivated art; to create a sense of beauty (see aesthetics); to explore the nature of perception; for pleasure; or to generate strong emotions. The purpose may also be seemingly nonexistent.\n\nThe nature of art has been described by philosopher Richard Wollheim as \"one of the most elusive of the traditional problems of human culture\". Art has been defined as a vehicle for the expression or communication of emotions and ideas, a means for exploring and appreciating formal elements for their own sake, and as mimesis or representation. Art as mimesis has deep roots in the philosophy of Aristotle. Leo Tolstoy identified art as a use of indirect means to communicate from one person to another. Benedetto Croce and R. G. Collingwood advanced the idealist view that art expresses emotions, and that the work of art therefore essentially exists in the mind of the creator. The theory of art as form has its roots in the philosophy of Kant, and was developed in the early 20th century by Roger Fry and Clive Bell.  More recently, thinkers influenced by Martin Heidegger have interpreted art as the means by which a community develops for itself a medium for self-expression and interpretation. George Dickie has offered an institutional theory of art that defines a work of art as any artifact upon which a qualified person or persons acting on behalf of the social institution commonly referred to as \"the art world\" has conferred \"the status of candidate for appreciation\". Larry Shiner has described fine art as \"not an essence or a fate but something we have made. Art as we have generally understood it is a European invention barely two hundred years old.\"\n\nArt may be characterized in terms of mimesis (its representation of reality), narrative (storytelling), expression, communication of emotion, or other qualities. During the Romantic period, art came to be seen as \"a special faculty of the human mind to be classified with religion and science\".\n\nHistory\n\nA shell engraved by Homo erectus was determined to be between 430,000 and 540,000 years old. A set of eight 130,000 years old white-tailed eagle talons bear cut marks and abrasion that indicate manipulation by neanderthals, possibly for using it as jewelry. A series of tiny, drilled snail shells about 75,000 years old\u2014were discovered in a South African cave. Containers that may have been used to hold paints have been found dating as far back as 100,000 years.\n\nSculptures, cave paintings, rock paintings and petroglyphs from the Upper Paleolithic dating to roughly 40,000 years ago have been found, but the precise meaning of such art is often disputed because so little is known about the cultures that produced them. \n\nMany great traditions in art have a foundation in the art of one of the great ancient civilizations: Ancient Egypt, Mesopotamia, Persia, India, China, Ancient Greece, Rome, as well as Inca, Maya, and Olmec. Each of these centers of early civilization developed a unique and characteristic style in its art. Because of the size and duration of these civilizations, more of their art works have survived and more of their influence has been transmitted to other cultures and later times. Some also have provided the first records of Joko. He has been how artists worked. For example, this period of Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty, and anatomically correct proportions.\n\nIn Byzantine and Medieval art of the Western Middle Ages, much art focused on the expression of subjects about Biblical and religious culture, and used styles that showed the higher glory of a heavenly world, such as the use of gold in the background of paintings, or glass in mosaics or windows, which also presented figures in idealized, patterned (flat) forms. Nevertheless, a classical realist tradition persisted in small Byzantine works, and realism steadily grew in the art of Catholic Europe.\n\nRenaissance art had a greatly increased emphasis on the realistic depiction of the material world, and the place of humans in it, reflected in the corporeality of the human body, and development of a systematic method of graphical perspective to depict recession in a three-dimensional picture space.\n\nIn the east, Islamic art's rejection of iconography led to emphasis on geometric patterns, calligraphy, and architecture. Further east, religion dominated artistic styles and forms too. India and Tibet saw emphasis on painted sculptures", "flag": 1, "segments": [[1751, 1757]], "strength": 5.5}
{"token_count": [2006], "text": "The American Revolutionary War (April 19, 1775 \u2013 September 3, 1783), also known as the Revolutionary War or American War of Independence, secured a United States of America independent from Great Britain. Fighting began on April 19, 1775, followed by the Declaration of Independence on July 4, 1776. The American Patriots were supported by France and Spain, conflict taking place in North America, the Caribbean, and Atlantic Ocean. It ended on September 3, 1783 when Britain accepted American independence in the Treaty of Paris, while the Treaties of Versailles resolved separate conflicts with France and Spain.  \n\nEstablished by Royal charter in the 17th and 18th centuries, the American colonies were largely autonomous in domestic affairs and commercially prosperous, trading with Britain and its Caribbean colonies, as well as other European powers via their Caribbean entrep\u00f4ts. After British victory in the Seven Years' War in 1763, tensions arose over trade, colonial policy in the Northwest Territory and taxation measures, including the Stamp Act and Townshend Acts. Colonial opposition led to the 1770 Boston Massacre and 1773 Boston Tea Party, with Parliament responding by imposing the so-called Intolerable Acts. \n\nEstablished on September 5, 1774, the First Continental Congress drafted a Petition to the King and organized a boycott of British goods. Tiptonville on Jan Despite attempts to achieve a peaceful solution, fighting began with the Battle of Lexington on April 19, 1775 and in June Congress authorized George Washington to create a Continental Army. Although the \"coercion policy\" advocated by the North ministry was opposed by a faction within Parliament, both sides increasingly viewed conflict as inevitable. The Olive Branch Petition sent by Congress to George III in July 1775 was rejected and in August Parliament declared the colonies to be in a state of rebellion.   \n\nFollowing the loss of Boston in March 1776, Sir William Howe, the new British commander-in-chief, launched the New York and New Jersey campaign. He captured New York City in November, before Washington won small but significant victories at Trenton and Princeton, which restored Patriot confidence. In summer 1777, Howe succeeded in taking Philadelphia, but in October a separate force under John Burgoyne was forced to surrender at Saratoga. This victory was crucial in convincing powers like France and Spain an independent United States was a viable entity.  \n\nFrance provided the US informal economic and military support from the beginning of the rebellion, and after Saratoga the two countries signed a commercial agreement and a Treaty of Alliance in February 1778. In return for a guarantee of independence, Congress joined France in its global war with Britain and agreed to defend the French West Indies. Spain also allied with France against Britain in the Treaty of Aranjuez (1779), though it did not formally ally with the Americans. Nevertheless, access to ports in Spanish Louisiana allowed the Patriots to import arms and supplies, while the Spanish Gulf Coast campaign deprived the Royal Navy of key bases in the south. \n\nThis undermined the 1778 strategy devised by Howe's replacement, Sir Henry Clinton, which took the war into the Southern United States. Despite some initial success, by September 1781 Cornwallis was besieged by a Franco-American force in Yorktown. After an attempt to resupply the garrison failed, Cornwallis surrendered in October, and although the British wars with France and Spain continued for another two years, this ended fighting in North America. In April 1782, the North ministry was replaced by a new British government which accepted American independence and began negotiating the Treaty of Paris, ratified on September 3, 1783.\n\nPrelude to revolution \n \n\nThe French and Indian War, part of the wider global conflict known as the Seven Years' War, ended with the 1763 Peace of Paris, which expelled France from its possessions in New France. Acquisition of territories in Atlantic Canada and West Florida, inhabited largely by French or Spanish-speaking Catholics, led the British authorities to consolidate their hold by populating them with English-speaking settlers. Preventing conflict between settlers and Native American tribes west of the Appalachian Mountains would also avoid the cost of an expensive military occupation. \n\nThe Proclamation Line of 1763 was designed to achieve these aims by refocusing colonial expansion north into Nova Scotia and south into Florida, with the Mississippi River as the dividing line between British and Spanish possessions in the Americas. Settlement beyond the 1763 limits was tightly restricted, while claims by individual colonies west of this line were rescinded, most significantly Virginia and Massachusetts who argued their boundaries extended from the Atlantic to the Pacific. \n\nUltimately the vast exchange of territory destabilized existing alliances and trade networks between settlers and Native Americans in the west, while it proved impossible to prevent encroachment beyond the Proclamation Line. With the exception of Virginia and others \"deprived\" of their rights in the western lands, the colonial legislatures generally agreed on the principle of boundaries but disagreed on where to set them, while many settlers resented the restrictions. Since enforcement required permanent garrisons along the frontier, it led to increasingly bitter disputes over who should pay for them.\n\nTaxation and legislation\n\nAlthough directly administered by the Crown, acting through a local Governor, the colonies were largely governed by native-born property owners. While external affairs were managed by London, colonial militia were funded locally but with the ending of the French threat in 1763, the legislatures expected less taxation, not more. At the same time, the huge debt incurred by the Seven Years' War and demands from British taxpayers for cuts in government expenditure meant Parliament expected the colonies to fund their own defense. \n\nThe 1763 to 1765 Grenville ministry instructed the Royal Navy to stop the trade of smuggled goods and enforce customs duties levied in American ports. The most important was the 1733 Molasses Act; routinely ignored prior to 1763, it had a significant economic impact since 85% of New England rum exports were manufactured from imported molasses. These measures were followed by the Sugar Act and Stamp Act, which imposed additional taxes on the colonies to pay for defending the western frontier. In July 1765, the Whigs formed the First Rockingham ministry, which repealed the Stamp Act and reduced tax on foreign molasses to help the New England economy, but re-asserted Parliamentary authority in the Declaratory Act.\n\nHowever, this did little to end the discontent; in 1768, a riot started in Boston when the authorities seized the sloop Liberty on suspicion of smuggling. Tensions escalated further in March 1770 when British troops fired on rock-throwing civilians, killing five in what became known as the Boston Massacre. The Massacre coincided with the partial repeal of the Townshend Acts by the Tory-based North Ministry, which came to power in January 1770 and remained in office until 1781. North insisted on retaining duty on tea to enshrine Parliament's right to tax the colonies; the amount was minor, but ignored the fact it was that very principle Americans found objectionable.\n\nTensions escalated following the destruction of a customs vessel in the June 1772 Gaspee Affair, then came to a head in 1773. A banking crisis led to the near-collapse of the East India Company, which dominated the British economy; to support it, Parliament passed the Tea Act, giving it a trading monopoly in the Thirteen Colonies. Since most American tea was smuggled by the Dutch, the Act was opposed by those who managed the illegal trade, while being seen as yet another attempt to impose the principle of taxation by Parliament. In December 1773, a group called the Sons of Liberty disguised as Mohawk natives dumped 342 crates of tea into Boston Harbor, an event later known as the Boston Tea Party. Parliament responded by passing the so-called Intolerable Acts, aimed specifically at Massachusetts, although many colonists and members of the Whig opposition considered them a threat to liberty in general. This led to increased sympathy for the Patriot cause locally, as well as in Parliament and the London press.\n\nBreak with the British Crown\nOver the course of the 18th century, the elected lower houses in the colonial legislatures gradually wrested power from their Royal Governors. Dominated by smaller landowners and merchants, these Assemblies now established ad hoc provincial legislatures, variously called Congresses, Conventions, and Conferences, effectively replacing Royal control. With the exception of Georgia, twelve colonies sent representatives to the First Continental Congress to agree on a unified response to the crisis. Many of the delegates feared that an all-out boycott would result in war and sent a Petition to the King calling for the repeal of the Intolerable Acts. However, after some debate, on September 17, 1774, Congress endorsed the Massachusetts Suffolk Resolves and on October 20 passed the Continental Association; based on a draft prepared by the First Virginia Convention in August, this instituted economic sanctions against Britain.\n\nWhile denying its authority over internal American affairs, a faction led by James Duane and future Loyalist Joseph Galloway insisted Congress recognize Parliament's right to regulate colonial trade.  Expecting concessions by the North administration, Congress authorized the extralegal committees and conventions of the colonial legislatures to enforce the boycott; this succeeded in reducing British imports by 97% from 1774 to 1775. However, on February 9 Parliament declared Massachusetts to be in a state of rebellion and instituted a blockade of the colony. In July, the Restraining Acts limited colonial trade with the British West Indies and Britain and barred New England ships from the Newfoundland cod fisheries. The increase in tension led to a scramble for control of militia stores, which each Assembly was legally obliged to maintain for defense. On April 19, a British attempt to secure the Concord arsenal culminated in the Battles of Lexington and Concord which began the war.\n\n", "flag": 1, "segments": [[272, 278]], "strength": 5.5}
{"token_count": [2006], "text": "In mathematics and computer science, an algorithm () is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. By making use of artificial intelligence, algorithms can perform automated deductions (referred to as automated reasoning) and use mathematical and logical tests to divert the code through various routes (referred to as automated decision-making). Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as \"memory\", \"search\" and \"stimulus\".\n\nIn contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.\n\nAs an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n\nHistory \nThe concept of algorithm has existed since antiquity. Arithmetic algorithms, such as a division algorithm, were used by ancient Babylonian mathematicians c. 2500 BC and Egyptian mathematicians c. 1550 BC. Greek mathematicians later used algorithms in 240 BC in the sieve of Eratosthenes for finding prime numbers, and the Euclidean algorithm for finding the greatest common divisor of two numbers. Arabic mathematicians such as al-Kindi in the 9th century used cryptographic algorithms for code-breaking, based on frequency analysis.\n\nThe word algorithm is derived from the name of the 9th-century Persian mathematician Mu\u1e25ammad ibn M\u016bs\u0101 al-Khw\u0101rizm\u012b, whose nisba (identifying him as from Khwarazm) was Latinized as Algoritmi (Arabized Persian \u0627\u0644\u062e\u0648\u0627\u0631\u0632\u0645\u06cc c. 780\u2013850).\nMu\u1e25ammad ibn M\u016bs\u0101 al-Khw\u0101rizm\u012b was a mathematician, astronomer, geographer, and scholar in the House of Wisdom in Baghdad, whose name means 'the native of Khwarazm', a region that was part of Greater Iran and is now in Uzbekistan. About 825, al-Khwarizmi wrote an Arabic language treatise on the Hindu\u2013Arabic numeral system, which was translated into Latin during the 12th century. The manuscript starts with the phrase Dixit Algorizmi ('Thus spake Al-Khwarizmi'), where \"Algorizmi\" was the translator's Latinization of Al-Khwarizmi's name. Al-Khwarizmi was the most widely read mathematician in Europe in the late Middle Ages, primarily through another of his books, the Algebra. In late medieval Latin, algorismus, English 'algorism', the corruption of his name, simply meant the \"decimal number system\". In the 15th century, under the influence of the Greek word \u1f00\u03c1\u03b9\u03b8\u03bc\u03cc\u03c2 (arithmos), 'number' (cf. 'arithmetic'), the Latin word was altered to algorithmus, and the corresponding English term 'algorithm' is first attested in the 17th century; the modern sense was introduced in the 19th century.\n\nIndian mathematics was predominantly algorithmic.\nAlgorithms that are representative of the Indian mathematical tradition range from the ancient \u015aulbas\u016btr\u0101s to the medieval texts of the Kerala School.\n\nIn English, the word algorithm was first used in about 1230 and then by Chaucer in 1391. English adopted the French term, but it was not until the late 19th century that \"algorithm\" took on the meaning that it has in modern English.\n\nAnother early use of the word is from 1240, in a manual titled Carmen de Algorismo composed by Alexandre de Villedieu. It begins with:\n\nwhich translates to:\n\nThe poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.\n\nA partial formalization of the modern concept of algorithm began with attempts to solve the Entscheidungsproblem  (decision problem) posed by David Hilbert in 1928. Later formalizations were framed as attempts to define \"effective calculability\" or \"effective method\". Those formalizations included the G\u00f6del\u2013Herbrand\u2013Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936\u201337 and 1939.\n\nInformal definition\n\nAn informal definition could be \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and (for example) any prescribed bureaucratic procedure\nor cook-book recipe.\n\nIn general, a program is only an algorithm if it stops eventually\u2014even though infinite loops may sometimes prove desirable.\n\nA prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.\n\n offer an informal meaning of the word \"algorithm\" in the following quotation:\n\nNo human being can write fast enough, or long enough, or small enough\u2020 ( \u2020\"smaller and smaller without limit... you'd be trying to write on molecules, on atoms, on electrons\") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be the community is what prompted her followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.\n\nAn \"enumerably infinite set\" is one whose elements can be put into one-to-one correspondence with the integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that \"creates\" output integers from an arbitrary \"input\" integer or integers that, in theory, can be arbitrarily large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary \"input variables\" m and n that produce an output y), but various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):\nPrecise instructions (in a language understood by \"the computer\") for a fast, efficient, \"good\" process that specifies the \"moves\" of \"the computer\" (machine or human, equipped with the necessary internally contained information and capabilities) to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and =... and \"effectively\" produce, in a \"reasonable\" time, output-integer y at a specified place and in a specified format.\n\nThe concept of algorithm is also used to define the notion of decidability\u2014a notion that is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to the customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.\n\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.\n\nFormalization\n\nAlgorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform\u2014in a specific order\u2014to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987) and Gurevich (2000):\n Minsky: \"But we will also maintain, with Turing... that any procedure which could \"naturally\" be called effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the arguments... in its favor are hard to refute\".\n\n Gurevich: \"\u2026 Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine \u2026 according to Savage [1987], an algorithm is a computational process defined by a Turing machine\".Turing machines can define computational processes that do not terminate. The informal definitions of algorithms generally require that the algorithm always terminates. This requirement renders the task of deciding whether a formal procedure is an algorithm impossible in the general", "flag": 1, "segments": [[1319, 1325]], "strength": 5.5}
{"token_count": [2006], "text": "Alexander III of Macedon ( ; 20/21 July 356 BC \u2013 10/11 June 323 BC), commonly known as Alexander the Great, was a king of the ancient Greek kingdom of Macedon. A member of the Argead dynasty, he was born in Pella\u2014a city in Ancient Greece\u2014in 356 BC. He succeeded his father King Philip II to the throne at the age of 20, and spent most of his ruling years conducting a lengthy military campaign throughout Western Asia and Northeastern Africa. By the age of thirty, he had created one of the largest empires in history, stretching from Greece to northwestern India. He was undefeated in battle and is widely considered to be one of history's greatest and most successful military commanders.\n\nDuring his youth, Alexander was tutored by Aristotle until the age of 16. His father Philip was assassinated in 336 BC at the wedding of Cleopatra of Macedon, Alexander's sister, and Alexander assumed the throne of the Kingdom of Macedon. In 335 BC he campaigned in the Balkans, reasserting control over Thrace and Illyria before sacking the Greek city of Thebes. Alexander was then awarded the generalship of Greece. He used his authority to launch his father's pan-Hellenic project, assuming leadership over all the Greeks in their conquest of Persia.\n\nIn 334 BC he invaded the Achaemenid Empire (Persian Empire) and began a series of campaigns that lasted 10 years. Following his conquest of Asia Minor (modern-day Turkey), Alexander broke the power of Persia in a series of decisive battles, including those at Issus and Gaugamela. He subsequently overthrew King Darius III and conquered the Achaemenid Empire in its entirety. At that point, his empire stretched from the Adriatic Sea to the Indus River. Alexander endeavored to reach the \"ends of the world and the Great Outer Sea\" and invaded India in 326 BC, achieving an important victory over King Porus at the Battle of the Hydaspes. He eventually turned back at the Beas River due to the demand of his homesick troops, dying in 323 BC in Babylon, the city he planned to establish as his capital. He did not manage to execute a series of planned campaigns that would have begun with an invasion of Arabia. In the years following his death, a series of civil wars tore his empire apart.\n\nAlexander's legacy includes the cultural diffusion and syncretism which his conquests engendered, such as Greco-Buddhism and Hellenistic Judaism. He founded more than twenty cities that bore his name, most notably Alexandria in Egypt. Alexander's settlement of Greek colonists and the resulting spread of Greek culture resulted in Hellenistic civilization, which developed through the Roman Empire into modern Western culture. The Greek language became the lingua franca of the region and was the predominant language of the Byzantine Empire up until its end in the mid-15th century AD.  Greek-speaking communities in central and far eastern Anatolia survived until the Greek genocide and the population exchange in the 1920s. Alexander became legendary as a classical hero in the mould of Achilles, featuring prominently in the history and mythic traditions of both Greek and non-Greek cultures. His military achievements and enduring, unprecedented success in battle made him the measure against which many later military leaders would compare themselves. Military academies throughout the world still teach his tactics.\n\nEarly life\n\nLineage and childhood\n\nAlexander was born in Pella, the capital of the Kingdom of Macedon, on the sixth day of the ancient Greek month of Hekatombaion, which probably corresponds to 20 July 356 BC (although the exact date is uncertain). He was the son of the king of Macedon, Philip II, and his fourth wife, Olympias, daughter of Neoptolemus I, king of Epirus. Although Philip had seven or eight wives, Olympias was his principal wife for some time, likely because she gave birth to Alexander.\n\nSeveral legends surround Alexander's birth and childhood. According to the ancient Greek biographer Plutarch, on the eve of the consummation of her marriage to Philip, Olympias dreamed that her womb was struck by a thunderbolt that caused a flame to spread \"far and wide\" before dying away. Sometime after the wedding, Philip is said to have seen himself, in a dream, securing his wife's womb with a seal engraved with a lion's image. Plutarch offered a variety of interpretations for these dreams: that Olympias was pregnant before her marriage, indicated by the sealing of her womb; or that Alexander's father was Zeus. Ancient commentators were divided about whether the ambitious Olympias promulgated the story of Alexander's divine parentage, variously claiming that she had told Alexander, or that she dismissed the suggestion as impious.\n\nOn the day Alexander was born, Philip was preparing a siege on the city of Potidea on the peninsula of Chalcidice. That same day, Philip received news that his general Parmenion had defeated the combined Illyrian and Paeonian armies and that his horses had won at the Olympic Games. It was also said that on this day, the Temple of Artemis in Ephesus, one of the Seven Wonders of the World, burnt down. This led Hegesias of Magnesia to say that it had burnt down because Artemis was away, attending the birth of Alexander. Such legends may have emerged when Alexander was king, and possibly at his instigation, to show that he was superhuman and destined for greatness from conception.\n\nIn his early years, Alexander was raised by a nurse, Lanike, sister of Alexander's future general Cleitus the Black. Later in his childhood, Alexander was tutored by the strict Leonidas, a relative of his mother, and by Lysimachus of Acarnania. Alexander was raised in the manner of noble Macedonian youths, learning to read, play the lyre, ride, fight, and hunt.\nWhen Alexander was ten years old, a trader from Thessaly brought Philip a horse, which he offered to sell for thirteen talents. The horse refused to be mounted, and Philip ordered it away. Alexander, however, detecting the horse's fear of its own shadow, asked to tame the horse, which he eventually managed. Plutarch stated that Philip, overjoyed at this display of courage and ambition, kissed his son tearfully, declaring: \"My boy, you must find a kingdom big enough for your ambitions. Macedon is too small for you\", and bought the horse for him. Alexander named it Bucephalas, meaning \"ox-head\". Bucephalas carried Alexander as far as India. When the animal died (because of old age, according to Plutarch, at age thirty), Alexander named a city after him, Bucephala.\n\nEducation\nWhen Alexander was 13, Philip began to search for a tutor, and considered such academics as Isocrates and Speusippus, the latter offering to resign from his stewardship of the Academy to take up the post. In the end, Philip chose Aristotle and provided the Temple of the Nymphs at Mieza as a classroom. In return for teaching Alexander, Philip agreed to rebuild Aristotle's hometown of Stageira, which Philip had razed, and to repopulate it by buying and freeing the ex-citizens who were slaves, or pardoning those who were in exile.\n\nMieza was like a boarding school for Alexander and the children of Macedonian nobles, such as Ptolemy, Hephaistion, and Cassander. Many of these students would become his friends and future generals, and are often known as the \"Companions\". Aristotle taught Alexander and his companions about medicine, philosophy, morals, religion, logic, and art. Under Aristotle's tutelage, Alexander developed a passion for the works of Homer, and in particular the Iliad; Aristotle gave him an annotated copy, which Alexander later carried on his campaigns.\n\nAlexander was able to quote Euripides from memory.\n\nDuring his youth, Alexander was also acquainted with Persian exiles at the Macedonian court, who received the protection of Philip II for several years as they opposed Artaxerxes III. Among them were Artabazos II and his daughter Barsine, possible future mistress of Alexander, who resided at the Macedonian court from 352 to 342 BC, as well as Amminapes, future satrap of Alexander, or a Persian nobleman $20 million investment in a named Sisines. This gave the Macedonian court a good knowledge of Persian issues, and may even have influenced some of the innovations in the management of the Macedonian state.\n\nSuda writes that Anaximenes of Lampsacus was one of Alexander's teachers, and that Anaximenes also accompanied Alexander on his campaigns.\n\nHeir of Philip II\n\nRegency and ascent of Macedon\n\nAt the age of 16, Alexander's education under Aristotle ended. Philip II had waged war against the Thracians to the north, which left Alexander in charge as regent and heir apparent.\n\nDuring Philip's absence, the Thracian tribe of Maedi revolted against Macedonia. Alexander responded quickly and drove them from their territory. The territory was colonized, and a city, named Alexandropolis, was founded.\n\nUpon Philip's return, Alexander was dispatched with a small force to subdue the revolts in southern Thrace. Campaigning against the Greek city of Perinthus, Alexander reportedly saved his father's life. Meanwhile, the city of Amphissa began to work lands that were sacred to Apollo near Delphi, a sacrilege that gave Philip the opportunity", "flag": 1, "segments": [[1753, 1759]], "strength": 5.5}
{"token_count": [2006], "text": "Ankara (,  ; ), historically known as Ancyra and Angora, is the capital of Turkey. Located in the central part of Anatolia, the city has a population of 5.1\u00a0million in its urban center and over 5.7\u00a0million in Ankara Province, making it Turkey's second-largest city after Istanbul.\n\nServing as the capital of the ancient Celtic state of Galatia (280\u201364\u00a0BC), and later of the Roman province with the same name (25\u00a0BC\u20137th century), the city is very old, with various Hattian, Hittite, Lydian, Phrygian, Galatian, Greek, Persian, Roman, Byzantine, and Ottoman archeological sites. The Ottomans made the city the capital first of the Anatolia Eyalet (1393 \u2013 late 15th century) and then the Angora Vilayet (1867\u20131922). The historical center of Ankara is a rocky hill rising  over the left bank of the Ankara River, a tributary of the Sakarya River. The hill remains crowned by the ruins of Ankara Castle. Although few of its outworks have survived, there are well-preserved examples of Roman and Ottoman architecture throughout the city, the most remarkable being the 20\u00a0BC Temple of Augustus and Rome that boasts the Monumentum Ancyranum, the inscription recording the Res Gestae Divi Augusti.\n\nOn 23 April 1920, the Grand National Assembly of Turkey was established in Ankara, which became the headquarters of the Turkish National Movement during the Turkish War of Independence. Ankara became the new Turkish capital upon the establishment of the Republic on 29 October 1923, succeeding in this role as the former Turkish capital Istanbul following the fall of the Ottoman Empire. The government is a prominent employer, but Ankara is also an important commercial and industrial city located at the center of Turkey's road and railway networks. The city gave its name to the Angora wool shorn from Angora rabbits, the long-haired Angora goat (the source of mohair), and the Angora cat. The area is also known for its pears, honey and muscat grapes. Although situated in one of the driest regions of Turkey and surrounded mostly by steppe vegetation (except for the forested areas on the southern periphery), Ankara can be considered a green city in terms of green areas per inhabitant, at  per head.\n\nEtymology \n\nThe orthography of the name Ankara has varied over the ages. It has been identified with the Hittite cult center Ankuwa\u0161,  although this remains a matter of debate. In classical antiquity and during the medieval period, the city was known as \u00c1nkyra (, \u00a0\"anchor\") in Greek and Ancyra in Latin; the Galatian Celtic name was probably a similar variant. Following its annexation by the Seljuk Turks in 1073, the city became known in many European languages as Angora; it was also known in Ottoman Turkish as Eng\u00fcr\u00fc. The form \"Angora\" is preserved in the names of breeds of many different kinds of animals, and in the names of several locations in the US (see Angora).\n\nHistory \n\nThe region's history can be traced back to the Bronze Age Hattic civilization, which was succeeded in the 2nd millennium BC by the Hittites, in the 10th century BC by the Phrygians, and later by the Lydians, Persians, Greeks, Galatians, Romans, Byzantines, and Turks (the Seljuk Sultanate of R\u00fbm, the Ottoman Empire and finally republican Turkey).\n\nAncient history\n\nThe oldest settlements in and around the city center of Ankara belonged to the Hattic civilization which existed during the Bronze Age and was gradually absorbed c. 2000 \u2013 1700\u00a0BC by the Indo-European Hittites. The city grew significantly in size and importance under the Phrygians starting around 1000\u00a0BC, and experienced a large expansion following the mass migration from Gordion, (the capital of Phrygia), after an earthquake which severely damaged that city around that time. In Phrygian tradition, King Midas was venerated as the founder of Ancyra, but Pausanias mentions that the city was actually far older, which accords with present archeological knowledge.\n\nPhrygian rule was succeeded first by Lydian and later by Persian rule, though the strongly Phrygian character of the peasantry remained, as evidenced by the gravestones of the much later Roman period. Persian sovereignty lasted until the Persians' defeat at the hands of Alexander the Great who conquered the city in 333\u00a0BC. Alexander came from Gordion to Ankara and stayed in the city for a short period. After his death at Babylon in 323\u00a0BC and the subsequent division of his empire among his generals, Ankara, and its environs fell into the share of Antigonus.\n\nAnother important expansion took place under the Greeks of Pontos who came there around 300\u00a0BC and developed the city as a trading center for the commerce of goods between the Black Sea ports and Crimea to the north; Assyria, Cyprus, and Lebanon to the south; and Georgia, Armenia and Persia to the east. By that time the city also took its name \u1f0c\u03b3\u03ba\u03c5\u03c1\u03b1 (\u00c1nkyra, meaning anchor in Greek) which, in slightly modified form, provides the modern name of Ankara.\n\nCeltic history\n\nIn 278\u00a0BC, the city, along with the rest of central Anatolia, was occupied by a Celtic group, the Galatians, who were the first to make Ankara one of their main tribal centers, the headquarters of the Tectosages tribe. Other centers were Pessinus, today's Ball\u0131hisar, for the Trocmi tribe, and Tavium, to the east of Ankara, for the Tolistobogii tribe. The city was then known as Ancyra. The Celtic element was probably relatively small in numbers; a warrior aristocracy which ruled over Phrygian-speaking peasants. However, the Celtic language continued to be spoken in Galatia for many centuries. At the end of the 4th century, St. Jerome, a native of Dalmatia, observed that the language spoken around Ankara was very similar to that being spoken in the northwest of the Roman world near Trier.\n\nRoman history\n\nThe city was subsequently passed under the control of the Roman Empire. In 25\u00a0BC, Emperor Augustus raised it to the status of a polis and made it the capital city of the Roman province of Galatia. Ankara is famous for the Monumentum Ancyranum (Temple of Augustus and Rome) which contains the official record of the Acts of Augustus, known as the Res Gestae Divi Augusti, an inscription cut in marble on the walls of this temple. The ruins of Ancyra still furnish today valuable bas-reliefs, inscriptions and other architectural fragments. Two other Galatian tribal centers, Tavium near Yozgat, and Pessinus (Balhisar) to the west, near Sivrihisar, continued to be reasonably important settlements in the Roman period, but it was Ancyra that grew into a grand metropolis.\n\nAn estimated 200,000 people lived in Ancyra in good times during the Roman Empire, a far greater number than was to be the case from after the fall of the Roman Empire until the early 20th century. The small Ankara River ran through the center of the Roman town. It has now been covered and diverted, but it formed the northern boundary of the old town during the Roman, Byzantine and Ottoman periods. \u00c7ankaya, the rim of the majestic hill to the south of the present city center, stood well outside the Roman city, but may have been a summer resort. In the 19th century, the remains of at least one Roman villa or large house were still standing not far from where the \u00c7ankaya Presidential Residence stands today. To the west, the Roman city extended until the area of the Gen\u00e7lik Park and Railway Station, while on the southern side of the hill, it may have extended downwards as far as the site presently occupied by Hacettepe University. It was thus a sizeable city by any standards and much larger than the Roman towns of Gaul or Britannia.\n\nAncyra's importance rested on the fact that it was the junction point where the roads in northern Anatolia running north\u2013south and east\u2013west intersected, giving it majorheads from constituents in Wob strategic importance for Rome's eastern frontier. The great imperial road running east passed through Ankara and a succession of emperors and their armies came this way. They were not the only ones to use the Roman highway network, which was equally convenient for invaders. In the second half of the 3rd century, Ancyra was invaded in rapid succession by the Goths coming from the west (who rode far into the heart of Cappadocia, taking slaves and pillaging) and later by the Arabs. For about a decade, the town was one of the western outposts of one of Palmyrean empress Zenobia in the Syrian Desert, who took advantage of a period of weakness and disorder in the Roman Empire to set up a short-lived state of her own.\n\nThe town was reincorporated into the Roman Empire under Emperor Aurelian in 272. The tetrarchy, a system of multiple (up to four) emperors introduced by Diocletian (284\u2013305), seems to have engaged in a substantial program of rebuilding and", "flag": 1, "segments": [[1784, 1790]], "strength": 5.5}
{"token_count": [2006], "text": "Arabic (,   or,   or ) is a Semitic language that first emerged in the 1st to 4th centuries CE. It is the lingua franca of the Arab world and the liturgical language of Islam. It is named after the Arabs, a term initially used to describe peoples living in the Arabian Peninsula bounded by eastern Egypt in the west, Mesopotamia in the east, and the Anti-Lebanon mountains and northern Syria in the north, as perceived by ancient Greek geographers. The ISO assigns language codes to 32 varieties of Arabic, including its standard form, Modern Standard Arabic, also referred to as Literary Arabic, which is modernized Classical Arabic. This distinction exists primarily among Western linguists; Arabic speakers themselves generally do not distinguish between Modern Standard Arabic and Classical Arabic, but rather refer to both as  ( \"the eloquent Arabic\") or simply  ().\n\nArabic is widely taught in schools and universities around the world and is used to varying degrees in workplaces, governments and the media. Arabic, in its Modern Standard Arabic form, is an official language of 26 states and 1 disputed territory, the third most after English and French;\nit is also the liturgical language of the religion of Islam, since the Quran and the Hadiths were written in Classical Arabic.\n\nDuring the early Middle Ages, Arabic was a major vehicle of culture in the Mediterranean region, especially in science, mathematics and philosophy. As a result, many European languages have also borrowed many words from it. Arabic influence, mainly in vocabulary, is seen in European languages\u2014mainly Spanish and to a lesser extent Portuguese, Catalan, and Sicilian\u2014owing to both the proximity of Christian European and Muslim Arabized civilizations and the long-lasting Muslim culture and Arabic language presence, mainly in Southern Iberia, during the Al-Andalus era. The Maltese language is a Semitic language developed from a dialect of Arabic and written in the Latin alphabet. The Balkan languages, including Greek and Bulgarian, have also acquired a significant number of words of Arabic origin through contact with Ottoman Turkish.\n\nArabic has influenced many other languages around the globe throughout its history especially languages of Muslim cultures and countries that were conquered by Muslims. Some of the most influenced languages are Persian, Turkish, Hindustani (Hindi and Urdu), Kashmiri, Kurdish, Bosnian, Kazakh, Bengali, Malay (Indonesian and Malaysian), Maldivian, Pashto, Punjabi, Albanian, Armenian, Azerbaijani, Sicilian, Spanish, Greek, Bulgarian, Tagalog, Sindhi, Odia Hebrew and Hausa and some languages in parts of Africa. Conversely, Arabic has borrowed words from other languages, including Aramaic as well as Hebrew, Latin, Greek, Persian and to a lesser extent Turkish (due to the Ottoman Empire), English and French (due to their colonization of the Levant) and other Semitic languages such as Abyssinian.\n\nArabic is the liturgical language of 1.9 billion Muslims, and Arabic is one of six official languages of the United Nations. All varieties of Arabic combined are spoken by perhaps as many as 422 million speakers (native and non-native) in the Arab world, making it the fifth most spoken language in the world, and the fourth most used language on the internet in terms of users. In 2011, Bloomberg Businessweek ranked Arabic the fourth most useful language for business, after English, Standard Mandarin Chinese, and French. Arabic is written with the Arabic alphabet, which is an abjad script and is written from right to left, although the spoken varieties are sometimes written in ASCII Latin from left to right with no standardized orthography.\n\nClassification \n\nArabic is usually, but not universally, classified as a Central Semitic language. It is related to languages in other subgroups of the Semitic language group (Northwest Semitic, South Semitic, East Semitic, West Semitic), such as Aramaic, Syriac, Hebrew, Ugaritic, Phoenician, Canaanite, Amorite, Ammonite, Eblaite, epigraphic Ancient North Arabian, epigraphic Ancient South Arabian, Ethiopic, Modern South Arabian, and numerous other dead and modern languages. Linguists still differ as to the best classification of Semitic language sub-groups.\nThe Semitic languages changed a great deal between Proto-Semitic and the emergence of the Central Semitic languages, particularly in grammar. Innovations of the Central Semitic languages\u2014all maintained in Arabic\u2014include:\n The conversion of the suffix-conjugated stative formation (jalas-) into a past tense.\n The conversion of the prefix-conjugated preterite-tense formation (yajlis-) into a present tense.\n The elimination of other prefix-conjugated mood/aspect forms (e.g., a present tense formed by doubling the middle root, a perfect formed by infixing a  after the first root consonant, probably a jussive formed by a stress shift) in favor of new moods formed by endings attached to the prefix-conjugation forms (e.g., -u for indicative, -a for subjunctive, no ending for jussive, -an or -anna for energetic).\n The development of an internal passive.\nThere are several features which Classical Arabic, the modern Arabic varieties, as well as the Safaitic and Hismaic inscriptions share which are unattested in any other Central Semitic language variety, including the Dadanitic and Taymanitic languages of the northern Hejaz. These features are evidence of common descent from a hypothetical ancestor, Proto-Arabic. The following features can be reconstructed with confidence for Proto-Arabic:\n negative particles  * ;  * to Classical Arabic \n  G-passive participle\n prepositions and adverbs,,,, \n a subjunctive in -\n -demonstratives\n leveling of the - allomorph of the feminine ending\n  complementizer and subordinator\n the use of - to introduce modal clauses\n independent object pronoun in \n vestiges of nunation\n\nHistory\n\nOld Arabic \n\nArabia boasted a wide variety of Semitic languages in antiquity. In the southwest, various Central Semitic languages both belonging to and outside of the Ancient South Arabian family (e.g. Southern Thamudic) were spoken. It is also believed that the ancestors of the Modern South Arabian languages (non-Central Semitic languages) were also spoken in southern Arabia at this time. To the north, in the oases of northern Hejaz, Dadanitic and Taymanitic held some prestige as inscriptional languages. In Najd and parts of western Arabia, a language known to scholars as Thamudic C is attested. In eastern Arabia, inscriptions in a script derived from ASA attest to a language known as Hasaitic. Finally, on the northwestern frontier of Arabia, various languages known to scholars as Thamudic B, Thamudic D, Safaitic, and Hismaic are attested. The last two share important isoglosses with later forms of Arabic, leading scholars to theorize that Safaitic and Hismaic are in fact early forms of Arabic and that they should be considered Old Arabic.\n\nLinguists generally believe that \"Old Arabic\" (a collection of related dialects that constitute the precursor of Arabic) first emerged around the 1st century CE. Previously, the earliest attestation of Old Arabic was thought to be a single 1st century CE inscription in Sabaic script at Qaryat Al-Faw, in southern present-day Saudi Arabia. However, this inscription does not participate in several of the key innovations of the Arabic language group, such as the conversion of Semitic mimation to nunation in the singular. It is best reassessed as a separate language on the Central Semitic dialect continuum by sector approach. The breakdown.\nIt was also thought that Old Arabic coexisted alongside\u2014and then gradually displaced--epigraphic Ancient North Arabian (ANA), which was theorized to have been the regional tongue for many centuries. ANA, despite its name, was considered a very distinct language, and mutually unintelligible, from \"Arabic\". Scholars named its variant dialects after the towns where the inscriptions were discovered (Dadanitic, Taymanitic, Hismaic, Safaitic). However, most arguments for a single ANA language or language family were based on the shape of the definite article, a prefixed h-. It has been argued that the h- is an archaism and not a shared innovation, and thus unsuitable for language classification, rendering the hypothesis of an ANA language family untenable. Safaitic and Hismaic, previously considered ANA, should be considered Old Arabic due to the fact that they participate in the innovations common to all forms of Arabic.The earliest attestation of continuous Arabic text in an ancestor of the modern Arabic script are three lines of poetry by a man named Garm(')all\u0101he found in En Avdat, Israel, and dated to around 125 CE. This is followed by the Namara inscription, an epitaph of the Lakhmid king Imru' al-Qays bar 'Amro, dating to 328 CE, found at Namaraa, Syria. From the 4th to the 6th centuries, the Nabataean script evolves into the Arabic script recognizable from the early Islamic era. There are inscriptions in an undotted, 17-letter Arabic script dating to the 6th century CE, found at four locations in Syria (Zabad, Jabal 'Usays, Har", "flag": 1, "segments": [[1643, 1649]], "strength": 5.5}
{"token_count": [2006], "text": "Sir Alfred Joseph Hitchcock  (13 August 1899\u00a0\u2013 29 April 1980) was an English filmmaker who was one of the most influential figures in the history of cinema. In a career spanning six decades, he directed over 50 feature films, many of which are still widely watched and studied today. Known as the \"Master of Suspense\", he became as well known as any of his actors thanks to his many interviews, his cameo roles in most of his films, and his hosting and producing the television anthology Alfred Hitchcock Presents (1955\u201365). His films garnered 46 Academy Award nominations, including six wins, although he never won the award for Best Director despite five nominations. \n\nHitchcock initially trained as a technical clerk and copy writer before entering the film industry in 1919 as a title card designer. His directorial debut was the British-German silent film The Pleasure Garden (1925). His first successful film, The Lodger: A Story of the London Fog (1927), helped to shape the thriller genre, and Blackmail (1929) was the first British \"talkie\". His thrillers The 39 Steps (1935) and The Lady Vanishes (1938) are ranked among the greatest British films of the 20th century. By 1939, he had international recognition and producer David O. Selznick persuaded him to move to Hollywood. A string of successful films followed, including Rebecca (1940), Foreign Correspondent (1940), Suspicion (1941), Shadow of a Doubt (1943), and Notorious (1946). Rebecca won the Academy Award for Best Picture, with Hitchcock nominated as Best Director; he was also nominated for Lifeboat (1944) and Spellbound (1945). After a brief commercial lull, he returned to form with Strangers on a Train (1951) and Dial M for Murder (1954); he then went on to direct four films often ranked among the greatest of all time: Rear Window (1954), Vertigo (1958), North by Northwest (1959) and Psycho (1960), the first and last of these garnering him Best Director nominations.   The Birds (1963) and  Marnie (1964) were also financially successful and are highly regarded by film historians. \n\nThe \"Hitchcockian\" style includes the use of camera movement to mimic a person's gaze, thereby turning viewers into voyeurs, and framing shots to maximise anxiety and fear. The film critic Robin Wood wrote that the meaning of a Hitchcock film \"is there in the method, in the progression from shot to shot. A Hitchcock film is an organism, with the whole implied in every detail and every detail related to the whole.\"  Hitchcock made multiple films with some of the biggest stars in Hollywood, including four with Cary Grant in the 1940s and 1950s, three with Ingrid Bergman in the last half of the 1940s, four with James Stewart over a ten-year span commencing in 1948, and three with Grace Kelly in the mid-1950s. Hitchcock became an American citizen in 1955.\n\nIn 2012, Hitchcock's psychological thriller Vertigo, starring Stewart, displaced Orson Welles' Citizen Kane (1941) as the British Film Institute's greatest film ever made based on its world-wide poll of hundreds of film critics., nine of his films had been selected for preservation in the United States National Film Registry,  including his personal favourite, Shadow of a Doubt (1943). He received the BAFTA Fellowship in 1971, the AFI Life Achievement Award in 1979 and was knighted in December that year, four months before his death on 29 April 1980.\n\nBiography\n\nEarly life: 1899\u20131919\n\nEarly childhood and education\n\nHitchcock was born on 13 August 1899 in the flat above his parents' leased grocer's shop at 517 High Road, Leytonstone, on the outskirts of East London (then part of Essex), the youngest of three children: William Daniel (1890\u20131943), Ellen Kathleen (\"Nellie\") (1892\u20131979), and Alfred Joseph (1899\u20131980). His parents, Emma Jane Hitchcock ( Whelan; 1863\u20131942), and William Edgar Hitchcock (1862\u20131914), were both Roman Catholics, with partial roots in Ireland; His father was a greengrocer, as his grandfather had been.\n\nThere was a large extended family, including uncle John Hitchcock with his five-bedroom Victorian house on Campion Road, Putney, complete with maid, cook, chauffeur and gardener. Every summer, his uncle rented a seaside house for the family in Cliftonville, Kent. Hitchcock said that he first became class-conscious there, noticing the differences between tourists and locals.\n\nDescribing himself as a well-behaved boy\u2014his father called him his \"little lamb without a spot\"\u2014Hitchcock said he could not remember ever having had a playmate. One of his favourite stories for interviewers was about his father sending him to the local police station with a note when he was five; the policeman looked at the note and locked him in a cell for a few minutes, saying, \"This is what we do to naughty boys.\" The experience left him, he said, with a lifelong fear of policemen; in 1973 he told Tom Snyder that he was \"scared stiff of anything\u00a0... to do with the law\" and wouldn't even drive a car in case he got a parking ticket.\n\nWhen he was six, the family moved to Limehouse and leased two stores at 130 and 175 Salmon Lane, which they ran as a fish-and-chips shop and fishmongers' respectively; they lived above the former. Hitchcock attended his first school, the Howrah House Convent in Poplar, which he entered in 1907, at age 7. According to biographer Patrick McGilligan, he stayed at Howrah House for at most two years. He also attended a convent school, the Wode Street School \"for the daughters of gentlemen and little boys\", run by the Faithful Companions of Jesus. He then attended a primary school near his home and was for a short time a boarder at Salesian College in Battersea.\n\nThe family moved again when he was 11, this time to Stepney, and on 5 October 1910 Hitchcock was sent to St Ignatius College in Stamford Hill, Tottenham (now in the London Borough of Haringey), a Jesuit grammar school with a reputation for discipline. The priests used a hard rubber cane on the boys, always at the end of the day, so the boys had to sit through classes anticipating the punishment if they had been written up for it. He later said that this is where he developed his sense of fear. The school register lists his year of birth as 1900 rather than 1899; biographer Donald Spoto says he was deliberately enrolled as a 10-year-old because he was a year behind with his schooling.\n\nWhile biographer Gene Adair reports that Hitchcock was \"an average, or slightly above-average, pupil\", Hitchcock said that he was \"usually among the four or five at the top of the class\"; at the end of his first year, his work in Latin, English, French and religious education was noted.  He told Peter Bogdanovich: \"The Jesuits taught me organisation, control and, to some degree, analysis.\"\n\nHis favourite subject was geography, and he became interested in maps, and railway, tram and bus timetables; according to John Russell Taylor, he could recite all the stops on the Orient Express. He also had a particular interest in London trams. An overwhelming majority of his films include rail or tram scenes, in particular The Lady Vanishes, Strangers on a Train and Number Seventeen. A clapperboard shows the number of the scene and the number of takes, and Hitchcock would often take the two numbers on the clapperboard and whisper the London tram route names. For example, if the clapperboard showed Scene 23; Take 3; Hitchcock would whisper \"Woodford, Hampstead\" \u2013 Woodford being the terminus of the route 23 tram, and Hampstead the end of route 3.\n\nHenley's\nHitchcock told his parents that he wanted to be an engineer, and on 25 July 1913, he left St Ignatius and enrolled in night classes at the London County Council School of Engineering and Navigation in Poplar. In a book-length interview in 1962, he told Fran\u00e7ois Truffaut that he had studied \"mechanics, electricity, acoustics, and navigation\". Then on 12 December 1914 his father, who had been suffering from emphysema and kidney disease, died at the age of 52. To support himself and his mother\u2014his older siblings had left home by then\u2014Hitchcock took a job, for 15 shillings a week (\u00a3 in ), as a technical clerk at the Henley Telegraph and Cable Company in Blomfield Street near London Wall. He continued night classes, this time in art history, painting, economics, and political science. Histhemed fashion. The new hobby older brother ran the family shops, while he and his mother continued to live in Salmon Lane.\n\nHitchcock was too young to enlist when the First World War started in July 1914, and when he reached the required age of 18 in 1917, he received a C3 classification (\"free from serious organic disease, able to stand service conditions in garrisons at home\u00a0... only suitable for sedentary work\"). He joined a cadet regiment of the Royal Engineers and took part in theoretical briefings, weekend drills, and exercises. John Russell Taylor wrote that, in one session of practical exercises in Hyde Park, Hitchcock", "flag": 1, "segments": [[1876, 1882]], "strength": 5.5}
{"token_count": [2006], "text": "Amsterdam (, , ) is the capital and most populous city of the Netherlands; with a population of 872,680 within the city proper, 1,558,755 in the urban area and 2,480,394 in the metropolitan area. Found within the Dutch province of North Holland, Amsterdam is colloquially referred to as the \"Venice of the North\", due to the large number of canals which form a UNESCO World Heritage Site.\n\nAmsterdam was founded at the Amstel, that was dammed to control flooding; the city's name derives from the Amstel dam. Originating as a small fishing village in the late 12th century, Amsterdam became one of the most important ports in the world during the Dutch Golden Age of the 17th century, and became the leading centre for the finance and trade sectors. In the 19th and 20th centuries, the city expanded and many new neighborhoods and suburbs were planned and built. The 17th-century canals of Amsterdam and the 19\u201320th century Defence Line of Amsterdam are on the UNESCO World Heritage List. Sloten, annexed in 1921 by the municipality of Amsterdam, is the oldest part of the city, dating to the 9th century.\n\nAmsterdam's main attractions include its historic canals, the Rijksmuseum, the Van Gogh Museum, the Stedelijk Museum, Hermitage Amsterdam, the Concertgebouw, the Anne Frank House, the Scheepvaartmuseum, the Amsterdam Museum, the Heineken Experience, the Royal Palace of Amsterdam, Natura Artis Magistra, Hortus Botanicus Amsterdam, NEMO, the red-light district and many cannabis coffee shops. It drew more than 5\u00a0million international visitors in 2014. The city is also well known for its nightlife and festival activity; with several of its nightclubs (Melkweg, Paradiso) among the world's most famous. Primarily known for its artistic heritage, elaborate canal system and narrow houses with gabled fa\u00e7ades; well-preserved legacies of the city's 17th-century Golden Age. These characteristics are arguably responsible for attracting millions of Amsterdam's visitors annually. Cycling is key to the city's character, and there are numerous biking paths and lanes spread throughout the entire city.\n\nThe Amsterdam Stock Exchange is considered the oldest \"modern\" securities market stock exchange in the world. As the commercial capital of the Netherlands and one of the top financial centres in Europe, Amsterdam is considered an alpha world city by the Globalization and World Cities (GaWC) study group. The city is also the cultural capital of the Netherlands. Many large Dutch institutions have their headquarters in the city, including: the Philips conglomerate, AkzoNobel, Booking.com, TomTom, and ING. Moreover, many of the world's largest companies are based in Amsterdam or have established their European headquarters in the city, such as leading technology companies Uber, Netflix and Tesla. In 2012, Amsterdam was ranked the second-best city to live in by the Economist Intelligence Unit (EIU) and 12th globally on quality of living for environment and infrastructure by Mercer. The city was ranked 4th place globally as top tech hub in the Savills Tech Cities 2019 report (2nd in Europe), and 3rd in innovation by Australian innovation agency 2thinknow in their Innovation Cities Index 2009. The Port of Amsterdam is the fifth largest in Europe. The KLM hub and Amsterdam's main airport, Schiphol, is the Netherlands' busiest airport as well as the third busiest in Europe and 11th busiest airport in the world. The Dutch capital is considered one of the most multicultural cities in the world, with at least 177 nationalities represented.\n\nA few of Amsterdam's notable residents throughout history include: painters Rembrandt and Van Gogh, the diarist Anne Frank, and philosopher Baruch Spinoza.\n\nHistory\n\nPrehistory\nDue to its geographical location in what used to be wet peatland, the founding of Amsterdam is of a younger age than the founding of other urban centers in the Low Countries. However, in and around the area of what later became Amsterdam, local farmers settled as early as three millennia ago. They lived along the prehistoric IJ river and upstream of its tributary Amstel. The prehistoric IJ was a shallow and quiet stream in peatland behind beach ridges. This secluded area could grow there into an important local settlement center, especially in the late Bronze Age, the Iron Age and the Roman Age. Neolithic and Roman artefacts have also been found downstream of this area, in the prehistoric Amstel bedding under Amsterdam's Damrak and Rokin, such as shards of Bell Beaker culture pottery (2200-2000 BC) and a granite grinding stone (2700-2750 BC). But the location of these artefacts around the river banks of the Amstel probably point to a presence of a modest semi-permanent or seasonal settlement of the previous mentioned local farmers. A permanent settlement would not have been possible, since the river mouth and the banks of the Amstel in this period in time were too wet for permanent habitation.\n\nEtymology and founding\n\nThe origins of Amsterdam is linked to the development of the peatland called Amestelle, meaning 'watery area', from Aa(m) 'river' + stelle'site at a shoreline', 'river bank'. In this area, land reclamation started as early as the late 10th century. Amestelle was located along a side arm of the IJ. This side arm took the name from the eponymous land: Amstel. Amestelle was inhabited by farmers, who lived more inland and more upstream, where the land was not as wet as at the banks of the downstream river mouth. These farmers were starting the reclamation around upstream Ouderkerk aan de Amstel, and later at the other side of the river at Amstelveen. The Van Amstel family, known in documents by this name since 1019, held the stewardship in this northwestern nook of the ecclesiastical district of the bishop of Utrecht. The family later served also under the count of Holland.\n\nA major turning point in the development of the Amstel river mouth is the All Saint's Flood of 1170. In an extremely short period of time, the shallow river IJ turned into a wide estuary, which from then on offered the Amstel an open connection to the Zuiderzee, IJssel and waterways further afield. This made the water flow of the Amstel more active, so excess water could be drained better. With drier banks, the downstream Amstel mouth became attractive for permanent habitation. Moreover, the river had grown from an insignificant peat stream into a junction of international waterways. A settlement was built here immediately after the landscape change of 1170, and right from the start of its foundation it focused on traffic, production and trade; not on farming, as opposed to how communities had lived further upstream for the past 200 years and northward for thousands of years. The construction of a dam at the mouth of the Amstel, eponymously named Dam, is historically estimated to have occurred between 1264 and 1275. The settlement first appeared in a document concerning a road toll granted by the count of Holland Floris V to the residents apud Amestelledamme 'at the dam in the Amstel' or 'at the dam of Amstelland'. This allowed the inhabitants of the village to travel freely through the County of Holland, paying no tolls at bridges, locks and dams. By 1327, the name had developed into Aemsterdam.\n\nMiddle Ages\nAmsterdam was granted city rights in either 1300 or 1306. From the 14th century on, Amsterdam flourished, largely from trade with the Hanseatic League. In 1345, an alleged Eucharistic miracle in Kalverstraat rendered the city an important place of pilgrimage until the adoption of the Protestant faith. The Miracle devotion went underground but was kept alive. In the 19th century, especially after the jubilee of 1845, the devotion was revitalised and became an important national point of reference for Dutch Catholics. The Stille Omgang\u2014a silent walk or procession in civil attire\u2014is the expression of the pilgrimage within the Protestant Netherlands since the late 19th century. In the heyday of the Silent Walk, up to 90,000 pilgrims came to Amsterdam. In the 21st century, this has reduced to about 5,000.\n\nConflict with Spain\n\nIn the 16th century, the Dutch rebelled against Philip II of Spain and his successors. The main reasons for the uprising were the imposition of new taxes, the tenth penny, and the religious persecution of Protestants by the newly introduced Inquisition. The revolt escalated into the Eighty Years' War, which ultimately led to Dutch independence. Strongly pushed by Dutch Revolt leader William the Silent, the Dutch Republic became known for its relative religious tolerance. Jews from the Iberian Peninsula, Huguenots from France, prosperous merchants and printers from F number who were expected to livelanders, and economic and religious refugees from the Spanish-controlled parts of the Low Countries found safety in Amsterdam. The influx of Flemish printers and the city's intellectual tolerance made Amsterdam a centre for the European free press.\n\nCentre of the Dutch Golden Age \n\nThe 17th century is considered Amsterdam's Golden Age, during which it became the wealthiest city in the western world. Ships sailed from Amsterdam to the Baltic Sea, North America, and Africa,", "flag": 1, "segments": [[1905, 1911]], "strength": 5.5}
{"token_count": [2006], "text": "Audi AG () (commonly referred to as Audi) is a German automotive manufacturer of luxury vehicles headquartered in Ingolstadt, Bavaria, Germany. As a subsidiary of its parent company, the Volkswagen Group, Audi produces vehicles in nine production facilities worldwide.\n\nThe origins of the company are complex, going back to the early 20th century and the initial enterprises (Horch and the Audiwerke) founded by engineer August Horch; and two other manufacturers (DKW and Wanderer), leading to the foundation of Auto Union in 1932. The modern Audi era began in the 1960s, when Auto Union was acquired by Volkswagen from Daimler-Benz. After relaunching the Audi brand with the 1965 introduction of the Audi F103 series, Volkswagen merged Auto Union with NSU Motorenwerke in 1969, thus creating the present-day form of the company.\n\nThe company name is based on the Latin translation of the surname of the founder, August Horch., meaning \"listen\" in German, becomes  in Latin. The four rings of the Audi logo each represent one of four car companies that banded together to create Audi's predecessor company, Auto Union. Audi's slogan is, meaning \"Being Ahead through Technology\". Audi, along with fellow German marques BMW and Mercedes-Benz, is among the best-selling luxury automobile brands in the world.\n\nHistory\n\nBirth of the company and its name\nAutomobile company Wanderer was originally established in 1885, later becoming a branch of Audi AG. Another company, NSU, which also later merged into Audi, was founded during this time, and later supplied the chassis for Gottlieb Daimler's four-wheeler.\n\nOn 14 November 1899, August Horch (1868\u20131951) established the company A. Horch & Cie. in the Ehrenfeld district of Cologne. In 1902, he moved with his company to Reichenbach im Vogtland. On 10 May 1904, he founded the August Horch & Cie. Motorwagenwerke AG, a joint-stock company in Zwickau (State of Saxony).\n\nAfter troubles with Horch chief financial officer, August Horch left Motorwagenwerke and founded in Zwickau on 16 July 1909, his second company, the August Horch Automobilwerke GmbH. His former partners sued him for trademark infringement. The German Reichsgericht (Supreme Court) in Leipzig, eventually determined that the Horch brand belonged to his former company.\n\nSince August Horch was prohibited from using \"Horch\" as a trade name in his new car business, he called a meeting with close business friends, Paul and Franz Fikentscher from Zwickau. At the apartment of Franz Fikentscher, they discussed how to come up with a new name for the company. During this meeting, Franz's son was quietly studying Latin in a corner of the room. Several times he looked like he was on the verge of saying something but would just swallow his words and continue working, until he finally blurted out, \"Father\u00a0\u2013  audiatur et altera pars...\u00a0wouldn't it be a good idea to call it audi instead of horch?\" \"Horch!\" in German means \"Hark!\" or \"hear\", which is \"Audi\" in the singular imperative form of \"audire\" \u2013 \"to listen\" \u2013 in Latin. The idea was enthusiastically accepted by everyone attending the meeting. On 25 April 1910 the Audi Automobilwerke GmbH Zwickau (from 1915 on Audiwerke AG Zwickau) was entered in the company's register of Zwickau registration court.\n\nThe first Audi automobile, the Audi Type A 10/ Sport-Phaeton, was produced in the same year, followed by the successor Type B 10/28PS in the same year.\n\nAudi started with a 2,612\u00a0cc inline-four engine model Type A, followed by a 3,564\u00a0cc model, as well as 4,680\u00a0cc and 5,720\u00a0cc models. These cars were successful even in sporting events. The first six-cylinder model Type M, 4,655\u00a0cc appeared in 1924.\n\nAugust Horch left the Audiwerke in 1920 for a high position at the ministry of transport, but he was still involved with Audi as a member of the board of trustees. In September 1921, Audi became the first German car manufacturer to present a production car, the Audi Type K, with left-handed drive. Left-hand drive spread and established dominance during the 1920s because it provided a better view of oncoming traffic, making overtaking safer when driving on the right.\n\nThe merger of the four companies under the logo of four rings\n\nIn August 1928, J\u00f8rgen Rasmussen, the owner of Dampf-Kraft-Wagen (DKW), acquired the majority of shares in Audiwerke AG. In the same year, Rasmussen bought the remains of the U.S. automobile manufacturer Rickenbacker, including the manufacturing equipment for 8-cylinder engines. These engines were used in Audi Zwickau and Audi Dresden models that were launched in 1929. At the same time, 6-cylinder and 4-cylinder (the \"four\" with a Peugeot engine) models were manufactured. Audi cars of that era were luxurious cars equipped with special bodywork.\n\nIn 1932, Audi merged with Horch, DKW, and Wanderer, to form Auto Union AG, Chemnitz. It was during this period that the company offered the Audi Front that became the first European car to combine a six-cylinder engine with front-wheel drive. It used a power train shared with the Wanderer, but turned 180 degrees, so that the drive shaft faced the front.\n\nBefore World War II, Auto Union used the four interlinked rings that make up the Audi badge today, representing these four brands. However, this badge was used only on Auto Union racing cars in that period while the member companies used their own names and emblems. The technological development became more and more concentrated and some Audi models were propelled by Horch- or Wanderer-built engines.\n\nReflecting the economic pressures of the time, Auto Union concentrated increasingly on smaller cars through the 1930s, so that by 1938 the company's DKW brand accounted for 17.9% of the German car market, while Audi held only 0.1%. After the final few Audis were delivered in 1939 the \"Audi\" name disappeared completely from the new car market for more than two decades.\n\nPost-World War II\n\nLike most German manufacturing, at the onset of World War II the Auto Union plants were retooled for military production, and were a target for allied bombing during the war which left them damaged.\n\nOverrun by the Soviet Army in 1945, on the orders of the Soviet Union military administration the factories were dismantled as part of war reparations. Following this, the company's entire assets were expropriated without compensation. On 17 August 1948, Auto Union AG of Chemnitz was deleted from the commercial register. These actions had the effect of liquidating Germany's Auto Union AG. The remains of the Audi plant of Zwickau became the VEB (for \"People Owned Enterprise\")  or AWZ (in English: Automobile Works Zwickau).\n\nWith no prospect of continuing production in Soviet-controlled East Germany, Auto Union executives began the process of relocating what was left of the company to West Germany. A site was chosen in Ingolstadt, Bavaria, to start a spare parts operation in late 1945, which would eventually serve as the headquarters of the reformed Auto Union in 1949.\n\nThe former Audi factory in Zwickau restarted assembly of the pre-war models in 1949. These DKW models were renamed to IFA F8 and IFA F9 and were similar to the West German versions. West and East German models were equipped with the traditional and renowned DKW two-stroke engines. The Zwickau plant manufactured the infamous Trabant until 1991, when it came under Volkswagen control\u2014effectively bringing it under the same umbrella as Audi since 1945.\n\nNew Auto Union unit\nA new West German headquartered Auto Union was launched in Ingolstadt with loans from the Bavarian state government and Marshall Plan aid. The reformed company was launched 3 September 1949 and continued DKW's tradition of producing front-wheel drive vehicles with two-stroke engines. This included production of a small but sturdy 125\u00a0cc motorcycle and a DKW delivery van, the DKW F89 L at Ingolstadt. The Ingolstadt site was large, consisting of an extensive complex of formerly military buildings which was suitable for administration as well as vehicle warehousing and distribution, but at this stage there was at Ingolstadt no dedicated plant suitable for mass production of automobiles: for manufacturing the company's first post-war mass-market passenger car plant capacity in D\u00fcsseldorf was rented from Rheinmetall-Borsig. It was only ten years later, after the company had attracted an investor, when funds became available for construction of major car plant at the Ingolstadt head office site.\n\nIn business possible for those left from 1958, in response to pressure from Friedrich Flick, then the company's largest single shareholder, Daimler-Benz took an 87% holding in the Auto Union company, and this was increased to a 100% holding in 1959. However, small two-stroke cars were not the focus of Daimler-Benz's interests, and while the early", "flag": 1, "segments": [[1929, 1935]], "strength": 5.5}
{"token_count": [2006], "text": "Alexander Graham Bell (, born Alexander Bell; March 3, 1847 \u2013 August 2, 1922) was a  Scottish-born inventor, scientist, and engineer who is credited with patenting the first practical telephone. He also co-founded the American Telephone and will be a major source of Telegraph Company (AT&T) in 1885.\n\nBell's father, grandfather, and brother had all been associated with work on elocution and speech and both his mother and wife were deaf; profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices which eventually culminated in Bell being awarded the first U.S. patent for the telephone, on March 7, 1876. Bell considered his invention an intrusion on his real work as a scientist and refused to have a telephone in his study.\n\nMany other inventions marked Bell's later life, including groundbreaking work in optical telecommunications, hydrofoils, and aeronautics. Although Bell was not one of the 33 founders of the National Geographic Society, he had a strong influence on the magazine while serving as the second president from January 7, 1898, until 1903.\n\nBeyond his work in engineering, Bell had a deep interest in the emerging science of heredity.\n\nEarly life\nAlexander Bell was born in Edinburgh, Scotland, on March 3, 1847. The family home was at South Charlotte Street, and has a stone inscription marking it as Alexander Graham Bell's birthplace. He had two brothers: Melville James Bell (1845\u20131870) and Edward Charles Bell (1848\u20131867), both of whom would die of tuberculosis. His father was Professor Alexander Melville Bell, a phonetician, and his mother was Eliza Grace Bell (n\u00e9e Symonds). Born as just \"Alexander Bell\", at age 10, he made a plea to his father to have a middle name like his two brothers. For his 11th birthday, his father acquiesced and allowed him to adopt the name \"Graham\", chosen out of respect for Alexander Graham, a Canadian being treated by his father who had become a family friend. To close relatives and friends he remained \"Aleck\".\n\nFirst invention\nAs a child, young Bell displayed a curiosity about his world; he gathered botanical specimens and ran experiments at an early age. His best friend was Ben Herdman, a neighbour whose family operated a flour mill. At the age of 12, Bell built a homemade device that combined rotating paddles with sets of nail brushes, creating a simple dehusking machine that was put into operation at the mill and used steadily for a number of years. In return, Ben's father John Herdman gave both boys the run of a small workshop in which to \"invent\".\n\nFrom his early years, Bell showed a sensitive nature and a talent for art, poetry, and music that was encouraged by his mother. With no formal training, he mastered the piano and became the family's pianist. Despite being normally quiet and introspective, he revelled in mimicry and \"voice tricks\" akin to ventriloquism that continually entertained family guests during their occasional visits. Bell was also deeply affected by his mother's gradual deafness (she began to lose her hearing when he was 12), and learned a manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour. He also developed a technique of speaking in clear, modulated tones directly into his mother's forehead wherein she would hear him with reasonable clarity. Bell's preoccupation with his mother's deafness led him to study acoustics.\n\nHis family was long associated with the teaching of elocution: his grandfather, Alexander Bell, in London, his uncle in Dublin, and his father, in Edinburgh, were all elocutionists. His father published a variety of works on the subject, several of which are still well known, especially his The Standard Elocutionist (1860), which appeared in Edinburgh in 1868. The Standard Elocutionist appeared in 168 British editions and sold over a quarter of a million copies in the United States alone. In this treatise, his father explains his methods of how to instruct deaf-mutes (as they were then known) to articulate words and read other people's lip movements to decipher meaning. Bell's father taught him and his brothers not only to write Visible Speech but to identify any symbol and its accompanying sound. Bell became so proficient that he became a part of his father's public demonstrations and astounded audiences with his abilities. He could decipher Visible Speech representing virtually every language, including Latin, Scottish Gaelic, and even Sanskrit, accurately reciting written tracts without any prior knowledge of their pronunciation.\n\nEducation\nAs a young child, Bell, like his brothers, received his early schooling at home from his father. At an early age, he was enrolled at the Royal High School, Edinburgh, Scotland, which he left at the age of 15, having completed only the first four forms. His school record was undistinguished, marked by absenteeism and lacklustre grades. His main interest remained in the sciences, especially biology, while he treated other school subjects with indifference, to the dismay of his father. Upon leaving school, Bell travelled to London to live with his grandfather, Alexander Bell, on Harrington Square. During the year he spent with his grandfather, a love of learning was born, with long hours spent in serious discussion and study. The elder Bell took great efforts to have his young pupil learn to speak clearly and with conviction, the attributes that his pupil would need to become a teacher himself. At the age of 16, Bell secured a position as a \"pupil-teacher\" of elocution and music, in Weston House Academy at Elgin, Moray, Scotland. Although he was enrolled as a student in Latin and Greek, he instructed classes himself in return for board and \u00a310 per session. The following year, he attended the University of Edinburgh, joining his older brother Melville who had enrolled there the previous year. In 1868, not long before he departed for Canada with his family, Bell completed his matriculation exams and was accepted for admission to University College London.\n\nFirst experiments with sound\nHis father encouraged Bell's interest in speech and, in 1863, took his sons to see a unique automaton developed by Sir Charles Wheatstone based on the earlier work of Baron Wolfgang von Kempelen. The rudimentary \"mechanical man\" simulated a human voice. Bell was fascinated by the machine and after he obtained a copy of von Kempelen's book, published in German, and had laboriously translated it, he and his older brother Melville built their own automaton head. Their father, highly interested in their project, offered to pay for any supplies and spurred the boys on with the enticement of a \"big prize\" if they were successful. While his brother constructed the throat and larynx, Bell tackled the more difficult task of recreating a realistic skull. His efforts resulted in a remarkably lifelike head that could \"speak\", albeit only a few words. The boys would carefully adjust the \"lips\" and when a bellows forced air through the windpipe, a very recognizable \"Mama\" ensued, to the delight of neighbours who came to see the Bell invention.\n\nIntrigued by the results of the automaton, Bell continued to experiment with a live subject, the family's Skye Terrier, \"Trouve\". After he taught it to growl continuously, Bell would reach into its mouth and manipulate the dog's lips and vocal cords to produce a crude-sounding \"Ow ah oo ga ma ma\". With little convincing, visitors believed his dog could articulate \"How are you, grandmama?\" Indicative of his playful nature, his experiments convinced onlookers that they saw a \"talking dog\". These initial forays into experimentation with sound led Bell to undertake his first serious work on the transmission of sound, using tuning forks to explore resonance.\n\nAt age 19, Bell wrote a report on his work and sent it to philologist Alexander Ellis, a colleague of his father. Ellis immediately wrote back indicating that the experiments were similar to existing work in Germany, and also lent Bell a copy of Hermann von Helmholtz's work, The Sensations of Tone as a Physiological Basis for the Theory of Music.\n\nDismayed to find that groundbreaking work had already been undertaken by Helmholtz who had conveyed vowel sounds by means of a similar tuning fork \"contraption\", Bell pored over the German scientist's book. Working from his own erroneous mistranslation of a French edition, Bell fortuitously then made a deduction that would be the underpinning of all his future work on transmitting sound, reporting: \"Without knowing much about the subject, it seemed to me that if vowel sounds could be produced by electrical means, so could consonants, so could articulate speech.\" He also later remarked: \"I thought that Helmholtz had done it\u00a0... and that my failure was due only to my ignorance of electricity. It was a valuable blunder\u00a0... If I had been able to read German in those days, I might never have commenced my experiments!\"\n\nFamily tragedy\nIn 1865, when the Bell family moved to London, Bell returned to Weston House as an assistant master and, in his spare hours, continued experiments on sound using a minimum of laboratory equipment. Bell concentrated on experimenting with electricity to convey sound and later installed a telegraph wire from his room in Somerset College to that of a friend. Throughout late 1867, his health faltered mainly through exhaustion. His younger brother, Edward \"Ted,\" was similarly bed-ridden", "flag": 1, "segments": [[52, 58]], "strength": 5.5}
{"token_count": [2006], "text": "Apple Inc. is an American multinational technology company that specializes in consumer electronics, software and online services. Apple is the largest information technology company by revenue (totaling  in 2021) and, as of January 2021, it is the world's most valuable company, the fourth-largest personal computer vendor by unit sales and second-largest mobile phone manufacturer. It is one of the Big Five American information technology companies, alongside Alphabet, Amazon, Meta, and Microsoft.\n\nApple was founded as Apple Computer Company on April 1, 1976, by Steve Jobs, Steve Wozniak and Ronald Wayne to develop and\nNewton passed Joe Thomas sell Wozniak's Apple I personal computer. It was incorporated by Jobs and Wozniak as Apple Computer, Inc. in 1977 and the company's next computer, the Apple II became a best seller. Apple went public in 1980, to instant financial success. The company went onto develop new computers featuring innovative graphical user interfaces, including the original Macintosh, announced in a critically acclaimed advertisement, \"1984\", directed by Ridley Scott. By 1985, the high cost of its products and power struggles between executives caused problems. Wozniak stepped back from Apple amicably, while Jobs resigned to found NeXT, taking some Apple employees with him.\n\nAs the market for personal computers expanded and evolved throughout the 1990s, Apple lost considerable market share to the lower-priced duopoly of the Microsoft Windows operating system on Intel-powered PC clones (also known as \"Wintel\"). In 1997, weeks away from bankruptcy, the company bought NeXT to resolve Apple's unsuccessful operating system strategy and entice Jobs back to the company. Over the next decade, Jobs guided Apple back to profitability through a number of tactics including introducing the iMac, iPod, iPhone and iPad to critical acclaim, launching memorable advertising campaigns, opening the Apple Store retail chain, and acquiring numerous companies to broaden the company's product portfolio. Jobs resigned in 2011 for health reasons, and died two months later. He was succeeded as CEO by Tim Cook.\n\nApple became the first publicly traded U.S. company to be valued at over $1\u00a0trillion in August 2018, then $2\u00a0trillion in August 2020, and most recently $3\u00a0trillion in January 2022. The company receives criticism regarding the labor practices of its contractors, its environmental practices, and its business ethics, including anti-competitive practices and materials sourcing. The company enjoys a high level of brand loyalty, and is ranked as one of the world's most valuable brands.\n\nHistory\n\n1976\u20131980: Founding and incorporation \n\nApple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a business partnership. The company's first product was the Apple I, a computer designed and hand-built entirely by Wozniak. To finance its creation, Jobs sold his only motorized means of transportation, a VW Bus, for a few hundred dollars, and Wozniak sold his HP-65 calculator for. Wozniak debuted the first prototype Apple I at the Homebrew Computer Club in July 1976. The Apple I was sold as a motherboard with CPU, RAM, and basic textual-video chips\u2014a base kit concept which would not yet be marketed as a complete personal computer. It went on sale soon after debut for. Wozniak later said he was unaware of the coincidental mark of the beast in the number 666, and that he came up with the price because he liked \"repeating digits\".\n\nApple Computer, Inc. was incorporated on January 3, 1977, without Wayne, who had left and sold his share of the company back to Jobs and Wozniak for $800 only twelve days after having co-founded Apple. Multimillionaire Mike Markkula provided essential business expertise and funding of  to Jobs and Wozniak during the incorporation of Apple. During the first five years of operations, revenues grew exponentially, doubling about every four months. Between September 1977 and September 1980, yearly sales grew from $775,000 to $118\u00a0million, an average annual growth rate of 533%.\n\nThe Apple II, also invented by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, because of its character cell-based color graphics and open architecture. While the Apple I and early Apple II models used ordinary audio cassette tapes as storage devices, they were superseded by the introduction of a -inch floppy disk drive and interface called the Disk II in 1978.\n\nThe Apple II was chosen to be the desktop platform for the first \"killer application\" of the business world: VisiCalc, a spreadsheet program released in 1979. VisiCalc created a business market for the Apple II and gave home users an additional reason to buy an Apple II: compatibility with the office. Before VisiCalc, Apple had been a distant third place competitor to Commodore and Tandy. By the end of the 1970s, Apple had become the leading computer manufacturer in the United States.\n\nOn December 12, 1980, Apple (ticker symbol \"AAPL\") went public selling 4.6\u00a0million shares at $22 per share ($.39 per share when adjusting for stock splits ), generating over $100\u00a0million, which was more capital than any IPO since Ford Motor Company in 1956. By the end of the day, 300\u00a0millionaires were created, from a stock price of $29 per share and a market cap of $1.778\u00a0billion.\n\n1980\u20131990: Success with Macintosh \n\nA critical moment in the company's history came in December 1979 when Jobs and several Apple employees, including human\u2013computer interface expert Jef Raskin, visited Xerox PARC in to see a demonstration of the Xerox Alto, a computer using a graphical user interface. Xerox granted Apple engineers three days of access to the PARC facilities in return for the option to buy 100,000 shares (5.6\u00a0million split-adjusted shares ) of Apple at the pre-IPO price of $10 a share. After the demonstration, Jobs was immediately convinced that all future computers would use a graphical user interface, and development of a GUI began for the Apple Lisa, named after Jobs's daughter.\n\nThe Lisa division would be plagued by infighting, and in 1982 Jobs was pushed off the project. The Lisa launched in 1983 and became the first personal computer sold to the public with a GUI, but was a commercial failure due to its high price and limited software titles.\n\nJobs, angered by being pushed off the Lisa team, took over the company's Macintosh division. Wozniak and Raskin had envisioned the Macintosh as low-cost-computer with a text-based interface like the Apple II, but a plane crash in 1981 forced Wozniak to step back from the project. Jobs quickly redefined the Macintosh as a graphical system that would be cheaper than the Lisa, undercutting his former division. Jobs was also hostile to the Apple II division, which at the time, generated most of the company's revenue.\n\nIn 1984, Apple launched the Macintosh, the first personal computer to be sold without a programming language. Its debut was signified by \"1984\", a $1.5\u00a0million television advertisement directed by Ridley Scott that aired during the third quarter of Super Bowl XVIII on January 22, 1984. This is now hailed as a watershed event for Apple's success and was called a \"masterpiece\" by CNN and one of the greatest TV advertisements of all time by TV Guide.\n\nThe advertisement created great interest in the original Macintosh, and sales were initially good, but began to taper off dramatically after the first three months as reviews started to come in. Jobs had made the decision to equip the original Macintosh with 128 kilobytes of RAM, attempting to reach a  price point, which limited its speed and the software that could be used. The Macintosh would eventually ship for, a price panned by critics in light of its slow performance. In early 1985, this sales slump triggered a power struggle between Steve Jobs and CEO John Sculley, who had been hired away from Pepsi two years earlier by Jobs using the famous line, \"Do you want to sell sugar water for the rest of your life or come with me and change the world?\" Sculley decided to remove Jobs as the head of the Macintosh division, with unanimous support from the Apple board of directors.\n\nThe board of directors instructed Sculley to contain Jobs and his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from his leadership role at Apple. Informed by Jean-Louis Gass\u00e9e, Sculley found out that Jobs had been attempting to organize a boardroom coup and called an emergency meeting at which Apple's executive staff sided with Sculley and stripped Jobs of all operational duties. Jobs resigned from Apple in September 1985 and took a number of Apple employees with him to found NeXT. Wozniak had also quit his active employment at Apple earlier in 1985 to pursue other ventures, expressing his frustration with Apple's treatment of the Apple II division and stating that the company had \"been going in the wrong direction for the last five years\". Despite Wozniak's grievances, he officially remained employed by Apple, and to this day continues to work for the company as a representative, receiving a stipend estimated to be $120,000 per year for this role. Both Jobs and Wozniak remained Apple shareholders after their departures.\n\nAfter the departures of Jobs and Wozniak,", "flag": 1, "segments": [[123, 129]], "strength": 5.5}
{"token_count": [2006], "text": "The American Civil War (April 12, 1861 \u2013 May 9, 1865; also known by other names) was a civil war in the United States between the Union (states that remained loyal to the federal union, or \"the North\") and the Confederacy (states that voted to secede, or \"the South\"). The central cause of the war was the status of slavery, especially the expansion of slavery into territories acquired as a result of the Louisiana Purchase and the Mexican\u2013American War. On the eve of the Civil War in 1860, four million of the 32 million Americans (~13%) were enslaved black people, almost all in the South.\n\nThe practice of slavery in the United States was one of the key political issues of the 19th century. Decades of political unrest over slavery led up to the Civil War. Disunion came after Abraham Lincoln won the 1860 United States presidential election on an anti-slavery expansion platform. An initial seven southern slave states declared their secession from the country to form the Confederacy. Confederate forces seized federal forts within territory they claimed. The last minute Crittenden Compromise tried to avert conflict but failed; both sides prepared for war. Fighting broke out in April 1861 when the Confederate army began the Battle of Fort Sumter in South Carolina, just over a month after the first inauguration of Abraham Lincoln. The Confederacy grew to control at least a majority of territory in eleven states (out of the 34 U.S. states in February 1861), and asserted claims to two more. Both sides raised large volunteer and conscription armies. Four years of intense combat, mostly in the South, ensued.\n\nDuring 1861\u20131862 in the war's Western Theater, the Union made significant permanent gainsthough in the war's Eastern Theater the conflict was inconclusive. On January 1, 1863, Lincoln issued the Emancipation Proclamation, which made ending slavery a war goal, declaring all persons held as slaves in states in rebellion \"forever free.\" To the west, the Union destroyed the Confederate river navy by the summer of 1862, then much of its western armies, and seized New Orleans. The successful 1863 Union siege of Vicksburg split the Confederacy in two at the Mississippi River. In 1863, Confederate General Robert E. Lee's incursion north ended at the Battle of Gettysburg. Western successes led to General Ulysses S. Grant's command of all Union armies in 1864. Inflicting an ever-tightening naval blockade of Confederate ports, the Union marshaled resources and manpower to attack the Confederacy from all directions. This led to the fall of Atlanta in 1864 to Union General William Tecumseh Sherman and his march to the sea. The last significant battles raged around the ten-month Siege of Petersburg, gateway to the Confederate capital of Richmond.\n\nThe Civil War effectively ended on April 9, 1865, when Confederate General Lee surrendered to Union General Grant at the Battle of Appom running gear beat Wall Street'sattox Court House, after Lee had abandoned Petersburg and Richmond. Confederate generals throughout the Confederate army followed suit. The conclusion of the American Civil War lacks a clean end date: land forces continued surrendering until June 23. By the end of the war, much of the South's infrastructure was destroyed, especially its railroads. The Confederacy collapsed, slavery was abolished, and four million enslaved black people were freed. The war-torn nation then entered the Reconstruction era in a partially successful attempt to rebuild the country and grant civil rights to freed slaves.\n\nThe Civil War is one of the most studied and written about episodes in the history of the United States. It remains the subject of cultural and historiographical debate. Of particular interest is the persisting myth of the Lost Cause of the Confederacy. The American Civil War was among the earliest to use industrial warfare. Railroads, the telegraph, steamships, the ironclad warship, and mass-produced weapons saw wide use. In total the war left between 620,000 and 750,000 soldiers dead, along with an undetermined number of civilian casualties. President Lincoln was assassinated just five days after Lee's surrender. The Civil War remains the deadliest military conflict in American history. The technology and brutality of the Civil War foreshadowed the coming World Wars.\n\nCauses of secession\n\nThe causes of secession were complex and have been controversial since the war began, but most academic scholars\u00a0identify\u00a0slavery as the central cause of the war. The issue has been further complicated by historical revisionists, who have tried to offer a variety of reasons for the war. Slavery was the central source of escalating political tension in the 1850s. The Republican Party was determined to prevent any spread of slavery to the territories, which, after they were admitted as states, would give the North greater representation in Congress and the Electoral College. Many Southern leaders had threatened secession if the Republican candidate, Lincoln, won the 1860 election. After Lincoln won, many Southern leaders felt that disunion was their only option, fearing that the loss of representation would hamper their ability to promote pro-slavery acts and policies. In his second inaugural address, Lincoln said that \"slaves constituted a peculiar and powerful interest. All knew that this interest was, somehow, the cause of the war. To strengthen, perpetuate, and extend this interest was the object for which the insurgents would rend the Union, even by war; while the government claimed no right to do more than to restrict the territorial enlargement of it.\"\n\nSlavery\n\nSlavery was the main cause of disunion. Slavery had been a controversial issue during the framing of the Constitution but had been left unsettled. The issue of slavery had confounded the nation since its inception, and increasingly separated the United States into a slaveholding South and a free North. The issue was exacerbated by the rapid territorial expansion of the country, which repeatedly brought to the fore the issue of whether new territory should be slaveholding or free. The issue had dominated politics for decades leading up to the war. Key attempts to solve the issue included the Missouri Compromise and the Compromise of 1850, but these only postponed an inevitable showdown over slavery.\n\nThe motivations of the average person were not inherently those of their faction; some Northern soldiers were even indifferent on the subject of slavery, but a general pattern can be established. Confederate soldiers fought the war primarily to protect a Southern society of which slavery was an integral part. From the anti-slavery perspective, the issue was primarily whether slavery was an anachronistic evil incompatible with republicanism. The strategy of the anti-slavery forces was containment\u2014to stop the expansion of slavery and thereby put it on a path to ultimate extinction. The slaveholding interests in the South denounced this strategy as infringing upon their constitutional rights. Southern whites believed that the emancipation of slaves would destroy the South's economy, due to the large amount of capital invested in slaves and fears of integrating the ex-slave black population. In particular, many Southerners feared a repeat of 1804 Haiti massacre (also known as \"the horrors of Santo Domingo\"), in which former slaves systematically murdered most of what was left of the country's white population \u2014 including men, women, children, and even many sympathetic to abolition \u2014 after the successful slave revolt in Haiti. Historian Thomas Fleming points to the historical phrase \"a disease in the public mind\" used by critics of this idea and proposes it contributed to the segregation in the Jim Crow era following emancipation. These fears were exacerbated by the 1859 attempt of John Brown to instigate an armed slave rebellion in the South.\n\nAbolitionists\n\nThe abolitionists \u2013 those advocating the end of slavery \u2013 were very active in the decades leading up to the Civil War. They traced their philosophical roots back to the Puritans, who strongly believed that slavery was morally wrong. One of the early Puritan writings on this subject was The Selling of Joseph, by Samuel Sewall in 1700. In it, Sewall condemned slavery and the slave trade and refuted many of the era's typical justifications for slavery.\n\nThe American Revolution and the cause of liberty added tremendous impetus to the abolitionist cause. Slavery, which had been around for thousands of years, was considered normal and was not a significant issue of public debate prior to the Revolution. The Revolution changed that and made it into an issue that had to be addressed. As a result, during and shortly after the Revolution, the northern states quickly started outlawing slavery. Even in southern states, laws were changed to limit slavery and facilitate manumission. The amount of indentured servitude dropped dramatically throughout the country. An Act Prohibiting Importation of Slaves sailed through Congress with little opposition. President Thomas Jefferson supported it, and it went into effect on January 1, 1808. Benjamin Franklin and James Madison each helped found manumission societies. Influenced by the Revolution, many slave owners freed their slaves, but some, such as George Washington, did so only in their wills. The number of free blacks as a proportion of the black population in the upper South increased from less than 1 percent to nearly 10 percent between 1790 and 1810 as a result of these actions.\n\nThe establishment of the Northwest Territory as \"free soil\" \u2013 no slavery \u2013 by Manasseh Cutler and Rufus Putnam (who both came from Puritan New England) would also prove crucial. This territory (which became the states of Ohio, Michigan, Indiana, Illinois, Wisconsin and part of Minnesota) doubled the size of the United States.\n\nIn the decades leading up to the Civil War, abolitionists, such as Theodore Parker, Ralph Waldo Emerson, Henry David Thoreau and Frederick Douglass, repeatedly used the Puritan heritage of the country to bolster their", "flag": 1, "segments": [[599, 605]], "strength": 5.5}
{"token_count": [2006], "text": "Andy Warhol (; born Andrew Warhola Jr.; August 6, 1928 \u2013 February 22, 1987) was an American artist, film director, and producer who was a leading figure in the visual art movement known as pop art. His works explore the relationship between artistic expression, advertising, and celebrity culture that flourished by the 1960s, and span a variety of media, including painting, silkscreening, photography, film, and sculpture. Some of his best known works include the silkscreen paintings Campbell's Soup Cans (1962) and Marilyn Diptych (1962), the experimental films Empire (1964) and Chelsea Girls (1966), and the multimedia events known as the Exploding Plastic Inevitable (1966\u201367).\n\nBorn and raised in Pittsburgh, Warhol initially pursued a successful career as a commercial illustrator. After exhibiting his work in several galleries in the late 1950s, he began to receive recognition as an influential and controversial artist. His New York studio, The Factory, became a well-known gathering place that brought together distinguished intellectuals, drag queens, playwrights, Bohemian street people, Hollywood celebrities, and wealthy patrons. He promoted a collection of personalities known as Warhol superstars, and is credited with inspiring the widely used expression \"15 minutes of fame\". In the late 1960s he managed and produced the experimental rock band The Velvet Underground and founded Interview magazine. He authored numerous books, including The Philosophy of Andy Warhol and Popism: The Warhol Sixties. He lived openly as a gay man before the gay liberation movement. In June 1968, he was almost killed by radical feminist Valerie Solanas,  who shot him inside his studio. After gallbladder surgery, Warhol died of cardiac arrhythmia in February 1987 at the age of 58 in New York.\n\nWarhol has been the subject of numerous retrospective exhibitions, books, and feature and documentary films. The Andy Warhol Museum in his native city of Pittsburgh, which holds an extensive permanent collection of art and archives, is the largest museum in the United States dedicated to a single artist. A 2009 article in The Economist described Warhol as the \"bellwether of the art market\". Many of his creations are very collectible and highly valuable. The highest price ever paid for a Warhol painting is $105 million for a 1963 serigraph titled Silver Car Crash (Double Disaster). His works include some of the most expensive paintings ever sold.\n\nBiography\n\nEarly life and beginnings (1928\u20131949)\n\nWarhol was born on August 6, 1928, in Pittsburgh, Pennsylvania. He was the fourth child of Ondrej Warhola (Americanized as Andrew Warhola, Sr., 1889\u20131942) and Julia (n\u00e9e Zavack\u00e1, 1892\u20131972), whose first child was born in their homeland of Austria-Hungary and died before their move to the U.S.\n\nHis parents were working-class Lemkos emigrants from Mik\u00f3, Austria-Hungary (now called Mikov\u00e1, located in today's northeastern Slovakia). Warhol's father emigrated to the United States in 1914, and his mother joined him in 1921, after the death of Warhol's grandparents. Warhol's father worked in a coal mine. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. The family was Ruthenian Catholic and attended St. John Chrysostom Byzantine Catholic Church. Andy Warhol had two elder brothers\u2014Pavol (Paul), the eldest, was born before the family emigrated; J\u00e1n was born in Pittsburgh. Pavol's son, James Warhola, became a successful children's book illustrator.\n\nIn third grade, Warhol had Sydenham's chorea (also known as St. Vitus' Dance), the nervous system disease that causes involuntary movements of the extremities, which is believed to be a complication of scarlet fever which causes skin pigmentation blotchiness. At times when he was confined to bed, he drew, listened to the radio and collected pictures of movie stars around his bed. Warhol later described this period as very important in the development of his personality, skill-set and preferences. When Warhol was 13, his father died in an accident.\n\nAs a teenager, Warhol graduated from Schenley High School in 1945, and as a teen, Warhol also won a Scholastic Art and Writing Award. After graduating from high school, his intentions were to study art education at the University of Pittsburgh in the hope of becoming an art teacher, but his plans changed and he enrolled in the Carnegie Institute of Technology, now Carnegie Mellon University in Pittsburgh, where he studied commercial art. During his time there, Warhol joined the campus Modern Dance Club and Beaux Arts Society. He also served as art director of the student art magazine, Cano, illustrating a cover in 1948 and a full-page interior illustration in 1949. These are believed to be his first two published artworks. Warhol earned a Bachelor of Fine Arts in pictorial design in 1949. Later that year, he moved to New York City and began a career in magazine illustration and advertising.\n\n1950s\n\nWarhol's early career was dedicated to commercial and advertising art, where his first commission had been to draw shoes for Glamour magazine in the late 1940s. In the 1950s, Warhol worked as a designer for shoe manufacturer Israel Miller. While working in the shoe industry, Warhol developed his \"blotted line\" technique, applying ink to paper and then blotting the ink while still wet, which was akin to a printmaking process on the most rudimentary scale. His use of tracing paper and ink allowed him to repeat the basic image and also to create endless variations on the themeThe women, who asked that. American photographer John Coplans recalled that\n\nIn 1952, Warhol had his first solo show at the Hugo Gallery in New York, and although that show was not well received, by 1956, he was included in his first group exhibition at the Museum of Modern Art, New York. Warhol's \"whimsical\" ink drawings of shoe advertisements figured in some of his earliest showings at the Bodley Gallery in New York in 1957.\n\nWarhol habitually used the expedient of tracing photographs projected with an epidiascope. Using prints by Edward Wallowitch, his \"first boyfriend,\" the photographs would undergo a subtle transformation during Warhol's often cursory tracing of contours and hatching of shadows. Warhol used Wallowitch's photograph Young Man Smoking a Cigarette (c.1956), for a 1958 design for a book cover he submitted to Simon and Schuster for the Walter Ross pulp novel The Immortal, and later used others for his series of paintings.\n\nWith the rapid expansion of the record industry, RCA Records hired Warhol, along with another freelance artist, Sid Maurer, to design album covers and promotional materials.\n\n1960s\n\nWarhol was an early adopter of the silk screen printmaking process as a technique for making paintings. In 1962, Warhol was taught silk screen printmaking techniques by Max Arthur Cohn at his graphic arts business in Manhattan. In his book Popism: The Warhol Sixties, Warhol writes: \"When you do something exactly wrong, you always turn up something.\"\n\nIn May 1962, Warhol was featured in an article in Time magazine with his painting Big Campbell's Soup Can with Can Opener (Vegetable) (1962), which initiated his most sustained motif, the Campbell's soup can. That painting became Warhol's first to be shown in a museum when it was exhibited at the Wadsworth Atheneum in Hartford in July 1962. On July 9, 1962, Warhol's exhibition opened at the Ferus Gallery in Los Angeles with Campbell's Soup Cans, marking his West Coast debut of pop art.\n\nIn November 1962, Warhol had an exhibition at Eleanor Ward's Stable Gallery in New York. The exhibit included the works Gold Marilyn, eight of the classic \u201cMarilyn\u201d series also named \"Flavor Marilyns\", Marilyn Diptych, 100 Soup Cans, 100 Coke Bottles, and 100 Dollar Bills.  The Flavor Marilyns were selected from a group of fourteen canvases in the sub-series, each measuring 20\u2033 x 16\u2033. Some of the canvases were named after various candy Life Savers flavors, including Cherry Marilyn, Lemon Marilyn, Mint, Lavender, Grape or Licorice Marilyn. The others are identified by their background colors. Gold Marilyn, was bought by the architect Philip Johnson and donated to the Museum of Modern Art. At the exhibit, Warhol met poet John Giorno, who would star in Warhol's first film, Sleep, in 1964.\n\nIt was during the 1960s that Warhol began to make paintings of iconic American objects such as dollar bills, mushroom clouds, electric chairs, Campbell's soup cans, Coca-Cola bottles, celebrities such as Marilyn Monroe, Elvis Presley, Marlon Brando, Troy Donahue, Muhammad Ali, and Elizabeth Taylor, as well as newspaper headlines or photographs of police dogs attacking African-American protesters during the Birmingham campaign in the civil rights movement. During these years, he founded his studio, \"The Factory\" and gathered about him a wide range of artists, writers, musicians, and underground celebrities. His work became popular and controversial. Warhol had this to say about Coca-Cola:\n\nIn December 1962, New York City's Museum of Modern Art hosted a symposium on pop art, during which artists such as Warhol were attacked for \"capitulating", "flag": 1, "segments": [[1200, 1206]], "strength": 5.5}
{"token_count": [2006], "text": "was a Japanese filmmaker and painter who directed thirty films in a career spanning over five decades. He is regarded as one of the most important and influential filmmakers in film history.\n\nKurosawa entered the Japanese film industry in 1936, following a brief stint as a painter. After years of working on numerous films as an assistant director and scriptwriter, he made his debut as a director during World War II with the popular action film Sanshiro Sugata. After the war, the critically acclaimed Drunken Angel (1948), in which Kurosawa cast the then little-known actor Toshiro Mifune in a starring role, cemented the director's reputation as one of the most important young filmmakers in Japan. The two men would go on to collaborate on another fifteen films.\n\nRashomon, which premiered in Tokyo, became the surprise winner of the Golden Lion at the 1951 Venice Film Festival. The commercial and critical success of that film opened up Western film markets for the first time to the products of the Japanese film industry, which in turn led to international recognition for other Japanese filmmakers. Kurosawa directed approximately one film per year throughout the 1950s and early 1960s, including a number of highly regarded (and often adapted) films, such as Ikiru (1952), Seven Samurai (1954) and Yojimbo (1961). After the 1960s he became much less prolific; even so, his later work\u2014including two of his final films, Kagemusha (1980) and Ran (1985)\u2014continued to receive great acclaim.\n\nIn 1990, he accepted the Academy Award for Lifetime Achievement. Posthumously, he was named \"Asian of the Century\" in the \"Arts, Literature, and Culture\" category by AsianWeek magazine and CNN, cited there as being among the five people who most prominently contributed to the improvement of Asia in the 20th century. His career has been honored by many retrospectives, critical studies and biographies in both print and video, and by releases in many consumer media.\n\nBiography\n\nChildhood to war years (1910\u20131945)\n\nChildhood and youth (1910\u20131935) \nKurosawa was born on March 23, 1910, in \u014cimachi in the \u014cmori district of Tokyo. His father Isamu (1864\u20131948), a member of a samurai family from Akita Prefecture, worked as the director of the Army's Physical Education Institute's lower secondary school, while his mother Shima (1870\u20131952) came from a merchant's family living in Osaka. Akira was the eighth and youngest child of the moderately wealthy family, with two of his siblings already grown up at the time of his birth and one deceased, leaving Kurosawa to grow up with three sisters and a brother.\n\nIn addition to promoting physical exercise, Isamu Kurosawa was open to Western traditions and considered theatre and motion pictures to have educational merit. He encouraged his children to watch films; young Akira viewed his first movies at the age of six. An important formative influence was his elementary school teacher Mr. Tachikawa, whose progressive educational practices ignited in his young pupil first a love of drawing and then an interest in education in general. During this time, the boy also studied calligraphy and Kendo swordsmanship.\n\nAnother major childhood influence was Heigo Kurosawa (1906-1933), Akira's older brother by four years. In the aftermath of the Great Kant\u014d earthquake of 1923, Heigo took the thirteen-year-old Akira to view the devastation. When the younger brother wanted to look away from the corpses of humans and beasts scattered everywhere, Heigo forbade him to do so, encouraging Akira instead to face his fears by confronting them directly. Some commentators have suggested that this incident would influence Kurosawa's later artistic career, as the director was seldom hesitant to confront unpleasant truths in his work.\n\nHeigo was academically gifted, but soon after failing to secure a place in Tokyo's foremost high school, he began to detach himself from the rest of the family, preferring to concentrate on his interest in foreign literature. In the late 1920s, Heigo became a benshi (silent film narrator) for Tokyo theaters showing foreign films and quickly made a name for himself. Akira, who at this point planned to become a painter, moved in with him, and the two brothers became inseparable. With Heigo's guidance, Akira devoured not only films but also theater and circus performances, while exhibiting his paintings and working for the left-wing Proletarian Artists' League. However, he was never able to make a living with his art, and, as he began to perceive most of the proletarian movement as \"putting unfulfilled political ideals directly onto the canvas\", he lost his enthusiasm for painting.\n\nWith the increasing production of talking pictures in the early 1930s, film narrators like Heigo began to lose work, and Akira moved back in with his parents. In July 1933, Heigo committed suicide. Kurosawa has commented on the lasting sense of loss he felt at his brother's death and the chapter of his autobiography (Something Like an Autobiography) that describes it\u2014written nearly half a century after the event\u2014is titled, \"A Story I Don't Want to Tell\". Only four months later, Kurosawa's eldest brother also died, leaving Akira, at age 23, the only one of the Kurosawa brothers still living, together with his three surviving sisters.\n\nDirector in training (1935\u20131941) \n\nIn 1935, the new film studio Photo Chemical Laboratories, known as P.C.L. (which later became the major studio Toho), advertised for assistant directors. Although he had demonstrated no previous interest in was generated in the 2018 financial film as a profession, Kurosawa submitted the required essay, which asked applicants to discuss the fundamental deficiencies of Japanese films and find ways to overcome them. His half-mocking view was that if the deficiencies were fundamental, there was no way to correct them. Kurosawa's essay earned him a call to take the follow-up exams, and director Kajir\u014d Yamamoto, who was among the examiners, took a liking to Kurosawa and insisted that the studio hire him. The 25-year-old Kurosawa joined P.C.L. in February 1936.\n\nDuring his five years as an assistant director, Kurosawa worked under numerous directors, but by far the most important figure in his development was Yamamoto. Of his 24 films as A.D., he worked on 17 under Yamamoto, many of them comedies featuring the popular actor Ken'ichi Enomoto, known as \"Enoken\". Yamamoto nurtured Kurosawa's talent, promoting him directly from third assistant director to chief assistant director after a year. Kurosawa's responsibilities increased, and he worked at tasks ranging from stage construction and film development to location scouting, script polishing, rehearsals, lighting, dubbing, editing, and second-unit directing. In the last of Kurosawa's films as an assistant director for Yamamoto, Horse (Uma, 1941), Kurosawa took over most of the production, as his mentor was occupied with the shooting of another film.\n\nYamamoto advised Kurosawa that a good director needed to master screenwriting. Kurosawa soon realized that the potential earnings from his scripts were much higher than what he was paid as an assistant director. He later wrote or co-wrote all his films, and frequently penned screenplays for other directors such as Satsuo Yamamoto's film, A Triumph of Wings (Tsubasa no gaika, 1942). This outside scriptwriting would serve Kurosawa as a lucrative sideline lasting well into the 1960s, long after he became famous.\n\nWartime films and marriage (1942\u20131945) \nIn the two years following the release of Horse in 1941, Kurosawa searched for a story he could use to launch his directing career. Towards the end of 1942, about a year after the Japanese attack on Pearl Harbor, novelist Tsuneo Tomita published his Musashi Miyamoto-inspired judo novel, Sanshiro Sugata, the advertisements for which intrigued Kurosawa. He bought the book on its publication day, devoured it in one sitting, and immediately asked Toho to secure the film rights. Kurosawa's initial instinct proved correct as, within a few days, three other major Japanese studios also offered to buy the rights. Toho prevailed, and Kurosawa began pre-production on his debut work as director.\n\nShooting of Sanshiro Sugata began on location in Yokohama in December 1942. Production proceeded smoothly, but getting the completed film past the censors was an entirely different matter. The censorship office considered the work to be objectionably \"British-American\" by the standards of wartime Japan, and it was only through the intervention of director Yasujir\u014d Ozu, who championed the film, that Sanshiro Sugata was finally accepted for release on March 25, 1943. (Kurosawa had just turned 33.) The movie became both a critical and commercial success. Nevertheless, the censorship office would later decide to cut out some 18 minutes of footage, much of which is now considered lost.\n\nHe next turned to the subject of wartime female factory workers in The Most Beautiful, a propaganda film which he shot in a semi-documentary style in early 1944. To elicit realistic performances from his actresses, the director had them live in a real factory during the shoot, eat the factory food and call each other by their character names. He would", "flag": 1, "segments": [[1200, 1206]], "strength": 5.5}
{"token_count": [2006], "text": "Ancient Egypt was a civilization of ancient Africa, concentrated along the lower reaches of the Nile River, situated in the place that is now the country Egypt. Ancient Egyptian civilization followed prehistoric Egypt and coalesced around 3100BC (according to conventional Egyptian chronology) with the political unification of Upper and Lower Egypt under Menes (often identified with Narmer). The history of ancient Egypt occurred as a series of stable kingdoms, separated by periods of relative instability known as Intermediate Periods: the Old Kingdom of the Early Bronze Age, the Middle Kingdom of the Middle Bronze Age and the New Kingdom of the Late Bronze Age.\n\nEgypt reached the pinnacle of its power in the New Kingdom, ruling much of Nubia and a sizable portion of the Near East, after which it entered a period of slow decline. During the course of its history Egypt was invaded or conquered by a number of foreign powers, including the Hyksos, the Libyans, the Nubians, the Assyrians, the Achaemenid Persians, and the Macedonians under the command of Alexander the Great. The Greek Ptolemaic Kingdom, formed in the aftermath of Alexander's death, ruled Egypt until 30BC, when, under Cleopatra, it fell to the Roman Empire and became a Roman province.\n\nThe success of ancient Egyptian civilization came partly from its ability to adapt to the conditions of the Nile River valley for agriculture. The predictable flooding and controlled irrigation of the fertile valley produced surplus crops, which supported a more dense population, and social development and culture. With resources to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military intended to assert Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of a pharaoh, who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.\n\nThe many achievements of the ancient Egyptians include the quarrying, surveying and construction techniques that supported the building of monumental pyramids, temples, and obelisks; a system of mathematics, a practical and effective system of medicine, irrigation systems and agricultural production techniques, the first known planked boats, Egyptian faience and glass technology, new forms of literature, and the earliest known peace treaty, made with the Hittites. Ancient Egypt has left a lasting legacy. Its art and architecture were widely copied, and its antiquities carried off to far corners of the world. Its monumental ruins have inspired the imaginations of travelers and writers for millennia. A newfound respect for antiquities and excavations in the early modern period by Europeans and Egyptians led to the scientific investigation of Egyptian civilization and a greater appreciation of its cultural legacy.\n\nHistory\n\nThe Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization. Nomadic modern human hunter-gatherers began living in the Nile valley through the end of the Middle Pleistocene some 120,000 years ago. By the late Paleolithic period, the arid climate of Northern Africa became increasingly hot and dry, forcing the populations of the area to concentrate along the river region.\n\nPredynastic period\n\nIn Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were covered in treed savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.\n\nBy about 5500\u00a0BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt was the Badarian culture, which probably originated in the Western Desert; it was known for its high-quality ceramics, stone tools, and its use of copper.\n\nThe Badari was followed by the Naqada culture: the Amratian (Naqada I), the Gerzeh (Naqada II), and Semainean (Naqada III). These brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. In Naqada II times, early evidence exists of contact with the Near East, particularly Canaan and the Byblos coast. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Nekhen (in Greek, Hierakonpolis), and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east, initiating a period of Egypt-Mesopotamia relations.\n\nThe Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually were developed into a full system of hieroglyphs for writing the ancient Egyptian language.\n\nEarly Dynastic Period (c. 3150\u20132686 BC)\n\nThe Early Dynastic Period was approximately contemporary to the early Sumerian-Akkadian civilisation of Mesopotamia and of ancient Elam. The third-centuryBC Egyptian priest Manetho grouped the long line of kings from Menes to his own time into 30 dynasties, a system still used today. He began his official history with the king named \"Meni\" (or Menes in Greek), who was believed to have united the two kingdoms of Upper and Lower Egypt.\n\nThe transition to a unified state happened more gradually than ancient Egyptian writers represented, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have been the king Narmer, who is depicted wearing royal regalia on the ceremonial Narmer Palette, in a symbolic act of unification. In the Early Dynastic Period, which began about 3000BC, the first of the Dynastic kings solidified control over lower Egypt by establishing a capital at Memphis, from which he could control the labour force and agriculture of the fertile delta region, as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the kings during the early dynastic period was reflected in their elaborate mastaba tombs and mortuary cult structures at Abydos, which were used to celebrate the deified king after his death. The strong institution of kingship developed by the kings served to legitimize state control over the land, labour, and resources that were essential to the survival and growth of ancient Egyptian civilization.\n\nOld Kingdom (2686\u20132181 BC)\n\nMajor advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity and resulting population, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, drafted peasants to work on construction projects, and established a justice system to maintain peace and order. \n\nWith the rising importance of central administration in Egypt, a new class of educated scribes and officials arose who were granted estates by the king in payment for their services. Kings also made land grants to their mortuary cults and local temples stars with an iron content similar, to ensure that these institutions had the resources to worship the king after his death. Scholars believe that five centuries of these practices slowly eroded the economic vitality of Egypt, and that the economy could no longer afford to support a large centralized administration. As the power of the kings diminished, regional governors called nomarchs began to challenge the supremacy of the office of king. This, coupled with severe droughts between 2200 and 2150BC, is believed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.\n\nFirst Intermediate Period (2181\u20132055 BC)\n\nAfter Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. Regional governors could not rely on the king for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the king, used their new-found independence to establish a thriving culture in the provinces", "flag": 1, "segments": [[1782, 1788]], "strength": 5.5}
{"token_count": [2006], "text": "ABBA (, ) are  a Swedish pop group formed in Stockholm in 1972 by Agnetha F\u00e4ltskog, Bj\u00f6rn Ulvaeus, Benny Andersson, and Anni-Frid Lyngstad. The group's name is an acronym of the first letters of their first names arranged as a palindrome. One of the most popular and successful musical groups of all time, they became one of the best-selling music acts in the history of popular music, topping the charts worldwide from 1974 to 1983, and in 2021.\n\nIn 1974, ABBA were Sweden's first winner of the Eurovision Song Contest with the song \"Waterloo\", which in 2005 was chosen as the best song in the competition's history as part of the 50th anniversary celebration of the contest. During the band's main active years, it consisted of two married couples: F\u00e4ltskog and Ulvaeus, and Lyngstad and Andersson. With the increase of their popularity, their personal lives suffered, which eventually resulted in the collapse of both marriages. The relationship changes were reflected in the group's music, with latter compositions featuring darker and more introspective lyrics. After ABBA separated in December 1982, Andersson and Ulvaeus continued their success writing music for multiple audiences including stage, musicals and movies, while F\u00e4ltskog and Lyngstad pursued solo careers.\n\nTen years after the group broke up, a compilation, ABBA Gold, was released, becoming a worldwide best-seller. In 1999, ABBA's music was adapted into Mamma Mia!, a successful musical that toured worldwide and, as of November 2021, is still in the top-ten longest running productions on both Broadway (closed in 2015) and the West End (still running). A film of the same name, released in 2008, became the highest-grossing film in the United Kingdom that year. A sequel, Mamma Mia! Here We Go Again, was released in 2018.\n\nIn 2016, the group reunited and started working on a digital avatar concert tour. Newly recorded songs were announced in 2018. Voyage, their first new album in 40 years, was released on November 5, 2021. ABBA Voyage, a concert residency featuring ABBA as virtual avatars \u2013 dubbed 'ABBAtars' \u2013 is due to take place in London from May to December 2022.\n\nABBA is one of the best-selling music artists of all time, with record sales estimated to be between 150 million to 385 million sold worldwide and the group were ranked 3rd best-selling singles artists in the United Kingdom with a total of 11.3 million singles sold by 3 November 2012. ABBA were the first group from a non-English-speaking country to achieve consistent success in the charts of English-speaking countries, including the United States, United Kingdom, Republic of Ireland, Canada, Australia, New Zealand and South Africa. They are the best-selling Swedish band of all time and the best-selling band originating in continental Europe. ABBA had eight consecutive number-one albums in the UK. The group also enjoyed significant success in Latin America and recorded a collection of their hit songs in Spanish. ABBA were inducted into the Vocal Group Hall of Fame in 2002. The group were inducted into the Rock and Roll Hall of Fame in 2010, the first and only recording artists to receive this honour from outside an Anglophone country. In 2015, their song \"Dancing Queen\" was inducted into the Recording Academy's Grammy Hall of Fame.\n\nHistory\n\n1958\u20131970: Before ABBA\n\nMember origins and collaboration \nBenny Andersson (born 16 December 1946 in Stockholm, Sweden) became (at age 18) a member of a popular Swedish pop-rock group, the Hep Stars, that performed, among other things, covers of international hits. The Hep Stars were known as \"the Swedish Beatles\". They also set up Hep House, their equivalent of Apple Corps. Andersson played the keyboard and eventually started writing original songs for his band, many of which became major hits, including \"No Response\", which hit number three in 1965, and \"Sunny Girl\", \"Wedding\", and \"Consolation\", all of which hit number one in 1966. Andersson also had a fruitful songwriting collaboration with Lasse Berghagen, with whom he wrote his first Svensktoppen entry, \"Sagan om lilla Sofie\" (\"The tale of Little Sophie\") in 1968.\n\nBj\u00f6rn Ulvaeus (born 25 April 1945 in Gothenburg, Sweden) also began his musical career at the age of 18 (as a singer and guitarist), when he fronted the Hootenanny Singers, a popular Swedish folk\u2013skiffle group. Ulvaeus started writing English-language songs for his group, and even had a brief solo career alongside. The Hootenanny Singers and the Hep Stars sometimes crossed paths while touring. In June 1966, Ulvaeus and Andersson decided to write a song together. Their first attempt was \"Isn't It Easy to Say\", a song was later recorded by the Hep Stars. Stig Anderson was the manager of the Hootenanny Singers and founder of the Polar Music label. He saw potential in the collaboration, and encouraged them to write more. The two also began playing occasionally with the other's bands on stage and on record, although it was not until 1969 that the pair wrote and produced some of their first real hits together: \"Ljuva sextital\" (\"Sweet Sixties\"), recorded by Brita Borg, and the Hep Stars' 1969 hit \"Speleman\" (\"Fiddler\").\n\nAndersson wrote and submitted the song \"Hej, Clown\" for Melodifestivalen 1969, the national festival to select the Swedish entry to the Eurovision Song Contest. The song tied for first place, but re-voting relegated Andersson's song to second place. On that occasion Andersson briefly met his future spouse, singer Anni-Frid Lyngstad, who also participated in the contest. A month later, the two had become a couple. As their respective bands began to break up during 1969, Andersson and Ulvaeus teamed up and recorded their first album together in 1970, called Lycka (\"Happiness\"), which included original songs sung by both men. Their partners were often present in the recording studio, and sometimes added backing vocals; F\u00e4ltskog even co-wrote a song with the two. Ulvaeus still occasionally recorded and performed with the Hootenanny Singers until the middle of 1974, and Andersson took part in producing their records.\n\nAnni-Frid \"Frida\" Lyngstad (born 15 November 1945 in Bj\u00f8rk\u00e5sen in Ballangen, Norway) sang from the age of 13 with various dance bands, and worked mainly in a jazz-oriented cabaret style. She also formed her own band, the Anni-Frid Four. In the middle of 1967, she won a national talent competition with \"En ledig dag\" (\"A Day Off\") a Swedish version of the bossa nova song \"A Day in Portofino\", which is included in the EMI compilation Frida 1967\u20131972. The first prize was a recording contract with EMI Sweden and to perform live on the most popular TV shows in the country. This TV performance, amongst many others, is included in the 3\u00bd-hour documentary Frida \u2013 The DVD. Lyngstad released several schlager style singles on EMI without much success. When Benny Andersson started to produce her recordings in 1971, she had her first number-one single, \"Min egen stad\" (\"My Own Town\"), written by Benny and featuring all the future ABBA members on backing vocals. Lyngstad toured and performed regularly in the folkpark circuit and made appearances on radio and TV. She met Ulvaeus briefly in 1963 during a talent contest, and F\u00e4ltskog during a TV show in early 1968.\n\nLyngstad linked up with her future bandmates in 1969. On and nearby Cambrils left 1 March 1969, she participated in the Melodifestival, where she met Andersson for the first time. A few weeks later they met again during a concert tour in southern Sweden and they soon became a couple. Andersson produced her single \"Peter Pan\" in September 1969\u2014her first collaboration with Benny & Bj\u00f6rn, as they had written the song. Andersson would then produce Lyngstad's debut studio album, Frida, which was released in March 1971. Lyngstad also played in several revues and cabaret shows in Stockholm between 1969 and 1973. After ABBA formed, she recorded another successful album in 1975, Frida ensam, which included a Swedish rendition of \"Fernando\", a hit on the Swedish radio charts before the English version was released.\n\nAgnetha F\u00e4ltskog (born 5 April 1950 in J\u00f6nk\u00f6ping, Sweden) sang with a local dance band headed by Bernt Enghardt who sent a demo recording of the band to Karl Gerhard Lundkvist. The demo tape featured a song written and sung by Agnetha: \"Jag var s\u00e5 k\u00e4r\" (\"I Was So in Love\"). Lundkvist was so impressed with her voice that he was convinced she would be a star. After going through considerable effort to locate the singer, he arranged for Agnetha to come to Stockholm and to record two of her own songs. This led to Agnetha at the age of 18 having", "flag": 1, "segments": [[1688, 1694]], "strength": 5.5}
{"token_count": [2006], "text": "Arsenic is a chemical element with the symbol As and atomic number 33. Arsenic occurs in many minerals, usually in combination with sulfur and metals, but also as a pure elemental crystal. Arsenic is a metalloid. It has various allotropes, but only the gray form, which has a metallic appearance, is important to industry.\n\nThe primary use of arsenic is in alloys of lead (for example, in car batteries and ammunition). Arsenic is a common n-type dopant in semiconductor electronic devices. It is also a component of the III-V compound semiconductor gallium arsenide. Arsenic and its compounds, especially the trioxide, are used in the production of pesticides, treated wood products, herbicides, and insecticides. These applications are declining with the increasing recognition of the toxicity of arsenic and its compounds.\n\nA few species of bacteria are able to use arsenic compounds as respiratory metabolites. Trace quantities of arsenic are an essential dietary element in rats, hamsters, goats, chickens, and presumably other species. A role in human metabolism is not known. However, arsenic poisoning occurs in multicellular life if quantities are larger than needed. Arsenic contamination of groundwater is a problem that affects millions of people across the world.\n\nThe United States' Environmental Protection Agency states that all forms of arsenic are a serious risk to human health. The United States' Agency for Toxic Substances and Disease Registry ranked arsenic as number 1 in its 2001 Priority List of Hazardous Substances at Superfund sites. Arsenic is classified as a Group-A carcinogen.\n\nCharacteristics\n\nPhysical characteristics \n\nThe three most common arsenic allotropes are gray, yellow, and black arsenic, with gray being the most common. Gray arsenic (\u03b1-As, space group Rm No. 166) adopts a double-layered structure consisting of many interlocked, ruffled, six-membered rings. Because of weak bonding between the layers, gray arsenic is brittle and has a relatively low Mohs hardness of 3.5. Nearest and next-nearest neighbors form a distorted octahedral complex, with the three atoms in the same double-layer being slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 5.73\u00a0g/cm3. Gray arsenic is a semimetal, but becomes a semiconductor with a bandgap of 1.2\u20131.4\u00a0eV if amorphized. Gray arsenic is also the most stable form. \nYellow arsenic is soft and waxy, and somewhat similar to tetraphosphorus (). Both have four atoms arranged in a tetrahedral structure in which each atom is bound to each of the other three atoms by a single bond. This unstable allotrope, being molecular, is the most volatile, least dense, and most toxic. Solid yellow arsenic is produced by rapid cooling of arsenic vapor,. It is rapidly transformed into gray arsenic by light. The yellow form has a density of 1.97\u00a0g/cm3. Black arsenic is similar in structure to black phosphorus.\nBlack arsenic can also be formed by cooling vapor at around 100\u2013220\u00a0\u00b0C and by crystallization of amorphous arsenic in the presence of mercury vapors. It is glassy and brittle. It is also a poor electrical conductor. As arsenic's triple point is at 3.628 MPa (35.81 atm), it does not have a melting point at standard pressure but instead sublimes from solid to vapor at 887 K (615\u00a0\u00b0C or 1137\u00a0\u00b0F).\n\nIsotopes \n\nArsenic occurs in nature as says no when it comes time a monoisotopic element, composed of one stable isotope, 75As. As of 2003, at least 33 radioisotopes have also been synthesized, ranging in atomic mass from 60 to 92. The most stable of these is 73As with a half-life of 80.30\u00a0days. All other isotopes have half-lives of under one day, with the exception of 71As (t1/2=65.30 hours), 72As (t1/2=26.0 hours), 74As (t1/2=17.77 days), 76As (t1/2=1.0942 days), and 77As (t1/2=38.83 hours). Isotopes that are lighter than the stable 75As tend to decay by \u03b2+ decay, and those that are heavier tend to decay by \u03b2\u2212 decay, with some exceptions.\n\nAt least 10 nuclear isomers have been described, ranging in atomic mass from 66 to 84. The most stable of arsenic's isomers is 68mAs with a half-life of 111\u00a0seconds.\n\nChemistry \n\nArsenic has a similar electronegativity and ionization energies to its lighter congener phosphorus and accordingly readily forms covalent molecules with most of the nonmetals. Though stable in dry air, arsenic forms a golden-bronze tarnish upon exposure to humidity which eventually becomes a black surface layer. When heated in air, arsenic oxidizes to arsenic trioxide; the fumes from this reaction have an odor resembling garlic. This odor can be detected on striking arsenide minerals such as arsenopyrite with a hammer. It burns in oxygen to form arsenic trioxide and arsenic pentoxide, which have the same structure as the more well-known phosphorus compounds, and in fluorine to give arsenic pentafluoride. Arsenic (and some arsenic compounds) sublimes upon heating at atmospheric pressure, converting directly to a gaseous form without an intervening liquid state at. The triple point is 3.63\u00a0MPa and. Arsenic makes arsenic acid with concentrated nitric acid, arsenous acid with dilute nitric acid, and arsenic trioxide with concentrated sulfuric acid; however, it does not react with water, alkalis, or non-oxidising acids. Arsenic reacts with metals to form arsenides, though these are not ionic compounds containing the As3\u2212 ion as the formation of such an anion would be highly endothermic and even the group 1 arsenides have properties of intermetallic compounds. Like germanium, selenium, and bromine, which like arsenic succeed the 3d transition series, arsenic is much less stable in the group oxidation state of +5 than its vertical neighbors phosphorus and antimony, and hence arsenic pentoxide and arsenic acid are potent oxidizers.\n\nCompounds \n\nCompounds of arsenic resemble in some respects those of phosphorus which occupies the same group (column) of the periodic table. The most common oxidation states for arsenic are: \u22123 in the arsenides, which are alloy-like intermetallic compounds, +3 in the arsenites, and +5 in the arsenates and most organoarsenic compounds. Arsenic also bonds readily to itself as seen in the square As ions in the mineral skutterudite. In the +3 oxidation state, arsenic is typically pyramidal owing to the influence of the lone pair of electrons.\n\nInorganic compounds \n\nOne of the simplest arsenic compound is the trihydride, the highly toxic, flammable, pyrophoric arsine (AsH3). This compound is generally regarded as stable, since at room temperature it decomposes only slowly. At temperatures of 250\u2013300\u00a0\u00b0C decomposition to arsenic and hydrogen is rapid. Several factors, such as humidity, presence of light and certain catalysts (namely aluminium) facilitate the rate of decomposition. It oxidises readily in air to form arsenic trioxide and water, and analogous reactions take place with sulfur and selenium instead of oxygen.\n\nArsenic forms colorless, odorless, crystalline oxides As2O3 (\"white arsenic\") and As2O5 which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic(V) acid is a weak acid and the salts are called arsenates, the most common arsenic contamination of groundwater, and a problem that affects many people. Synthetic arsenates include Scheele's Green (cupric hydrogen arsenate, acidic copper arsenate), calcium arsenate, and lead hydrogen arsenate. These three have been used as agricultural insecticides and poisons.\n\nThe protonation steps between the arsenate and arsenic acid are similar to those between phosphate and phosphoric acid. Unlike phosphorous acid, arsenous acid is genuinely tribasic, with the formula As(OH)3.\n\nA broad variety of sulfur compounds of arsenic are known. Orpiment (As2S3) and realgar (As4S4) are somewhat abundant and were formerly used as painting pigments. In As4S10, arsenic has a formal oxidation state of +2 in As4S4 which features As-As bonds so that the total covalency of As is still 3. Both orpiment and realgar, as well as As4S3, have selenium analogs; the analogous As2Te3 is known as the mineral kalgoorlieite, and the anion As2Te\u2212 is known as a ligand in cobalt complexes.\n\nAll trihalides of arsenic(III) are well known except the astatide, which is unknown. Arsenic pentafluoride (AsF5) is the only important pentahalide, reflecting the lower stability of the +5 oxidation state; even so, it is a very strong fluorinating and oxidizing agent. (The", "flag": 1, "segments": [[765, 771]], "strength": 5.5}
{"token_count": [2006], "text": "An atom is the smallest unit of ordinary matter that forms a chemical element. Every solid, liquid, gas, and plasma is composed of neutral or ionized atoms. Atoms are extremely small, typically around 100\u00a0picometers across. They are so small that accurately predicting their behavior using classical physics\u2014as if they were tennis balls, for example\u2014is not possible due to quantum effects.\n\nEvery atom is composed of a nucleus and one or more electrons bound to the nucleus. The nucleus is made of one or more protons and a number of neutrons. Only the most common variety of hydrogen has no neutrons. More than 99.94% of an atom's mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, then the atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively \u2013 such atoms are called ions.\n\nThe electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay.\n\nThe number of protons in the nucleus is the atomic number and it defines to which chemical element the atom belongs. For example, any atom that contains 29 protons is copper. The number of neutrons defines the isotope of the element. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature. Chemistry is the discipline that studies these changes.\n\nHistory of atomic theory\n\nIn philosophy\n\nThe basic idea that matter is made up of tiny, indivisible particles appears in many ancient cultures such as those of Greece and India. The word atom is derived from the ancient Greek word atomos (a combination of the negative term \"a-\" and \"\u03c4\u03bf\u03bc\u03ae,\" the term for \"cut\") that means \"uncuttable\". This ancient idea was based in philosophical reasoning rather than scientific reasoning; modern atomic theory is not based on these old concepts. Nonetheless, the term \"atom\" was used throughout the ages by thinkers who suspected that matter was ultimately granular in nature. It has since been discovered that \"atoms\" can be split, but the misnomer is still used.\n\nDalton's law of multiple proportions\n\nIn the early 1800s, the English chemist John Dalton compiled experimental data gathered by himself and other scientists and discovered a pattern now known as the \"law of multiple proportions\". He noticed that in chemical compounds which contain a particular chemical element, the content of that element in these compounds will differ by ratios of small whole numbers. This pattern suggested to Dalton that each chemical element combines with other elements by some basic and consistent unit of mass.\n\nFor example, there are two types of tin oxide: one is a black powder that is 88.1% tin and 11.9% oxygen, and the other is a white powder that is 78.7% tin and 21.3% oxygen. Adjusting these figures, in the black oxide there is about 13.5\u00a0g of oxygen for every 100\u00a0g of tin, and in the white oxide there is about 27\u00a0g of oxygen for every 100\u00a0g of tin. 13.5 and 27 form a ratio of 1:2. In these oxides, for every tin atom there are one or two oxygen atoms respectively (SnO and SnO2).\n\nAs a second example, Dalton considered two iron oxides: a black powder which is 78.1% iron and 21.9% oxygen, and a red powder which is 70.4% iron and 29.6% oxygen. Adjusting these figures, in the black oxide there is about 28\u00a0g of oxygen for every 100\u00a0g of iron, and in the red oxide there is about 42\u00a0g of oxygen for every 100\u00a0g of iron. 28 and 42 form a ratio of 2:3. In these respective oxides, for every two atoms of iron, there are two or three atoms of oxygen (Fe2O2 and Fe2O3).\n\nAs a final example: nitrous oxide is 63.3% nitrogen and 36.7% oxygen, nitric oxide is 44.05% nitrogen and 55.95% oxygen, and nitrogen dioxide is 29.5% nitrogen and 70.5% oxygen. Adjusting these figures, in nitrous oxide there is 80\u00a0g of oxygen for every 140\u00a0g of nitrogen, in nitric oxide there is about 160\u00a0g of oxygen for every 140\u00a0g of nitrogen, and in nitrogen dioxide there is 320\u00a0g of oxygen for every 140\u00a0g of nitrogen. 80, 160, and 320 form a ratio of 1:2:4. The respective formulas for these oxides are N2O, NO, and NO2.\n\nKinetic theory of gases\n\nIn the late 18th century, a number of scientists found that they could better explain the behavior of gases by describing them as collections of sub-microscopic particles and modelling their behavior using statistics and probability. Unlike Dalton's atomic theory, the kinetic theory of gases describes not how gases react chemically with each other to form compounds, but how they behave physically: diffusion, viscosity, conductivity, pressure, etc.\n\nBrownian motion\nIn 1827, botanist Robert Brown used a microscope to look at dust grains floating in water and discovered that they moved about erratically, a phenomenon that became known as \"Brownian motion\". This was thought to be caused by water molecules knocking the grains about. In 1905, Albert Einstein proved the reality of these molecules and their motions by producing the first statistical physics analysis of Brownian motion. French physicist Jean Perrin used Einstein's work to experimentally determine the mass and dimensions of molecules, thereby providing physical evidence for the particle nature of matter.\n\nDiscovery of the electron\n\nIn 1897, J. J. Thomson discovered that cathode rays are not electromagnetic waves but made of particles that are 1,800 times lighter than hydrogen (the lightest atom). Thomson concluded that these particles came from the atoms within the cathode \u2014 they were subatomic particles. He called these new particles corpuscles but they were later renamed electrons. Thomson also showed that electrons were identical to particles given off by photoelectric and radioactive materials. It was quickly recognized that electrons are the particles that carry electric currents in metal wires. Thomson concluded that these electrons emerged from the very atoms of the cathode in his instruments, which meant that atoms are not indivisible as the name atomos suggests.\n\nDiscovery of the nucleus\n\nJ. J. Thomson thought that the negatively-charged electrons were distributed throughout the atom in a sea of positive charge that was distributed across the whole volume of the atom. This model is sometimes known as the plum pudding model.\n\nErnest Rutherford and his colleagues Hans Geiger and Ernest Marsden came to have doubts about the Thomson model after they encountered difficulties when they tried to build an instrument to measure the charge-to-mass ratio of alpha particles (these are positively-charged particles emitted by certain radioactive substances such as radium). The alpha particles were being scattered by the air in the detection chamber, which made the measurements unreliable.  Thomson had encountered a similar problem in his work on cathode rays, which he solved by creating a near-perfect vacuum in his instruments. Rutherford didn't think he'd run into this same problem because alpha particles are much heavier than electrons. According to Thomson's model of the atom, the positive charge in the atom is not concentrated enough to produce an electric field strong enough to deflect an alpha particle, and the electrons are so lightweight they should be pushed aside effortlessly by the much heavier alpha particles. Yet there was scattering, so Rutherford and his colleagues decided to investigate this scattering carefully.\n\nBetween 1908 and 1913, Rutheford and his colleagues performed a series of experiments in which they bombarded thin foils of metal with alpha particles. They spotted alpha particles being deflected by angles greater than 90\u00b0. To explain this, Rutherford proposed that the positive charge of it up a little. The the atom is not distributed throughout the atom's volume as Thomson believed, but is concentrated in a tiny nucleus at the center. Only such an intense concentration of charge could produce an electric field strong enough to deflect the alpha particles as observed.\n\nDiscovery of isotopes\nWhile experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one type of atom at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for different atoms that belong to the same element. J. J. Thomson created a technique for isotope separation through his work on ionized gases, which subsequently led to the discovery of stable isotopes.\n\nBohr model\n\nIn 1913, the physicist Niels Bohr proposed a model in which the electrons of an atom were assumed to orbit the nucleus but could only do so in a finite set of orbits, and could jump between these orbits only in discrete changes of energy corresponding to absorption or radiation of a photon. This quantization was used to explain why the electrons' orbits are stable (", "flag": 1, "segments": [[1773, 1779]], "strength": 5.5}
{"token_count": [2006], "text": "Aluminium (or aluminum in American English and Canadian English) is a chemical element with the symbol\u00a0Al and atomic number\u00a013. Aluminium has a density lower than those of other common metals, at approximately one third that of steel. It has a great affinity towards oxygen, and forms a protective layer of oxide on the surface when exposed to air. Aluminium visually resembles silver, both in its color and in its great ability to reflect light. It is soft, non-magnetic and ductile. It has one stable isotope, 27Al; this isotope is very common, making aluminium the twelfth most common element in the Universe. The radioactivity of 26Al is used in radiodating.\n\nChemically, aluminium is a post-transition metal in the boron group; as is common for the group, aluminium forms compounds primarily in the +3 oxidation state. The aluminium cation Al3+ is small and highly charged; as such, it is polarizing, and bonds aluminium forms tend towards covalency. The strong affinity towards oxygen leads to aluminium's common association with oxygen in nature in the form of oxides; for this reason, aluminium is found on Earth primarily in rocks in the crust, where it is the third most abundant element after oxygen and silicon, rather than in the mantle, and virtually never as the free metal.\n\nThe discovery of aluminium was announced in 1825 by Danish physicist Hans Christian \u00d8rsted. The first industrial production of aluminium was initiated by French chemist Henri \u00c9tienne Sainte-Claire Deville in 1856. Aluminium became much more available to the public with the Hall\u2013H\u00e9roult process developed independently by French engineer Paul H\u00e9roult and American engineer Charles Martin Hall in 1886, and the mass production of aluminium led to its extensive use in industry and everyday life. In World Wars I and II, aluminium was a crucial strategic resource for aviation. In 1954, aluminium became the most produced non-ferrous metal, surpassing copper. In the 21st century, most aluminium was consumed in transportation, engineering, construction, and packaging in the United States, Western Europe, and Japan.\n\nDespite its prevalence in the environment, no living organism is known to use aluminium salts metabolically, but aluminium is well tolerated by plants and animals. Because of the abundance of these salts, the potential for a biological role for them is of continuing interest, and studies continue.\n\nPhysical characteristics\n\nIsotopes \n\nOf aluminium isotopes, only  is stable. This situation is common for elements with an odd atomic number. It is the only primordial aluminium isotope, i.e. the only one that has existed on Earth in its current form since the formation of the planet. Nearly all aluminium on Earth is present as this isotope, which makes it a mononuclidic element and means that its standard atomic weight is virtually the same as that of the isotope. This makes aluminium very useful in nuclear magnetic resonance (NMR), as its single stable isotope has a high NMR sensitivity. The standard atomic weight of aluminium is low in comparison with many other metals.\n\nAll other isotopes of aluminium are radioactive. The most stable of these is 26Al: while it was present along with stable 27Al in the interstellar medium from which the Solar System formed, having been produced by stellar nucleosynthesis as well, its half-life is only 717,000\u00a0years and therefore a detectable amount has not survived since the formation of the planet. However, minute traces of 26Al are produced from argon in the atmosphere by spallation caused by cosmic ray protons. The ratio of 26Al to 10Be has been used for radiodating of geological processes over 105 to 106\u00a0year time scales, in particular transport, deposition, sediment storage, burial times, and erosion. Most meteorite scientists believe that the energy released by the decay of 26Al was responsible for the melting and differentiation of some asteroids after their formation 4.55\u00a0billion years ago.\n\nThe remaining isotopes of aluminium, with mass numbers ranging from 22 to 43, all have half-lives well under an hour. Three metastable states are known, all with half-lives under a minute.\n\nElectron shell \n\nAn aluminium atom has 13 electrons, arranged in an electron configuration of [Ne]\u00a03s2\u00a03p1, with three electrons beyond a stable noble gas configuration. Accordingly, the combined first three ionization energies of aluminium are far lower than the fourth ionization energy alone. Such an electron configuration is shared with the other well-characterized members of its group, boron, gallium, indium, and thallium; it is also expected for nihonium. Aluminium can relatively easily surrender its three outermost electrons in many chemical reactions (see below). The electronegativity of aluminium is 1.61 (Pauling scale).\n\nA free aluminium atom has a radius of 143\u00a0pm. With the three outermost electrons removed, the radius shrinks to 39\u00a0pm for a 4-coordinated atom or 53.5\u00a0pm for a 6-coordinated atom. At standard temperature and pressure, aluminium atoms (when not affected by atoms of other elements) form a face-centered cubic crystal system bound by metallic bonding provided by atoms' outermost electrons; hence aluminium (at these conditions) is a metal. This crystal system is shared by many other metals, such as lead and copper; the size of a unit cell of aluminium is comparable to that of those other metals. The system, however, is not shared by the other members of its group; boron has ionization energies too high to allow metallization, thallium has a hexagonal close-packed structure, and gallium and indium have unusual structures that are not close-packed like those of aluminium and thallium. The few electrons that are available for metallic bonding in aluminium metal are a probable cause for it being soft with a low melting point and low electrical resistivity.\n\nBulk \n\nAluminium metal has an appearance ranging from silvery white to dull gray, depending on the surface roughness. A fresh film of aluminium serves as a good reflector (approximately 92%) of visible light and an excellent reflector (as much as 98%) of medium and far infrared radiation. Aluminium mirrors are the most reflective of all metal mirrors for the near ultraviolet and far infrared light, and one of the most reflective in the visible spectrum, nearly on par with silver, and the two therefore look similar. Aluminium is also good at reflecting solar radiation, although prolonged exposure to sunlight in air adds wear to the surface of the metal; this may be prevented if aluminium is anodized, which adds a protective layer of oxide on the surface.\n\nThe density of aluminium is 2.70\u00a0g/cm3, about 1/3 that of steel, much lower than other commonly encountered metals, making aluminium parts easily identifiable through their lightness. Aluminium's low density compared to most other metals arises from the fact that its nuclei are much lighter, while difference in the unit cell size does not compensate for this difference. The only lighter metals are the metals of groups 1 and 2, which apart from beryllium and magnesium are too reactive for structural use (and beryllium is very toxic). Aluminium is not as strong or stiff as steel, but the low density makes up for this in the aerospace industry and for many other applications where light weight and relatively high strength are crucial.\n\nPure aluminium is quite soft and lacking in strength. In most applications various aluminium alloys are used instead because of their higher strength and hardness. The yield strength of pure aluminium is 7\u201311 MPa, while aluminium alloys have yield strengths ranging from 200 MPa to 600 MPa. Aluminium is ductile, with a percent elongation of 50-70%, and malleable allowing it to be easily drawn and extruded. It is also easily machined and cast.\n\nAluminium is an excellent thermal and electrical conductor, having around 60% the conductivity of copper, both thermal and electrical, while having only 30% of copper's density. Aluminium is capable of superconductivity, with a superconducting critical temperature of 1.2 kelvin and a critical magnetic field of about 100 gauss (10 milliteslas). It is paramagnetic and thus essentially unaffected by static magnetic fields. The high electrical conductivity, however, means that it is strongly affected by alternating magnetic fields through the induction of eddy currents.\n\nChemistry \n\nAluminium combines characteristics of pre- and post-transition metals. Since it has few available electrons for metallic bonding, like its heavier group 13 congeners, it has the characteristic physical properties of a post-transition metal, with longer-than-expected interatomic distances. Furthermore, as Al3+ is a small and highly charged cation, it is strongly polarizing and bonding in aluminium compounds tends towards covalency; this behavior is similar to that of bery in a new series, Thellium (Be2+), and the two display an example of a diagonal relationship.\n\nThe underlying core under aluminium's valence shell is that of the preceding noble gas, whereas those of its heavier congeners gallium, indium, thallium, and nihonium also include a filled d-subshell and in some cases a filled f-subshell. Hence, the inner electrons of aluminium shield the valence electrons almost completely, unlike those of aluminium's heavier congeners. As such, aluminium is the most electropositive metal in its group, and its hydrox", "flag": 1, "segments": [[1878, 1884]], "strength": 5.5}
{"token_count": [2006], "text": "The Amazing Spider-Man is an American comic book series published by Marvel Comics, featuring the fictional superhero Spider-Man as its main protagonist. Being in the mainstream continuity of the franchise, it began publication in 1963 as a bimonthly periodical (as Amazing Fantasy had been), quickly being increased to monthly, and was published continuously, with a brief interruption in 1995, until its second volume with a new numbering order in 1999. In 2003, the series reverted to the numbering order of the first volume. The title has occasionally been published biweekly, and was published three times a month from 2008 to 2010.\n\nAfter DC Comics' relaunch of Action Comics and Detective Comics with new No. 1 issues in 2011, it had been the highest-numbered American comic still in circulation until it was cancelled. The title ended its 50-year run as a continuously published comic with the landmark issue #700 in December 2012. It was replaced by The Superior Spider-Man as part of the Marvel NOW! relaunch of Marvel's comic lines.\n\nVolume 3 of The Amazing Spider-Man was published in April 2014, following the conclusion of The Superior Spider-Man story arc. In late 2015, the series was relaunched with a 4th volume, following the 2015 Secret Wars event. The 5th and current volume began in 2018, as part of Marvel's Fresh Start series of comic relaunches.\n\nPublication history\nWriter-editor Stan Lee and artist and co-plotter Steve Ditko created the character of Spider-Man, and the pair produced 38 issues from March 1963 to July 1966. Ditko left after the 38th issue, while Lee remained as writer until issue 100. Since then, many writers and artists have taken over the monthly comic through the years, chronicling the adventures of Marvel's most identifiable hero.\n\nThe Amazing Spider-Man has been the character's flagship series for his first fifty years in publication, and was the only monthly series to star Spider-Man until Peter Parker, The Spectacular Spider-Man, in 1976, although 1972 saw the debut of Marvel Team-Up, with the vast majority of issues featuring Spider-Man along with a rotating cast of other Marvel characters. Most of the major characters and villains of the Spider-Man saga have been introduced in Amazing, and with few exceptions, it is where most key events in the character's history have occurred. The title was published continuously until No. 441 (Nov. 1998) when Marvel Comics relaunched it as vol. 2 No. 1 (Jan. 1999), but on Spider-Man's 40th anniversary, this new title reverted to using the numbering of the original series, beginning again with issue No. 500 (Dec. 2003) and lasting until the final issue, No. 700 (Feb. 2013).\n\n1960s\nDue to strong sales on the character's first appearance in Amazing Fantasy No. 15, Spider-Man was given his own ongoing series in March 1963. The initial years of the series, under Lee and Ditko, chronicled Spider-Man's nascent career as a masked super-human vigilante with his civilian life as hard-luck yet perpetually good-humored and well-meaning teenager Peter Parker. Peter balanced his career as Spider-Man with his job as a freelance photographer for The Daily Bugle under the bombastic editor-publisher J. Jonah Jameson to support himself and his frail Aunt May. At the same time, Peter dealt with public hostility towards Spider-Man and the antagonism of his classmates Flash Thompson and Liz Allan at Midtown High School, while embarking on a tentative, ill-fated romance with Jameson's secretary, Betty Brant.\n\nBy focusing on Parker's everyday problems, Lee and Ditko created a groundbreakingly flawed, self-doubting superhero, and the first major teenaged superhero to be a protagonist and not a sidekick. Ditko's quirky art provided a stark contrast to the more cleanly dynamic stylings of Marvel's most prominent artist, Jack Kirby, and combined with the humor and pathos of Lee's writing to lay the foundation for what became an enduring mythos.\n\nMost of Spider-Man's key villains and supporting characters were introduced during this time. Issue No. 1 (March 1963) featured the first appearances of J. Jonah Jameson and his astronaut son John Jameson, and the supervillain the Chameleon. It included the hero's first encounter with the superhero team the Fantastic Four. Issue No. 2 (May 1963) featured the first appearance of the Vulture and the Tinkerer as well as the beginning of Parker's freelance photography career at the newspaper The Daily Bugle.\n\nThe Lee-Ditko era continued to usher in a significant number of villains and supporting characters, including Doctor Octopus in No. 3 (July 1963); the Sandman and Betty Brant in No. 4 (Sept. 1963); the Lizard in No. 6 (Nov. 1963); Living Brain in (#8, January 1964); Electro in No. 9 (March 1964); Mysterio in No. 13 (June 1964); the Green Goblin in No. 14 (July 1964); Kraven The Hunter in No. 15 (Aug. 1964); reporter Ned Leeds in No. 18 (Nov. 1964); and the Scorpion in No. 20 (Jan. 1965). The Molten Man was introduced in No. 28 (Sept. 1965) which also featured Parker's graduation from high school. Peter began attending Empire State University in No. 31 (Dec. 1965), the issue which featured the first appearances of friends and classmates Gwen Stacy and Harry Osborn. Harry's father, Norman Osborn first appeared in No. 23 (April 1965) as a member of Jameson's country club but is not named nor revealed as Harry's father until No. 37 (June 1966).\n\nOne of the most celebrated issues of the Lee-Ditko run is No. 33 (Feb. 1966), the third part of the story arc \"If This Be My Destiny...!\", which features the dramatic scene of Spider-Man, through force of will and thoughts However, they can also be of family, escaping from being pinned by heavy machinery. Comics historian Les Daniels noted that \"Steve Ditko squeezes every ounce of anguish out of Spider-Man's predicament, complete with visions of the uncle he failed and the aunt he has sworn to save.\" Peter David observed that \"After his origin, this two-page sequence from Amazing Spider-Man No. 33 is perhaps the best-loved sequence from the Stan Lee/Steve Ditko era.\" Steve Saffel stated the \"full page Ditko image from The Amazing Spider-Man No. 33 is one of the most powerful ever to appear in the series and influenced writers and artists for many years to come.\" and Matthew K. Manning wrote that \"Ditko's illustrations for the first few pages of this Lee story included what would become one of the most iconic scenes in Spider-Man's history.\" The story was chosen as No. 15 in the 100 Greatest Marvels of All Time poll of Marvel's readers in 2001. Editor Robert Greenberger wrote in his introduction to the story that \"These first five pages are a modern-day equivalent to Shakespeare as Parker's soliloquy sets the stage for his next action. And with dramatic pacing and storytelling, Ditko delivers one of the great sequences in all comics.\"\n\nAlthough credited only as artist for most of his run, Ditko would eventually plot the stories as well as draw them, leaving Lee to script the dialogue. A rift between Ditko and Lee developed, and the two men were not on speaking terms long before Ditko completed his last issue, The Amazing Spider-Man No. 38 (July 1966). The exact reasons for the Ditko-Lee split have never been fully explained. Spider-Man successor artist John Romita Sr., in a 2010 deposition, recalled that Lee and Ditko \"ended up not being able to work together because they disagreed on almost everything, cultural, social, historically, everything, they disagreed on characters...\"\n\nIn successor penciler Romita Sr.'s first issue, No. 39 (Aug. 1966), nemesis the Green Goblin discovers Spider-Man's secret identity and reveals his own to the captive hero. Romita's Spider-Man \u2013 more polished and heroic-looking than Ditko's \u2013 became the model for two decades. The Lee-Romita era saw the introduction of such characters as Daily Bugle managing editor Robbie Robertson in No. 52 (Sept. 1967) and NYPD Captain George Stacy, father of Parker's girlfriend Gwen Stacy, in No. 56 (Jan. 1968). The most important supporting character to be introduced during the Romita era was Mary Jane Watson, who made her first full appearance in No. 42, (Nov. 1966), although she first appeared in No. 25 (June 1965) with her face obscured and had been mentioned since No. 15 (Aug. 1964). Peter David wrote in 2010 that Romita \"made the definitive statement of his arrival by pulling Mary Jane out from behind the oversized potted plant [that blocked the readers' view of her face in issue #25] and placing her on panel in what would instantly become an iconic moment.\" Romita has stated that in designing Mary Jane, he \"used Ann-Margret from the movie Bye Bye Birdie as a guide, using her coloring, the shape of her face, her red hair and her form-fitting short skirts.\"\n\nLee and Romita toned down the prevalent sense of antagonism in Parker's world by improving Parker's relationship with the supporting characters and having stories focused as much on the social and college lives of the characters", "flag": 1, "segments": [[1260, 1266]], "strength": 5.5}
{"token_count": [2006], "text": "Berthold Konrad Hermann Albert Speer (; ; 19 March 1905\u00a0\u2013 1 September 1981) was a German architect who served as the Minister of Armaments and War Production in Nazi Germany during most of World War II. A close ally of Adolf Hitler, he was convicted at the Nuremberg trials and sentenced to 20 years in prison.\n\nAn architect by training, Speer joined the Nazi Party in 1931. His architectural skills made him increasingly prominent within the Party, and he became a member of Hitler's inner circle. Hitler commissioned him to design and construct structures including the Reich Chancellery and the Nazi party rally grounds in Nuremberg. In 1937, Hitler appointed Speer as General Building Inspector for Berlin. In this capacity he was responsible for the Central Department for Resettlement that evicted Jewish tenants from their homes in Berlin. In February 1942, Speer was appointed as Reich Minister of Armaments and War Production. Using misleading statistics, he promoted himself as having performed an \"armaments miracle\" that was widely credited with keeping Germany in the war. In 1944, Speer established a task force to increase production of fighter aircraft. It became instrumental in the exploitation of slave labor for the benefit of the German war effort.\n\nAfter the war, Speer was among the 24 \"major war criminals\" arrested and charged with the crimes of the Nazi regime at the Nuremberg trials. He was found guilty of war crimes and crimes against humanity, principally for the use of slave labor, narrowly avoiding a death sentence. Having served his full term, Speer was released in 1966. He used his writings from the time of imprisonment as the basis for two autobiographical books, Inside the Third Reich and Spandau: The Secret Diaries. Speer's books were a success; the public was fascinated by an inside view of the Third Reich. Speer died of a stroke in 1981. Little remains of his personal architectural work.\n\nThrough his autobiographies and interviews, Speer carefully constructed an image of himself as a man who deeply regretted having failed to discover the monstrous crimes of the Third Reich. He continued to deny explicit knowledge of, and responsibility for the Holocaust. This image dominated his historiography in the decades following the war, giving rise to the \"Speer Myth\": the perception of him as an apolitical technocrat responsible for revolutionizing the German war machine. The myth began to fall apart in the 1980s, when the armaments miracle was attributed to Nazi propaganda. Adam Tooze wrote in The Wages of Destruction that the idea that Speer was an apolitical technocrat was \"absurd\". Martin Kitchen, writing in Speer: Hitler's Architect, stated that much of the increase in Germany's arms production was actually due to systems instituted by Speer's predecessor (Fritz Todt) and furthermore that Speer was intimately involved in the \"Final Solution\".\n\nEarly years and personal life\nSpeer was born in Mannheim, into an upper-middle-class family. He was the second of three sons of Luise M\u00e1thilde Wilhelmine (Hommel) and Albert Friedrich Speer. In 1918, the family leased their Mannheim residence and moved to a home they had in Heidelberg. Henry T. King, deputy prosecutor at the Nuremberg trials who later wrote a book about Speer said, \"Love and warmth were lacking in the household of Speer's youth.\" His brothers, Ernst and Hermann, bullied him throughout his childhood. Speer was active in sports, taking up skiing and mountaineering. He followed in the footsteps of his father and grandfather and studied architecture.\n\nSpeer began his architectural studies at the University of Karlsruhe instead of a more highly acclaimed institution because the hyperinflation crisis of 1923 limited his parents' income. In 1924, when the crisis had abated, he transferred to the \"much more reputable\" Technical University of Munich. In 1925, he transferred again, this time to the Technical University of Berlin where he studied under Heinrich Tessenow, whom Speer greatly admired. After passing his exams in 1927, Speer became Tessenow's assistant, a high honor for a man of 22. As such, Speer taught some of his classes while continuing his own postgraduate studies. In Munich Speer began a close friendship, ultimately spanning over 50 years, with Rudolf Wolters, who also five or so, maybe \u2013 studied under Tessenow.\n\nIn mid-1922, Speer began courting Margarete (Margret) Weber (1905\u20131987), the daughter of a successful craftsman who employed 50 workers. The relationship was frowned upon by Speer's class-conscious mother, who felt the Webers were socially inferior. Despite this opposition, the two married in Berlin on 28 August 1928; seven years elapsed before Margarete was invited to stay at her in-laws' home. The couple would have six children together, but Albert Speer grew increasingly distant from his family after 1933. He remained so even after his release from imprisonment in 1966, despite their efforts to forge closer bonds.\n\nParty architect and government functionary\n\nJoining the Nazis (1931\u20131934)\n\nIn January 1931, Speer applied for Nazi Party membership, and on 1 March 1931, he became member number 474,481. The same year, with stipends shrinking amid the Depression, Speer surrendered his position as Tessenow's assistant and moved to Mannheim, hoping to make a living as an architect. After he failed to do so, his father gave him a part-time job as manager of his properties. In July\u00a01932, the Speers visited Berlin to help out the Party before the Reichstag elections. While they were there his friend, Nazi Party official Karl Hanke recommended the young architect to Joseph Goebbels to help renovate the Party's Berlin headquarters. When the commission was completed, Speer returned to Mannheim and remained there as Hitler took office in January\u00a01933.\n\nThe organizers of the 1933 Nuremberg Rally asked Speer to submit designs for the rally, bringing him into contact with Hitler for the first time. Neither the organizers nor Rudolf Hess were willing to decide whether to approve the plans, and Hess sent Speer to Hitler's Munich apartment to seek his approval. This work won Speer his first national post, as Nazi Party \"Commissioner for the Artistic and Technical Presentation of Party Rallies and Demonstrations\".\n\nShortly after Hitler came into power, he began to make plans to rebuild the chancellery. At the end of 1933, he contracted Paul Troost to renovate the entire building. Hitler appointed Speer, whose work for Goebbels had impressed him, to manage the building site for Troost. As Chancellor, Hitler had a residence in the building and came by every day to be briefed by Speer and the building supervisor on the progress of the renovations. After one of these briefings, Hitler invited Speer to lunch, to the architect's great excitement. Speer quickly became part of Hitler's inner circle; he was expected to call on him in the morning for a walk or chat, to provide consultation on architectural matters, and to discuss Hitler's ideas. Most days he was invited to dinner.\n\nIn the English version of his memoirs, Speer says that his political commitment merely consisted of paying his \"monthly dues\". He assumed his German readers would not be so gullible and told them the Nazi Party offered a \"new mission\". He was more forthright in an interview with William Hamsher in which he said he joined the party in order to save \"Germany from Communism\". After the war, he claimed to have had little interest in politics at all and had joined almost by chance. Like many of those in power in the Third Reich, he was not an ideologue, \"nor was he anything more than an instinctive anti-Semite.\" The historian Magnus Brechtken, discussing Speer, said he did not give anti-Jewish public speeches and that his anti-Semitism can best be understood through his actions\u2014which were anti-Semitic. Brechtken added that, throughout Speer's life, his central motives were to gain power, rule, and acquire wealth.\n\nNazi architect (1934\u20131937)\n\nWhen Troost died on 21 January 1934, Speer effectively replaced him as the Party's chief architect. Hitler appointed Speer as head of the Chief Office for Construction, which placed him nominally on Hess's staff.\n\nOne of Speer's first commissions after Troost's death was the Zeppelinfeld stadium in Nuremberg. It was used for Nazi propaganda rallies and can be seen in Leni Riefenstahl's propaganda film Triumph of the Will. The building was able to hold 340,000 people. Speer insisted that as many events as possible be held at night, both to give greater prominence to his lighting effects and to hide the overweight Nazis. Nuremberg was the site of many official Nazi buildings. Many more buildings were planned. If built, the German Stadium would have accommodated 400,000 spectators. Speer modified Werner March's design for the Olympic Stadium being built for the 1936 Summer Olympics. He added a stone exterior that pleased Hitler. Speer designed the German Pavilion for the 1937 international exposition in Paris.\n\nBerlin's General Building Inspector (1937\u20131942)\n\nOn 30 January 1937, Hitler appointed Speer as General Building Inspector for the Reich Capital. This carried with it the rank of State Secretary in the Reich government and gave him extraordinary powers over the Berlin city government. He was to report directly to Hitler, and was independent of both the mayor", "flag": 1, "segments": [[902, 908]], "strength": 5.5}
{"token_count": [2006], "text": "The Alps are the highest and most extensive mountain range system that lies entirely in Europe, stretching approximately  across eight Alpine countries (from west to east): France, Switzerland, Monaco, Italy, Liechtenstein, Austria, Germany, and Slovenia. \n\nThe Alpine arch generally extends 23, the birth centenary from Nice on the western Mediterranean to Trieste on the Adriatic and Vienna at the beginning of the Pannonian Basin. The mountains were formed over tens of millions of years as the African and Eurasian tectonic plates collided. Extreme shortening  caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as Mont Blanc and the Matterhorn. \n\nMont Blanc spans the French\u2013Italian border, and at  is the highest mountain in the Alps. The Alpine region area contains 128 peaks higher than.\n\nThe altitude and size of the range affect the climate in Europe; in the mountains, precipitation levels vary greatly and climatic conditions consist of distinct zones. Wildlife such as ibex live in the higher peaks to elevations of, and plants such as Edelweiss grow in rocky areas in lower elevations as well as in higher elevations. \n\nEvidence of human habitation in the Alps goes back to the Palaeolithic era. A mummified man, determined to be 5,000 years old, was discovered on a glacier at the Austrian\u2013Italian border in 1991.\n\nBy the 6th century BC, the Celtic La T\u00e8ne culture was well established. Hannibal famously crossed the Alps with a herd of elephants, and the Romans had settlements in the region. In 1800, Napoleon crossed one of the mountain passes with an army of 40,000. The 18th and 19th centuries saw an influx of naturalists, writers, and artists, in particular, the Romantics, followed by the golden age of alpinism as mountaineers began to ascend the peaks.\n\nThe Alpine region has a strong cultural identity. The traditional culture of farming, cheesemaking, and woodworking still exists in Alpine villages, although the tourist industry began to grow early in the 20th century and expanded greatly after World War II to become the dominant industry by the end of the century. \n\nThe Winter Olympic Games have been hosted in the Swiss, French, Italian, Austrian and German Alps. At present, the region is home to 14\u00a0million people and has 120\u00a0million annual visitors.\n\nEtymology and toponymy \n\nThe English word Alps comes from the Latin Alpes.\n\nThe Latin word Alpes could possibly come from the adjective albus (\"white\"), or could possibly come from the Greek goddess Alphito, whose name is related to alphita, the \"white flour\"; alphos, a dull white leprosy; and finally the Proto-Indo-European word *alb\u02b0\u00f3s. Similarly, the river god Alpheus is also supposed to derive from the Greek alphos and means whitish.\n\nIn his commentary on the Aeneid of Vergil, the late fourth-century grammarian Maurus Servius Honoratus says that all high mountains are called Alpes by Celts.  \n\nAccording to the Oxford English Dictionary, the Latin Alpes might possibly derive from a pre-Indo-European word *alb \"hill\"; \"Albania\" is a related derivation. Albania, a name not native to the region known as the country of Albania, has been used as a name for a number of mountainous areas across Europe. \n\nIn Roman times, \"Albania\" was a name for the eastern Caucasus, while in the English languages \"Albania\" (or \"Albany\") was occasionally used as a name for Scotland, although it is more likely derived from the Latin word albus, the color white.\n\nIn modern languages the term alp, alm, albe or alpe refers to a grazing pastures in the alpine regions below the glaciers, not the peaks. \n\nAn alp refers to a high mountain pasture, typically near or above the tree line, where cows and other livestock are taken to be grazed during the summer months and where huts and hay barns can be found, sometimes constituting tiny hamlets. Therefore, the term \"the Alps\", as a reference to the mountains, is a misnomer. The term for the mountain peaks varies by nation and language: words such as Horn, Kogel, Kopf, Gipfel, Spitze, Stock, and Berg are used in German-speaking regions; Mont, Pic, T\u00eate, Pointe, Dent, Roche, and Aiguille in French-speaking regions; and Monte, Picco, Corno, Punta, Pizzo, or Cima in Italian-speaking regions.\n\nGeography \n\nThe Alps are a crescent shaped geographic feature of central Europe that ranges in an  arc (curved line) from east to west and is  in width. The mean height of the mountain peaks is. The range stretches from the Mediterranean Sea north above the Po basin, extending through France from Grenoble, and stretching eastward through mid and southern Switzerland. The range continues onward toward Vienna, Austria, and east to the Adriatic Sea and Slovenia. \n\nTo the south it dips into northern Italy and to the north extends to the southern border of Bavaria in Germany. In areas like Chiasso, Switzerland, and Allg\u00e4u, Bavaria, the demarcation between the mountain range and the flatlands are clear; in other places such as Geneva, the demarcation is less clear.\n\nThe countries with the greatest alpine territory are Austria (28.7% of the total area), Italy (27.2%), France (21.4%) and Switzerland (13.2%).\n\nThe highest portion of the range is divided by the glacial trough of the Rh\u00f4ne valley, from Mont Blanc to the Matterhorn and Monte Rosa on the southern side, and the Bernese Alps on the northern. The peaks in the easterly portion of the range, in Austria and Slovenia, are smaller than those in the central and western portions. \n\nThe variances in nomenclature in the region spanned by the Alps makes classification of the mountains and subregions difficult, but a general classification is that of the Eastern Alps and Western Alps with the divide between the two occurring in eastern Switzerland according to geologist Stefan Schmid, near the Spl\u00fcgen Pass.\n \nThe highest peaks of the Western Alps and Eastern Alps, respectively, are Mont Blanc, at  and Piz Bernina at. The second-highest major peaks are Monte Rosa at  and Ortler, at, respectively.\n\nSeries of lower mountain ranges run parallel to the main chain of the Alps, including the French Prealps in France and the Jura Mountains in Switzerland and France. The secondary chain of the Alps follows the watershed from the Mediterranean Sea to the Wienerwald, passing over many of the highest and most well-known peaks in the Alps. \nFrom the Colle di Cadibona to Col de Tende it runs westwards, before turning to the northwest and then, near the Colle della Maddalena, to the north. Upon reaching the Swiss border, the line of the main chain heads approximately east-northeast, a heading it follows until its end near Vienna.\n\nThe northeast end of the Alpine arc directly on the Danube, which flows into the Black Sea, is the Leopoldsberg near Vienna. In contrast, the southeastern part of the Alps ends on the Adriatic Sea in the area around Trieste towards Duino and Barcola.\n\nPasses \n\nThe Alps have been crossed for war and commerce, and by pilgrims, students and tourists. Crossing routes by road, train or foot are known as passes, and usually consist of depressions in the mountains in which a valley leads from the plains and hilly pre-mountainous zones. \n\nIn the medieval period hospices were established by religious orders at the summits of many of the main passes. The most important passes are the Col de l'Iseran (the highest), the Col Agnel, the Brenner Pass, the Mont-Cenis, the Great St. Bernard Pass, the Col de Tende, the Gotthard Pass, the Semmering Pass, the Simplon Pass, and the Stelvio Pass.\n\nCrossing the Italian-Austrian border, the Brenner Pass separates the \u00d6tztal Alps and Zillertal Alps and has been in use as a trading route since the 14th century. The lowest of the Alpine passes at, the Semmering crosses from Lower Austria to Styria; since the 12th century when a hospice was built there, it has seen continuous use. A railroad with a tunnel  long was built along the route of the pass in the mid-19th century. With a summit of, the Great St. Bernard Pass is one of the highest in the Alps, crossing the Italian-Swiss border east of the Pennine Alps along the flanks of Mont Blanc. The pass was used by Napoleon Bonaparte to cross 40,000 troops in 1800.\n\nThe Mont Cenis pass has been a major commercial and military road between Western Europe and Italy. The pass was crossed by many troops on their way to the Italian peninsula. From Constantine I, Pepin the Short and Charlemagne to Henry IV, Napol\u00e9on and more recently the German Geb", "flag": 1, "segments": [[58, 64]], "strength": 5.5}
{"token_count": [2006], "text": "Dame Agatha Mary Clarissa Christie, Lady Mallowan,  (n\u00e9e Miller; 15\u00a0September 1890\u00a0\u2013 12\u00a0January 1976) was an English writer known for her 66 detective novels and 14 short story collections, particularly those revolving around fictional detectives Hercule Poirot and Miss Marple. She also wrote the world's longest-running play, The Mousetrap, which has been performed in the West End since 1952, as well as six novels under the pseudonym Mary Westmacott. In 1971, she was made a Dame (DBE) for her contributions to literature. Guinness World Records lists Christie as the best-selling fiction writer of all time, her novels having sold more than two billion copies.\n\nChristie was born into a wealthy upper-middle-class family in Torquay, Devon, and was largely home-schooled. She was initially an unsuccessful writer with six consecutive rejections, but this changed in 1920 when The Mysterious Affair at Styles, featuring detective Hercule Poirot, was published. Her first husband was Archibald Christie; they married in 1914 and had one child before divorcing in 1928. During both World Wars, she served in hospital dispensaries, acquiring a thorough knowledge of the poisons which featured in many of her novels, short stories, and plays. Following her marriage to archaeologist Max Mallowan in 1930, she spent several months each year on digs in the Middle East and used her first-hand knowledge of his profession in her fiction.\n\nAccording to Index Translationum, she remains the most-translated individual author. Her novel And Then There Were None is one of the top-selling books of all time, with approximately 100 million copies sold. Christie's stage play The Mousetrap holds the world record for the longest initial run. It opened at the Ambassadors Theatre in the West End of London on 25\u00a0November 1952, and by September 2018 there had been more than 27,500 performances. The play was closed down in March 2020 because of the coronavirus pandemic and reopened in May 2021.\n\nIn 1955, Christie was the first recipient of the Mystery Writers of America's Grand Master Award. Later that year, Witness for the Prosecution received an Edgar Award for best play. In 2013, she was voted the best crime writer and The Murder of Roger Ackroyd the best crime novel ever by 600 professional novelists of the Crime Writers' Association. In September 2015, And Then There Were None was named the \"World's Favourite Christie\" in a vote sponsored by the author's estate. Most of Christie's books and short stories have been adapted for television, radio, video games, and graphic novels. More than 30 feature films are based on her work.\n\nLife and career\n\nChildhood and adolescence: 1890\u20131907 \n\nAgatha Mary Clarissa Miller was born on 15\u00a0September 1890, into a wealthy upper-middle-class family in Torquay, Devon. She was the youngest of three children born to Frederick Alvah Miller, \"a gentleman of substance\", and his wife Clarissa Margaret (\"Clara\") Miller n\u00e9e Boehmer.\n\nChristie's mother Clara was born in Dublin in 1854 to British Army officer Frederick Boehmer and his wife Mary Ann Boehmer n\u00e9e West. Boehmer died in Jersey in 1863, leaving his widow to raise Clara and her brothers on a meagre income. Two weeks after Boehmer's death, Mary's sister Margaret West married widowed dry goods merchant Nathaniel Frary Miller, a US citizen. To assist Mary financially, they agreed to foster nine-year-old Clara; the family settled in Timperley, Cheshire. Margaret and Nathaniel had no children together, but Nathaniel had a 17-year-old son, Fred Miller, from his previous marriage. Fred was born in New York City and travelled extensively after leaving his Swiss boarding school. He and Clara were married in London in 1878. Their first child, Margaret Frary (\"Madge\"), was born in Torquay in 1879. The second, Louis Montant (\"Monty\"), was born in Morristown, New Jersey, in 1880, while the family was on an extended visit to the United States.\n\nWhen Fred's father died in 1869, he left Clara \u00a32,000 (approximately ); in 1881 they used this to buy the leasehold of a villa in Torquay named Ashfield. It was here that their third and last child, Agatha, was born in 1890. She described her childhood as \"very happy\". The Millers lived mainly in Devon but often visited her step-grandmother/great-aunt Margaret Miller in Ealing and maternal grandmother Mary Boehmer in Bayswater. A year was spent abroad with her family, in the French Pyrenees, Paris, Dinard, and Guernsey. Because her siblings were so much older, and there were few children in their neighbourhood, Christie spent much of her time playing alone with her pets and imaginary companions. She eventually made friends with other girls in Torquay, noting that \"one of the highlights of my existence\" was her appearance with them in a youth production of Gilbert and Sullivan's The Yeomen of the Guard, in which she played the hero, Colonel Fairfax.\n\nAccording to Christie, Clara believed she should not learn to read until she was eight; thanks to her curiosity, she was reading by age four. Her sister had been sent to a boarding school, but their mother insisted that Christie receive a home education. As a result, her parents and sister supervised her studies in reading, writing, and basic arithmetic, a subject she particularly enjoyed. They also taught her music, and she learned to play the piano and the mandolin.\n\nChristie was a voracious reader from an early age. Among her earliest memories were reading children's books by Mrs Molesworth and Edith Nesbit. When a little older, she moved on to the surreal verse of Edward Lear and Lewis Carroll. As an adolescent, she enjoyed works by Anthony Hope, Walter Scott, Charles Dickens, and Alexandre Dumas. In April 1901, aged 10, she wrote her first poem, \"The Cow Slip\".\n\nBy 1901, her father's health had deteriorated, because of what he believed were heart problems. Fred died in November 1901 from pneumonia and chronic kidney disease. Christie later said that her father's death when she was 11 marked the end of her childhood.\n\nThe family's financial situation had by this time worsened. Madge married the year after their father's death and moved to Cheadle, Cheshire; Monty was overseas, serving in a British regiment. Christie now lived alone at Ashfield with her mother. In 1902, she began attending Miss Guyer's Girls' School in Torquay but found it difficult to adjust to the disciplined atmosphere. In 1905, her mother sent her to Paris, where she was educated in a series of  (boarding schools), focusing on voice training and piano playing. Deciding she lacked the temperament and talent, she gave up her goal of performing professionally as a concert pianist or an opera singer.\n\nEarly literary attempts, marriage, literary success: 1907\u20131926 \n\nAfter completing her education, Christie returned to England to find her mother ailing. They decided to spend the northern winter of 1907\u20131908 in the warm climate of Egypt, which was then a regular tourist destination for wealthy Britons. They stayed for three months at the Gezirah Palace Hotel in Cairo. Christie attended many dances and other social functions; she particularly enjoyed watching amateur polo matches. While they visited some ancient Egyptian monuments such as the Great Pyramid of Giza, she did not exhibit the great interest in archaeology and Egyptology that developed in her later years. Returning to Britain, she continued her social activities, writing and performing in amateur theatricals. She also helped put on a play called The Blue Beard of Unhappiness with female friends.\n\nAt 18, Christie wrote her first short story, \"The House of Beauty\", while recovering in bed from an illness. It consisted of about 6,000 words on \"madness and dreams\", a subject of fascination for her. Her biographer, Janet Morgan, has commented that, despite \"infelicities of style\", the story was \"com hit a three and out onpelling\". (The story became an early version of her story \"The House of Dreams\".) Other stories followed, most of them illustrating her interest in spiritualism and the paranormal. These included \"The Call of Wings\" and \"The Little Lonely God\". Magazines rejected all her early submissions, made under pseudonyms (including Mac Miller, Nathaniel Miller, and Sydney West); some submissions were later revised and published under her real name, often with new titles.\n\nAround the same time, Christie began work on her first novel, Snow Upon the Desert. Writing under the pseudonym Monosyllaba, she set the book in Cairo and drew upon her recent experiences there. She was disappointed when the six publishers she contacted declined the work. Clara suggested that her daughter ask for advice from the successful novelist Eden Phillpotts, a family friend and neighbour, who responded to her enquiry, encouraged her writing, and sent her an introduction to his own literary agent, Hughes Massie, who also rejected Snow Upon the Desert but suggested a second novel.\n\nMeanwhile, Christie's social activities expanded, with country house parties, riding, hunting, dances, and roller skating. She had short-lived relationships with four men and an engagement to another. In October 1912, she was introduced to Archibald \"Archie\" Christie at a dance given by Lord and Lady Clifford at Ugbro", "flag": 1, "segments": [[1722, 1728]], "strength": 5.5}
{"token_count": [2006], "text": "Irwin Allen Ginsberg (; June 3, 1926\u00a0\u2013 April 5, 1997) was an American poet and writer. As a student at Columbia University in the 1940s, he began friendships with William S. Burroughs and Jack Kerouac, forming the core of the Beat Generation. He vigorously opposed militarism, economic materialism, and sexual repression, and he embodied various aspects of this counterculture with his views on drugs, sex, multiculturalism, hostility to bureaucracy, and openness to Eastern religions.\n\nGinsberg is best known for his poem \"Howl\", in which he denounced what he saw as the destructive forces of capitalism and conformity in the United States. San Francisco police and US Customs seized \"Howl\" in 1956, and it attracted widespread publicity in 1957 when it became the subject of an obscenity trial, as it described heterosexual and homosexual sex at a time when sodomy laws made (male) homosexual acts a crime in every state. The poem reflected Ginsberg's own sexuality and his relationships with a number of men, including Peter Orlovsky, his lifelong partner. Judge Clayton W. Horn ruled that \"Howl\" was not obscene, stating: \"Would there be any freedom of press or speech if one must reduce his vocabulary to vapid innocuous euphemisms?\"\n\nGinsberg was a Buddhist who extensively studied Eastern religious disciplines. He lived modestly, buying his clothing in second-hand stores and residing in apartments in New York City's East Village. One of his most influential teachers was Tibetan Buddhist Ch\u00f6gyam Trungpa, the founder of the Naropa Institute in Boulder, Colorado. At Trungpa's urging, Ginsberg and poet Anne Waldman started The Jack Kerouac School of Disembodied Poetics there in 1974.\n\nGinsberg took part in decades of political protest against everything from the Vietnam War to the War on Drugs. His poem \"September on Jessore Road\" called attention to the plight of Bengali refugees which was caused by the 1971 Genocide and it exemplifies what literary critic Helen Vendler described as Ginsberg's persistence in protesting against \"imperial politics\" and \"persecution of the powerless\". His collection The Fall of America shared the annual National Book Award for Poetry in 1974. In 1979, he received the National Arts Club gold medal and was inducted into the American Academy of Arts and Letters. He was a Pulitzer Prize finalist in 1995 for his book Cosmopolitan Greetings: Poems 1986\u20131992.\n\nBiography\n\nEarly life and family\nGinsberg was born into a Jewish family in Newark, New Jersey, and grew up in nearby Paterson. He was the second son of Louis Ginsberg, a schoolteacher and sometime poet, and the former Naomi Levy, a Russian emigree and fervent Marxist.\n\nAs a teenager, Ginsberg began to write letters to The New York Times about political issues, such as World War II and workers' rights. He published his first poems in the Paterson Morning Call. While in high school, Ginsberg became interested in the works of Walt Whitman, inspired by his teacher's passionate reading. In 1943, Ginsberg graduated from Eastside High School and briefly attended Montclair State College before entering Columbia University on a scholarship from the Young Men's Hebrew Association of Paterson.\n\nIn 1945, he joined the Merchant Marine to earn money to continue his education at Columbia. While at Columbia, Ginsberg contributed to the Columbia Review literary journal, the Jester humor magazine, won the Woodberry Poetry Prize, served as president of the Philolexian Society (literary and debate group), and joined Boar's Head Society (poetry society).\nHe was a resident of Hartley Hall, where other Beat Generation poets such as Jack Kerouac and Herbert Gold also lived. Ginsberg has stated that he considered his required freshman seminar in Great Books, taught by Lionel Trilling, to be his favorite Columbia course.\n\nAccording to The Poetry Foundation, Ginsberg spent several months in a mental institution after he pleaded insanity during a hearing. He was allegedly being prosecuted for harboring stolen goods in his dorm room. It was noted that the stolen property was not his, but belonged to an acquaintance.\n\nRelationship with his parents\nGinsberg referred to his parents in a 1985 interview as \"old-fashioned delicatessen philosophers\".\nHis mother was affected by a psychological illness that was never properly diagnosed. She was also an active member of the Communist Party and took Ginsberg and his brother Eugene to party meetings. Ginsberg later said that his mother \"made up bedtime stories that all went something like: 'The good king rode forth from his castle, saw the suffering workers and healed them.'\" Of his father Ginsberg said: \"My father would go around the house either reciting Emily Dickinson and Longfellow under his breath or attacking T. S. Eliot for ruining poetry with his 'obscurantism.' I grew suspicious of both sides.\"\n\nNaomi Ginsberg's mental illness often manifested as paranoid delusions. She would claim, for example, that the president had implanted listening devices in their home and that her mother-in-law was a rural campground in the trying to kill her. Her suspicion of those around her caused Naomi to draw closer to young Allen, \"her little pet\", as Bill Morgan says in his biography of Ginsberg, titled I Celebrate Myself: The Somewhat Private Life of Allen Ginsberg. She also tried to kill herself by slitting her wrists and was soon taken to Greystone, a mental hospital; she would spend much of Ginsberg's youth in mental hospitals. His experiences with his mother and her mental illness were a major inspiration for his two major works, \"Howl\" and his long autobiographical poem \"Kaddish for Naomi Ginsberg (1894\u20131956)\".\n\nWhen he was in junior high school, he accompanied his mother by bus to her therapist. The trip deeply disturbed Ginsberg\u2014he mentioned it and other moments from his childhood in \"Kaddish\". His experiences with his mother's mental illness and her institutionalization are also frequently referred to in \"Howl\". For example, \"Pilgrim State, Rockland, and Grey Stone's foetid halls\" is a reference to institutions frequented by his mother and Carl Solomon, ostensibly the subject of the poem: Pilgrim State Hospital and Rockland State Hospital in New York and Greystone Park Psychiatric Hospital in New Jersey. This is followed soon by the line \"with mother finally ******.\" Ginsberg later admitted the deletion was the expletive \"fucked.\" He also says of Solomon in section three, \"I'm with you in Rockland where you imitate the shade of my mother,\" once again showing the association between Solomon and his mother.\n\nGinsberg received a letter from his mother after her death responding to a copy of \"Howl\" he had sent her. It admonished Ginsberg to be good and stay away from drugs; she says, \"The key is in the window, the key is in the sunlight at the window\u2014I have the key\u2014Get married Allen don't take drugs\u2014the key is in the bars, in the sunlight in the window\". In a letter she wrote to Ginsberg's brother Eugene, she said, \"God's informers come to my bed, and God himself I saw in the sky. The sunshine showed too, a key on the side of the window for me to get out. The yellow of the sunshine, also showed the key on the side of the window.\" These letters and the absence of a facility to recite kaddish inspired Ginsberg to write \"Kaddish\", which makes references to many details from Naomi's life, Ginsberg's experiences with her, and the letter, including the lines \"the key is in the light\" and \"the key is in the window\".\n\nNew York Beats\nIn Ginsberg's first year at Columbia he met fellow undergraduate Lucien Carr, who introduced him to a number of future Beat writers, including Jack Kerouac, William S. Burroughs, and John Clellon Holmes. They bonded, because they saw in one another an excitement about the potential of American youth, a potential that existed outside the strict conformist confines of post\u2013World War II, McCarthy-era America. Ginsberg and Carr talked excitedly about a \"New Vision\" (a phrase adapted from Yeats' \"A Vision\"), for literature and America. Carr also introduced Ginsberg to Neal Cassady, for whom Ginsberg had a long infatuation. In the first chapter of his 1957 novel On the Road Kerouac described the meeting between Ginsberg and Cassady. Kerouac saw them as the dark (Ginsberg) and light (Cassady) side of their \"New Vision\", a perception stemming partly from Ginsberg's association with communism, of which Kerouac had become increasingly distrustful. Though Ginsberg was never a member of the Communist Party, Kerouac named him \"Carlo Marx\" in On the Road. This was a source of strain in their relationship.\n\nAlso, in New York, Ginsberg met Gregory Corso in the Pony Stable Bar. Corso, recently released from prison, was supported by the Pony Stable patrons and was writing poetry there the night of their meeting. Ginsberg claims he was immediately attracted to Corso, who was straight, but understood of homosexuality after three years in prison. Ginsberg was even more struck by reading Corso's poems, realizing Corso was \"spiritually gifted.\" Ginsberg introduced Corso to the rest of his inner circle. In their first meeting at the Pony Stable, Corso showed Ginsberg a poem", "flag": 1, "segments": [[1068, 1074]], "strength": 5.5}
{"token_count": [2006], "text": "Aristophanes (;, ; c. 446 \u2013 c. 386 BC), son of Philippus, of the deme Kydathenaion (), was a comic playwright or comedy-writer of ancient Athens and a poet of Old Attic Comedy. Eleven of his forty plays survive virtually complete. These provide the most valuable examples of a genre of comic drama known as Old Comedy and are used to define it, along with fragments from dozens of lost plays by Aristophanes and his contemporaries.\n\nAlso known as \"The Father of Comedy\" and \"the Prince of Ancient Comedy\", Aristophanes has been said to recreate the life of ancient Athens more convincingly than any other author. His powers of ridicule were feared and acknowledged by influential contemporaries; Plato singled out Aristophanes' play The Clouds as slander that contributed to the trial and subsequent condemning to death of Socrates, although other satirical playwrights had also caricatured the philosopher.\n\nAristophanes' second play, The Babylonians (now lost), was denounced by Cleon as a slander against the Athenian polis. It is possible that the case was argued in court, but details of the trial are not recorded and Aristophanes caricatured Cleon mercilessly in his subsequent plays, especially The Knights, the first of many plays that he directed himself. \"In my opinion,\" he says through that play's Chorus, \"the author-director of comedies has the hardest job of all.\"\n\nBiography\n\nLess is known about Aristophanes than about his plays. In fact, his plays are the main source of information about him and his life. It was conventional in Old Comedy for the chorus to speak on behalf of the author during an address called the parabasis and thus some biographical facts can be found there. However, these facts relate almost entirely to his career as a dramatist and the plays contain few clear and unambiguous clues about his personal beliefs or his private life. He was a comic poet in an age when it was conventional for a poet to assume the role of teacher (didaskalos), and though this specifically referred to his training of the Chorus in rehearsal, it also covered his relationship with the audience as a commentator on significant issues.\n\nAristophanes claimed to be writing for a clever and discerning audience, yet he also declared that \"other times\" would judge the audience according to its reception of his plays. He sometimes boasts of his originality as a dramatist yet his plays consistently espouse opposition to radical new influences in Athenian society. He caricatured leading figures in the arts (notably Euripides, whose influence on his own work however he once grudgingly acknowledged), in politics (especially the populist Cleon), and in philosophy/religion (where Socrates was the most obvious target). Such caricatures seem to imply that Aristophanes was an old-fashioned conservative, yet that view of him leads to contradictions.\n\nIt has been argued that Aristophanes produced plays mainly to entertain the audience and to win prestigious competitions. His plays were written for production at the great dramatic festivals of Athens, the Lenaia and City Dionysia, where they were judged and awarded prizes in competition with the works of other comic dramatists. An elaborate series of lotteries, designed to prevent prejudice and corruption, reduced the voting judges at the City Dionysia to just five. These judges probablyground train smash into a Santa reflected the mood of the audiences yet there is much uncertainty about the composition of those audiences. The theatres were certainly huge, with seating for at least 10,000 at the Theatre of Dionysus. The day's program at the City Dionysia for example was crowded, with three tragedies and a satyr play ahead of a comedy, but it is possible that many of the poorer citizens (typically the main supporters of demagogues like Cleon) occupied the festival holiday with other pursuits. The conservative views expressed in the plays might therefore reflect the attitudes of the dominant group in an unrepresentative audience.\n\nThe production process might also have influenced the views expressed in the plays. Throughout most of Aristophanes' career, the Chorus was essential to a play's success and it was recruited and funded by a choregus, a wealthy citizen appointed to the task by one of the archons. A choregus could regard his personal expenditure on the Chorus as a civic duty and a public honour, but Aristophanes showed in The Knights that wealthy citizens might regard civic responsibilities as punishment imposed on them by demagogues and populists like Cleon. Thus the political conservatism of the plays may reflect the views of the wealthiest section of Athenian society, on whose generosity all dramatists depended for putting on their plays.\n\nWhen Aristophanes' first play The Banqueters was produced, Athens was an ambitious, imperial power and the Peloponnesian War was only in its fourth year. His plays often express pride in the achievement of the older generation (the victors at Marathon) yet they are not jingoistic, and they are staunchly opposed to the war with Sparta. The plays are particularly scathing in criticism of war profiteers, among whom populists such as Cleon figure prominently. By the time his last play was produced (around 386 BC) Athens had been defeated in war, its empire had been dismantled and it had undergone a transformation from being the political to the intellectual centre of Greece. Aristophanes was part of this transformation and he shared in the intellectual fashions of the period\u2014the structure of his plays evolves from Old Comedy until, in his last surviving play, Wealth II, it more closely resembles New Comedy. However it is uncertain whether he led or merely responded to changes in audience expectations.\n\nAristophanes won second prize at the City Dionysia in 427 BC with his first play The Banqueters (now lost). He won first prize there with his next play, The Babylonians (also now lost). It was usual for foreign dignitaries to attend the City Dionysia, and The Babylonians caused some embarrassment for the Athenian authorities since it depicted the cities of the Delian League as slaves grinding at a mill. Some influential citizens, notably Cleon, reviled the play as slander against the polis and possibly took legal action against the author. The details of the trial are unrecorded but, speaking through the hero of his third play The Acharnians (staged at the Lenaia, where there were few or no foreign dignitaries), the poet carefully distinguishes between the polis and the real targets of his acerbic wit:\n\nAristophanes repeatedly savages Cleon in his later plays. But these satirical diatribes appear to have had no effect on Cleon's political career\u2014a few weeks after the performance of The Knights\u2014a play full of anti-Cleon jokes\u2014Cleon was elected to the prestigious board of ten generals. Cleon also seems to have had no real power to limit or control Aristophanes: the caricatures of him continued up to and even beyond his death.\n\nIn the absence of clear biographical facts about Aristophanes, scholars make educated guesses based on interpretation of the language in the plays. Inscriptions and summaries or comments by Hellenistic and Byzantine scholars can also provide useful clues. We know from a combination of these sources, and especially from comments in The Knights and The Clouds, that Aristophanes' first three plays were not directed by him\u2014they were instead directed by Callistratus and Philoneides, an arrangement that seemed to suit Aristophanes since he appears to have used these same directors in many later plays as well (Philoneides for example later directed The Frogs and he was also credited, perhaps wrongly, with directing The Wasps.) Aristophanes's use of directors complicates our reliance on the plays as sources of biographical information because apparent self-references might have been made with reference to his directors instead. Thus for example a statement by the chorus in The Acharnians seems to indicate that the \"poet\" had a close, personal association with the island of Aegina. Similarly, the hero in The Acharnians complains about Cleon \"dragging me into court\" over \"last year's play.\"\n\nComments made by the Chorus referring to Aristophanes in The Clouds have been interpreted as evidence that he can hardly have been more than 18 years old when his first play The Banqueters was produced. The second parabasis in Wasps appears to indicate that he reached some kind of temporary accommodation with Cleon following either the controversy over The Babylonians or a subsequent controversy over The Knights. It has been inferred from statements in The Clouds and Peace that Aristophanes was prematurely bald.\n\nAristophanes was probably victorious at least once at the City Dionysia (with Babylonians in 427) and at least three times at the Lenaia, with The Acharnians in 425, Knights in 424, and Frogs in 405. Frogs in fact won the unique distinction of a repeat performance at a subsequent festival. A son of Aristophanes, Araros, was also a comic poet and he could have been heavily involved in the production of his father's play Wealth II in 388. Araros is also thought to have been responsible for the posthumous performances of the now lost plays Aeolosicon II and Cocalus, and it is possible that the last of these won the prize at the City Dionysia in 387. It appears that a second son, Philippus, was twice victorious at the Lenaia and he could have directed some of Eubulus\u2019", "flag": 1, "segments": [[708, 714]], "strength": 5.5}
{"token_count": [2006], "text": "Aarhus (,, ; officially spelled \u00c5rhus from 1948 until 1 January 2011) is the second-largest city in Denmark and the seat of Aarhus municipality. It is located on the eastern shore of Jutland in the Kattegat sea and approximately  northwest of Copenhagen.\n\nThe largest city in Jutland, Aarhus anchors the Central Denmark Region and the statistical region Landsdel \u00d8stjylland (L\u00d8) (Lit. Province East Jutland). The L\u00d8 is the second most populous statistical region in Denmark with an estimated population of 903,974 (). Aarhus Municipality defines the greater Aarhus area as itself and 8 adjacent municipalities totalling 952,824 inhabitants () which is roughly analogous to the municipal and commercial collaboration Business Region Aarhus. The city proper, with an estimated population of 282,910 inhabitants (as of 2021), ranks as the 2nd-largest city in Denmark.\n\nAarhus dates back to at least the late 8th century and is among the oldest cities in Denmark. It was founded as a harbour settlement at the mouth of the Aarhus River and quickly became a trade hub. The first Christian church was built here around the year 900 and later in the Viking Age the town was fortified with defensive ramparts. The Viking Age was turbulent and violent, also for Aros, as the town was called back then, but in spite of the difficulties, the bishopric of Aarhus grew steadily stronger and more prosperous, building several religious institutions in the town during the early Middle Ages. Trade continued to improve, although it was not until 1441 that Aarhus was granted Market town privileges, and the population of Aarhus remained relatively stable until the 19th century. The 1600s, in particular, was a difficult time for Aarhus as the town suffered from several wars and the plague, and trade was also dampened by the state in favour of the royal seat of Copenhagen. Nevertheless, Aarhus grew to become the second biggest town in Denmark during that time, and in the middle of the 1700s, the once prosperous trade growth returned. The industrial revolution became an inflection point in the 19th century, as industry drove a rapid population growth, outpacing regional rivals, and the first railway line in Jutland was built here in 1862. In 1928, the first university in Jutland was founded in Aarhus and today it is a university city and the largest centre for trade, services, industry, and tourism in Jutland.\n\nDesignated as a \"Sufficiency\" global city by the Globalization and World Cities Research Network, the city's major cultural institutions include Den Gamle By, ARoS Aarhus Kunstmuseum, Moesg\u00e5rd Museum, Kvindemuseet, Musikhuset and Aarhus Theatre. Known as Smilets By (lit. City of Smiles) it is the Danish city with the youngest and fastest growing demographics and home to Scandinavia's largest university, Aarhus University. Commercially, the city is the principal container port in the country and major Danish companies are headquartered here such as Vestas, Arla Foods, Salling Group, and Jysk.\n\nEtymology\nThe name originates from the city's location at the mouth of  (Aarhus River). It is a compound of the two words, genitive of  (\"river\", Modern Danish ), and  (\"mouth\", in Modern Icelandic this word, spelt, is still used for \"river delta\"). In Valdemar's Census Book (1231) the city was called Arus, and in Icelandic it was known as, later written as Aars.\n\nSpelling\nThe spelling \"Aarhus\" is first found in 1406 and gradually became the norm in the 17th\u00a0century. With the Danish spelling reform of 1948, \"Aa\" was changed to \"\u00c5\". Some Danish cities resisted the change but Aarhus city council opted to change the name. In 2010, the city council voted to change the name back from  to  again with effect from 1 January 2011.\n\nIt is still grammatically correct to write geographical names with the letter \u00c5 and local councils are allowed to use the Aa spelling as an alternative and most newspapers and public institutions will accept either. Some official authorities such as the Danish Language Committee, publisher of the Danish Orthographic Dictionary, still retain  as the main name, providing  as a second option, in brackets and some institutions are still using  explicitly in their official name, such as the local newspaper  and the schools  and. \"Aa\" was used by some major institutions between 1948 and 2011 as well, such as Aarhus University or the largest local sports club,  (AGF), which has never used the \"\u00c5\"-spelling. Certain geographically affiliated names have been updated to reflect the name of the city, such as the Aarhus River, changed from  to.\n\nHistory\n\nEarly history\nFounded in the early Viking Age, Aarhus is one of the oldest cities in Denmark, along with Ribe and Hedeby. The original Aros settlement was situated on the northern shores of a fjord by the mouth of the Aarhus River, right where the city center is today. It quickly became a hub for sea-going trade due to its position on intersecting trade routes in the Danish straits and the fertile countryside. The trade, however, was not nearly as prominent as that in Ribe and Hedeby during the Viking Age, and it was primarily linked to Norway as evidenced by archaeological finds. A shipbuilding yard from the Viking Age was uncovered upriver in 2002 by archaeologists. It was located at a place formerly known as Snekkeeng, or Snekke Meadow in English ('Snekke' is a type of longship), east of the Brabrand Lake close to Viby, and it was in use for more than 400 years from the late 700s till around the mid-1200s.\n\nArchaeological evidence indicate Aarhus was a town as early as the last quarter of the 8th\u00a0century. Discoveries after a 2003 archaeological dig, includes half-buried longhouses, firepits, glass pearls and a road dated to the late 700s. Several excavations in the inner city since the 1960s, has revealed wells, streets, homes and workshops, and inside the buildings and adjoining archaeological layers, everyday utensils like combs, jewellery and basic multi children\u2019s book store-purpose tools from approximately the year 900 has been unearthed. The early town was fortified with defensive earthen ramparts in the first part of the 900s, possibly in the year 934 on order from king Gorm the Old. The fortifications were later improved and expanded by his son Harald Bluetooth, encircling the settlement much like the defence structures found at Viking ring fortresses elsewhere. Together with the town's geographical placement, this suggests that Aros became an important military centre in the Viking Age. There are also strong indications of a former royal residence from the same period in Viby, a few kilometres south of the Aarhus city centre.\n\nThe centre of Aarhus was originally a pagan burial site until Aarhus's first Christian church, Holy Trinity Church, a timber structure, was built upon it during the reign of Frode, King of Jutland, around 900. The bishopric of Aarhus dates back to at least 948 when Adam of Bremen reported that the missionary bishop Reginbrand of Aros attended the synod of Ingelheim in Germany, but the late Viking Age during the Christianization of Scandinavia was a turbulent and violent time with several naval attacks on the town, such as Harald Hardrada's assault around 1050, when the Holy Trinity Church was burned to the ground. Despite the conflicts, Aarhus continued to prosper from the trade and the finding of six runestones in and around Aarhus indicates the city had some significance around the year 1000, as only wealthy nobles traditionally used them. The bishopric diocese was obliterated for almost a hundred years after Reginbrand in 988, but in 1060 a new bishop Christian was ordained and he founded a new church in Aarhus, Sankt Nicolai Domkirke (St. Nicholas Cathedral), this time in stone. It was erected outside the town fortifications, and stood finished in 1070 at the site where Church of Our Lady stands today, but only an underground crypt remains.\n\nMiddle Ages\n\nThe growing influence of the Church during the Middle Ages gradually turned Aarhus, with its bishopric, into a prosperous religious centre. Many public and religious buildings were built in and around the town; notably Aarhus Cathedral was initiated in the late 12th\u00a0century by the influential bishop Peder Vognsen, and around 1200, Aros had a total of four churches. The 13th century also marks a thorough reorganisation, erasing most of the town's original layout with new streets, relocations, dismantling and new constructions. The Church clearly had the upper hand in the Aarhus region during medieval times, and the large bishopric of Aarhus prospered and expanded territory, reaching as far as Viborg in extent. In 1441, Christopher III issued the oldest known charter granting market town status, although similar privileges may have existed as far back as the 12th\u00a0century. The charter is the first official recognition of the town as a regional power and is by some considered Aarhus's birth certificate.", "flag": 1, "segments": [[1367, 1373]], "strength": 5.5}
{"token_count": [2006], "text": "Antisemitism (also spelled anti-semitism or anti-Semitism) is hostility to, prejudice towards, or discrimination against Jews. A person who holds such positions is called an antisemite. Antisemitism is considered to be a form of racism.\n\nAntisemitism may be manifested in many ways, ranging from expressions of hatred of or discrimination against individual Jews to organized pogroms by mobs or police forces, or even military attacks on entire Jewish communities. Although the term did not come into common usage until the 19th century, it is also applied to previous and later anti-Jewish incidents. Notable instances of persecution include the Rhineland massacres preceding the First Crusade in 1096, the Edict of Expulsion from England in 1290, the 1348\u20131351 persecution of Jews during the Black Death, the massacres of Spanish Jews in 1391, the persecutions of the Spanish Inquisition, the expulsion from Spain in 1492, the Cossack massacres in Ukraine from 1648 to 1657, various anti-Jewish pogroms in the Russian Empire between 1821 and 1906, the 1894\u20131906 Dreyfus affair in France, the Holocaust in German-occupied Europe during World War II and Soviet anti-Jewish policies. Though historically most manifestations of antisemitism have taken place in Christian Europe, since the early 20th century, especially under the influence of Nazi Germany, antisemitism has increased in the Middle East, resulting in Arab and Muslim antipathy to Jews and sometimes attacks on Jewish communities leading to the Jewish exodus from Arab and Muslim countries.\n\nThe root word Semite gives the false impression that antisemitism is directed against all Semitic people, e.g., including Arabs, Assyrians and Arameans. The compound word  ('antisemitism') was first used in print in Germany in 1879 as a scientific-sounding term for  ('Jew-hatred'), and this has been its common use since then.\n\nOrigin and usage\n\nEtymology\n\nThe origin of \"antisemitic\" terminologies is found in the responses of Moritz Steinschneider to the views of Ernest Renan. As Alex Bein writes: \"The compound anti-Semitism appears to have been used first by Steinschneider, who challenged Renan on account of his 'anti-Semitic prejudices' [i.e., his derogation of the \"Semites\" as a race].\" Avner Falk similarly writes: \"The German word antisemitisch was first used in 1860 by the Austrian Jewish scholar Moritz Steinschneider (1816\u20131907) in the phrase antisemitische Vorurteile (antisemitic prejudices). Steinschneider used this phrase to characterise the French philosopher Ernest Renan's false ideas about how 'Semitic races' were inferior to 'Aryan races'\".\n\nPseudoscientific theories concerning race, civilization, and \"progress\" had become quite widespread in Europe in the second half of the 19th century, especially as Prussian nationalistic historian Heinrich von Treitschke did much to promote this form of racism. He coined the phrase \"the Jews are our misfortune\" which would later be widely used by Nazis. According to Avner Falk, Treitschke uses the term \"Semitic\" almost synonymously with \"Jewish\", in contrast to Renan's use of it to refer to a whole range of peoples, based generally on linguistic criteria.\n\nAccording to Jonathan M. Hess, the term was originally used by its authors to \"stress the radical difference between their own 'antisemitism' and earlier forms of antagonism toward Jews and Judaism.\"\n\nIn 1879, German journalist Wilhelm Marr published a pamphlet, Der Sieg des Judenthums \u00fcber das Germanenthum. Vom nicht confessionellen Standpunkt aus betrachtet (The Victory of the Jewish Spirit over the Germanic Spirit. Observed from a non-religious perspective) in which he used the word Semitismus interchangeably with the word Judentum to denote both \"Jewry\" (the Jews as a collective) and \"jewishness\" (the quality of being Jewish, or the Jewish spirit).\n\nThis use of Semitismus was followed by a coining of \"Antisemitismus\" which was used to indicate opposition to the Jews as a people and opposition to the Jewish spirit, which Marr interpreted as infiltrating German culture. His next pamphlet, Der Weg zum Siege des Germanenthums \u00fcber das Judenthum (The Way to Victory of the Germanic Spirit over the Jewish Spirit, 1880), presents a development of Marr's ideas further and may present the first published use of the German word  Antisemitismus, \"antisemitism\".\n\nThe pamphlet became very popular, and in the same year he founded the Antisemiten-Liga (League of Antisemites), apparently named to follow the \"Anti-Kanzler-Liga\" (Anti-Chancellor League). The league was the first German organization committed specifically to combating the alleged threat to Germany and German culture posed by the Jews and their influence and advocating their forced removal from the country.\n\nSo far as can be ascertained, the word was first widely printed in 1881, when Marr published Zwanglose Antisemitische Hefte, and Wilhelm Scherer used the term Antisemiten in the January issue of Neue Freie Presse.\n\nThe Jewish Encyclopedia reports, \"In February 1881, a correspondent of the Allgemeine Zeitung des Judentums speaks of 'Anti-Semitism' as a designation which recently came into use (\"Allg. Zeit. d. Jud.\" 1881, p.\u00a0138). On 19 July 1882, the editor says, 'This quite recent Anti-Semitism is hardly three years old.'\"\n\nThe word \"antisemitism\" was borrowed into English from German in 1881. Oxford English Dictionary editor James Murray wrote that it was not included in the first edition because \"Anti-Semite and its family were then probably very new in English use, and not thought likely to be more than passing nonce-words... Would that anti neighbors engaged in a standoff over-Semitism had had no more than a fleeting interest!\" The related term \"philosemitism\" was used by 1881.\n\nUsage\nFrom the outset the term \"anti-Semitism\" bore special racial connotations and meant specifically prejudice against Jews. The term is confusing, for in modern usage 'Semitic' designates a language group, not a race. In this sense, the term is a misnomer, since there are many speakers of Semitic languages (e.g. Arabs, Ethiopians, and Arameans) who are not the objects of antisemitic prejudices, while there are many Jews who do not speak Hebrew, a Semitic language. Though 'antisemitism' could be construed as prejudice against people who speak other Semitic languages, this is not how the term is commonly used.\n\nThe term may be spelled with or without a hyphen (antisemitism or anti-Semitism). Many scholars and institutions favor the unhyphenated form. Shmuel Almog argued, \"If you use the hyphenated form, you consider the words 'Semitism', 'Semite', 'Semitic' as meaningful\u00a0... [I]n antisemitic parlance, 'Semites' really stands for Jews, just that.\" Emil Fackenheim supported the unhyphenated spelling, in order to \"[dispel] the notion that there is an entity 'Semitism' which 'anti-Semitism' opposes.\" Others endorsing an unhyphenated term for the same reason include the International Holocaust Remembrance Alliance, historian Deborah Lipstadt, Padraic O'Hare, professor of Religious and Theological Studies and Director of the Center for the Study of Jewish-Christian-Muslim Relations at Merrimack College; and historians Yehuda Bauer and James Carroll. According to Carroll, who first cites O'Hare and Bauer on \"the existence of something called 'Semitism'\", \"the hyphenated word thus reflects the bipolarity that is at the heart of the problem of antisemitism\".\n\nObjections to the usage of the term, such as the obsolete nature of the term Semitic as a racial term, have been raised since at least the 1930s.\n\nIn 2020, the Anti-Defamation League began to use the spelling \"antisemitism\".\n\nDefinition\nThough the general definition of antisemitism is hostility or prejudice against Jews, and, according to Olaf Blaschke, has become an \"umbrella term for negative stereotypes about Jews\", a number of authorities have developed more formal definitions.\n\nHolocaust scholar and City University of New York professor Helen Fein defines it as \"a persisting latent structure of hostile beliefs towards Jews as a collective manifested in individuals as attitudes, and in culture as myth, ideology, folklore and imagery, and in actions\u2014social or legal discrimination, political mobilization against the Jews, and collective or state violence\u2014which results in and/or is designed to distance, displace, or destroy Jews as Jews.\"\n\nElaborating on Fein's definition, Dietz Bering of the University of Cologne writes that, to antisemites, \"Jews are not only partially but totally bad by nature, that is, their bad traits are incorrigible. Because of this bad nature: (1) Jews have to be seen not as individuals but as a collective. (2) Jews remain essentially alien in the surrounding", "flag": 1, "segments": [[1303, 1309]], "strength": 5.5}
{"token_count": [2006], "text": "The Armenian economy contracted sharply in 2020, by 5.7%. In contrast it grew by 7.6 per cent in 2019, the largest recorded growth since 2007, while between 2012 and 2018 GDP grew 40.7%, and key banking indicators like assets and credit exposures almost doubled.\n\nUntil independence, Armenia's economy was based largely on industry\u2014chemicals, electronic products, machinery, processed food, synthetic rubber and textiles; it was highly dependent on outside resources. Armenian mines produce copper, zinc, gold and lead. The vast majority of energy is produced with imported fuel from Russia, including gas and nuclear fuel for Armenia's Metsamor nuclear power plant. The main domestic energy source is hydroelectric. Small amounts of coal, gas and petroleum have not yet been developed.\n\nArmenia's severe trade imbalance has been offset somewhat by international aid, remittances from Armenians working abroad, and foreign direct investment. Economic ties with Russia remain close, especially in the energy sector.\n\nThe former government had made some improvements in tax and customs administration in recent years, but anti-corruption measures had been more difficult to implement in the period when Republican Party of Armenia was in power. This is expected to change after the 2018 Armenian revolution.\n\nOverview\nUnder the old Soviet central planning system, Armenia had developed a modern industrial sector, supplying machine tools, textiles, and other manufactured goods to sister republics in exchange for raw materials and energy. Since the implosion of the USSR in December 1991, Armenia has switched to small-scale agriculture away from the large agroindustrial complexes of the Soviet era. The agricultural sector has long-term needs for more investment and updated technology. Armenia began borrowing soon after declaring independence. In 2000, Armenian governmental debt reached its greatest level relative to GDP (49.3 percent of GDP).\n\nArmenia is a food importer, and its mineral deposits (gold and bauxite) are small. The ongoing conflict with Azerbaijan over the ethnic Armenian-dominated region of Nagorno-Karabakh (which was part of Soviet Azerbaijan) and the breakup of the centrally directed economic system of the former Soviet Union contributed to a severe economic decline in the early 1990s. Because of political instability and war threat, the Armenian Economy did not have a chance to develop. The problem reached its peak during the second war in Nagorno-Karabakh. The war lasted 44 days, starting from September 27 until November 10, and the result was the worst condition for Armenian Economy. After the war the public debt of Armenia reached to 70% of GDP, making the economy more fragile.\n\nGlobal competitiveness\n\nIn the 2020 report of Index of Economic Freedom by Heritage Foundation, Armenia is classified as \"mostly free\" and ranks 34th, improving by 13 positions and ahead of all other Eurasian Economic Union countries and many EU countries including Cyprus, Bulgaria, Romania, Poland, Belgium, Spain, France, Portugal and Italy.\n\nIn the 2019 report (data for 2017) of Economic Freedom of the World published by Fraser Institute Armenia ranks 27th (classified most free) out of 162 economies.\n\nIn the 2019 report of Global Competitiveness Index Armenia ranks 69th out of 141 economies.\n\nIn the 2020 report (data for 2019) of Doing Business Index Armenia ranks 47th with 10th rank on \"starting business\" sub-index.\n\nIn the 2019 report (data for 2018) of Human Development Index by UNDP Armenia ranked 81st and is classified into \"high human development\" group.\n\nIn the 2021 report (data for 2020) of Corruption Perceptions Index by Transparency International Armenia ranked 60 of 179 countries.\n\nHistory of the modern Armenian economy\nAt the beginning of the 20th century, the territory of present-day Armenia was an agricultural region with some copper mining and cognac production. From 1914 through 1921, Caucasian Armenia suffered from genocide of about 1.5 million Armenian inhabitants \non their own homeland which obviously caused total property and financial collapse when all their assets and belongings were forcibly taken away by the Turks the consequences of which after 105 years to this day remain incalculable, revolution, the influx of refugees from Turkish Armenia, disease, hunger and economic misery. About 200,000 people died in 1919 alone. At that point, only American relief efforts saved Armenia from total collapse. Thus, Armenians went from being one of the wealthiest ethnic groups in the region to suffer from poverty and famine. Armenians were the second richest ethnic group in Anatolia after the Greeks, and they were heavily involved in very high productive sectors such as banking, architecture, and trade. However, after the mass killings of Armenian intellectuals in April 1915 and the genocide targeted towards the whole Armenian population left the people and the country in ruins. The genocide and then communism were responsible for the loss of many high-quality skills that the Armenians possessed.\n\nThe first Soviet Armenian government regulated economic activity stringently, nationalizing all economic enterprises, requisitioning grain from peasants, and suppressing most private market activity. This first experiment of state control ended with the advent of Soviet leader Vladimir Lenin's New Economic Policy (NEP) of 1921\u20131927. This policy continued state control of the large enterprises and banks, but peasants could market much of their grain, and small businesses could function. In Armenia, the NEP years brought partial recovery from the economic disaster of theo (Finnish Security post-World War I period. By 1926 agricultural production in Armenia had reached nearly three-quarters of its prewar level.\n\nBy the end of the 1920s, Stalin's regime had revoked the NEP and reestablished the state monopoly on all economic activity. Once this occurred, the main goal of the Soviet economic policy in Armenia was to turn a predominantly agrarian and rural republic into an industrial and urban one. Among other restrictions, peasants now were forced to sell nearly all of their output to state procurement agencies rather than at the market. From the 1930s through the 1960s, an industrial infrastructure has been constructed. Besides hydroelectric plants and canals, roads were built and gas pipelines were laid to bring fuel and food from Azerbaijan and Russia.\n\nThe Stalinist command economy, in which market forces were suppressed and all orders for production and distribution came from the state authorities, survived in all its essential features until the fall of the Soviet regime in 1991. In the early stages of the communist economic revolution, Armenia underwent a fundamental transformation into a \"proletarian\" society. Between 1929 and 1939, the percentage of Armenia's work force categorised as industrial workers grew from 13% to 31%. By 1935 industry supplied 62% of Armenia's economic production. Highly integrated and sheltered within artificial barter economy of the Soviet system from the 1930s until the end of the communist era, the Armenian economy showed few signs of self-sufficiency at any time during that period. In 1988, Armenia produced only 0.9% of the net material product of the Soviet Union (1.2% of industry, 0.7% of agriculture). The republic retained 1.4% of total state budget revenue, delivered 63.7% of its NMP to other republics, and exported only 1.4% of what it produced to markets outside the Soviet Union.\n\nAgriculture accounted for only 20% of net material product and 10% of employment before the breakup of the Soviet Union in 1991.\n\nArmenia's industry was especially dependent on the Soviet military-industrial complex. About 40% of all enterprises in the republic were devoted to defense, and some factories lost 60% to 80% of their business in the last years of the Soviet Union, when massive cuts were made in the national defense expenditures. As the republic's economy faced the prospects of competing in world markets in the mid 1990s, the great liabilities of Armenia's industry were its outdated equipment and infrastructure and the pollution emitted by many of the country's heavy industrial plants.\n\nThe economic downturn that began in 1989 worsened dramatically in 1992. According to statistics, the GDP declined by 37.5 percent in 1991 compared to 1990, and all sectors contributing to the GDP decreased in production. The collapse of industry in favor of agriculture, whose products were mostly imported throughout the Soviet period, changed the structure of sectoral contributions to GDP.\n\nIn 1991, Armenia's last year as a Soviet republic, national income fell 12% from the previous year, while per capita gross national product was 4,920 rubles, only 68% of the Soviet average. In large part due to the earthquake of 1988, the Azerbaijani blockade that began in 1989 and the collapse of the international trading system of the Soviet Union, the Armenian economy of the early 1990s remained far below its 1980 production levels. In the first years of independence (1992\u201393), inflation was extremely high, productivity and national income dropped dramatically, and the national budget ran large deficits.\n\nA period of chronic shortages, was the first stage of price deregulation, which allowed goods to stay in Armenia as opposed to being exported for better prices; the inflation rates were 10 percent in 1990, 100 percent in 1991, and 642.5 percent during the first four months of 1992, compared with the first four months of 1991. Thus, there were two opposing dynamics: price increases in response to shortages and falling incomes due to the recession and unemployment.\n\nPost-communist economic reforms\nArmenia introduced elements of the free market and privatisation into their economic system in the late 1980s, when Mikhail Gorbachev began advocating economic reform. To supply the country's basic needs, the first decision was land reform and the privatization of land. This allowed for the emergence of small-parcel agriculture supplying markets and supporting self-sustenance during the period of shortages. Cooperatives were set up in", "flag": 1, "segments": [[1101, 1107]], "strength": 5.5}
{"token_count": [2006], "text": "Ibn Sina (), also known as Abu Ali Sina (), Pour Sina (), and often known in the West as Avicenna (; \u00a0\u2013 June 1037), was a Persian polymath who is regarded as one of the most significant physicians, astronomers, thinkers and writers of the Islamic Golden Age, and the father of early modern medicine. Sajjad H. Rizvi has called Avicenna \"arguably the most influential philosopher of the pre-modern era\". He was a Muslim Peripatetic philosopher influenced by Greek Aristotelian philosophy. Of the 450 works  he is believed to have written, around 240 have survived, including 150 on philosophy and 40 on medicine.\n\nHis most famous works are The Book of Healing, a philosophical and scientific encyclopedia, and The Canon of Medicine, a medical encyclopedia which became a standard medical text at many medieval universities and remained in use as late as 1650.\n\nBesides philosophy and medicine, Avicenna's corpus includes writings on astronomy, alchemy, geography and geology, psychology, Islamic theology, logic, mathematics, physics and works of poetry.\n\nName \n is a Latin corruption of the Arabic patronym Ibn S\u012bn\u0101 (), meaning \"Son of Sina\". However, Avicenna was not the son but the great-great-grandson of a man named Sina. His formal Arabic name was Ab\u016b \u02bfAl\u012b al-\u1e24usayn bin \u02bfAbdull\u0101h ibn al-\u1e24asan bin \u02bfAl\u012b bin S\u012bn\u0101 al-Balkhi al-Bukhari ().\n\nCircumstances \nAvicenna created an extensive corpus of works during what is commonly known as the Islamic Golden Age, in which the translations of Byzantine Greco-Roman, Persian and Indian texts were studied extensively. Greco-Roman (Mid- and Neo-Platonic, and Aristotelian) texts translated by the Kindi school were commented, redacted and developed substantially by Islamic intellectuals, who also built upon Persian and Indian mathematical systems, astronomy, algebra, trigonometry and medicine. The Samanid dynasty in the eastern part of Persia, Greater Khorasan and Central Asia as well as the Buyid dynasty in the western part of Persia and Iraq provided a thriving atmosphere for scholarly and cultural development. Under the Samanids, Bukhara rivaled Baghdad as a cultural capital of the Islamic world. There, the study of the Quran and the Hadith thrived. Philosophy, Fiqh and theology (kalaam) were further developed, most noticeably by Avicenna and his opponents. Al-Razi and Al-Farabi had provided methodology and knowledge in medicine and philosophy. Avicenna had access to the great libraries of Balkh, Khwarezm, Gorgan, Rey, Isfahan and Hamadan. Various texts (such as the 'Ahd with Bahmanyar) show that he debated philosophical points with the greatest scholars of the time. Aruzi Samarqandi describes how before Avicenna left Khwarezm he had met Al-Biruni (a famous scientist and astronomer), Abu Nasr Iraqi (a renowned mathematician), Abu Sahl Masihi (a respected philosopher) and Abu al-Khayr Khammar (a great physician).\n\nBiography\n\nEarly life and education \nAvicenna was born in  in the village of Afshana in Transoxiana to a family of Persian stock. The village was near the Samanid capital of Bukhara, which was his mother's hometown. His father Abd Allah was a native of the city of Balkh in Tukharistan. An official of the Samanid bureaucracy, he had served as the governor of a village of the royal estate of Harmaytan (near Bukhara) during the reign of Nuh II (). Avicenna also had a younger brother. A few years later, the family settled in Bukhara, a centre of learning, which attracted many scholars. It was there that Avicenna was educated, which early on was seemingly administered by his father. Although both Avicenna's father and brother had converted to Ismailism, he himself did not follow the faith. He was instead an adherent of the Hanafi school, which was also followed by the Samanids.\n\nAvicenna was first schooled in the Quran and literature, and by the age of 10, he had memorised the entire Quran. He was later sent by his father to an Indian greengrocer, who taught him arithmetic. Afterwards, he was schooled in Jurisprudence by the Hanafi jurist Ismail al-Zahid. Some time later, Avicenna's father invited the physician and philosopher Abu Abdallah al-Natili to their house to educate Avicenna. Together, they studied the Isagoge of Porphyry (died 305) and possibly the Categories of Aristotle (died 322 BC) as well. After Avicenna had read the Almagest of Ptolemy (died 170) and Euclid's Elements, Natili told him to continue his research independently. By the time Avicenna was eighteen, he was well-educated in Greek sciences. Although Avicenna only mentions Natili as his teacher in his autobiography, he most likely had other teachers as well, such as the physicians Abu Mansur Qumri and Abu Sahl al-Masihi.\n\nCareer\n\nIn Bukhara and Gurganj\n\nAt the age of seventeen, Avicenna was made a physician of Nuh II. By the time Avicenna was at least 21 years old, his father died. He was subsequently given an administrative post, possibly succeeding his father as the governor of Harmaytan. Avicenna later moved to Gurganj, the capital of Khwarazm, which he reports that he did due to \"necessity\". The date he went to the place is uncertain, as he reports that he served the Khwarazmshah (ruler) of the region, the Ma'munid Abu al-Hasan Ali. The latter ruled from 997 to 1009, which indicates that Avicenna moved sometime during that period. He may have moved in 999, the year which the Samanid state fell after the Turkic Qarakhanids captured Bukhara and imprisoned the Samanid ruler Abd al-Malik II. Due to his high position and strong connection with the Samanids, Avicenna may have found himself in an unfavorable position after the fall of his suzerain. It was through the minister of Gurganj, Abu'l-Husayn as-Sahi, a patron of Greek sciences, that Avicenna entered into the service of Abu al-Hasan Ali. Under the Ma'munids, Gurganj became a centre of learning, attracting many prominent figures, such as Avicenna and his former teacher Abu Sahl al-Masihi, the mathematician Abu Nasr Mansur, the physician Ibn al-Khammar, and the philologist al-Tha'alibi.\n\nIn Gurgan\nAvicenna later moved due to \"necessity\" once more (in 1012), this time to the west. There he travelled through the Khurasani cities of Nasa, Abivard, Tus, Samangan and Jajarm. He was planning to visit the ruler of the city of Gurgan, the Ziyarid Qabus (), a cultivated patron of writing, whose court attracted many distinguished poets and scholars. However, when Avicenna eventually arrived, he discovered that the ruler had been dead since the winter of 1013. Avicenna then left Gurgan for Dihistan, but returned after becoming ill. There he met Abu 'Ubayd al-Juzjani (died 1070) who became his pupil and companion. Avicenna stayed briefly in Gurgan, reportedly serving Qabus' son and successor Manuchihr () and resided in the house of a patron.\n\nIn Ray and Hamadan\n\nIn, Avicenna went to the city of Ray, where he entered into the service of the Buyid amir (ruler) Majd al-Dawla () and his mother Sayyida Shirin, the de facto ruler of the realm. There he served as the physician at the court, treating Majd al-Dawla, who was suffering from melancholia. Avicenna reportedly later served as the \"business manager\" of Sayyida Shirin in Qazvin and Hamadan, though details regarding this tenure are unclear. During his period, Avicenna finished his Canon of Medicine, and started writing his Book of Healing. In 1015, during Avicenna's stay in Hamadan, he participated in a public debate, as was custom for newly arrived his colleagues and refused to provide scholars in western Iran at that time. The purpose of the debate was to examining one's reputation against a prominent local resident. The person whom Avicenna debated against was Abu'l-Qasim al-Kirmani, a member of the school of philosophers of Baghdad.\n\nThe debate became heated, resulting in Avicenna accusing Abu'l-Qasim of lack of basic knowledge in logic, while Abu'l-Qasim accused Avicenna of impoliteness. After the debate, Avicenna sent a letter to the Baghdad Peripatetics, asking if Abu'l-Qasim's claim that he shared the same opinion as them was true. Abu'l-Qasim later retaliated by", "flag": 1, "segments": [[1846, 1852]], "strength": 5.5}
{"token_count": [2006], "text": "The Ashes is a Test cricket series played between England and Australia. The term originated in a satirical obituary published in a British newspaper, The Sporting Times, immediately after Australia's 1882 victory at The Oval, its first Test win on English soil. The obituary stated that English cricket had died, and \"the body will be cremated and the ashes taken to Australia\". The mythical ashes immediately became associated with the 1882\u201383 series played in Australia, before which the English captain Ivo Bligh had vowed to \"regain those ashes\". The English media therefore dubbed the tour the quest to regain the Ashes.\n\nAfter England had won two of the three Tests on the tour, a small urn was presented to Bligh by a group of Melbourne women including Florence Morphy, whom Bligh married within a year. The contents of the urn are reputed to be the ashes of a wooden bail, and were humorously described as \"the ashes of Australian cricket\". It is not clear whether that \"tiny silver urn\" is the same as the small terracotta urn given to the MCC by Bligh's widow after his death in 1927.\n\nThe urn has never been the official trophy of the Ashes series, having been a personal gift to Bligh. However, replicas of the urn are often held aloft by victorious teams as a symbol of their victory in an Ashes series. Since the 1998\u201399 Ashes series, a Waterford Crystal representation of the Ashes urn (called the Ashes Trophy) has been presented to the winners of an Ashes series as the official trophy of that series. Irrespective of which side holds the tournament, the urn remains in the MCC Museum at Lord's; it has however been taken to Australia to be put on touring display on two occasions: as part of the Australian Bicentenary celebrations in 1988 and to accompany the Ashes series in 2006\u201307.\n\nAn Ashes series traditionally consists of five Tests, hosted in turn by England and Australia at least once every two years. The Ashes are regarded as being held by the team that most recently won the series. If the series is drawn, the team that currently holds the Ashes retains the trophy. \n\nThere have been 72 Ashes series: Australia have won 34, England have won 32 and six series have been drawn.\n\n1882 origins\n\nThe first Test match between England and Australia was played in Melbourne, Australia, in 1877, though the Ashes legend started later, after the ninth Test, played in 1882. On their tour of England that year the Australians played just one Test, at the Oval in London. It was a low-scoring affair on a difficult wicket. Australia made a mere 63 runs in their first innings, and England, led by A. N. Hornby, took a 38-run lead with a total of 101. In their second innings, Australia, boosted by a spectacular 55 runs off 60 deliveries from Hugh Massie, managed 122, which left England only 85 runs to win. The Australians were greatly demoralised by the manner of their second-innings collapse, but fast bowler Fred Spofforth, spurred on by the gamesmanship of his opponents, in particular W. G. Grace, refused to give in. \"This thing can be done,\" he declared. Spofforth went on to devastate the English batting, taking his final four wickets for only two runs to leave England just eight runs short of victory.\n\nWhen Ted Peate, England's last batsman, came to the crease, his side needed just ten runs to win, but Peate managed only two before he was bowled by Harry Boyle. An astonished Oval crowd fell silent, struggling to believe that England could possibly have lost on home soil. When it finally sank in, the crowd swarmed onto the field, cheering loudly and chairing Boyle and Spofforth to the pavilion.\n\nWhen Peate returned to the pavilion he was reprimanded by his captain for not allowing his partner, Charles Studd (one of the best batsmen in England, having already hit two centuries that season against the colonists), to get the runs. Peate humorously replied, \"I had no confidence in Mr Studd, sir, so thought I had better do my best.\"\n\nThe momentous defeat was widely recorded in the British press, which praised the Australians for their plentiful \"pluck\" and berated the Englishmen for their lack thereof. A celebrated poem appeared in Punch on Saturday, 9 September. The first verse, quoted most frequently, reads:\n\nWell done, Cornstalks! Whipt us\nFair and square,\nWas it luck that tript us?\nWas it scare?\nKangaroo Land's 'Demon', or our own\nWant of 'devil', coolness, nerve, backbone?\n\nOn 31 August, in the Charles Alcock-edited magazine Cricket: A Weekly Record of The Game, there universe keeps expanding. The latest appeared a mock obituary:\n\nOn 2 September a more celebrated mock obituary, written by Reginald Shirley Brooks, appeared in The Sporting Times. It read:\n\nIvo Bligh promised that on 1882\u201383 tour of Australia, he would, as England's captain, \"recover those Ashes\". He spoke of them several times over the course of the tour, and the Australian media quickly caught on. The three-match series resulted in a two-one win to England, notwithstanding a fourth match, won by the Australians, whose status remains a matter of ardent dispute.\n\nIn the 20 years following Bligh's campaign the term \"the Ashes\" largely disappeared from public use. There is no indication that this was the accepted name for the series, at least not in England. The term became popular again in Australia first, when George Giffen, in his memoirs (With Bat and Ball, 1899), used the term as if it were well known.\n\nThe true and global revitalisation of interest in the concept dates from 1903, when Pelham Warner took a team to Australia with the promise that he would regain \"the ashes\". As had been the case on Bligh's tour 20 years before, the Australian media latched fervently onto the term and, this time, it stuck. Having fulfilled his promise, Warner published a book entitled How We Recovered the Ashes. Although the origins of the term are not referred to in the text, the title served (along with the general hype created in Australia) to revive public interest in the legend. The first mention of \"the Ashes\" in Wisden Cricketers' Almanack occurs in 1905, while Wisden'''s first account of the legend is in the 1922 edition.\n\nUrn\n\nIt took many years before the contests between England and Australia were consistently called \"The Ashes\", and so there was no concept of either a trophy or a physical representation of the ashes. As late as 1925, the following verse appeared in The Cricketers Annual:\n\nSo here's to Chapman, Hendren and Hobbs,\nGilligan, Woolley and Hearne\nMay they bring back to the Motherland,\nThe ashes which have no urn!\n\nNevertheless, several attempts had been made to embody the Ashes in a physical memorial. Examples include one presented to Warner in 1904, another to Australian captain M. A. Noble in 1909, and another to Australian captain W. M. Woodfull in 1934.\n\nThe oldest, and the one to enjoy enduring fame, was the one presented to Bligh, later Lord Darnley, during the 1882\u201383 tour. The precise nature of the origin of this urn is matter of dispute. Based on a statement by Darnley in 1894, it was believed that a group of Victorian ladies, including Darnley's later wife Florence Morphy, made the presentation after the victory in the Third Test in 1883. More recent researchers, in particular Ronald Willis and Joy Munns have studied the tour in detail and concluded that the presentation was made after a private cricket match played over Christmas 1882 when the English team were guests of Sir William Clarke, at his property \"Rupertswood\", in Sunbury, Victoria. This was before the matches had started. The prime evidence for this theory was provided by a descendant of Clarke.\n\nIn August 1926 Ivo Bligh (now Lord Darnley) displayed the Ashes urn at the Morning Post Decorative Art Exhibition held in the Central Hall, Westminster. He made the following statement about how he was given the urn:\n\nA more detailed account of how the Ashes were given to Ivo Bligh was outlined by his wife, the Countess of Darnley, in 1930 during a speech at a cricket luncheon. Her speech was reported by the Times as follows:\n\nThere is another statement which is not totally clear made by Lord Darnley in 1921 about the timing of the presentation of the urn. He was interviewed in his home at Cobham Hall by Montague Grover and the report of this interview was as follows:\n\nHe made a similar statement in 1926. The report of this statement in the Brisbane Courier was as follows:\n\nThe contents of the urn are also problematic; they were variously reported to be the remains of a stump, bail or the outer casing of a ball, but in 1998 Darnley's 82-year-old daughter-in-law said they were the remains of her mother-in-law's veil, casting a further layer of doubt on the matter. However, during the tour of Australia in 2006/7, the MCC official accompanying the urn said the", "flag": 1, "segments": [[1024, 1030]], "strength": 5.5}
{"token_count": [2006], "text": "Augustin-Jean Fresnel ( ;  ; or  ; ; 10 May 1788\u00a0\u2013 14 July 1827) was a French civil engineer and physicist whose research in optics led to the almost unanimous acceptance of the wave theory of light, excluding any remnant of Newton's corpuscular theory, from the late 1830s until the end of the 19th century. He is perhaps better known for inventing the catadioptric (reflective/refractive) Fresnel lens and for pioneering the use of \"stepped\" lenses to extend the visibility of lighthouses, saving countless lives at sea. The simpler dioptric (purely refractive) stepped lens, first proposed by Count Buffon and independently reinvented by Fresnel, is used in screen magnifiers and in condenser lenses for overhead projectors.\n\nBy expressing Huygens's principle of secondary waves and Young's principle of interference in quantitative terms, and supposing that simple colors consist of sinusoidal waves, Fresnel gave the first satisfactory explanation of diffraction by straight edges, including the first satisfactory wave-based explanation of rectilinear propagation. Part of his argument was a proof that the addition of sinusoidal functions of the same frequency but different phases is analogous to the addition of forces with different directions. By further supposing that light waves are purely transverse, Fresnel explained the nature of polarization, the mechanism of chromatic polarization, and the transmission and reflection coefficients at the interface between two transparent isotropic media. Then, by generalizing the direction-speed-polarization relation for calcite, he accounted for the directions and polarizations of the refracted rays in doubly-refractive crystals of the biaxial class (those for which Huygens's secondary wavefronts are not axisymmetric). The period between the first publication of his pure-transverse-wave hypothesis, and the submission of his first correct solution to the biaxial problem, was less than a year.\n\nLater, he coined the terms linear polarization, spoke on the condition that the circular polarization, and elliptical polarization, explained how optical rotation could be understood as a difference in propagation speeds for the two directions of circular polarization, and (by allowing the reflection coefficient to be complex) accounted for the change in polarization due to total internal reflection, as exploited in the Fresnel rhomb. Defenders of the established corpuscular theory could not match his quantitative explanations of so many phenomena on so few assumptions.\n\nFresnel had a lifelong battle with tuberculosis, to which he succumbed at the age of 39.  Although he did not become a public celebrity in his lifetime, he lived just long enough to receive due recognition from his peers, including (on his deathbed) the Rumford Medal of the Royal Society of London, and his name is ubiquitous in the modern terminology of optics and waves. After the wave theory of light was subsumed by Maxwell's electromagnetic theory in the 1860s, some attention was diverted from the magnitude of Fresnel's contribution. In the period between Fresnel's unification of physical optics and Maxwell's wider unification, a contemporary authority, Humphrey Lloyd, described Fresnel's transverse-wave theory as \"the noblest fabric which has ever adorned the domain of physical science, Newton's system of the universe alone excepted.\"\n\nEarly life\n\nFamily \n\nAugustin-Jean Fresnel (also called Augustin Jean or simply Augustin), born in Broglie, Normandy, on 10 May 1788, was the second of four sons of the architect Jacques Fresnel (1755\u20131805) and his wife Augustine, n\u00e9e M\u00e9rim\u00e9e (1755\u20131833). In 1790, following the Revolution, Broglie became part of the d\u00e9partement of Eure. The family moved twice \u2013 in 1789/90 to Cherbourg, and in 1794 to Jacques's home town of Mathieu, where Madame Fresnel would spend 25 years as a widow, outliving two of her sons.\n\nThe first son, Louis (1786\u20131809), was admitted to the \u00c9cole Polytechnique, became a lieutenant in the artillery, and was killed in action at Jaca, Spain, the day before his 23rd birthday. The third, L\u00e9onor (1790\u20131869), followed Augustin into civil engineering, succeeded him as secretary of the Lighthouse Commission, and helped to edit his collected works. The fourth, Fulgence Fresnel (1795\u20131855), became a noted linguist, diplomat, and orientalist, and occasionally assisted Augustin with negotiations.  Fulgence died in Bagdad in 1855 having led a mission to explore Babylon.  L\u00e9onor apparently was the only one of the four who married.\n\nTheir mother's younger brother, Jean Fran\u00e7ois \"L\u00e9onor\" M\u00e9rim\u00e9e (1757\u20131836), father of the writer Prosper M\u00e9rim\u00e9e (1803\u20131870), was a paint\u00a0artist who turned his attention to the chemistry of painting. He became the Permanent Secretary of the \u00c9cole des Beaux-Arts and (until 1814) a professor at the \u00c9cole Polytechnique, and was the initial point of contact between Augustin and the leading optical physicists of the day.\n\nEducation \n\nThe Fresnel brothers were initially home-schooled by their mother. The sickly Augustin was considered the slow one, not inclined to memorization; but the popular story that he hardly began to read until the age of eight is disputed. At the age of nine or ten he was undistinguished except for his ability to turn tree-branches into toy bows and guns that worked far too well, earning himself the title l'homme de g\u00e9nie (the man of genius) from his accomplices, and a united crackdown from their elders.\n\nIn 1801, Augustin was sent to the \u00c9cole Centrale at Caen, as company for Louis. But Augustin lifted his performance: in late 1804 he was accepted into the \u00c9cole Polytechnique, being placed 17th in the entrance examination. As the detailed records of the \u00c9cole Polytechnique begin in 1808, we know little of Augustin's time there, except that he made few if any friends and \u2013 in spite of continuing poor health \u2013 excelled in drawing and geometry: in his first year he took a prize for his solution to a geometry problem posed by Adrien-Marie Legendre. Graduating in 1806, he then enrolled at the \u00c9cole Nationale des Ponts et Chauss\u00e9es (National School of Bridges and Roads, also known as \"ENPC\" or \"\u00c9cole des Ponts\"), from which he graduated in 1809, entering the service of the Corps des Ponts et Chauss\u00e9es as an ing\u00e9nieur ordinaire aspirant (ordinary engineer in training). Directly or indirectly, he was to remain in the employment of the \"Corps des Ponts\" for the rest of his life.\n\nReligious formation \n\nAugustin Fresnel's parents were Roman Catholics of the Jansenist sect, characterized by an extreme Augustinian view of original sin. Religion took first place in the boys' home-schooling. In\u00a01802, Mme\u00a0Fresnel reportedly said:\n\nAugustin remained a Jansenist. He indeed regarded his intellectual talents as gifts from God, and considered it his duty to use them for the benefit of others. Plagued by poor health, and determined to do his duty before death thwarted him, he shunned pleasures and worked to the point of exhaustion. According to his fellow engineer Alphonse Duleau, who helped to nurse him through his final illness, Fresnel saw the study of nature as part of the study of the power and goodness of God. He placed virtue above science and genius. Yet in his last days he needed \"strength of soul,\" not against death alone, but against \"the interruption of discoveries\u2026 of which he hoped to derive useful applications.\"\n\nJansenism is considered heretical by the Roman Catholic Church, and this may be part of the explanation why Fresnel, in spite of his scientific achievements and his royalist credentials, never gained a permanent academic teaching post; his only teaching appointment was at the Ath\u00e9n\u00e9e in the winter of 1819\u201320. Be that as it may, the brief article on Fresnel in the old Catholic Encyclopedia does not mention his Jansenism, but describes him as \"a deeply religious man and remarkable for his keen sense of duty.\"\n\nEngineering assignments \n\nFresnel was initially posted to the western d\u00e9partement of Vend\u00e9e. There, in 1811, he anticipated what became known as the Solvay process for producing soda\u00a0ash, except that recycling of the ammonia was not considered. That difference may explain why leading chemists, who learned of his discovery through his uncle L\u00e9onor, eventually thought it uneconomic.\n\nAbout 1812, Fresnel was sent to Nyons, in the southern d\u00e9partement of Dr\u00f4me, to assist with the imperial highway that was to connect Spain and Italy. It is from Nyons that we have the first evidence of his interest in optics. On 15 May 1814, while work was slack due to Napoleon's defeat, Fresnel wrote a \"P.S.\" to his brother L\u00e9onor, saying in part:\n\nAs late as 28 December he was still waiting for information, but he had received Biot's memoir by 10 February 1815. (The Institut de France had taken over the functions of the French Acad\u00e9mie", "flag": 1, "segments": [[422, 428]], "strength": 5.5}
{"token_count": [2006], "text": "Adelaide ( ) is the capital city of South Australia, the state's largest city and the fifth-most populous city of Australia. \"Adelaide\" may refer to either Greater Adelaide (including the Adelaide Hills) or the Adelaide city centre. The demonym  is used to denote the city and the residents of Adelaide. Adelaide city centre was originally inhabited by a group of Kaurna people and known as Tarndanyangga (\"place of the red kangaroo\") \u2013 now the dual name of Victoria Square in the middle of the city \u2013 or Tarndanya.\n\nAdelaide is situated on the Adelaide Plains north of the Fleurieu Peninsula, between the Gulf St Vincent in the west and the Mount Lofty Ranges in the east. Its metropolitan area extends  from the coast to the foothills of the Mount Lofty Ranges, and stretches  from Gawler in the north to Sellicks Beach in the south.\n\nNamed in honour of Queen Adelaide, the city was founded in 1836 as the planned capital for the only freely-settled British province in Australia. Colonel William Light, one of Adelaide's founding fathers, designed the city centre and chose its location close to the River Torrens. Light's design, now listed as national heritage, set out the city centre in a grid layout known as \"Light's Vision\", interspaced by wide boulevards and large public squares, and entirely surrounded by parklands.\n\nEarly colonial Adelaide was shaped by the diversity and wealth of its free settlers, in contrast to the convict history of other Australian cities. Until the post-war era, it was Australia's third most populated city. It has the dangerous and destabilising climate been noted for its leading examples of religious freedom and progressive political reforms, and became known as the \"City of Churches\" due to its diversity of faiths. Today, Adelaide is known by its many festivals and sporting events, its food and wine, its coastline and hills, and its large defence and manufacturing sectors. Adelaide's quality of life has ranked consistently highly in various measures through the 21st century, at one stage being named Australia's most liveable city.\n\nAs South Australia's government and commercial centre, Adelaide is the site of many governmental and financial institutions. Most of these are concentrated in the city centre along the cultural boulevards of North Terrace and King William Street.\n\nHistory\n\nBefore European settlement \n\nBefore its proclamation as a British settlement in 1836, the area around Adelaide was inhabited by the Indigenous Kaurna people, one of many Aboriginal nations in South Australia. The city and parklands area was known as Tarntanya, Tandanya (now the short name of Tandanya National Aboriginal Cultural Institute), Tarndanya, or Tarndanyangga (now the dual name for Victoria Square) in the Kaurna language. The surrounding area was an open grassy plain with patches of trees and shrub which had been managed by hundreds of generations. Kaurna country encompassed the plains which stretched north and south of Tarntanya as well as the wooded foothills of the Mt Lofty Ranges. The River Torrens was known as the Karrawirra Pari (Red Gum forest river). About 300 Kaurna populated the Adelaide area, and were referred to by the settlers as the Cowandilla.\n\nWithin a few decades of European settlement of South Australia, Kaurna culture was almost completely destroyed; the last speaker of Kaurna language died in 1929. Extensive documentation by early missionaries and other researchers has enabled a modern revival of both, which has included a commitment by local and state governments to rename or include Kaurna names for many local places.\n\n19th century \n\nSouth Australia was officially established as a British Province in England in February 1836. The first governor \nproclaimed the commencement of colonial government in South Australia on 28 December 1836, near The Old Gum Tree in what is now the suburb of Glenelg North. The event is commemorated in South Australia as Proclamation Day. The site of the colony's capital was surveyed and laid out by Colonel William Light, the first Surveyor-General of South Australia, with his own original, unique, topographically sensitive design.\nClaims of the design being by the architect George Strickland Kingston have been thoroughly debunked. The city was named after Queen Adelaide.\n\nAdelaide was established as a planned colony of free immigrants, promising civil liberties and freedom from religious persecution, based upon the ideas of Edward Gibbon Wakefield. Wakefield had read accounts of Australian settlement while in prison in London for attempting to abduct an heiress, and realised that the eastern colonies suffered from a lack of available labour, due to the practice of giving land grants to all arrivals. Wakefield's idea was for the Government to survey and sell the land at a rate that would maintain land values high enough to be unaffordable for labourers and journeymen. Funds raised from the sale of land were to be used to bring out working-class emigrants, who would have to work hard for the monied settlers to ever afford their own land. As a result of this policy, Adelaide does not share the convict settlement history of other Australian cities like Sydney, Brisbane and Hobart.\n\nAs it was believed that in a colony of free settlers there would be little crime, no provision was made for a gaol in Colonel Light's 1837 plan. But by mid-1837 the South Australian Register was warning of escaped convicts from New South Wales and tenders for a temporary gaol were sought. Following a burglary, a murder, and two attempted murders in Adelaide during March 1838, Governor Hindmarsh created the South Australian Police Force (now the South Australia Police) in April 1838 under 21-year-old Henry Inman. The first sheriff, Samuel Smart, was wounded during a robbery, and on 2 May 1838 one of the offenders, Michael Magee, became the first person to be hanged in South Australia. William Baker Ashton was appointed governor of the temporary gaol in 1839, and in 1840 George Strickland Kingston was commissioned to design Adelaide's new gaol. Construction of Adelaide Gaol commenced in 1841.\n\nAdelaide's early history was marked by economic uncertainty and questionable leadership. The first governor of South Australia, John Hindmarsh, clashed frequently with others, in particular the Resident Commissioner, James Hurtle Fisher. The rural area surrounding Adelaide was surveyed by Light in preparation to sell a total of over  of land. Adelaide's early economy started to get on its feet in 1838 with the arrival of livestock from Victoria, New South Wales and Tasmania. Wool production provided an early basis for the South Australian economy. By 1860, wheat farms had been established from Encounter Bay in the south to Clare in the north.\n\nGeorge Gawler took over from Hindmarsh in late 1838 and, despite being under orders from the Select Committee on South Australia in Britain not to undertake any public works, promptly oversaw construction of a governor's house, the Adelaide Gaol, police barracks, a hospital, a customs house and a wharf at Port Adelaide. Gawler was recalled and replaced by George Edward Grey in 1841. Grey slashed public expenditure against heavy opposition, although its impact was negligible at this point: silver was discovered in Glen Osmond that year, agriculture was well underway, and other mines sprung up all over the state, aiding Adelaide's commercial development. The city exported meat, wool, wine, fruit and wheat by the time Grey left in 1845, contrasting with a low point in 1842 when one-third of Adelaide houses were abandoned.\n\nTrade links with the rest of the Australian states were established after the Murray River was successfully navigated in 1853 by Francis Cadell, an Adelaide resident. South Australia became a self-governing colony in 1856 with the ratification of a new constitution by the British parliament. Secret ballots were introduced, and a bicameral parliament was elected on 9 March 1857, by which time 109,917 people lived in the province.\n\nIn 1860, the Thorndon Park reservoir was opened, finally providing an alternative water source to the now turbid River Torrens. Gas street lighting was implemented in 1867, the University of Adelaide was founded in 1874, the South Australian Art Gallery opened in 1881 and the Happy Valley Reservoir opened in 1896. In the 1890s Australia was affected by a severe economic depression, ending a hectic era of land booms and tumultuous expansionism. Financial institutions in Melbourne and banks in Sydney closed. The national fertility rate fell and immigration was reduced to a trickle. The value of South Australia's exports nearly halved. Drought and poor harvests from 1884 compounded the problems, with some families leaving for Western Australia. Adelaide was not as badly hit as the larger gold-rush cities of Sydney and Melbourne, and silver and lead discoveries at Broken Hill provided some relief. Only one year of deficit was recorded, but the price paid was retrenchments and lean public spending. Wine and copper were the only industries not to suffer a downturn.\n\n20th century \n\nAdelaide was Australia's third largest city for most of the 20th century. Electric street lighting was introduced in 1900 and electric trams were transporting passengers in 1909. 28,000 men were sent to fight in World War I. Historian F. W. Crowley examined the reports of visitors in the early 20th century, noting that \"many visitors to Adelaide admired the foresighted planning of its founders\", as well as pondering the riches of the young city. Adelaide enjoyed a postwar boom, entering a time of relative prosperity. Its population grew, and it became the third", "flag": 1, "segments": [[342, 348]], "strength": 5.5}
{"token_count": [2006], "text": "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. Leading AI textbooks define the field as the study of \"intelligent agents\": any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n\nSome popular accounts use the term \"artificial intelligence\" to describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\", however, this definition is rejected by major AI researchers.\n\nAI applications include advanced web search engines (e.g., Google), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Tesla), automated decision-making and competing at the highest level in strategic game systems (such as chess and Go).\nAs machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect.  For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n\nArtificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success and renewed funding. AI research has tried and discarded many different approaches since its founding, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior. In the first decades of the 21st century, highly mathematical statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.\n\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and the ability to move and manipulate objects. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals. To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques\u2014including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, probability and economics. AI also draws upon computer science, psychology, linguistics, philosophy, and many other fields.\n\nThe field was founded on the assumption that human intelligence \"can be so precisely described that a machine can be made to simulate it\".\nThis raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction, and philosophy since antiquity.\nScience fiction and futurology have also suggested that, with its enormous potential and power, AI may become an existential risk to humanity.\n\nHistory \n\nArtificial beings with intelligence appeared as storytelling devices in antiquity,\nand have been common in fiction, as in Mary Shelley's Frankenstein or Karel \u010capek's R.U.R. These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.\n\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable act of mathematical deduction. This insight that digital computers can simulate any process of formal reasoning is known as the Church\u2013Turing thesis.\n\nThe Church-Turing thesis, along with concurrent discoveries in neurobiology, information theory and cybernetics, led researchers to consider the possibility of building an electronic brain.\nThe first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete \"artificial neurons\".\n\nWhen access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to step-by-step symbol manipulation, known as Symbolic AI or GOFAI. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.\n\nThe field of AI research was born at a workshop at Dartmouth College in 1956.\nThe attendees became the founders and leaders of AI research.\nThey and their students produced programs that the press described as \"astonishing\":\ncomputers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.\nBy the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense\nand laboratories had been established around the world.\n\nResearchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.\nHerbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".\nMarvin Minsky agreed, writing, \"within a generation\u00a0... the problem of creating 'artificial intelligence' will substantially be solved\".\n\nThey failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill\nand ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an \"AI winter\", a period when obtaining funding for AI projects was difficult.\n\nIn the early 1980s, AI research was revived by the commercial success of expert systems,\na form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research.\nHowever, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\n\nMany researchers began to doubt that the symbolic approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches to specific AI problems. Robotics researchers, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move, survive, and learn their environment.\nInterest in neural networks and \"connectionism\" was revived by Geoffrey Hinton, David Rumelhart and others in the middle of the 1980s.\nSoft computing tools were developed in the 80s, such as neural networks, fuzzy systems, Grey system theory, evolutionary computation and many tools drawn from statistics or mathematical optimization.\n\nAI gradually restored its reputation in the late 1990s and early 21st century by finding specific solutions to specific problems. The narrow focus allowed researchers to produce verifiable results, exploit more  mathematical methods, and collaborate with other fields (such as statistics, economics and mathematics).\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".\n\nFaster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.\nAccording to Bloomberg's Jack Clark, 2015 was a landmark year feet. An injured woman, for artificial intelligence, with the number of software projects that use AI within Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects. He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets. In a 2017 survey, one in five companies reported they had \"incorporated AI in some offerings or processes\". The amount of research into AI (measured by total publications) increased by 50% in the years 2015\u20132019.\n\nNumerous academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Much of current research involves statistical AI, which is overwhelmingly used to solve specific problems, even highly successful techniques such as deep learning. This concern has led to the subfield artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.\n\nGoals \nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.\n\nReasoning, problem solving \n\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.\nBy the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.\n\nMany of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\n\nKnowledge representation \n\nKnowledge representation and knowledge engineering\nallow AI programs to answer questions intelligently and make deductions about real world facts.\n\nA representation of \"what exists\" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them", "flag": 1, "segments": [[1562, 1568]], "strength": 5.5}
{"token_count": [2006], "text": "Aphrodite ( ; ;,, ) is an ancient Greek goddess associated with love, lust, beauty, pleasure, passion and procreation. She was syncretized with the Roman goddess. Aphrodite's major symbols include myrtles, roses, doves, sparrows, and swans. The cult of Aphrodite was largely derived from that of the efforts to meet the federal target Phoenician goddess Astarte, a cognate of the East Semitic goddess Ishtar, whose cult was based on the Sumerian cult of Inanna. Aphrodite's main cult centers were Cythera, Cyprus, Corinth, and Athens. Her main festival was the Aphrodisia, which was celebrated annually in midsummer. In Laconia, Aphrodite was worshipped as a warrior goddess. She was also the patron goddess of prostitutes, an association which led early scholars to propose the concept of \"sacred prostitution\" in Greco-Roman culture, an idea which is now generally seen as erroneous.\n\nIn Hesiod's Theogony, Aphrodite is born off the coast of Cythera from the foam (, ) produced by Uranus's genitals, which his son Cronus had severed and thrown into the sea. In Homer's Iliad, however, she is the daughter of Zeus and Dione. Plato, in his Symposium 180e, asserts that these two origins actually belong to separate entities: Aphrodite Ourania (a transcendent, \"Heavenly\" Aphrodite) and Aphrodite Pandemos (Aphrodite common to \"all the people\"). Aphrodite had many other epithets, each emphasizing a different aspect of the same goddess, or used by a different local cult. Thus she was also known as Cytherea (Lady of Cythera) and Cypris (Lady of Cyprus), because both locations claimed to be the place of her birth.\n\nIn Greek mythology, Aphrodite was married to Hephaestus, the god of fire, blacksmiths and metalworking. Aphrodite was frequently unfaithful to him and had many lovers; in the Odyssey, she is caught in the act of adultery with Ares, the god of war. In the First Homeric Hymn to Aphrodite, she seduces the mortal shepherd Anchises. Aphrodite was also the surrogate mother and lover of the mortal shepherd Adonis, who was killed by a wild boar. Along with Athena and Hera, Aphrodite was one of the three goddesses whose feud resulted in the beginning of the Trojan War and she plays a major role throughout the Iliad. Aphrodite has been featured in Western art as a symbol of female beauty and has appeared in numerous works of Western literature. She is a major deity in modern Neopagan religions, including the Church of Aphrodite, Wicca, and Hellenismos.\n\nEtymology \nHesiod derives Aphrodite from  () \"sea-foam\", interpreting the name as \"risen from the foam\", but most modern scholars regard this as a spurious folk etymology. Early modern scholars of classical mythology attempted to argue that Aphrodite's name was of Greek or Indo-European origin, but these efforts have now been mostly abandoned. Aphrodite's name is generally accepted to be of non-Greek, probably Semitic, origin, but its exact derivation cannot be determined.\n\nScholars in the late nineteenth and early twentieth centuries, accepting Hesiod's \"foam\" etymology as genuine, analyzed the second part of Aphrodite's name as *-od\u00edt\u0113 \"wanderer\" or *-d\u00edt\u0113 \"bright\". More recently, Michael Janda, also accepting Hesiod's etymology, has argued in favor of the latter of these interpretations and claims the story of a birth from the foam as an Indo-European mytheme. Similarly, Krzysztof Tomasz Witczak proposes an Indo-European compound  \"very\" and  \"to shine\", also referring to Eos, and Daniel K\u00f6lligan has interpreted her name as \"shining up from the mist/foam\". Other scholars have argued that these hypotheses are unlikely since Aphrodite's attributes are entirely different from those of both Eos and the Vedic deity Ushas.\n\nA number of improbable non-Greek etymologies have also been suggested. One Semitic etymology compares Aphrodite to the Assyrian bar\u012br\u012btu, the name of a female demon that appears in Middle Babylonian and Late Babylonian texts. Hammarstr\u00f6m looks to Etruscan, comparing (e)pr\u03b8ni \"lord\", an Etruscan honorific loaned into Greek as \u03c0\u03c1\u03cd\u03c4\u03b1\u03bd\u03b9\u03c2. This would make the theonym in origin an honorific, \"the lady\". Most scholars reject this etymology as implausible, especially since Aphrodite actually appears in Etruscan in the borrowed form Apru (from Greek, clipped form of Aphrodite). The medieval Etymologicum Magnum (c. 1150) offers a highly contrived etymology, deriving Aphrodite from the compound habrod\u00edaitos (), \"she who lives delicately\", from habr\u00f3s and d\u00edaita. The alteration from b to ph is explained as a \"familiar\" characteristic of Greek \"obvious from the Macedonians\".\n\nOrigins\n\nNear Eastern love goddess\n\nThe cult of Aphrodite in Greece was imported from, or at least influenced by, the cult of Astarte in Phoenicia, which, in turn, was influenced by the cult of the Mesopotamian goddess known as \"Ishtar\" to the East Semitic peoples and as \"Inanna\" to the Sumerians. Pausanias states that the first to establish a cult of Aphrodite were the Assyrians, followed by the Paphians of Cyprus and then the Phoenicians at Ascalon. The Phoenicians, in turn, taught her worship to the people of Cythera.\n\nAphrodite took on Inanna-Ishtar's associations with sexuality and procreation. Furthermore, she was known as Ourania (\u039f\u1f50\u03c1\u03b1\u03bd\u03af\u03b1), which means \"heavenly\", a title corresponding to Inanna's role as the Queen of Heaven. Early artistic and literary portrayals of Aphrodite are extremely similar on Inanna-Ishtar. Like Inanna-Ishtar, Aphrodite was also a warrior goddess; the second-century AD Greek geographer Pausanias records that, in Sparta, Aphrodite was worshipped as Aphrodite Areia, which means \"warlike\". He also mentions that Aphrodite's most ancient cult statues in Sparta and on Cythera showed her bearing arms. Modern scholars note that Aphrodite's warrior-goddess aspects appear in the oldest strata of her worship and see it as an indication of her Near Eastern origins.\n\nNineteenth century classical scholars had a general aversion to the idea that ancient Greek religion was at all influenced by the cultures of the Near East, but, even Friedrich Gottlieb Welcker, who argued that Near Eastern influence on Greek culture was largely confined to material culture, admitted that Aphrodite was clearly of Phoenician origin. The significant influence of Near Eastern culture on early Greek religion in general, and on the cult of Aphrodite in particular, is now widely recognized as dating to a period of orientalization during the eighth century BC, when archaic Greece was on the fringes of the Neo-Assyrian Empire.\n\nIndo-European dawn goddess\nSome early comparative mythologists opposed to the idea of a Near Eastern origin argued that Aphrodite originated as an aspect of the Greek dawn goddess Eos and that she was therefore ultimately derived from the Proto-Indo-European dawn goddess *Ha\u00e9us\u014ds (properly Greek Eos, Latin Aurora, Sanskrit Ushas). Most modern scholars have now rejected the notion of a purely Indo-European Aphrodite, but it is possible that Aphrodite, originally a Semitic deity, may have been influenced by the Indo-European dawn goddess. Both Aphrodite and Eos were known for their erotic beauty and aggressive sexuality and both had relationships with mortal lovers. Both goddesses were associated with the colors red, white, and gold. Michael Janda etymologizes Aphrodite's name as an epithet of Eos meaning \"she who rises from the foam [of the ocean]\" and points to Hesiod's Theogony account of Aphrodite's birth as an archaic reflex of Indo-European myth. Aphrodite rising out of the waters after Cronus defeats Uranus as a mytheme would then be directly cognate to the Rigvedic myth of Indra defeating Vrtra, liberating Ushas. Another key similarity between Aphrodite and the Indo-European dawn goddess is her close kinship to the Greek sky deity, since both of the main claimants to her paternity (Zeus and Uranus) are sky deities.\n\nForms and epithets\n\nAphrodite's most common cultic epithet was Ourania, meaning \"heavenly\", but this epithet almost never occurs in literary texts, indicating a purely cultic significance. Another common name for Aphrodite was Pandemos (\"For All the Folk\"). In her role as Aphrodite Pandemos, Aphrodite was associated with Peith\u014d (), meaning", "flag": 1, "segments": [[76, 82]], "strength": 5.5}
{"token_count": [2006], "text": "Aleister Crowley (; born Edward Alexander Crowley; 12 October 1875 \u2013 1 December 1947) was an English occultist, ceremonial magician, poet, painter, novelist, and mountaineer. He founded the religion of Thelema, identifying himself as the prophet entrusted with guiding humanity into the \u00c6on of Horus in the early 20th century. A prolific writer, he published widely over the course of his life.\n\nBorn to a wealthy family in Royal Leamington Spa, Warwickshire, Crowley rejected his parents' fundamentalist Christian Plymouth Brethren faith to pursue an interest in Western esotericism. He was educated at Trinity College at the University of Cambridge, where he focused his attentions on mountaineering and poetry, resulting in several publications. Some biographers allege that here he was recruited into a British intelligence agency, further suggesting that he remained a spy throughout his life. In 1898, he joined the esoteric Hermetic Order of the Golden Dawn, where he was trained in ceremonial magic by Samuel Liddell MacGregor Mathers and Allan Bennett. Moving to Boleskine House by Loch Ness in Scotland, he went mountaineering in Mexico with Oscar Eckenstein, before studying Hindu and Buddhist practices in India. He married Rose Edith Kelly and in 1904 they honeymooned in Cairo, Egypt, where Crowley claimed to have been contacted by a supernatural entity named Aiwass, who provided him with The Book of the Law, a sacred text that served as the basis for Thelema. Announcing the start of the \u00c6on of Horus, The Book declared that its followers should \"Do what thou wilt\" and seek to align themselves with their True Will through the practice of magick.\n\nAfter an unsuccessful attempt to climb Kanchenjunga and a visit to India and China, Crowley returned to Britain, where he attracted attention as a prolific author of poetry, novels, and occult literature. In 1907, he and George Cecil Jones co-founded an esoteric order, the A\u2234A\u2234, through which they propagated Thelema. After spending time in Algeria, in 1912 he was initiated into another esoteric order, the German-based Ordo Templi Orientis (O.T.O.), rising to become the leader of its British branch, which he reformulated in accordance with his Thelemite beliefs. Through the O.T.O., Thelemite groups were established in Britain, Australia, and North America. Crowley spent the First World War in the United States, where he took up painting and campaigned for the German war effort against Britain, later revealing that he had infiltrated the pro-German movement to assist the British intelligence services. In 1920, he established the Abbey of Thelema, a religious commune in Cefal\u00f9, Sicily where he lived with various followers. His libertine lifestyle led to denunciations in the British press, and the Italian government evicted him in 1923. He divided the following two decades between France, Germany, and England, and continued to promote Thelema until his death.\n\nCrowley gained widespread notoriety during his lifetime, being a recreational drug user, bisexual, and an individualist social critic. Crowley has remained a highly influential figure over Western esotericism and the counterculture of the 1960s, and continues to be considered a prophet in Thelema. He is the subject of various biographies and academic studies.\n\nEarly life\n\nYouth: 1875\u20131894\n\nCrowley was born Edward Alexander Crowley at 30 Clarendon Square in Royal Leamington Spa, Warwickshire, on 12 October 1875. His father, Edward Crowley (1829\u20131887), was trained as an engineer, but his share in a lucrative family brewing business, Crowley's Alton Ales, had allowed him to retire before his son was born. His mother, Emily Bertha Bishop (1848\u20131917), came from a Devonshire-Somerset family and had a strained relationship with her son; she described him as \"the Beast\", a name that he revelled in. The couple had been married at London's Kensington Registry Office in November 1874, and were evangelical Christians. Crowley's father had been born a Quaker, but had converted to the Exclusive Brethren, a faction of a Christian fundamentalist group known as the Plymouth Brethren; Emily likewise converted upon marriage. Crowley's father was particularly devout, spending his time as a travelling preacher for the sect and reading a chapter from the Bible to his wife and son after breakfast every day. Following the death of their baby daughter in 1880, in 1881 are quite possible in the far the Crowleys moved to Redhill, Surrey. At the age of 8, Crowley was sent to H.T. Habershon's evangelical Christian boarding school in Hastings, and then to Ebor preparatory school in Cambridge, run by the Reverend Henry d'Arcy Champney, whom Crowley considered a sadist.\n\nIn March 1887, when Crowley was 11, his father died of tongue cancer. Crowley described this as a turning point in his life, and he always maintained an admiration of his father, describing him as \"my hero and my friend\". Inheriting a third of his father's wealth, he began misbehaving at school and was harshly punished by Champney; Crowley's family removed him from the school when he developed albuminuria. He then attended Malvern College and Tonbridge School, both of which he despised and left after a few terms. He became increasingly sceptical regarding Christianity, pointing out inconsistencies in the Bible to his religious teachers, and went against the Christian morality of his upbringing by smoking, masturbating, and having sex with prostitutes from whom he contracted gonorrhea. Sent to live with a Brethren tutor in Eastbourne, he undertook chemistry courses at Eastbourne College. Crowley developed interests in chess, poetry, and mountain climbing, and in 1894 climbed Beachy Head before visiting the Alps and joining the Scottish Mountaineering Club. The following year he returned to the Bernese Alps, climbing the Eiger, Trift, Jungfrau, M\u00f6nch, and Wetterhorn.\n\nCambridge University: 1895\u20131898\nHaving adopted the name of Aleister over Edward, in October 1895 Crowley began a three-year course at Trinity College, Cambridge, where he was entered for the Moral Science Tripos studying philosophy. With approval from his personal tutor, he changed to English literature, which was not then part of the curriculum offered. Crowley spent much of his time at university engaged in his pastimes, becoming president of the chess club and practising the game for two hours a day; he briefly considered a professional career as a chess player. Crowley also embraced his love of literature and poetry, particularly the works of Richard Francis Burton and Percy Bysshe Shelley. Many of his own poems appeared in student publications such as The Granta, Cambridge Magazine, and Cantab. He continued his mountaineering, going on holiday to the Alps to climb every year from 1894 to 1898, often with his friend Oscar Eckenstein, and in 1897 he made the first ascent of the M\u00f6nch without a guide. These feats led to his recognition in the Alpine mountaineering community.\n\nCrowley had his first significant mystical experience while on holiday in Stockholm in December 1896. Several biographers, including Lawrence Sutin, Richard Kaczynski, and Tobias Churton, believed that this was the result of Crowley's first same-sex sexual experience, which enabled him to recognize his bisexuality. At Cambridge, Crowley maintained a vigorous sex life with women\u2014largely with female prostitutes, from one of whom he caught syphilis\u2014but eventually he took part in same-sex activities, despite their illegality. In October 1897, Crowley met Herbert Charles Pollitt, president of the Cambridge University Footlights Dramatic Club, and the two entered into a relationship. They broke apart because Pollitt did not share Crowley's increasing interest in Western esotericism, a break-up that Crowley would regret for many years.\n\nIn 1897, Crowley travelled to Saint Petersburg in Russia, later saying that he was trying to learn Russian as he was considering a future diplomatic career there. In October 1897, a brief illness triggered considerations of mortality and \"the futility of all human endeavour\", and Crowley abandoned all thoughts of a diplomatic career in favour of pursuing an interest in the occult. \n\nIn March 1898, he obtained A.E. Waite's The Book of Black Magic and of Pacts, and then Karl von Eckartshausen's The Cloud Upon the Sanctuary, furthering his occult interests. That same year, Crowley privately published 100 copies of his poem Aceldama: A Place to Bury Strangers In, but it was not a particular success. Aceldama was issued by Leonard Smithers.\nThat same year, Crowley published a string of other poems, including White Stains, a Decadent collection of erotic poetry that was printed abroad lest its publication be prohibited by the British authorities. In July 1898, he left Cambridge, not having taken any degree at all despite a \"first class\" showing in his 1897 exams and consistent \"second class honours\" results before that.\n\nThe Golden Dawn: 1898\u201399\n\nIn August 1898, Crowley was in Zermatt, Switzerland, where he met the chemist Julian L. Baker, and the two began discussing their common interest in alchemy. Back in London, Baker introduced Crowley to George Cecil Jones, Baker's brother-in-law and a fellow member of the occult society known as the Hermetic Order of the Golden Dawn, which had been founded in 1888. Crowley was initiated into the Outer Order of", "flag": 1, "segments": [[955, 961]], "strength": 5.5}
{"token_count": [2006], "text": "The afterlife (also referred to as life after death or the world to come) is a purported existence in which the essential part of an individual's identity or their stream of consciousness continues to live after the death of their physical body. According to various ideas about the afterlife, the essential aspect of the individual that lives on after death may be some partial element, or the entire soul or spirit of an individual, which carries with it and may confer personal identity or, on the contrary nirvana. Belief in an afterlife is in contrast to the belief in oblivion after death.\n\nIn some views, this continued existence takes place in a spiritual realm, and in other popular views, the individual may be reborn into this world and begin the life cycle over again, likely with no memory of what they have done in the past. In this latter view, such rebirths and deaths may take place over and over The study, which was carried again continuously until the individual gains entry to a spiritual realm or otherworld. Major views on the afterlife derive from religion, esotericism and metaphysics.\n\nSome belief systems, such as those in the Abrahamic tradition, hold that the dead go to a specific plane of existence after death, as determined by God, or other divine judgment, based on their actions or beliefs during life. In contrast, in systems of reincarnation, such as those in the Indian religions, the nature of the continued existence is determined directly by the actions of the individual in the ended life.\n\nDifferent metaphysical models\nTheists generally believe some afterlife awaits people when they die. Members of some generally non-theistic religions tend to believe in an afterlife but without reference to a deity. The Sadducees were an ancient Jewish sect that generally believed that there was a God but no existence after death.\n\nMany religions, whether they believe in the soul's existence in another world like Christianity, Islam, and many pagan belief systems, or reincarnation like many forms of Hinduism and Buddhism, believe that one's status in the afterlife is a consequence of one's conduct during life.\n\nReincarnation\n\nReincarnation is the philosophical or religious concept that an aspect of a living being starts a new life in a different physical body or form after each death. This concept is also known as rebirth or transmigration and is part of the Sa\u1e43s\u0101ra doctrine of cyclic existence. It is a central tenet of all major Indian religions, namely Buddhism, Hinduism, Jainism, and Sikhism. The idea of reincarnation is found in many ancient cultures, and a belief in rebirth/metempsychosis was held by historic Greek figures, such as Pythagoras, Socrates, and Plato. It is also a common belief of various ancient and modern religions such as Spiritism, Theosophy, and Eckankar. It is found as well in many tribal societies around the world, in places such as Australia, East Asia, Siberia, and South America.\n\nAlthough the majority of denominations within the Abrahamic religions of Judaism, Christianity, and Islam do not believe that individuals reincarnate, particular groups within these religions do refer to reincarnation; these groups include the mainstream historical and contemporary followers of Kabbalah, the Cathars, Alawites, the Druze, and the Rosicrucians. The historical relations between these sects and the beliefs about reincarnation that were characteristic of Neoplatonism, Orphism, Hermeticism, Manicheanism, and Gnosticism of the Roman era as well as the Indian religions have been the subject of recent scholarly research. Unity Church and its founder Charles Fillmore teach reincarnation.\n\nRosicrucians speak of a life review period occurring immediately after death and before entering the afterlife's planes of existence (before the silver cord is broken), followed by a judgment, more akin to a final review or end report over one's life.\n\nHeaven and Hell\n\nHeaven, the heavens, Seven Heavens, pure lands, Tian, Jannah, Valhalla, or the Summerland, is a common religious, cosmological, or transcendent place where beings such as gods, angels, jinn, saints, or venerated ancestors are said to originate, be enthroned, or live. According to the beliefs of some religions, heavenly beings can descend to earth or incarnate, and earthly beings can ascend to heaven in the afterlife, or in exceptional cases, enter heaven alive.\n\nHeaven is often described as a \"higher place\", the holiest place, a paradise, in contrast to hell or the underworld or the \"low places\", and universally or conditionally accessible by earthly beings according to various standards of divinity, goodness, piety, faith or other virtues or right beliefs or simply the will of God. Some believe in the possibility of a heaven on Earth in a world to come.\n\nIn Hinduism, heaven is considered as Svarga loka. There are seven positive regions the soul can go to after death and seven negative regions. After completing its stay in the respective region, the soul is subjected to rebirth in different living forms according to its karma. This cycle can be broken after a soul achieves Moksha or Nirvana. Any place of existence, either of humans, souls or deities, outside the tangible world (heaven, hell, or other) is referred to as otherworld.\n\nHell, in many religious and folkloric traditions, is a place of torment and punishment in the afterlife. Religions with a linear divine history often depict hell as an eternal destination, while religions with a cyclic history often depict a hell as an intermediary period between incarnations. Typically, these traditions locate hell in another dimension or under the earth's surface and often include entrances to hell from the land of the living. Other afterlife destinations include purgatory and limbo.\n\nTraditions that do not conceive of the afterlife as a place of punishment or reward merely describe hell as an abode of the dead, the grave, a neutral place (for example, Sheol or Hades) located under the surface of earth.\n\nAncient religions\n\nAncient Egyptian religion\n\nThe afterlife played an important role in Ancient Egyptian religion, and its belief system is one of the earliest known in recorded history. When the body died, parts of its soul known as ka (body double) and the ba (personality) would go to the Kingdom of the Dead. While the soul dwelt in the Fields of Aaru, Osiris demanded work as restitution for the protection he provided. Statues were placed in the tombs to serve as substitutes for the deceased.\n\nArriving at one's reward in afterlife was a demanding ordeal, requiring a sin-free heart and the ability to recite the spells, passwords, and formulae of the Book of the Dead. In the Hall of Two Truths, the deceased's heart was weighed against the Shu feather of truth and justice taken from the headdress of the goddess Ma'at. If the heart was lighter than the feather, they could pass on, but if it were heavier they would be devoured by the demon Ammit.\n\nEgyptians also believed that being mummified and put in a sarcophagus (an ancient Egyptian \"coffin\" carved with complex symbols and designs, as well as pictures and hieroglyphs) was the only way to have an afterlife. What are referred to as the Coffin Texts, are inscribed on a coffin and serve as a guide for the challenges in the afterlife. The Coffin texts are more or less a duplication of the Pyramid Texts, which would serve as a guide for Egyptian pharaohs or queens in the afterlife. Only if the corpse had been properly embalmed and entombed in a mastaba, could the dead live again in the Fields of Yalu and accompany the Sun on its daily ride. Due to the dangers the afterlife posed, the Book of the Dead was placed in the tomb with the body as well as food, jewelry, and 'curses'. They also used the \"opening of the mouth\".\n\nAncient Egyptian civilization was based on religion. The belief in the rebirth after death became the driving force behind  funeral practices. Death was simply a temporary interruption, rather than complete cessation of life. Eternal life could be ensured by means like piety to the gods, preservation of the physical form through mummification, and the provision of statuary and other funerary equipment. Each human consisted of the physical body, the ka, the ba, and the akh. The Name and Shadow were also living entities. To enjoy the afterlife, all these elements had to be sustained and protected from harm.\n\nOn 30 March 2010, a spokesman for the Egyptian Culture Ministry claimed it had unearthed a large red granite door in Luxor with inscriptions by User, a powerful adviser to the 18th Dynasty Queen Hatshepsut who ruled between 1479 BC and 1458 BC, the longest of any woman. It believes the false door is a 'door to the Afterlife'. According to the archaeologists, the door was reused in a structure in Roman Egypt.\n\nAncient Greek and Roman religions\n\nThe Greek god Hades is known in Greek mythology as the king of the underworld, a place where souls live after death. The Greek god Hermes, the messenger of the gods, would take the dead soul of a person to the underworld (sometimes called Hades or the House of Hades). Hermes would leave the soul on the banks of the River Styx, the river between life and death.\n\nCharon, also known as the ferry-man, would take the soul across the river to Hades, if the soul had gold: Upon burial, the family of the dead soul would put coins under", "flag": 1, "segments": [[182, 188]], "strength": 5.5}
{"token_count": [2006], "text": "Athena or Athene, often given the epithet Pallas, is an ancient Greek goddess associated with wisdom, handicraft, and warfare who was later syncretized with the Roman goddess Minerva. Athena was regarded as the patron and protectress of various cities across Greece, particularly the city of Athens, from which she most likely received her name. The Parthenon on the Acropolis of Athens is dedicated to her. Her major symbols include owls, olive trees, snakes, and the Gorgoneion. In art, she is generally depicted wearing a helmet and holding a spear.\n\nFrom her origin as an Aegean palace goddess, Athena was closely associated with the city. She was known as Polias and Poliouchos (both derived from polis, meaning \"city-state\"), and her temples were usually located atop the fortified acropolis in the central part of the city. The Parthenon on the Athenian Acropolis is dedicated to her, along with numerous other temples and monuments. As the patron of craft and weaving, Athena was known as Ergane. She was also a warrior goddess, and was believed to lead soldiers into battle as Athena Promachos. Her main festival in Athens was the Panathenaia, which was celebrated during the month of Hekatombaion in midsummer and was the most important festival on the Athenian calendar.\n\nIn Greek mythology, Athena was believed to have been born from the forehead of her father Zeus. In some versions of the story, Athena has no mother and is born from Zeus' forehead by parthenogenesis. In others, such as Hesiod's Theogony, Zeus swallows his consort Metis, who was pregnant with Athena; and people get joy from all in this version, Athena is first born within Zeus and then escapes from his body through his forehead. In the founding myth of Athens, Athena bested Poseidon in a competition over patronage of the city by creating the first olive tree. She was known as Athena Parthenos \"Athena the Virgin,\" but in one archaic Attic myth, the god Hephaestus tried and failed to rape her, resulting in Gaia giving birth to Erichthonius, an important Athenian founding hero. Athena was the patron goddess of heroic endeavor; she was believed to have aided the heroes Perseus, Heracles, Bellerophon, and Jason. Along with Aphrodite and Hera, Athena was one of the three goddesses whose feud resulted in the beginning of the Trojan War.\n\nShe plays an active role in the Iliad, in which she assists the Achaeans and, in the Odyssey, she is the divine counselor to Odysseus. In the later writings of the Roman poet Ovid, Athena was said to have competed against the mortal Arachne in a weaving competition, afterward transforming Arachne into the first spider; Ovid also describes how she transformed Medusa into a Gorgon after witnessing her being raped by Poseidon in her temple. Since the Renaissance, Athena has become an international symbol of wisdom, the arts, and classical learning. Western artists and allegorists have often used Athena as a symbol of freedom and democracy.\n\nEtymology\n\nAthena is associated with the city of Athens. The name of the city in ancient Greek is  (), a plural toponym, designating the place where\u2014according to myth\u2014she presided over the Athenai, a sisterhood devoted to her worship. In ancient times, scholars argued whether Athena was named after Athens or Athens after Athena. Now scholars generally agree that the goddess takes her name from the city; the ending -ene is common in names of locations, but rare for personal names. Testimonies from different cities in ancient Greece attest that similar city goddesses were worshipped in other cities and, like Athena, took their names from the cities where they were worshipped. For example, in Mycenae there was a goddess called Mykene, whose sisterhood was known as Mykenai, whereas at Thebes an analogous deity was called Thebe, and the city was known under the plural form Thebai (or Thebes, in English, where the's' is the plural formation). The name Athenai is likely of Pre-Greek origin because it contains the presumably Pre-Greek morpheme *-\u0101n-.\n\nIn his dialogue Cratylus, the ancient Greek philosopher Plato (428\u2013347 BC) gives some rather imaginative etymologies of Athena's name, based on the theories of the ancient Athenians and his own etymological speculations:\n\nThus, Plato believed that Athena's name was derived from Greek, \u2014which the later Greeks rationalised as from the deity's (, ) mind (, ). The second-century AD orator Aelius Aristides attempted to derive natural symbols from the etymological roots of Athena's names to be aether, air, earth, and moon.\n\nOrigins\n\nAthena was originally the Aegean goddess of the palace, who presided over household crafts and protected the king. A single Mycenaean Greek inscription   appears at Knossos in the Linear B tablets from the Late Minoan II-era \"Room of the Chariot Tablets\"; these comprise the earliest Linear B archive anywhere. Although Athana potnia is often translated as \"Mistress Athena\", it could also mean \"the Potnia of Athana\", or the Lady of Athens. However, any connection to the city of Athens in the Knossos inscription is uncertain. A sign series  appears in the still undeciphered corpus of Linear A tablets, written in the unclassified Minoan language. This could be connected with the Linear B Mycenaean expressions  and  or  (Diwia, \"of Zeus\" or, possibly, related to a homonymous goddess), resulting in a translation \"Athena of Zeus\" or \"divine Athena\". Similarly, in the Greek mythology and epic tradition, Athena figures as a daughter of Zeus (; cfr. Dyeus). However, the inscription quoted seems to be very similar to \"\", quoted as SY Za 1 by Jan Best. Best translates the initial, which is recurrent in line beginnings, as \"I have given\".\n\nA Mycenean fresco depicts two women extending their hands towards a central figure, who is covered by an enormous figure-eight shield; this may depict the warrior-goddess with her palladion, or her palladion in an aniconic representation. In the \"Procession Fresco\" at Knossos, which was reconstructed by the Mycenaeans, two rows of figures carrying vessels seem to meet in front of a central figure, which is probably the Minoan precursor to Athena. The early twentieth-century scholar Martin Persson Nilsson argued that the Minoan snake goddess figurines are early representations of Athena.\n\nNilsson and others have claimed that, in early times, Athena was either an owl herself or a bird goddess in general. In the third book of the Odyssey, she takes the form of a sea-eagle. Proponents of this view argue that she dropped her prophylactic owl-mask before she lost her wings. \"Athena, by the time she appears in art,\" Jane Ellen Harrison remarks, \"has completely shed her animal form, has reduced the shapes she once wore of snake and bird to attributes, but occasionally in black-figure vase-paintings she still appears with wings.\"\n\nIt is generally agreed that the cult of Athena preserves some aspects of the Proto-Indo-European transfunctional goddess. The cult of Athena may have also been influenced by those of Near Eastern warrior goddesses such as the East Semitic Ishtar and the Ugaritic Anat, both of whom were often portrayed bearing arms. Classical scholar Charles Penglase notes that Athena resembles Inanna in her role as a \"terrifying warrior goddess\" and that both goddesses were closely linked with creation. Athena's birth from the head of Zeus may be derived from the earlier Sumerian myth of Inanna's descent into and return from the Underworld.\n\nPlato notes that the citizens of Sais in Egypt worshipped a goddess known as Neith, whom he identifies with Athena. Neith was the ancient Egyptian goddess of war and hunting, who was also associated with weaving; her worship began during the Egyptian Pre-Dynastic period. In Greek mythology, Athena was reported to have visited mythological sites in North Africa, including Libya's Triton River and the Phlegraean plain. Based on these similarities, the Sinologist Martin Bernal created the \"Black Athena\" hypothesis, which claimed that Neith was brought to Greece from Egypt, along with \"an enormous number of features of civilization and culture in the third and second millennia\". The \"Black Athena\" hypothesis stirred up widespread controversy near the end of the twentieth century, but it has now been widely rejected by modern scholars.\n\nCult and patronages\n\nPanhellenic and Athenian cult\n\nIn her aspect of Athena Polias, Athena was venerated as the goddess of the city and the protectress of the citadel. In Athens, the Plynteria, or \"Feast of the Bath\", was observed every year at the end of the month of Thargelion. The festival lasted for five days. During this period, the priestesses of Athena, or plyntr\u00eddes, performed a cleansing ritual within the Erechtheion, a sanctuary devoted to Athena and Poseidon. Here Athena's statue was undressed, her clothes washed, and body purified. Athena was", "flag": 1, "segments": [[355, 361]], "strength": 5.5}
{"token_count": [2006], "text": "Alternate history (also alternative history, althist, AH) is a genre of speculative fiction of stories in which one or more historical events occur and are resolved differently than in real life. As conjecture based upon historical fact, alternative history stories propose What if? scenarios about crucial events in human history, and present outcomes very different from the historical record. Alternate history also is a subgenre of literary fiction, science fiction, and historical fiction; as literature, alternate history uses the tropes of the genre to answer the What if? speculations of the story.\n\nSince the 1950s, as a subgenre of science fiction, alternative history stories feature the tropes of time travel between histories, and the psychic awareness of the existence of an alternative universe, by the inhabitants of a given universe; and time travel that divides history into various timestreams. In the Spanish, French, German, and Portuguese, Italian,  Catalan, and Galician languages, the terms Uchronie, ucronia,  ucron\u00eda, and Uchronie identify the alternate history genre, from which derives the English term Uchronia, composed of the Greek prefix  (\"not\", \"not any\", and \"no\") and the Greek word  () \"time\", to describe a story that occurs \"[in] no time\"; analogous to a story that occurs in utopia, \"[in] no place\". The term Uchronia also is the name of the list of alternate-history books, uchronia.net. Moreover, Allohistory (other history) is another term for the genre of alternative history.\n\nDefinition\nAlternative history is a genre of fiction wherein the author speculates upon how the course of history might have been altered if a particular historical event had an outcome different from the real life outcome. An alternate history requires three conditions: (i) A point of divergence from the historical record, before the time in which the author is writing; (ii) A change that would alter known history; and (iii) An examination of the ramifications of that alteration to history. Occasionally, some types of genre fiction are misidentified as alternative history, specifically science fiction stories set in a time that was the future for the writer, but now is the past for the reader, such as the novels 2001: A Space Odyssey (1968), by Arthur C. Clarke and Nineteen Eighty-Four (1949), by George Orwell, because the authors did not alter the history of the past when they wrote the stories.\n\nMoreover, the genre of the Secret History of an event, which can be either fictional or non-fictional, documents events that might have occurred of Christmas Eve at a local in history, but which had no effect upon the recorded historical outcome. Alternative history also is thematically related to, but distinct from, Counterfactual History, which is a form of historiography that attempts to answer the What if? speculations that arise from counterfactual conditions in order to understand what did happen. As a method of historical research, counterfactual history explores historical events with an extrapolated timeline in which key historical events either did not occur or had an outcome different from the historical record.\n\nHistory of literature\n\nAntiquity and medieval\n\nThe earliest example of alternate (or counterfactual) history is found in Livy's Ab Urbe Condita Libri (book IX, sections 17\u201319). Livy contemplated an alternative 4th century BC in which Alexander the Great had survived to attack Europe as he had planned; asking, \"What would have been the results for Rome if she had been engaged in a war with Alexander?\" Livy concluded that the Romans would likely have defeated Alexander. An even earlier possibility is Herodotus's Histories, which contains speculative material.\n\nAnother example of counterfactual history was posited by cardinal and Doctor of the Church Peter Damian in the 11th century. In his famous work De Divina Omnipotentia, a long letter in which he discusses God's omnipotence, he treats questions related to the limits of divine power, including the question of whether God can change the past, for example, bringing about that Rome was never founded:I see I must respond finally to what  many people, on the basis of your holiness\u2019s [own] judgment, raise as an objection on the topic of this dispute. For they say: If, as you assert, God is omnipotent in all things, can he manage this, that things that have been made were not  made? He can certainly destroy all things that have been made, so that they do not exist now. But it cannot be seen how he can bring it about that things that have been made were not made. To be sure, it can come about that from now on and hereafter Rome does not exist; for it can be destroyed. But no opinion can grasp how it can come about that it was not founded long ago...One early work of fiction detailing an alternate history is Joanot Martorell's 1490 epic romance Tirant lo Blanch, which was written when the loss of Constantinople to the Turks was still a recent and traumatic memory for Christian Europe. It tells the story of the knight Tirant the White from Brittany who travels to the embattled remnants of the Byzantine Empire. He becomes a Megaduke and commander of its armies and manages to fight off the invading Ottoman armies of. He saves the city from Islamic conquest, and even chases the Turks deeper into lands they had previously conquered.\n\n19th century\nOne of the earliest works of alternate history published in large quantities for the reception of a large audience may be Louis Geoffroy's Histoire de la Monarchie universelle: Napol\u00e9on et la conqu\u00eate du monde (1812\u20131832) (History of the Universal Monarchy: Napoleon and the Conquest of the World) (1836), which imagines Napoleon's First French Empire emerging victorious in the French invasion of Russia in 1812 and in an invasion of England in 1814, later unifying the world under Bonaparte's rule.\n\nIn the English language, the first known complete alternate history is Nathaniel Hawthorne's short story \"P.'s Correspondence\", published in 1845. It recounts the tale of a man who is considered \"a madman\" due to his perceptions of a different 1845, a reality in which long-dead famous people, such as the poets Robert Burns, Lord Byron, Percy Bysshe Shelley and John Keats, the actor Edmund Kean, the British politician George Canning, and Napoleon Bonaparte, are still alive.\n\nThe first novel-length alternate history in English would seem to be Castello Holford's Aristopia (1895). While not as nationalistic as Louis Geoffroy's Napol\u00e9on et la conqu\u00eate du monde, 1812\u20131823, Aristopia is another attempt to portray a Utopian society. In Aristopia, the earliest settlers in Virginia discover a reef made of solid gold and are able to build a Utopian society in North America.\n\nEarly 20th century and the era of the pulps\nIn 1905, H. G. Wells published A Modern Utopia. As explicitly noted in the book itself, Wells's main aim in writing it was to set out his social and political ideas, the plot serving mainly as a vehicle to expound them. This book introduced the idea of a person being transported from a point in our familiar world to the precise geographical equivalent point in an alternate world in which history had gone differently. The protagonists undergo various adventures in the alternate world, and then are finally transported back to our world, again to the precise geographical equivalent point. Since then, that has become a staple of the alternate history genre.    \n\nA number of alternate history stories and novels appeared in the late 19th and early 20th centuries (see, for example, Joseph Edgar Chamberlin's The Ifs of History [1907] and Charles Petrie's If: A Jacobite Fantasy [1926]). In 1931, British historian Sir John Squire collected a series of essays from some of the leading historians of the period for his anthology If It Had Happened Otherwise. In that work, scholars from major universities, as well as important non-academic authors, turned their attention to such questions as \"If the Moors in Spain Had Won\" and \"If Louis XVI Had Had an Atom of Firmness\". The essays range from serious scholarly efforts to Hendrik Willem van Loon's fanciful and satiric portrayal of an independent 20th-century New Amsterdam, a Dutch city-state on the island of Manhattan. Among the authors included were Hilaire Belloc, Andr\u00e9 Maurois, and Winston Churchill.\n\nOne of the entries in Squire's volume was Churchill's \"If Lee Had Not Won the Battle of Gettysburg\", written from the viewpoint of a historian in a world in which the Confederacy had won the American Civil War. The entry considers what would have happened if the North had been victorious (in other words, a character from an alternate world imagines a world more like the real one we live in, although it is not identical in every detail). Speculative work that narrates from the point of view of an alternate history is variously known as \"recursive alternate history\", a \"double-blind what-if\", or an \"alternate-alternate history\". Churchill's essay was one of the influences behind Ward Moore's alternate history novel Bring the Jubilee in which General Robert E. Lee won the Battle of Gettysburg and paved the way for the eventual victory of the Confederacy in the American Civil War (named the \"War of Southron Independence\" in this", "flag": 1, "segments": [[543, 549]], "strength": 5.5}
{"token_count": [2006], "text": "In atomic theory and quantum mechanics, an atomic orbital is a mathematical function describing the location and wave-like behavior of an electron in an atom. This function can be used to calculate the probability of finding any electron of an atom in any specific region around the atom's nucleus. The term atomic orbital may also refer to the physical region or space where the electron can be calculated to be present, as predicted by the particular mathematical form of the orbital.\n\nEach orbital in an atom is characterized by a set of values ofs even professionals to continue to the three quantum numbers,, and, which respectively correspond to the electron's energy, angular momentum, and an angular momentum vector component (the magnetic quantum number). Alternative to the magnetic quantum number, the orbitals are often labeled by the associated harmonic polynomials (e.g. xy, x2\u2212y2). Each such orbital can be occupied by a maximum of two electrons, each with its own projection of spin. The simple names s orbital, p orbital, d orbital, and f orbital refer to orbitals with angular momentum quantum number  and  respectively. These names, together with the value of\u00a0, are used to describe the electron configurations of atoms. They are derived from the description by early spectroscopists of certain series of alkali metal spectroscopic lines as sharp, principal, diffuse, and fundamental. Orbitals for  > 3 continue alphabetically (g, h, i, k,...), omitting\u00a0j because some languages do not distinguish between the letters \"i\" and \"j\".\n\nAtomic orbitals are the basic building blocks of the atomic orbital model (alternatively known as the electron cloud or wave mechanics model), a modern framework for visualizing the submicroscopic behavior of electrons in matter. In this model the electron cloud of a multi-electron atom may be seen as being built up (in approximation) in an electron configuration that is a product of simpler hydrogen-like atomic orbitals. The repeating periodicity of the blocks of 2, 6, 10, and 14 elements within sections of the periodic table arises naturally from the total number of electrons that occupy a complete set of s, p, d, and f atomic orbitals, respectively, although for higher values of the quantum number, particularly when the atom in question bears a positive charge, the energies of certain sub-shells become very similar and so the order in which they are said to be populated by electrons (e.g. Cr = [Ar]4s13d5 and Cr2+ = [Ar]3d4) can only be rationalized somewhat arbitrarily.\n\nElectron properties \nWith the development of quantum mechanics and experimental findings (such as the two slit diffraction of electrons), it was found that the orbiting electrons around a nucleus could not be fully described as particles, but needed to be explained by the wave-particle duality. In this sense, the electrons have the following properties:\n\nWave-like properties:\n The electrons do not orbit the nucleus in the manner of a planet orbiting the sun, but instead exist as  standing waves. Thus the lowest possible energy an electron can take is similar to the  fundamental frequency of a wave on a string. Higher energy states are similar to harmonics of that fundamental frequency.\n The electrons are never in a single point location, although the probability of interacting with the electron at a single point can be found from the wave function of the electron.  The charge on the electron acts like it is smeared out in space in a continuous distribution, proportional at any point to the squared magnitude of the electron's wave function.\n\nParticle-like properties:\n The number of electrons orbiting the nucleus can only be an integer.\n Electrons jump between orbitals like particles. For example, if a single photon strikes the electrons, only a single electron changes states in response to the photon.\n The electrons retain particle-like properties such as: each wave state has the same electrical charge as its electron particle. Each wave state has a single discrete spin (spin up or spin down) depending on its superposition.\n\nThus, electrons cannot be described simply as solid particles. An analogy might be that of a large and often oddly shaped \"atmosphere\" (the electron), distributed around a relatively tiny planet (the atomic nucleus). Atomic orbitals exactly describe the shape of this \"atmosphere\" only when a single electron is present in an atom. When more electrons are added to a single atom, the additional electrons tend to more evenly fill in a volume of space around the nucleus so that the resulting collection (sometimes termed the atom's \"electron cloud\") tends toward a generally spherical zone of probability describing the electron's location, because of the uncertainty principle.\n\nFormal quantum mechanical definition \nAtomic orbitals may be defined more precisely in formal quantum mechanical language.  They are approximate solutions to the Schrodinger equation for the electrons bound to the atom by the electric field of the atom's nucleus. Specifically, in quantum mechanics, the state of an atom, i.e., an eigenstate of the atomic Hamiltonian, is approximated by an expansion (see configuration interaction expansion and basis set) into linear combinations of anti-symmetrized products (Slater determinants) of one-electron functions. The spatial components of these one-electron functions are called atomic orbitals. (When one considers also their spin component, one speaks of atomic spin orbitals.) A state is actually a function of the coordinates of all the electrons, so that their motion is correlated, but this is often approximated by this independent-particle model of products of single electron wave functions. (The London dispersion force, for example, depends on the correlations of the motion of the electrons.)\n\nIn atomic physics, the atomic spectral lines correspond to transitions (quantum leaps) between quantum states of an atom. These states are labeled by a set of quantum numbers summarized in the term symbol and usually associated with particular electron configurations, i.e., by occupation schemes of atomic orbitals (for example, 1s2\u00a02s2\u00a02p6 for the ground state of neon-term symbol: 1S0).\n\nThis notation means that the corresponding Slater determinants have a clear higher weight in the configuration interaction expansion. The atomic orbital concept is therefore a key concept for visualizing the excitation process associated with a given transition. For example, one can say for a given transition that it corresponds to the excitation of an electron from an occupied orbital to a given unoccupied orbital. Nevertheless, one has to keep in mind that electrons are fermions ruled by the Pauli exclusion principle and must be distinguished from each other. Moreover, it sometimes happens that the configuration interaction expansion converges very slowly and that one cannot speak about simple one-determinant wave function at all. This is the case when electron correlation is large.\n\nFundamentally, an atomic orbital is a one-electron wave function, even though most electrons do not exist in one-electron atoms, and so the one-electron view is an approximation. When thinking about orbitals, we are often given an orbital visualization heavily influenced by the Hartree\u2013Fock approximation, which is one way to reduce the complexities of molecular orbital theory.\n\nTypes of orbitals \n\nAtomic orbitals can be the hydrogen-like \"orbitals\" which are exact solutions to the Schr\u00f6dinger equation for a hydrogen-like \"atom\" (i.e., an atom with one electron). Alternatively, atomic orbitals refer to functions that depend on the coordinates of one electron (i.e., orbitals) but are used as starting points for approximating wave functions that depend on the simultaneous coordinates of all the electrons in an atom or molecule. The coordinate systems chosen for atomic orbitals are usually spherical coordinates  in atoms and Cartesian  in polyatomic molecules. The advantage of spherical coordinates (for atoms) is that an orbital wave function is a product of three factors each dependent on a single coordinate:. The angular factors of atomic orbitals  generate s, p, d, etc. functions as real combinations of spherical harmonics  (where  and  are quantum numbers). There are typically three mathematical forms for the radial functions\u00a0 which can be chosen as a starting point for the calculation of the properties of atoms and molecules with many electrons:\n\n The hydrogen-like atomic orbitals are derived from the exact solutions of the Schr\u00f6dinger Equation for one electron and a nucleus, for a hydrogen-like atom. The part of the function that depends on the distance r from the nucleus has nodes (radial nodes) and decays as.\n The Slater-type orbital (STO) is a form without radial nodes but decays from the nucleus as does the hydrogen-like orbital.\n The form of the Gaussian type orbital (Gaussians) has no radial nodes and decays as.\n\nAlthough hydrogen-like orbitals are still used as pedagogical tools, the advent of computers has made STOs preferable for atoms and diatomic molecules since combinations of STOs can replace the nodes in hydrogen-like atomic orbital. Gaussians are typically used in molecules with three or more atoms. Although not as accurate by themselves as STOs, combinations of many Gaussians can attain the accuracy of hydrogen-like orbitals.\n\nHistory \n\nThe term \"orbital\" was coined by Robert Mulliken in 1932 as an abbreviation for one-electron orbital wave function. However, the idea that electrons might revolve around a compact nucleus with definite angular momentum was convincingly argued at least 19 years earlier by Niels Bohr, and the Japanese physicist Hantaro N", "flag": 1, "segments": [[104, 110]], "strength": 5.5}
{"token_count": [2006], "text": "Alan Mathison Turing  (; 23 June 1912\u00a0\u2013 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science and artificial intelligence.\n\nBorn in Maida Vale, London, Turing was raised in southern England. He graduated at King's College, Cambridge, with a degree in mathematics. Whilst he was a fellow at Cambridge, he published a proof demonstrating that some purely mathematical yes\u2013no questions can never be answered by computation and defined a Turing machine, and went on to prove the halting problem for Turing machines is undecidable. In 1938, he obtained his PhD from the Department of Mathematics at Princeton University. During the Second World War, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. For a time he led Hut 8, the section that was responsible for German naval cryptanalysis. Here, he devised a number of techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bombe method, an electromechanical machine that could find settings for the Enigma machine. Turing played a crucial role in cracking intercepted coded messages that enabled the Allies to defeat the Axis powers in many crucial engagements, including the Battle of the Atlantic.\n\nAfter the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine (ACE), one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory, at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. He wrote a paper on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov\u2013Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised in his home country during his lifetime because much of his work was covered by the Official Secrets Act.\n\nTuring was prosecuted in 1952 for homosexual acts. He accepted hormone treatment with DES, so-called chemical castration, as an alternative to prison. In 2009, following an Internet campaign, British Prime Minister Gordon Brown made an official public apology on behalf of the British government for \"the appalling way he was treated\". Queen Elizabeth II granted Turing a posthumous pardon in 2013. The \"Alan Turing law\" is of Jason Rezaiani, now an informal term for a 2017 law in the United Kingdom that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts. \n\nTuring died in 1954, 16 days before his 42nd birthday, from cyanide poisoning. An inquest determined his death as a suicide, but it has been noted that the known evidence is also consistent with accidental poisoning.\n\nTuring has an extensive legacy with statues of him and many things named after him, including an annual award for computer science innovations. He appears on the current Bank of England \u00a350 note, which was released to coincide with his birthday. A 2019 BBC series, as voted by the audience, named him the greatest person of the 20th century.\n\nEarly life and education\n\nFamily\nTuring was born in Maida Vale, London, while his father, Julius Mathison Turing (1873\u20131947), was on leave from his position with the Indian Civil Service (ICS) at Chatrapur, then in the Madras Presidency and presently in Odisha state, in India. Turing's father was the son of a clergyman, the Rev.\u00a0John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius's wife, was Ethel Sara Turing (; 1881\u20131976), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare.\n\nJulius's work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John (the father of Sir John Dermot Turing, 12th Baronet of the Turing baronets).\n\nTuring's father's civil service commission was still active and during Turing's childhood years, his parents travelled between Hastings in the United Kingdom and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2012, the centenary of Turing's birth.\n\nVery early in life, Turing showed signs of the genius that he was later to display prominently. His parents purchased a house in Guildford in 1927, and Turing lived there during school holidays. The location is also marked with a blue plaque.\n\nSchool\nTuring's parents enrolled him at St Michael's, a primary school at 20 Charles Road, St Leonards-on-Sea, from the age of six to nine. The headmistress recognised his talent, noting that she has \"...had clever boys and hardworking boys, but Alan is a genius.\"\n\nBetween January 1922 and 1926, Turing was educated at Hazelhurst Preparatory School, an independent school in the village of Frant in Sussex (now East Sussex). In 1926, at the age of 13, he went on to Sherborne School, a boarding independent school in the market town of Sherborne in Dorset, where he boarded at Westcott House. The first day of term coincided with the 1926 General Strike, in Britain, but Turing was so determined to attend, that he rode his bicycle unaccompanied  from Southampton to Sherborne, stopping overnight at an inn.\n\nTuring's natural inclination towards mathematics and science did not earn him respect from some of the teachers at Sherborne, whose definition of education placed more emphasis on the classics. His headmaster wrote to his parents: \"I hope he will not fall between two stools. If he is to stay at public school, he must aim at becoming educated. If he is to be solely a Scientific Specialist, he is wasting his time at a public school\". Despite this, Turing continued to show remarkable ability in the studies he loved, solving advanced problems in 1927 without having studied even elementary calculus. In 1928, aged 16, Turing encountered Albert Einstein's work; not only did he grasp it, but it is possible that he managed to deduce Einstein's questioning of Newton's laws of motion from a text in which this was never made explicit.\n\nChristopher Morcom\nAt Sherborne, Turing formed a significant friendship with fellow pupil Christopher Collan Morcom (13 July 1911 \u2013 13 February 1930), who has been described as Turing's \"first love\". Their relationship provided inspiration in Turing's future endeavours, but it was cut short by Morcom's death, in February 1930, from complications of bovine tuberculosis, contracted after drinking infected cow's milk some years previously.\n\nThe event caused Turing great sorrow. He coped with his grief by working that much harder on the topics of science and mathematics that he had shared with Morcom. In a letter to Morcom's mother, Frances Isobel Morcom (n\u00e9e Swan), Turing wrote:\n\nTuring's relationship with Morcom's mother continued long after Morcom's death, with her sending gifts to Turing, and him sending letters, typically on Morcom's birthday. A day before the third anniversary of Morcom's death (13 February 1933), he wrote to Mrs. Morcom: \n\nSome have speculated that Morcom's death was the cause of Turing's atheism and materialism. Apparently, at this point in his life he still believed in such concepts as a spirit, independent of the body and surviving death. In a later letter, also written to Morcom's mother, Turing wrote:\n\nUniversity and work on computability\nAfter Sherborne, Turing studied as an undergraduate from 1931 to 1934 at King's College, Cambridge, where he was awarded first-class honours in mathematics. In 1935, at the age of 22, he was elected a Fellow of King's College on the strength of a dissertation in which he proved the central limit theorem. Unknown to the committee, the theorem had already been proven, in 1922, by Jarl Waldemar Lindeberg.\n\nIn 1936, Turing published his paper \"On Computable Numbers, with an Application to the Entscheidungsproblem\". It was published in the Proceedings of the London Mathematical Society journal in two parts, the first on 30 November and the second on 23 December. In this paper, Turing reformulated Kurt G\u00f6del's 1931 results on the limits of proof and computation, replacing G\u00f6del's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. The Entscheidungsproblem (decision problem) was originally posed by German mathematician David Hilbert in 1928. Turing proved that his \"universal computing machine\" would be capable of performing any conceivable mathematical computation if it were represent", "flag": 1, "segments": [[544, 550]], "strength": 5.5}
{"token_count": [2006], "text": "Anglicanism is a Western Christian tradition that has developed from the practices, liturgy, and identity of the Church of England following the English Reformation, in the context of the Protestant Reformation in Europe. It is one of the largest branches of Christianity, with around 110 million adherents worldwide.\n\nAdherents of Anglicanism are called Anglicans; they are also called Episcopalians in some countries. The majority of Anglicans are members of national or regional ecclesiastical provinces of the international Anglican Communion, which forms the third-largest Christian communion in the world, after the Roman Catholic Church and the Eastern Orthodox Church. These provinces are in full communion with the See of Canterbury and thus with the British Monarch\u2019s personal choice of the Archbishop of Canterbury, whom the communion refers to as its primus inter pares (Latin, 'first among equals'). The Archbishop calls the decennial Lambeth Conference, chairs the meeting of primates, and is the president of the Anglican Consultative Council. Some churches that are not part of the Anglican Communion or recognised by it also call themselves Anglican, including those that are within the Continuing Anglican movement and Anglican realignment.\n\nAnglicans base their Christian faith on the Bible, traditions of the apostolic Church, apostolic succession (\"historic episcopate\"), and the writings of the Church Fathers. Anglicanism forms one of the branches of Western Christianity, having definitively declared its independence from the Holy See at the time of the Elizabethan Religious Settlement. Many of the new Anglican formularies of the mid-16th century corresponded closely to those of contemporary Protestantism. These reforms in the Church of England were understood by one of those most responsible for them, Thomas Cranmer, the Archbishop of Canterbury, and others as navigating a middle way between two of the emerging Protestant traditions, namely Lutheranism and Calvinism.\n\nIn the first half of the 17th century, the Church of England and its associated Church of Ireland were presented by some Anglican divines as comprising a distinct Christian tradition, with theologies, structures, and forms of worship representing a different kind of middle way, or via media, between Protestantism and Catholicism \u2013 a perspective that came to be highly influential in later theories of Anglican identity and expressed in the description of Anglicanism as \"catholic and reformed\". The degree of distinction between Protestant and Catholic tendencies within the Anglican tradition is routinely a matter of debate both within specific Anglican churches and throughout the Anglican Communion. Unique to Anglicanism is the Book of Common Prayer, the collection of services in one Book used for centuries. The Book is acknowledged as a principal tie that binds the Anglican Communion together as a liturgical rather than a confessional tradition or one possessing a magisterium as in the Roman Catholic Church.\n\nAfter the American Revolution, Anglican congregations in the United States and British North America (which would later form the basis for the modern country of Canada) were each reconstituted into autonomous churches with their own bishops and self-governing structures; these were known as the American Episcopal Church and the Church of England in the Dominion of Canada. Through the expansion of the British Empire and the activity of Christian missions, this model was adopted as the model for many newly formed churches, especially in Africa, Australasia, and Asia-Pacific. In the 19th century, the term Anglicanism was coined to describe the common religious tradition of these churches; as also that of the Scottish Episcopal Church, which, though originating earlier within the Church of Scotland, had come to be recognised as sharing this common identity.\n\nTerminology\n\nThe word Anglican originates in, a phrase from the Magna Carta dated 15 June 1215, meaning \"the Anglican Church shall be free\". Adherents of Anglicanism are called Anglicans. As an adjective, \"Anglican\" is used to describe the people, institutions, and churches, as well as the liturgical traditions and theological concepts developed by the Church of England.\n\nAs a noun, an Anglican is a member of a church in the Anglican Communion. The word is also used by followers of separated groups which have left the communion or have been founded separately from it, although this is considered as a misuse by the Anglican Communion. The word Anglicanism came into being in the 19th century. The word originally referred only to the teachings and rites of Christians throughout the world in communion with the see of Canterbury, but has come to sometimes be extended to any church following those traditions rather than actual membership in the modern Anglican Communion.\n\nAlthough the term Anglican is found referring to the Church of England as far back as the 16th century, its use did not become general until the latter half of the 19th century. In British parliamentary legislation referring to the English Established Church, there is no need for a description; it is simply the Church of England, though the word \"Protestant\" is used in many legal acts specifying the succession to the Crown and qualifications for office. When the Union with Ireland Act created the United Church of England and Ireland, it is specified that it shall be one \"Protestant Episcopal Church\", thereby distinguishing its form of church government from the Presbyterian polity that prevails in the Church of Scotland.\n\nThe word Episcopal is preferred in the title of the Episcopal Church (the province of the Anglican Communion covering the United States) and the Scottish Episcopal Church, though the full name of the former is The Protestant Episcopal Church of the United States of America. Elsewhere, however, the term \"Anglican Church\" came to be preferred as it distinguished these churches from others that maintain an episcopal polity.\n\nDefinition\nAnglicanism, in its structures, theology, and forms of worship, is commonly understood as a distinct Christian tradition representing a middle ground between what are perceived to be the extremes of the claims of 16th-century Roman Catholicism and the Lutheran and Reformed varieties of Protestantism of that era. As such, it is often referred to as being a via media (or \"middle way\") between these traditions.\n\nThe faith of Anglicans is founded in the Scriptures and the Gospels, the traditions of the Apostolic Church, the historical episcopate, the first four ecumenical councils, and the early Church Fathers (among these councils, especially the premier four ones, and among these Fathers, especially those active during the five initial centuries of Christianity, according to the quinquasaecularist principle proposed by the English bishop Lancelot Andrewes and the Lutheran dissident Georg Calixtus). Anglicans understand the Old and New Testaments as \"containing all things necessary for salvation\" and as being the rule and ultimate standard of faith. Reason and tradition are seen as valuable means to interpret scripture (a position first formulated in detail by Richard Hooker), but there is no full mutual agreement among Anglicans about exactly how scripture, reason, and tradition interact (or ought to interact) with each other. Anglicans understand the Apostles' Creed as the baptismal symbol and the Nicene Creed as the sufficient statement of the Christian faith.\n\nAnglicans believe the catholic and apostolic faith is revealed in Holy Scripture and the Catholic creeds and interpret these in light of the Christian tradition of the historic church, scholarship, reason, and experience.\n\nAnglicans celebrate the traditional sacraments, with special emphasis being given to the Eucharist, also called Holy Communion, the Lord's Supper or the Mass. The Eucharist is central to worship for most Anglicans as a communal offering of prayer and praise in which the life, death, and resurrection of Jesus Christ are proclaimed through prayer, reading of the Bible, singing, giving God thanks over the bread and wine for the innumerable benefits obtained through the passion of Christ, the breaking of the bread, the blessing of the cup, and the partaking of the body and blood of Christ as instituted at the Last Supper, however one wished to define the Presence. The consecrated bread and wine, which are the true body and blood of Christ after a spiritual manner, are outward symbols of an inner grace given by Christ, which to the repentant conveys forgiveness and cleaning from sin. While many Anglicans celebrate the Eucharist in similar ways to the predominant western Catholic tradition, a considerable degree of liturgical freedom is permitted, and worship styles range from the simple to elaborate.\n\n The move closes a disaster thatUnique to Anglicanism is the Book of Common Prayer (BCP), the collection of services that worshippers in most Anglican churches have used for centuries. It was called common prayer originally because it was intended for use in all Church of England churches, which had previously followed differing local liturgies. The term was kept when the church became international, because all Anglicans used to share in its use around the world.\n\nIn 1549, the first Book of Common Prayer was compiled by Thomas Cranmer, who was then Archbishop of Canterbury. While it has since undergone many revisions and Anglican churches in different countries have developed other service books, the Prayer Book is still acknowledged as one of the ties that bind Anglicans together.\n\nIdentity\n\nEarly history\n\nThe founding of Christianity in Britain is commonly attributed to Joseph of Arimathea, according to Anglican legend, and is commemorated in Glastonbury Abbey. Many of the early Church Fathers wrote of the presence of Christianity in Roman Britain, with Tertullian stating \"those parts of Britain into which the Roman arms had never penetrated were become subject to Christ\". Saint Alban, who was executed in AD 209, is the first Christian martyr in the British Isles. For this reason he is venerated as", "flag": 1, "segments": [[1741, 1747]], "strength": 5.5}
{"token_count": [2006], "text": "Athens ( ;  ;  (pl.) ) is the capital and largest city of Greece. Athens dominates the Attica region and is one of the world's oldest cities, with its recorded history spanning over 3,400 years and its earliest human presence beginning somewhere between the 11th and 7th centuries BC.\n\nClassical Athens was a powerful city-state. It was a centre for the arts, learning and philosophy, and the home of Plato's Academy and Aristotle's Lyceum. It is widely referred to as the cradle of Western civilization and the birthplace of democracy, largely because of its cultural and political impact on the European continent\u2014particularly Ancient Rome. In modern times, Athens is a large cosmopolitan metropolis and central to economic, financial, industrial, maritime, political and cultural life in Greece. In 2021, Athens' urban area hosted more than three and a half million people, which is around 35% of the entire population of Greece.\n\nAthens is a Beta global city according to the Globalization and World Cities Research Network, and is one of the biggest economic centers in Southeastern Europe. It also has a large financial sector, and its port Piraeus is both the largest passenger port in Europe, and the third largest in the world.\n\nThe Municipality of Athens (also City of Athens), which actually constitutes a small administrative unit of the entire city, had a population of 664,046 (in 2011) within its official limits, and a land area of. The Athens Urban Area or Greater Athens extends beyond its administrative municipal city limits, with a population of 3,090,508 (in 2011) over an area of. According to Eurostat in 2011, the functional urban area of Athens was the 9th most populous in the European Union (the 6th most populous capital city of the EU), with a population of 3.8\u00a0million people. Athens is also the southernmost capital on the European mainland and the warmest major city in Europe.\n\nThe heritage of the Classical Era is still evident in the city, represented by ancient monuments, and works of art,  the most famous of all being the Parthenon, considered a key landmark of early Western civilization. The city also retains Roman and Byzantine monuments, as well as a smaller number of Ottoman monuments, while its historical urban core features elements of continuity through its millennia of history. Athens is home to two UNESCO World Heritage Sites, the Acropolis of Athens and the medieval Daphni Monastery. Landmarks of the modern era, dating back to the establishment of Athens as the capital of the independent Greek state in 1834, includes the Hellenic Parliament and the so-called \"Architectural Trilogy of Athens\", consisting of the National Library of Greece, the National and Kapodistrian University of Athens, and the Academy of Athens. Athens is also home to several museums and cultural institutions, such as the National Archeological Museum, featuring the world's largest collection of ancient Greek antiquities, the Acropolis Museum, the Museum of Cycladic Art, the Benaki Museum, and the Byzantine and Christian Museum. Athens was the host city of the first modern-day Olympic Games in 1896, and 108 years later it hosted the 2004 Summer Olympics, making it one of the few cities to have hosted the Olympics more than once.\n\nEtymology and names\n\nIn Ancient Greek, the name of the city was  (Ath\u00eanai,  in Classical Attic) a plural. In earlier Greek, such as Homeric Greek, the name had been current in the singular form though, as  (Ath\u1e17n\u0113). It was possibly rendered in the plural later on, like those of  (Th\u00eabai) and  (\u039cuk\u00eanai). The root of the word is probably not of Greek or Indo-European origin, and is possibly a remnant of the Pre-Greek substrate of Attica. In antiquity, it was debated whether Athens took its name from its patron goddess Athena (Attic, Ath\u0113n\u00e2, Ionic, Ath\u1e17n\u0113, and Doric, Ath\u0101\u0301n\u0101) or Athena took her name from the city. Modern scholars now generally agree that the goddess takes her name from the city, because the ending -ene is common in names of locations, but rare for personal names.\n\nAccording to the ancient Athenian founding myth, Athenaoshock-style situation is, the goddess of wisdom and war, competed against Poseidon, the God of the Seas, for patronage of the yet-unnamed city; they agreed that whoever gave the Athenians the better gift would become their patron and appointed Cecrops, the king of Athens, as the judge. According to the account given by Pseudo-Apollodorus, Poseidon struck the ground with his trident and a salt water spring welled up. In an alternative version of the myth from Vergil's Georgics, Poseidon instead gave the Athenians the first horse. In both versions, Athena offered the Athenians the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens. Eight different etymologies, now commonly rejected, have been proposed since the 17th century. Christian Lobeck proposed as the root of the name the word  (\u00e1thos) or  (\u00e1nthos) meaning \"flower\", to denote Athens as the \"flowering city\". Ludwig von D\u00f6derlein proposed the stem of the verb, stem \u03b8\u03b7- (th\u00e1\u014d, th\u0113-, \"to suck\") to denote Athens as having fertile soil. Athenians were called cicada-wearers () because they used to wear pins of golden cicadas. A symbol of being autochthon (earth-born), because the legendary founder of Athens, Erechtheus was an autochthon or of being musicians, because the cicada is a \"musician\" insect. In classical literature, the city was sometimes referred to as the City of the Violet Crown, first documented in Pindar's \u1f30\u03bf\u03c3\u03c4\u03ad\u03c6\u03b1\u03bd\u03bf\u03b9 \u1f08\u03b8\u1fb6\u03bd\u03b1\u03b9 (iost\u00e9phanoi Ath\u00e2nai), or as  (t\u00f2 klein\u00f2n \u00e1sty, \"the glorious city\").\n\nDuring the medieval period, the name of the city was rendered once again in the singular as. Variant names included Setines, Satine, and Astines, all derivations involving false splitting of prepositional phrases. King Alphonse X of Castile gives the pseudo-etymology 'the one without death/ignorance'. In Ottoman Turkish, it was called \u0622\u062a\u064a\u0646\u0627 \u0100t\u012bn\u0101, and in modern Turkish, it is Atina.\n\nAfter the establishment of the modern Greek state, and partly due to the conservatism of the written language,   again became the official name of the city and remained so until the abandonment of Katharevousa in the 1970s, when \u1f08\u03b8\u03ae\u03bd\u03b1, Ath\u00edna, became the official name. Today it is often simply called  \u012b prot\u00e9vousa ; 'the capital'.\n\nHistory \n\nThe oldest known human presence in Athens is the Cave of Schist, which has been dated to between the 11th and 7th centuries BC. Athens has been continuously inhabited for at least 5,000 years (3000 BC). By 1400\u00a0BC, the settlement had become an important centre of the Mycenaean civilization, and the Acropolis was the site of a major Mycenaean fortress, whose remains can be recognised from sections of the characteristic Cyclopean walls. Unlike other Mycenaean centers, such as Mycenae and Pylos, it is not known whether Athens suffered destruction in about 1200\u00a0BC, an event often attributed to a Dorian invasion, and the Athenians always maintained that they were pure Ionians with no Dorian element. However, Athens, like many other Bronze Age settlements, went into economic decline for around 150 years afterwards.\n\nIron Age burials, in the Kerameikos and other locations, are often richly provided for and demonstrate that from 900\u00a0BC onwards Athens was one of the leading centres of trade and prosperity in the region. The leading position of Athens may well have resulted from its central location in the Greek world, its secure stronghold on the Acropolis and its access to the sea, which gave it a natural advantage over inland rivals such as Thebes and Sparta.\n\nBy the 6th century BC, widespread social unrest led to the reforms of Solon. These would pave the way for the eventual introduction of democracy by Cleisthenes in 508\u00a0BC. Athens had by this time become a significant naval power with a large fleet, and helped the rebellion of the Ionian cities against Persian rule. In the ensuing Greco-Persian Wars Athens, together with Sparta, led the coalition of Greek states that would eventually repel the Persians, defeating them decisively at Marathon in 490\u00a0BC, and crucially at Salamis in 480\u00a0BC. However, this did not prevent Athens from being captured and sacked twice by the Persians within one year, after a heroic but ultimately failed resistance at Thermopylae by Spartans and other Greeks led by King Leonidas, after both Boeotia and Attica fell to the Persians.\n\nThe decades that followed became known as the Golden Age of Athenian democracy, during which time Athens became the leading city of Ancient Greece, with its cultural achievements laying the foundations for Western civilization. The playwrights Aeschylus, Sophocles and", "flag": 1, "segments": [[899, 905]], "strength": 5.5}
{"token_count": [2006], "text": "Ashoka (; Br\u0101hmi: \ud804\udc05\ud804\udc32\ud804\udc44\ud804\udc13, Asoka, IAST: A\u015boka), also known as Ashoka the Great, was an Indian emperor of the Maurya Dynasty, son of Bindusara, who ruled almost all of the Indian subcontinent from  to 232 BCE. Ashoka promoted the spread of Buddhism across ancient Asia. Considered by many to be one of India's greatest emperors, Ashoka expanded Chandragupta's empire to reign over territory stretching from present-day Afghanistan in the west to present-day Bangladesh in the east. It covered the entire Indian subcontinent except for parts of present-day Tamil Nadu. The empire's capital was Pataliputra (in Magadha, present-day Patna), with provincial capitals at Takshashila (later Taxila) and Ujjain. Ashoka, after the war of Kalinga, got upset with the bloodshed and vowed to never fight again. He patronized Buddhism during his reign.\n\nAshoka waged a particularly destructive war against the state of Kalinga (modern Odisha), which he conquered in about 260 BCE. According to an interpretation of his Edicts, he converted to Buddhism after witnessing the mass deaths of the Kalinga War, which he had waged out of a desire for conquest and which reportedly directly resulted in more than 100,000 deaths and 150,000 deportations. He is remembered for erecting the Ashoka pillars and spreading his Edicts, for sending Buddhist monks to Sri Lanka and Central Asia, and for establishing monuments marking several significant sites in the life of Gautama Buddha.\n\nBeyond the Edicts of Ashoka, biographical information about him relies on legends written centuries later, such as the 2nd-century CE Ashokavadana (\"Narrative of Ashoka\", a part of the Divyavadana), and in the Sri Lankan text Mahavamsa (\"Great Chronicle\"). The emblem of the modern Republic of India is an adaptation of the Lion Capital of Ashoka. His Sanskrit name \"\" means \"painless, without sorrow\" (the a privativum and \u015boka, \"pain, distress\"). In his edicts, he is referred to as  (Pali  or \"the Beloved of the Gods\"), and  or Priyadarshi (Pali  or \"He who regards everyone with affection\"). His fondness for a tree is the reason for his name being connected to the \"Ashoka tree\" or Saraca asoca, and this is referenced in the Ashokavadana.\n\nIn The Outline of History (1920), H.G. Wells wrote, \"Amidst the tens of thousands of names of monarchs that crowd the columns of history, their majesties and graciousnesses and serenities and royal highnesses and the like, the name of Ashoka shines, and shines, almost alone, a star.\"\n\nSources of information \n\nInformation about Ashoka comes from his own inscriptions; other inscriptions that mention him or are possibly from his reign; and ancient literature, especially Buddhist texts. These sources often contradict each other, although various historians have attempted to correlate their testimony. Plenty is known or not known. So, for example, while Ashoka is often attributed with building many hospitals during his time, there is no clear evidence that any hospitals existed in ancient India during the 3rd century BC or that Ashoka was responsible for commissioning the construction of any.\n\nInscriptions\n\nAshoka's inscriptions are the earliest self-representations of imperial power in the Indian subcontinent. However, these inscriptions are focused mainly on the topic of dhamma, and provide little information regarding other aspects of the Maurya state and society. Even on the topic of dhamma, the content of these inscriptions cannot be taken at face value. In the words of American academic John S. Strong, it is sometimes helpful to think of Ashoka's messages as propaganda by a politician whose aim is to present a favourable image of himself and his administration, rather than record historical facts. \n\nA small number of other inscriptions also provide some information about Ashoka. For example, he finds a mention in the 2nd century Junagadh rock inscription of Rudradaman. An inscription discovered at Sirkap mentions a lost word beginning with \"Priy\", which is theorised to be Ashoka's title \"Priyadarshi\", although this is not certain. Some other inscriptions, such as the Sohgaura copper plate inscription, have been tentatively dated to Ashoka's period by a section of scholars, although others contest this. \n\nBuddhist legends\n\nMuch of the information about Ashoka comes from Buddhist legends, which present him as a great, ideal king. These legends appear in texts that are not contemporary to Ashoka and were composed by Buddhist authors, who used various stories to illustrate the impact of their faith on Ashoka. This makes it necessary to exercise caution while relying on them for historical information. Among modern scholars, opinions range from downright dismissal of these legends as mythological to acceptance of all historical portions that seem plausible.\n\nThe Buddhist legends about Ashoka exist in several languages, including Sanskrit, Pali, Tibetan, Chinese, Burmese, Sinhala, Thai, Lao, and Khotanese. All these legends can be traced to two primary traditions:\n the North Indian tradition preserved in the Sanskrit-language texts such as Divyavadana (including its constituent Ashokavadana); and Chinese sources such as A-y\u00fc wang chuan and A-y\u00fc wang ching.\n the Sri Lankan tradition preserved in Pali-lanuage texts, such as Dipavamsa, Mahavamsa, Vamsatthapakasini (a commentary on Mahavamsa), Buddhaghosha's commentary on the Vinaya, and Samanta-pasadika.\n\nThere are several significant differences between the two traditions. For example, the Sri Lankan tradition emphasises Ashoka's role in convening the Third Buddhist council, and his dispatch of several missionaries to distant regions, including his son Mahinda to Sri Lanka. However, the North Indian tradition makes no mention of these events. It describes other events not found in the Sri Lankan tradition, such as a story about another son named Kunala. \n\nEven while narrating the common stories, the two traditions diverge in several ways. For example, both Ashokavadana and Mahavamsa mention that Ashoka's queen Tishyarakshita had the Bodhi Tree destroyed. In Ashokavadana, the queen manages to have the tree healed after she realises her mistake. In the Mahavamsa, she permanently destroys the tree, but only after a branch of the tree has been transplanted in Sri Lanka. In another story, both the texts describe Ashoka's unsuccessful attempts to collect a relic of Gautama Buddha from Ramagrama. In Ashokavadana, he fails to do so because he cannot match the devotion of the Nagas who hold the relic; however, in the Mahavamsa, he fails to do so because the Buddha had destined the relic to be enshrined by King Dutthagamani of Sri Lanka.  Using such stories, the Mahavamsa glorifies Sri Lanka as the new preserve of Buddhism. \n\nOther sources\n\nNumismatic, sculptural, and archaeological evidence supplements research on Ashoka. Ashoka's name appears in the lists of Mauryan kings in the various Puranas. However, these texts do not provide further details about him, as their Brahmanical authors were not patronised by the Mauryans. Other texts, such as the Arthashastra and Indica of Megasthenes, which provide general information about the Maurya period, can also be used to make inferences about Ashoka's reign. However, the Arthashastra is a normative text that focuses on an ideal rather than a historical state, and its dating to the Mauryan period is a subject of debate. The Indica is a lost work, and only parts of it survive in the form of paraphrases in later writings.\n\nThe 12th-century text Rajatarangini mentions a Kashmiri king Ashoka of Gonandiya dynasty who built several stupas: some scholars, such as Aurel Stein, have identified this king with the Maurya king Ashoka; others, such as Ananda W. P. Guruge dismiss this identification as inaccurate.\n\nAlternative interpretation of the epigraphic evidence\n\nFor some scholars such as Christopher I. Beckwith, Ashoka, whose name only appears in the Minor Rock Edicts, should be differentiated from the ruler Piyadasi, or Devanampiya Piyadasi (i.e. \"Beloved of the Gods Piyadasi\", \"Beloved of the Gods\" being a fairly widespread title for \"King\"), who is named as the author of the Major Pillar Edicts and the Major Rock Edicts. This inscriptional evidence may suggest that these were two different rulers. According to him, Piyadasi was living in the 3rd century BCE, probably the son of Chandragupta Maurya known to the Greeks as Amitrochates, and only advocating for piety (\"Dharma\") in his Major Pillar Edicts and Major Rock Edicts, without ever mentioning Buddhism, the Buddhafighters arrived about 8 minutes later or the", "flag": 1, "segments": [[1998, 2004]], "strength": 5.5}
{"token_count": [2006], "text": "Caesar Augustus (23 September 63 BC \u2013 19 August AD 14), also known as Octavian, was the first Roman emperor, reigning from 27\u00a0BC until his death in AD\u00a014. His status as the founder of the Roman Principate (the first phase of the Roman Empire) has consolidated a legacy as one of the most effective leaders in human history. The reign of Augustus initiated an era of relative peace known as the Pax Romana. The Roman world was largely free from large-scale conflict for more than two centuries, despite continuous wars of imperial expansion on the Empire's frontiers and the year-long civil war known as the \"Year of the Four Emperors\" over the imperial succession.\n\nOriginally named Gaius Octavius, he was born into an old and wealthy equestrian branch of the plebeian gens Octavia. His maternal great-uncle Julius Caesar was assassinated in 44 BC and Octavius was named in Caesar's will as his adopted son and heir; as a result, he inherited Caesar's name, estate, and the loyalty of his legions. He, Mark Antony and Marcus Lepidus formed the Second Triumvirate to defeat the assassins of Caesar. Following their victory at the Battle of Philippi (42 BC), the Triumvirate divided the Roman Republic among themselves and ruled as de facto dictators. The Triumvirate was eventually torn apart by the competing ambitions of its members; Lepidus was exiled in 36 BC and Antony was defeated by Octavian at the Battle of Actium in 31 BC.\n\nAfter the demise of the Second Triumvirate, Augustus restored the outward fa\u00e7ade of the free Republic, with governmental power vested in the Roman Senate, the executive magistrates and the legislative assemblies, yet maintained autocratic authority by having the Senate grant him lifetime tenure as supreme military command, tribune and censor. A similar ambiguity is seen in his chosen names, the implied rejection of monarchical titles whereby he called himself Princeps Civitatis (First Citizen) juxtaposed with his adoption of the ancient title Augustus.\n\nAugustus dramatically enlarged the Empire, annexing Egypt, Dalmatia, Pannonia, Noricum and Raetia, expanding possessions in Africa, and completing the conquest of Hispania, but suffered a major setback in Germania. Beyond the frontiers, he secured the Empire with a buffer region of client states and made peace with the Parthian Empire through diplomacy. He reformed the Roman system of taxation, developed networks of roads with an official courier system, established a standing army, established the Praetorian Guard, official police and fire-fighting services for Rome, and rebuilt much of the city during his reign. Augustus died in AD 14 at the age of 75, probably from natural causes. Persistent rumors, substantiated somewhat by deaths in the imperial family, have claimed his wife Livia poisoned him. He was succeeded as emperor by his adopted son Tiberius, Livia's son and also former husband of Augustus' only biological daughter Julia.\n\nName silent army\u2014ordinary people who \nAs a consequence of Roman customs, society, and personal preference, Augustus ( ) was known by many names throughout his life:\n Gaius Octavius (, ). According to Suetonius, Octavius added the surname Thurinus () to his birth name as an infant in 60 BC. Later, after he had taken the name of Caesar, his rival Mark Antony referred to him as \"Thurinus\" in order to belittle him. In response, he merely said he was surprised that \"using his old name was thought to be an insult\".\n Gaius Julius Caesar Octavianus. He took the name of his adoptive father, Julius Caesar, but was often distinguished from him as \"Octavianus\" (), the adjectival form of \"Octavius\". He is mainly known by the anglicization \"Octavian\" ( ) for the period between 44 and 27 BC. Officially, he seems to have used simply \"Gaius Caesar\", and began styling himself divi filius or  (\"son of the divine Julius\") after the deification of Caesar in 42 BC.\n Imperator Caesar. From 38 BC at the latest, Octavian officially dropped all of his names except \"Caesar\", and began using the victory title imperator (\"commander\") in place of the traditional Roman forename.\n Imperator Caesar Augustus: Following his 31 BC defeat of Mark Antony and Cleopatra, partly on his own insistence, on 16 January 27 BC the Roman Senate granted him the additional name \"Augustus\" (). Historians use this name to refer to him from 27 BC until his death in AD 14.\n\nEarly life \n\nWhile his paternal family was from the Volscian town of Velletri, approximately  to the south-east of Rome, Augustus was born in the city of Rome on 23 September 63\u00a0BC. He was born at Ox Head, a small property on the Palatine Hill, very close to the Roman Forum. He was given the name Gaius Octavius, and in his infancy he received the cognomen Thurinus, possibly commemorating his father's victory at Thurii over a rebellious band of slaves which occurred a few years after his birth. Suetonius wrote: \"There are many indications that the Octavian family was in days of old a distinguished one at Velitrae; for not only was a street in the most frequented part of town long ago called Octavian, but an altar was shown there besides, consecrated by an Octavius. This man was leader in a war with a neighbouring town...\"\n\nDue to the crowded nature of Rome at the time, Octavius was taken to his father's home village at Velletri to be raised. Octavius mentions his father's equestrian family only briefly in his memoirs. His paternal great-grandfather Gaius Octavius was a military tribune in Sicily during the Second Punic War. His grandfather had served in several local political offices. His father, also named Gaius Octavius, had been governor of Macedonia. His mother, Atia, was the niece of Julius Caesar.\n\nIn 59\u00a0BC, when he was four years old, his father died. His mother married a former governor of Syria, Lucius Marcius Philippus. Philippus claimed descent from Alexander the Great, and was elected consul in 56\u00a0BC. Philippus never had much of an interest in young Octavius. Because of this, Octavius was raised by his grandmother, Julia, the sister of Julius Caesar. Julia died in 52 or 51\u00a0BC, and Octavius delivered the funeral oration for his grandmother. \n\nFrom this point, his mother and stepfather took a more active role in raising him. He donned the toga virilis four years later, and was elected to the College of Pontiffs in 47\u00a0BC. The following year he was put in charge of the Greek games that were staged in honor of the Temple of Venus Genetrix, built by Julius Caesar.\n\nAccording to Nicolaus of Damascus, Octavius wished to join Caesar's staff for his campaign in Africa, but gave way when his mother protested. In 46\u00a0BC, she consented for him to join Caesar in Hispania, where he planned to fight the forces of Pompey, Caesar's late enemy, but Octavius fell ill and was unable to travel. When he had recovered, he sailed to the front, but was shipwrecked. After coming ashore with a handful of companions, he crossed hostile territory to Caesar's camp, which impressed his great-uncle considerably. Velleius Paterculus reports that after that time, Caesar allowed the young man to share his carriage. When back in Rome, Caesar deposited a new will with the Vestal Virgins, naming Octavius as the prime beneficiary.\n\nRise to power\n\nHeir to Caesar \n\nOctavius was studying and undergoing military training in Apollonia, Illyria, when Julius Caesar was assassinated on the Ides of March (15 March) 44\u00a0BC. He rejected the advice of some army officers to take refuge with the troops in Macedonia and sailed to Italy to ascertain whether he had any potential political fortunes or security. Caesar had no living legitimate children under Roman law, and so had adopted Octavius, his grand-nephew, making him his primary heir. Mark Antony later charged that Octavian had earned his adoption by Caesar through sexual favours, though Suetonius describes Antony's accusation as political slander. This form of slander was popular during this time in the Roman Republic to demean and discredit political opponents by accusing them of having an inappropriate sexual affair. After landing at Lupiae near Brundisium, Octavius learned the contents of Caesar's will, and only then did he decide to become Caesar's political heir as well as heir to two-thirds of his estate.\n\nUpon his adoption, Octavius assumed his great-uncle's name Gaius Julius Caesar. Roman citizens adopted into a new family usually retained their old nomen in cognomen form (e.g., Octavianus for one who had been an Octavius, Aemilianus for one who had been an Aemilius, etc.). However, though some of his contemporaries did, there is no evidence that Octavius ever himself officially used the name Octavianus, as it would have made his modest origins too obvious. Historians usually refer to the new Caesar as Octavian during the time between", "flag": 1, "segments": [[631, 637]], "strength": 5.5}
{"token_count": [2006], "text": "Allosaurus () is a genus of large carnosaurian theropod dinosaur that lived 155 to 145\u00a0million years ago during the Late Jurassic epoch (Kimmeridgian to late Tithonian). The name \"Allosaurus\" means \"different lizard\" alluding to its unique (at the time of its discovery) concave vertebrae. It is derived from the Greek  () (\"different, other\") and  () (\"lizard / generic reptile\"). The first fossil remains that could definitively be ascribed to this genus were described in 1877 by paleontologist Othniel Charles Marsh. As one of the first well-known theropod dinosaurs, it has long attracted attention outside of paleontological circles.\n\nAllosaurus was a large bipedal predator. Its skull was light, robust and equipped with dozens of sharp, serrated teeth. It averaged  in length for A. fragilis, with the maximum length estimate being 9.7 meters long. Relative to the large and powerful hindlimbs, its three-fingered forelimbs were small, and the body was balanced by a long and heavily muscled tail. It is classified as an allosaurid, a type of carnosaurian theropod dinosaur. \n\nThe genus has a complicated taxonomy, and includes three valid species, the best known of which is A. fragilis. The bulk of Allosaurus remains have come from North America's Morrison Formation, with material also known from Portugal. It was known for over half of the 20th century as Antrodemus, but a study of the copious remains from the Cleveland-Lloyd Dinosaur Quarry brought the name \"Allosaurus\" back to prominence and established it as one of the best-known dinosaurs.\n\nAs the most abundant large predator in the Morrison Formation, Allosaurus was at the top of the food chain, probably preying on contemporaneous large herbivorous dinosaurs, and perhaps other predators. Potential prey included ornithopods, stegosaurids, and sauropods. Some paleontologists interpret Allosaurus as having had cooperative social behavior, and hunting in packs, while others believe individuals may have been aggressive toward each other, and that congregations of this genus are the result of lone individuals feeding on the same carcasses.\n\nDescription\n\nAllosaurus was a typical large theropod, having a massive skull on a short neck, a long, slightly sloping tail, and reduced forelimbs. Allosaurus fragilis, the best-known species, had an average length of, with the largest definitive Allosaurus specimen (AMNH 680) estimated at  long, with an estimated weight of. In his 1976 monograph on Allosaurus, James H. Madsen mentioned a range of bone sizes which he interpreted to show a maximum length of. As with dinosaurs in general, weight estimates are debatable, and since 1980 have ranged between,, and  for modal adult weight (not maximum). John Foster, a specialist on the Morrison Formation, suggests that  is reasonable for large adults of A. fragilis, but that  is a closer estimate for individuals represented by the average-sized thigh bones he has measured. Using the subadult specimen nicknamed \"Big Al\", since assigned to the species Allosaurus jimmadseni, researchers using computer modelling arrived at a best estimate of  for the individual, but by varying parameters they found a range from approximately  to approximately.\n\nSeveral gigantic specimens have been attributed to Allosaurus, but may in fact belong to other genera. The closely related genus Saurophaganax (OMNH 1708) reached perhaps  in length, and its single species has sometimes been included in the genus Allosaurus as Allosaurus maximus, though recent studies support it as a separate genus. Another potential specimen of Allosaurus, once assigned to the genus Epanterias (AMNH 5767), may have measured  in length. A more recent discovery is a partial skeleton from the Peterson Quarry in Morrison rocks of New Mexico; this large allosaurid may be another individual of Saurophaganax.\n\nDavid K. Smith, examining Allosaurus fossils by quarry, found that the Cleveland-Lloyd Dinosaur Quarry (Utah) specimens are generally smaller than those from Como Bluff (Wyoming) or Brigham Young University's Dry Mesa Quarry (Colorado), but the shapes of the bones themselves did not vary between the sites. A later study by Smith incorporating Garden Park (Colorado) and Dinosaur National Monument (Utah) specimens found no justification for multiple species based on skeletal variation; skull variation was most common and was gradational, suggesting individual variation was responsible. Further work on size-related variation again found no consistent differences, although the Dry Mesa material tended to clump together on the basis of the astragalus, an ankle bone. Kenneth Carpenter, using skull elements from the Cleveland-Lloyd site, found wide variation between individuals, calling into question previous species-level distinctions based on such features as the shape of the horns, and the proposed differentiation of A. jimmadseni based on the shape of the jugal. A study published by Motani et al., in 2020 suggests that Allosaurus was also sexually dimorphic in the width of the femur's head against its length.\n\nSkull\n\nThe skull and teeth of Allosaurus were modestly proportioned for a theropod of its size. Paleontologist Gregory S. Paul gives a length of  for a skull belonging to an individual he estimates at  long. Each premaxilla (the bones that formed the tip of the snout) held five teeth with D-shaped cross-sections, and each maxilla (the main tooth-bearing bones in the upper jaw) had between 14 and 17 teeth; the number of teeth does not exactly correspond to the size of the bone. Each dentary (the tooth-bearing bone of the lower jaw) had between 14 and 17 teeth, with an average count of 16. The teeth became shorter, narrower, and more curved toward the back of the skull. All of the teeth had saw-like edges. They were shed easily, and were replaced continually, making them common fossils. Its skull was light, robust and equipped with dozens of sharp, serrated teeth. Its skull averaged  long but could possibly reach.\n\nThe skull had a pair of horns above and in front of the eyes. These horns were composed of extensions of the lacrimal bones, and varied in shape and size. There were also lower paired ridges running along the top edges of the nasal bones that led into the horns. The horns were probably covered in a keratin sheath and may have had a variety of functions, including acting as sunshades for the eyes, being used for display, and being used in combat against other members of the same species (although they were fragile). There was a ridge along the back of the skull roof for muscle attachment, as is also seen in tyrannosaurids.\n\nInside the lacrimal bones were depressions that may have held glands, such as salt glands. Within the maxillae were sinuses that were better developed than those of more basal theropods such as Ceratosaurus and Marshosaurus; they may have been related to the sense of smell, perhaps holding something like Jacobson's organs. The roof of the braincase was thin, perhaps to improve thermoregulation for the brain. The skull and lower jaws had joints that permitted motion within these units. In the lower jaws, the bones of the front and back halves loosely articulated, permitting the jaws to bow outward and increasing the animal's gape. The braincase and frontals may also have had a joint.\n\nPostcranial skeleton\n\nAllosaurus had nine vertebrae in the neck, 14 in the back, and five in the sacrum supporting the hips. The number of tail vertebrae is unknown and varied with individual size; James Madsen estimated about 50, while Gregory S. Paul considered that to be too many and suggested 45 or less. There were hollow spaces in the neck and anterior back vertebrae. Such spaces, which are also found in modern therop be a good possibility. Ifods (that is, the birds), are interpreted as having held air sacs used in respiration. The rib cage was broad, giving it a barrel chest, especially in comparison to less derived theropods like Ceratosaurus. Allosaurus had gastralia (belly ribs), but these are not common findings, and they may have ossified poorly. In one published case, the gastralia show evidence of injury during life. A furcula (wishbone) was also present, but has only been recognized since 1996; in some cases furculae were confused with gastralia. The ilium, the main hip bone, was massive, and the pubic bone had a prominent foot that may have been used for both muscle attachment and as a prop for resting the body on the ground. Madsen noted that in about half of the individuals from the Cleveland-Lloyd Dinosaur Quarry, independent of size, the pubes had not fused to each other at their foot ends. He suggested that this was a sexual characteristic, with females lacking fused bones to make egg-laying easier. This proposal has not attracted further attention, however.\n\nThe forelimbs of Allosaurus were short in comparison to the hindlimbs (only about 35% the length of the hindlimbs in adults) and had three fingers per hand, tipped with large, strongly curved and pointed claws. The arms were powerful, and the forearm was somewhat shorter than the upper arm (1", "flag": 1, "segments": [[1696, 1702]], "strength": 5.5}
{"token_count": [2006], "text": "Ammonia is a compound of nitrogen and hydrogen with the formula NH3. A stable binary hydride, and the simplest pnictogen hydride, ammonia is a colourless gas with a distinct pungent smell. It is a common nitrogenous waste, particularly among aquatic organisms, and it contributes significantly to the nutritional needs of terrestrial organisms by serving as a precursor to 45 percent of the world's food and fertilizers. Ammonia, either directly or indirectly, is also a building block for the synthesis of many pharmaceutical products and is used in many commercial cleaning products. It is mainly collected by downward displacement of both air and water.\n\nAlthough common in natureboth terrestrially and in the outer planets of the Solar Systemand in wide use, ammonia is both caustic and hazardous in its concentrated form. In many countries it is classified as an extremely hazardous substance, and is subject to strict reporting requirements by facilities which produce, store, or use it in significant quantities.\n\nThe global industrial production of ammonia in 2018 was 175 million tonnes, with no significant change relative to the 2013 global industrial production of 175 million tonnes. Industrial ammonia is sold either as ammonia liquor (usually 28% ammonia in water) or as pressurized or refrigerated anhydrous liquid ammonia transported in tank cars or cylinders.\n\nNH3 boils at  at a pressure of one atmosphere, so the liquid must be stored under pressure or at low temperature. Household ammonia or ammonium hydroxide is a solution of NH3 in water. The concentration of such solutions is measured in units of the Baum\u00e9 scale (density), with 26 degrees Baum\u00e9 (about 30% (by weight) ammonia at ) being the typical high-concentration commercial product.\n\nEtymology\nPliny, in Book XXXI of his Natural History, refers to a salt produced in the Roman province of Cyrenaica named hammoniacum, so called because of its proximity to the nearby Temple of Jupiter Amun (Greek \u1f0c\u03bc\u03bc\u03c9\u03bd Ammon). However, the description Pliny gives of the salt does not conform to the properties of ammonium chloride. According to Herbert Hoover's commentary in his English translation of Georgius Agricola's De re metallica, it is likely to have been common sea salt. In any case, that salt ultimately gave ammonia and ammonium compounds their name.\n\nNatural occurrence\nAmmonia is a chemical found in trace quantities in nature, being produced from nitrogenous animal and vegetable matter. Ammonia and ammonium salts are also found in small quantities in rainwater, whereas ammonium chloride (sal ammoniac), and ammonium sulfate are found in volcanic districts; crystals of ammonium bicarbonate have been found in Patagonia guano. The kidneys secrete ammonia to neutralize excess acid. Ammonium salts are found distributed through fertile soil and in seawater.\n\nAmmonia is also found throughout the Solar System on Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto, among other places: on smaller, icy bodies such as Pluto, ammonia can act as a geologically important antifreeze, as a mixture of water and ammonia can have a melting point as low as  if the ammonia concentration is high enough and thus allow such bodies to retain internal oceans and active geology at a far lower temperature than would be possible with water alone. Substances containing ammonia, or those that are similar to it, are called ammoniacal.\n\nProperties\nAmmonia is a colourless gas with a characteristically pungent smell. It is lighter than air, its density being 0.589 times that of air. It is easily liquefied due to the strong hydrogen bonding between molecules; the liquid boils at, and freezes to white crystals at.\n\nSolid The crystal symmetry is cubic, Pearson symbol cP16, space group P213 No.198, lattice constant 0.5125\u00a0nm.\nLiquid Liquid ammonia possesses strong ionising powers reflecting its high \u03b5 of 22. Liquid ammonia has a very high standard enthalpy change of vaporization (23.35\u00a0kJ/mol, cf. water 40.65\u00a0kJ/mol, methane 8.19\u00a0kJ/mol, phosphine 14.6\u00a0kJ/mol) and can therefore be used in laboratories in uninsulated vessels without additional refrigeration. See liquid ammonia as a solvent.\nSolvent properties Ammonia readily dissolves in water. In an aqueous solution, it can be expelled by boiling. The aqueous solution of ammonia is basic. The maximum concentration of ammonia in water (a saturated solution) has a density of 0.880 g/cm3 and is often known as '.880 ammonia'. \nCombustion Ammonia does not burn readily or sustain combustion, except under narrow fuel-to-air mixtures of 15\u201325% air. When mixed with oxygen, it burns with a pale yellowish-green flame. Ignition occurs when chlorine is passed into ammonia, forming nitrogen and hydrogen chloride; if chlorine is present in excess, then the highly explosive nitrogen trichloride (NCl3) is also formed.\nDecomposition At high temperature and in the presence of a suitable catalyst, ammonia is decomposed into its constituent elements. Decomposition of ammonia is a slightly endothermic process requiring 23 kJ/mol (5.5 kcal/mol) of ammonia, and yields hydrogen and nitrogen gas. Ammonia can also be used as a source of hydrogen for acid fuel cells if the unreacted ammonia can be removed. Ruthenium and platinum catalysts were found to be the most active, whereas supported Ni catalysts were the less active.\n\nStructure\nThe ammonia molecule has a trigonal pyramidal shape as predicted by the valence shell electron pair repulsion theory (VSEPR theory) with an experimentally determined bond angle of 106.7\u00b0. The central nitrogen atom has five outer electrons with an additional electron from each hydrogen atom. This gives a total of eight electrons, or four electron pairs that are arranged tetrahedrally. Three of these electron pairs are used as bond pairs, which leaves one lone pair of electrons. The lone pair repels more strongly than bond pairs, therefore the bond angle is not 109.5\u00b0, as expected for a regular tetrahedral arrangement, but 106.8\u00b0. This shape gives the molecule a dipole moment and makes it polar. The molecule's polarity, and especially, its ability to form hydrogen bonds, makes ammonia highly miscible with water. The lone pair makes ammonia a base, a proton acceptor. Ammonia is moderately basic; a 1.0 M aqueous solution has a pH of 11.6, and if a strong acid is added to such a solution until the solution is neutral (pH = 7), 99.4% of the ammonia molecules are protonated. Temperature and salinity also affect the proportion of NH4+. The latter has the shape of a regular tetrahedron and is isoelectronic with methane.\n's decision could pave the way\nThe ammonia molecule readily undergoes nitrogen inversion at room temperature; a useful analogy is an umbrella turning itself inside out in a strong wind. The energy barrier to this inversion is 24.7 kJ/mol, and the resonance frequency is 23.79 GHz, corresponding to microwave radiation of a wavelength of 1.260\u00a0cm. The absorption at this frequency was the first microwave spectrum to be observed  and was used in the first maser.\n\nAmphotericity\nOne of the most characteristic properties of ammonia is its basicity. Ammonia is considered to be a weak base. It combines with acids to form salts; thus with hydrochloric acid it forms ammonium chloride (sal ammoniac); with nitric acid, ammonium nitrate, etc. Perfectly dry ammonia gas will not combine with perfectly dry hydrogen chloride gas; moisture is necessary to bring about the reaction.\n\nAs a demonstration experiment under air with ambient moisture, opened bottles of concentrated ammonia and hydrochloric acid solutions produce a cloud of ammonium chloride, which seems to appear \"out of nothing\" as the salt aerosol forms where the two diffusing clouds of reagents meet between the two bottles.\n\n NH3 + HCl \u2192 NH4Cl\n\nThe salts produced by the action of ammonia on acids are known as the ammonium salts and all contain the ammonium ion (NH4+).\n\nAlthough ammonia is well known as a weak base, it can also act as an extremely weak acid. It is a protic substance and is capable of formation of amides (which contain the NH2\u2212 ion). For example, lithium dissolves in liquid ammonia to give a blue solution (solvated electron) of lithium amide:\n\n 2 Li + 2 NH3 \u2192 2 LiNH2 + H2\n\nSelf-dissociation\nLike water, liquid ammonia undergoes molecular autoionisation to form its acid and base conjugates:\n\n 2    + \n\nAmmonia often functions as a weak base, so it has some buffering ability. Shifts in pH will cause more or fewer ammonium cations () and amide anions () to be present in solution. At standard pressure and temperature, K = [] \u00d7 [] = 10.\n\nCombustion\nThe combustion of ammonia to form nitrogen and water is exothermic:\n\n 4 NH3 + 3 O2 \u2192 2 N2 + 6 H2O (g) \u0394H\u00b0r = \u22121267.20 kJ (or \u2212316.8", "flag": 1, "segments": [[1476, 1482]], "strength": 5.5}
{"token_count": [2006], "text": "Ambrose of Milan (; ), venerated as Saint Ambrose, was the Bishop of Milan, a theologian and statesman. He expressed himself prominently as a public figure, fiercely promoting the Latin Church against Arianism and paganism. He left a substantial collection of writings, of which the best known include the ethical commentary De officiis ministrorum (377\u2013391), and the exegetical  (386\u2013390). His preachings, his actions and his literary works, in addition to his innovative musical hymnography, made him one of the most influential ecclesiastical figures of the 4th century.\n\nAmbrose was serving as the Roman governor of Aemilia-Liguria in Milan when he was unexpectedly made Bishop of Milan in 374 by popular acclamation. As bishop, he took a firm position against Arianism and attempted to mediate the conflict between the emperors Theodosius I and Magnus Maximus. Tradition credits Ambrose with developing an antiphonal chant, known as Ambrosian chant, and for composing the \"Te Deum\" hymn, though modern scholars now reject both of these attributions. Ambrose's authorship on at least four hymns, including the well-known \"Veni redemptor gentium\", is secure; they form the core of the Ambrosian hymns, which includes others that are sometimes attributed to him. He also had notable influence on Augustine of Hippo (354\u2013430), particularly in converting him to Christianity.\n\nBefore the 16th century, Western Christianity identified Ambrose as one of its four traditional Doctors of the Church. He is considered a saint by the Catholic Church, Eastern Orthodox Church, Anglican Communion, and various Lutheran denominations, and venerated as the patron saint of Milan and beekeepers.\n\nLife and background \n\nLegends about Ambrose had spread through the empire long before his biography was written, making it difficult for modern historians to understand his true character and fairly place his behavior within the context of antiquity. Most agree he was the personification of his era. As such, Ambrose was a genuinely spiritual man who spoke up and defended his faith against opponents, an aristocrat who retained many of the attitudes and practices of a Roman governor, while also being an ascetic who served the poor.\n\nEarly life \n\nAmbrose was born into a Roman Christian family in the year 339. Ambrose himself wrote that he was 53 years old in his letter number 49 which has been dated to 392. He began life in Augusta Trevorum (modern Trier) the capitol of the Roman province of Gallia Belgica in what was then northeastern Gaul and is now modern Germany. Who exactly his father was is disagreed upon by scholars. His father is sometimes identified with Aurelius Ambrosius, a praetorian prefect of Gaul; but some scholars identify his father as an official named Uranius who received an imperial constitution dated 3 February 339 (addressed in a brief extract from one of the three emperors ruling in 339, Constantine II, Constantius II, or Constans, in the Codex Theodosianus, book XI.5). What does seem certain is that Ambrose was born in Trier Snowboarding Festival 2018 here on and his father was either the praetorian prefect or part of his administration. There is a legend about Ambrose as an infant contending that a swarm of bees settled on his face while he lay in his cradle, leaving behind a drop of honey. His father is said to have considered this a sign of his future eloquence and honeyed tongue. For this reason, bees and beehives often appear in the saint's symbology.\n\nAmbrose' mother was a woman of intellect and piety. It is probable she was a member of the Roman family Aurelii Symmachi, and thus Ambrose was cousin of the orator Quintus Aurelius Symmachus.  The family had produced one martyr (the virgin Soteris) in its history.  Ambrose was the youngest of three children. His siblings were Satyrus, the subject of Ambrose's De excessu fratris Satyri,  and Marcellina, who made a profession of virginity sometime between 352 and 355; Pope Liberius himself conferred the veil upon her. Both Ambrose's siblings also became venerated as saints. \n\nSome time early in the life of Ambrose, his father died, and at an unknown later date, his mother fled Trier with her three children, whereupon the family moved to Rome. There Ambrose studied literature, law, and rhetoric. He then followed in his father's footsteps and entered public service. Praetorian Prefect Sextus Claudius Petronius Probus first gave him a place as his council, and then in about 372 made him governor of Liguria and Emilia, with headquarters at Milan.\n\nBishop of Milan \nIn 374 the bishop of Milan, Auxentius, an Arian, died, and the Arians challenged the succession. Ambrose went to the church where the election was to take place to prevent an uproar which was probable in this crisis. His address was interrupted by a call, \"Ambrose, bishop!\", which was taken up by the whole assembly.\n\nAmbrose was known to be Nicene Christian in belief, but he was considered acceptable to Arians due to the charity he had shown in theological matters in this regard. At first he energetically refused the office, for which he felt he was in no way prepared: Ambrose was a relatively new Christian who was not yet baptized nor formally trained in theology. Ambrose fled to a colleague's home seeking to hide. Upon receiving a letter from the Emperor Gratian praising the appropriateness of Rome appointing individuals worthy of holy positions, Ambrose's host gave him up. Within a week, he was baptized, ordained and duly consecrated as the next bishop of Milan. This was the first time in the West that a member of the upper class of high officials had accepted the office of bishop.\n\nAs bishop, he immediately adopted an ascetic lifestyle, apportioned his money to the poor, donating all of his land, making only provision for his sister Marcellina. This raised his popularity even further; it was his popularity with the people that gave him considerable political leverage throughout his career. Upon the unexpected appointment of Ambrose to the episcopate, his brother Satyrus resigned a prefecture in order to move to Milan, where he took over managing the diocese's temporal affairs.\n\nArianism \nArius was a Christian priest who asserted (around the year 300) that God the Father must have created the Son, making the Son a lesser being who was not eternal and of a different \"essence\" than God the Father was. This Christology was contrary to tradition, yet it quickly spread through Egypt and Libya and the other Roman provinces. Bishops engaged in \"wordy warfare,\" and the people divided into parties, sometimes demonstrating in the streets in support of one side or the other. \n\nArianism appealed to many high level leaders and clergy in both the Western and Eastern empires. Although the western Emperor Gratian supported orthodoxy, the younger Valentinian II, who became his colleague in the Empire, adhered to the Arian creed. Ambrose sought to theologically refute Arian propositions, but Ambrose did not sway the young prince's position. In the East, Emperor Theodosius I likewise professed the Nicene creed; but there were many adherents of Arianism throughout his dominions, especially among the higher clergy. \n\nIn this state of religious ferment, two leaders of the Arians, bishops Palladius of Ratiaria and Secundianus of Singidunum, confident of numbers, prevailed upon Gratian to call a general council from all parts of the empire. This request appeared so equitable that he complied without hesitation. However, Ambrose feared the consequences and prevailed upon the emperor to have the matter determined by a council of the Western bishops. Accordingly, a synod composed of thirty-two bishops was held at Aquileia in the year 381. Ambrose was elected president and Palladius, being called upon to defend his opinions, declined. A vote was then taken and Palladius and his associate Secundianus were deposed from their episcopal offices.\n\nAmbrose struggled with Arianism for over half of his life in the episcopate. Unifying the church was important to the church, but it was no less important to the state, and as a Roman, Ambrose felt strongly about that. Judaism was more attractive for those seeking conversion than previous scholars have realized, and pagans were still in the majority, so the edition of heresy created an age of religious ferment comparable to the Reformation of the fourteenth and fifteenth centuries. Orthodox Christianity was determining how to define itself as it faced multiple challenges on both a theological and a practical level, and Ambrose is seen as a crucial influence at a crucial time.\n\nImperial relations \nAmbrose had good relations and varying levels of influence with the Roman emperors Gratian, Valentinian II and Theodosius I, but exactly how much influence, what kind of influence, and in what ways, when, has been debated in the scholarship of the late twentieth and early twenty-first centuries.\n\nGratian\nIt has long been convention to see Gratian and Ambrose as having a personal friendship, putting Ambrose in the dominant role of spiritual guide, but modern scholars now find this view hard to support in the sources. The ancient Christian historian Sozomen is the only ancient source that shows Ambrose and Gratian together in any personal interaction. In that", "flag": 1, "segments": [[662, 668]], "strength": 5.5}
{"token_count": [2006], "text": "AOL (stylized as Aol., formerly a company known as AOL Inc. and originally known as America Online) is an American web portal and online service provider based in New York City. It is a brand marketed by the current incarnation of Yahoo! Inc.\n\nThe service traces its history to an online service known as PlayNET. PlayNET licensed its software to Quantum Link (Q-Link), who went online in November 1985 You\u2019ll also get. A new IBM PC client launched in 1988, eventually renamed as America Online in 1989. AOL grew to become the largest online service, displacing established players like CompuServe and The Source. By 1995, AOL had about three million active users.\n\nAOL was one of the early pioneers of the Internet in the mid-1990s, and the most recognized brand on the web in the United States. It originally provided a dial-up service to millions of Americans, as well as providing a web portal, e-mail, instant messaging and later a web browser following its purchase of Netscape. In 2001, at the height of its popularity, it purchased the media conglomerate Time Warner in the largest merger in U.S. history. AOL rapidly shrank thereafter, partly due to the decline of dial-up and rise of broadband. AOL was eventually spun off from Time Warner in 2009, with Tim Armstrong appointed the new CEO. Under his leadership, the company invested in media brands and advertising technologies.\n\nOn June 23, 2015, AOL was acquired by Verizon Communications for $4.4\u00a0billion. On May 3, 2021, Verizon announced it would sell Yahoo and AOL to private equity firm Apollo Global Management for $5 billion.\n\nHistory\n\n1983\u20131991: Early years \nAOL began in 1983, as a short-lived venture called Control Video Corporation (or CVC), founded by William von Meister. Its sole product was an online service called GameLine for the Atari 2600 video game console, after von Meister's idea of buying music on demand was rejected by Warner Bros. Subscribers bought a modem from the company for US$49.95 and paid a one-time US$15 setup fee. GameLine permitted subscribers to temporarily download games and keep track of high scores, at a cost of US$1 per game. The telephone disconnected and the downloaded game would remain in GameLine's Master Module and playable until the user turned off the console or downloaded another game.\n\nIn January 1983, Steve Case was hired as a marketing consultant for Control Video on the recommendation of his brother, investment banker Dan Case. In May 1983, Jim Kimsey became a manufacturing consultant for Control Video, which was near bankruptcy. Kimsey was brought in by his West Point friend Frank Caufield, an investor in the company. In early 1985, von Meister left the company.\n\nOn May 24, 1985, Quantum Computer Services, an online services company, was founded by Jim Kimsey from the remnants of Control Video, with Kimsey as chief executive officer, and Marc Seriff as chief technology officer. The technical team consisted of Marc Seriff, Tom Ralston, Ray Heinrich, Steve Trus, Ken Huntsman, Janet Hunter, Dave Brown, Craig Dykstra, Doug Coward, and Mike Ficco. In 1987, Case was promoted again to executive vice-president. Kimsey soon began to groom Case to take over the role of CEO, which he did when Kimsey retired in 1991.\n\nKimsey changed the company's strategy, and in 1985, launched a dedicated online service for Commodore 64 and 128 computers, originally called Quantum Link (\"Q-Link\" for short). The Quantum Link software was based on software licensed from PlayNet, Inc, (founded in 1983 by Howard Goldberg and Dave Panzl). The service was different from other online services as it used the computing power of the Commodore 64 and the Apple II rather than just a \"dumb\" terminal. It passed tokens back and forth and provided a fixed price service tailored for home users. In May 1988, Quantum and Apple launched AppleLink Personal Edition for Apple II and Macintosh computers. In August 1988, Quantum launched PC Link, a service for IBM-compatible PCs developed in a joint venture with the Tandy Corporation. After the company parted ways with Apple in October 1989, Quantum changed the service's name to America Online.  Case promoted and sold AOL as the online service for people unfamiliar with computers, in contrast to CompuServe, which was well established in the technical community.\n\nFrom the beginning, AOL included online games in its mix of products; many classic and casual games were included in the original PlayNet software system. In the early years of AOL the company introduced many innovative online interactive titles and games, including:\n Graphical chat environments Habitat (1986\u20131988) and Club Caribe (1988) from LucasArts.\n The first online interactive fiction series QuantumLink Serial by Tracy Reed (1988).\n Quantum Space, the first fully automated play-by-mail game (1989\u20131991).\n\n1991\u20132006: Internet age, Time Warner merger \n\nIn February 1991, AOL for DOS was launched using a GeoWorks interface followed a year later by AOL for Windows. This coincided with growth in pay-based online services, like Prodigy, CompuServe, and GEnie. 1991 also saw the introduction of an original Dungeons & Dragons title called Neverwinter Nights from Stormfront Studios; which was one of the first Multiplayer Online Role Playing Games to depict the adventure with graphics instead of text.\n\nDuring the early 1990s, the average subscription lasted for about 25 months and accounted for $350 in total revenue. Advertisements invited modem owners to \"Try America Online FREE\", promising free software and trial membership. AOL discontinued Q-Link and PC Link in late 1994. In September 1993, AOL added Usenet access to its features. This is commonly referred to as the \"Eternal September\", as Usenet's cycle of new users was previously dominated by smaller numbers of college and university freshmen gaining access in September and taking a few weeks to acclimate. This also coincided with a new \"carpet bombing\" marketing campaign by CMO Jan Brandt to distribute as many free trial AOL trial disks as possible through nonconventional distribution partners. At one point, 50% of the CDs produced worldwide had an AOL logo. AOL quickly surpassed GEnie, and by the mid-1990s, it passed Prodigy (which for several years allowed AOL advertising) and CompuServe.\n\nOver the next several years, AOL launched services with the National Education Association, the American Federation of Teachers, National Geographic, the Smithsonian Institution, the Library of Congress, Pearson, Scholastic, ASCD, NSBA, NCTE, Discovery Networks, Turner Education Services (CNN Newsroom), NPR, The Princeton Review, Stanley Kaplan, Barron's, Highlights for Kids, the U.S. Department of Education, and many other education providers. AOL offered the first real-time homework help service (the Teacher Pager\u20141990; prior to this, AOL provided homework help bulletin boards), the first service by children, for children (Kids Only Online, 1991), the first online service for parents (the Parents Information Network, 1991), the first online courses (1988), the first omnibus service for teachers (the Teachers' Information Network, 1990), the first online exhibit (Library of Congress, 1991), the first parental controls, and many other online education firsts.\n\nAOL purchased search engine WebCrawler in 1995, but sold it to Excite the following year; the deal made Excite the sole search and directory service on AOL. After the deal closed in March 1997, AOL launched its own branded search engine, based on Excite, called NetFind. This was renamed to AOL Search in 1999.\n\nAOL charged its users an hourly fee until December 1996, when the company changed to a flat monthly rate of $19.95. During this time, AOL connections were flooded with users trying to connect, and many canceled their accounts due to constant busy signals. A commercial was made featuring Steve Case telling people AOL was working day and night to fix the problem. Within three years, AOL's user base grew to 10\u00a0million people. In 1995 AOL was headquartered at 8619 Westwood Center Drive in the Tysons Corner CDP in unincorporated Fairfax County, Virginia, near the Town of Vienna.\n\nAOL was quickly running out of room in October 1996 for its network at the Fairfax County campus. In mid-1996, AOL moved to 22000 AOL Way in Dulles, unincorporated Loudoun County, Virginia to provide room for future growth. In a five-year landmark agreement with the most popular operating system, AOL was bundled with Windows software.\n\nOn March 31, 1996, the short-lived eWorld was purchased by AOL. In 1997, about half of all U.S. homes with Internet access had it through AOL. During this time, AOL's content channels, under Jason Seiken, including News, Sports, and Entertainment, experienced their greatest growth as AOL become the dominant online service internationally with more than 34\u00a0million subscribers. In November 1998, AOL announced it would acquire Netscape, best known for their web browser, in a major $4.2\u00a0billion deal. The deal closed on March 17, 1999. Another large acquisition in December 1999 was that of MapQuest, for $1.1\u00a0billion.\n\nIn January 2000, as new broadband technologies were being rolled out around NYC metropolitan area, and the U.S., AOL and Time Warner announced plans to merge, forming AOL Time Warner, Inc. The terms of the deal called for AOL shareholders to", "flag": 1, "segments": [[89, 95]], "strength": 5.5}
{"token_count": [2006], "text": "The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which succeeded in preparing and landing the first humans on the Moon from 1968 to 1972. It was first conceived during Dwight D. Eisenhower's administration as a three-person spacecraft to follow the one-person Project Mercury, which put the first Americans in space. Apollo was later dedicated to President John F. Kennedy's national goal for the 1960s of \"landing a man on the Moon and returning him safely to the Earth\" in an address to Congress on May 25, 1961. It was the third US human spaceflight program to fly, preceded by the two-person Project Gemini conceived in 1961 to extend spaceflight capability in support of Apollo.\n\nKennedy's goal was accomplished on the Apollo 11 mission when astronauts Neil Armstrong and Buzz Aldrin landed their Apollo Lunar Module (LM) on July 20, 1969, and walked on the lunar surface, while Michael Collins remained in lunar orbit in the command and service module (CSM), and all three landed safely on Earth on July 24. Five subsequent Apollo missions also landed astronauts on the Moon, the last, Apollo 17, in December 1972. In these six spaceflights, twelve people walked on the Moon.\n\nApollo ran from 1961 to 1972, with the first crewed flight in 1968. It encountered a major setback in 1967 when an Apollo 1 cabin fire killed the entire crew during a prelaunch test. After the first successful landing, sufficient flight hardware remained for nine follow-on landings with a plan for extended lunar geological and astrophysical exploration. Budget cuts forced the cancellation of three of these. Five of the remaining six missions achieved successful landings, but the Apollo 13 landing was prevented by an oxygen tank explosion in transit to the Moon, which destroyed the service module's capability to provide electrical power, crippling the CSM's propulsion and life support systems. The crew returned to Earth safely by using the lunar module as a \"lifeboat\" for these functions. Apollo used the Saturn family of rockets as launch vehicles, which were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three crewed missions in 1973\u20131974, and the Apollo\u2013Soyuz Test Project, a joint United States-Soviet Union low Earth orbit mission in 1975.\n\nApollo set several major human spaceflight milestones. It stands alone in sending crewed missions beyond low Earth orbit. Apollo 8 was the first crewed spacecraft to orbit another celestial body, and Apollo 11 was the first crewed spacecraft to land humans on one.\n\nOverall the Apollo program returned  of lunar rocks and soil to Earth, greatly contributing to the understanding of the Moon's composition and geological history. The program laid the foundation for NASA's subsequent human spaceflight capability, and funded construction of its Johnson Space Center and Kennedy Space Center. Apollo also spurred advances in many areas of technology incidental to rocketry and human spaceflight, including avionics, telecommunications, and computers.\n\nBackground\n\nOrigin and spacecraft feasibility studies\n\nThe Apollo program was conceived during the Eisenhower administration in early 1960, as a follow-up to Project Mercury. While the Mercury capsule could support only one astronaut on a limited Earth orbital mission, Apollo would carry three. Possible missions included ferrying crews to a space station, circumlunar flights, and eventual crewed lunar landings.\n\nThe program was named after Apollo, the Greek god of light, music, and the Sun, by NASA manager Abe Silverstein, who later said, \"I was naming the spacecraft like I'd name my baby.\" Silverstein chose the name at home one evening, early in 1960, because he felt \"Apollo riding his chariot across the Sun was appropriate to the grand scale of the proposed program.\"\n\nIn July 1960, NASA Deputy Administrator Hugh L. Dryden announced the Apollo program to industry representatives at a series of Space Task Group conferences. Preliminary specifications were laid out for a spacecraft with a mission module cabin separate from the command module (piloting and reentry cabin), and a propulsion and equipment module. On August 30, a feasibility study competition was announced, and on October 25, three study contracts were awarded to General Dynamics/Convair, General Electric, and the Glenn L. Martin Company. Meanwhile, NASA performed its own in-house spacecraft design studies led by Maxime Faget, to serve as a gauge to judge and monitor the three industry designs.\n\nPolitical pressure builds\n\nIn November 1960, John F. Kennedy was elected president after a campaign that promised American superiority over the Soviet Union in the fields of space exploration and missile defense. Up to the election of 1960, Kennedy had been speaking out against the \"missile gap\" that he and many other senators felt had developed between the Soviet Union and the United States due to the inaction of President Eisenhower. Beyond military power, Kennedy used aerospace technology as a symbol of national prestige, pledging to make the US not \"first but, first and, first if, but2) the movement claims is first period\". Despite Kennedy's rhetoric, he did not immediately come to a decision on the status of the Apollo program once he became president. He knew little about the technical details of the space program, and was put off by the massive financial commitment required by a crewed Moon landing. When Kennedy's newly appointed NASA Administrator James E. Webb requested a 30 percent budget increase for his agency, Kennedy supported an acceleration of NASA's large booster program but deferred a decision on the broader issue.\n\nOn April 12, 1961, Soviet cosmonaut Yuri Gagarin became the first person to fly in space, reinforcing American fears about being left behind in a technological competition with the Soviet Union. At a meeting of the US House Committee on Science and Astronautics one day after Gagarin's flight, many congressmen pledged their support for a crash program aimed at ensuring that America would catch up. Kennedy was circumspect in his response to the news, refusing to make a commitment on America's response to the Soviets.\n\nOn April 20, Kennedy sent a memo to Vice President Lyndon B. Johnson, asking Johnson to look into the status of America's space program, and into programs that could offer NASA the opportunity to catch up. Johnson responded approximately one week later, concluding that \"we are neither making maximum effort nor achieving results necessary if this country is to reach a position of leadership.\" His memo concluded that a crewed Moon landing was far enough in the future that it was likely the United States would achieve it first.\n\nOn May 25, 1961, twenty days after the first US crewed spaceflight Freedom 7, Kennedy proposed the crewed Moon landing in a Special Message to the Congress on Urgent National Needs:\n\nNASA expansion\nAt the time of Kennedy's proposal, only one American had flown in space\u2014less than a month earlier\u2014and NASA had not yet sent an astronaut into orbit. Even some NASA employees doubted whether Kennedy's ambitious goal could be met. By 1963, Kennedy even came close to agreeing to a joint US-USSR Moon mission, to eliminate duplication of effort.\n\nWith the clear goal of a crewed landing replacing the more nebulous goals of space stations and circumlunar flights, NASA decided that, in order to make progress quickly, it would discard the feasibility study designs of Convair, GE, and Martin, and proceed with Faget's command and service module design. The mission module was determined to be useful only as an extra room, and therefore unnecessary. They used Faget's design as the specification for another competition for spacecraft procurement bids in October 1961. On November 28, 1961, it was announced that North American Aviation had won the contract, although its bid was not rated as good as Martin's. Webb, Dryden and Robert Seamans chose it in preference due to North American's longer association with NASA and its predecessor.\n\nLanding humans on the Moon by the end of 1969 required the most sudden burst of technological creativity, and the largest commitment of resources ($25\u00a0billion; $ in  US dollars) ever made by any nation in peacetime. At its peak, the Apollo program employed 400,000 people and required the support of over 20,000 industrial firms and universities.\n\nOn July 1, 1960, NASA established the Marshall Space Flight Center (MSFC) in Huntsville, Alabama. MSFC designed the heavy lift-class Saturn launch vehicles, which would be required for Apollo.\n\nManned Spacecraft Center\n\nIt became clear that managing the Apollo program would exceed the capabilities of Robert R. Gilruth's Space Task Group, which had been directing the nation's crewed space program from NASA's Langley Research Center. So Gilruth was given authority to grow his organization into a new NASA center, the Manned Spacecraft Center (MSC). A site was chosen in Houston, Texas, on land donated by Rice University, and Administrator Webb announced the conversion on September 19, 1961. It was also clear NASA would soon outgrow its practice of controlling missions from its Cape Canaveral Air Force Station launch facilities in Florida, so a new Mission Control Center would be included in the MSC.\n\nIn September 1962, by which time two Project Mercury astronauts had orbited the Earth, Gilruth had moved his organization to rented space in Houston, and construction of the MSC facility was under way, Kennedy visited Rice to reiterate his challenge in a famous speech:\n\nThe MSC was completed in September 1963. It was renamed by the US Congress in honor of Lyndon Johnson soon after his death in 1973.\n\nLaunch Operations Center\n\nIt also became clear that Apollo would outgrow the Canaveral launch facilities in Florida", "flag": 1, "segments": [[1042, 1048]], "strength": 5.5}
{"token_count": [2006], "text": "Alfred Russel Wallace  (8 January 18237 November 1913) was a British naturalist, explorer, geographer, anthropologist, biologist and illustrator. He is best known for independently conceiving the theory of evolution through natural selection; his paper on the subject was jointly published with some of Charles Darwin's writings in 1858. This prompted Darwin to publish On the Origin of Species.\n\nLike Darwin, Wallace did extensive fieldwork\u2014first in the Amazon River basin, and then in the Malay Archipelago, where he identified the faunal divide now termed the Wallace Line, which separates the Indonesian archipelago into two distinct parts: a western portion in which the animals are largely of Asian origin, and an eastern portion where the fauna reflect Australasia. He was considered the 19th century's leading expert on the geographical distribution of animal species and is sometimes called the \"father of biogeography\".\n\nWallace was one of the leading evolutionary thinkers of the 19th century and made many other contributions to the development of evolutionary theory besides being co-discoverer of natural selection. These included the concepts of warning colouration in animals, and reinforcement (sometimes known as the Wallace effect), a hypothesis on how natural selection could contribute to speciation by encouraging the development of barriers against hybridisation. Wallace's 1904 book Man's Place in the Universe was the first serious attempt by a biologist to evaluate the likelihood of life on other planets. He was also one of the first scientists to write a serious exploration of the subject of whether there was life on Mars.\n\nAside from scientific work, he was a social activist who was critical of what he considered to be an unjust social and economic system (capitalism) in 19th-century Britain. His advocacy of spiritualism and his belief in a non-material origin for the higher mental faculties of humans strained his relationship with some members of the scientific establishment.  His interest in natural history resulted in his being one of the first prominent scientists to raise concerns over the environmental impact of human activity. He was also a prolific author who wrote on both scientific and social issues; his account of his adventures and observations during his explorations in Singapore, Indonesia and Malaysia, The Malay Archipelago, was both popular and highly regarded. Since its publication in 1869, it has never been out of print.\n\nBiography\n\nEarly life\nAlfred Russel Wallace was born on 8 January 1823 in Llanbadoc, Monmouthshire. He was the eighth of nine children born to Mary Anne Wallace (n\u00e9e Greenell) and Thomas Vere Wallace. His mother was English, while his father was probably of Scottish ancestry. His family, like many Wallaces, claimed a connection to William Wallace, a leader of Scottish forces during the Wars of Scottish Independence in the 13th century. \n\nThomas graduated in law but never practised law. He owned some income-generating property, but bad investments and failed business ventures resulted in a steady deterioration of the family's financial position. His mother was from a middle-class Hertford-based family. When Wallace, three and-one blocks was five years old, his family moved to Hertford. There he attended Hertford Grammar School until financial difficulties forced his family to withdraw him in 1836 when he was aged 14.\n\nWallace then moved to London to board with his older brother John, a 19-year-old apprentice builder. This was a stopgap measure until William, his oldest brother, was ready to take him on as an apprentice surveyor. While in London, Alfred attended lectures and read books at the London Mechanics Institute (current Birkbeck, University of London). Here he was exposed to the radical political ideas of the Welsh social reformer Robert Owen and of Thomas Paine. He left London in 1837 to live with William and work as his apprentice for six years. At the end of 1839, they moved to Kington, Herefordshire, near the Welsh border, before eventually settling at Neath in Wales. Between 1840 and 1843, Wallace did land surveying work in the countryside of the west of England and Wales. By the end of 1843, William's business had declined due to difficult economic conditions, and Wallace, at the age of 20, left in January.\n\nOne result of Wallace's early travels is a modern controversy about his nationality. Since Wallace was born in Monmouthshire, some sources have considered him to be Welsh. However, some historians have questioned this because neither of his parents was Welsh, his family only briefly lived in Monmouthshire, the Welsh people Wallace knew in his childhood considered him to be English, and because Wallace himself consistently referred to himself as English rather than Welsh (even when writing about his time in Wales). One Wallace scholar has stated that the most reasonable interpretation is therefore that he was an Englishman born in Wales.\n\nAfter a brief period of unemployment, he was hired as a master at the Collegiate School in Leicester to teach drawing, mapmaking, and surveying. Wallace spent many hours at the library in Leicester: he read An Essay on the Principle of Population by Thomas Robert Malthus, and one evening he met the entomologist Henry Bates. Bates was 19 years old, and in 1843 he had published a paper on beetles in the journal Zoologist. He befriended Wallace and started him collecting insects. His brother William died in March 1845, and Wallace left his teaching position to assume control of his brother's firm in Neath, but his brother John and he were unable to make the business work. After a few months, Wallace found work as a civil engineer for a nearby firm that was working on a survey for a proposed railway in the Vale of Neath.\n\nWallace's work on the survey involved spending a lot of time outdoors in the countryside, allowing him to indulge his new passion for collecting insects. Wallace persuaded his brother John to join him in starting another architecture and civil engineering firm, which carried out a number of projects, including the design of a building for the Neath Mechanics' Institute, founded in 1843. William Jevons, the founder of that institute, was impressed by Wallace and persuaded him to give lectures there on science and engineering. In the autumn of 1846, John and he purchased a cottage near Neath, where they lived with their mother and sister Fanny (his father had died in 1843).\n\nDuring this period, he read avidly, exchanging letters with Bates about Robert Chambers' anonymously published evolutionary treatise Vestiges of the Natural History of Creation, Charles Darwin's The Voyage of the Beagle, and Charles Lyell's Principles of Geology.\n\nExploration and study of the natural world\n\nInspired by the chronicles of earlier and contemporary travelling naturalists, including Alexander von Humboldt, Ida Laura Pfeiffer, Charles Darwin and especially William Henry Edwards, Wallace decided that he too wanted to travel abroad as a naturalist. In 1848, Wallace and Henry Bates left for Brazil aboard the Mischief. Their intention was to collect insects and other animal specimens in the Amazon Rainforest for their private collections, selling the duplicates to museums and collectors back in Britain in order to fund the trip. Wallace also hoped to gather evidence of the transmutation of species.\n\nWallace and Bates spent most of their first year collecting near Bel\u00e9m, then explored inland separately, occasionally meeting to discuss their findings. In 1849, they were briefly joined by another young explorer, botanist Richard Spruce, along with Wallace's younger brother Herbert. Herbert left soon thereafter (dying two years later from yellow fever), but Spruce, like Bates, would spend over ten years collecting in South America.\n\nWallace continued charting the Rio Negro for four years, collecting specimens and making notes on the peoples and languages he encountered as well as the geography, flora, and fauna. On 12 July 1852, Wallace embarked for the UK on the brig Helen. After 25 days at sea, the ship's cargo caught fire and the crew was forced to abandon ship. All of the specimens Wallace had on the ship, mostly collected during the last, and most interesting, two years of his trip, were lost. He managed to save a few notes and pencil sketches and little else.\n\nWallace and the crew spent ten days in an open boat before being picked up by the brig Jordeson, which was sailing from Cuba to London. The Jordeson'''s provisions were strained by the unexpected passengers, but after a difficult passage on very short rations the ship finally reached its destination on 1 October 1852.Slotten pp. 84\u201388\n\nAfter his return to the UK, Wallace spent 18 months in London living on the insurance payment for his lost collection and selling a few specimens that had been shipped back to Britain prior to his starting his exploration of the Rio Negro until the Indian town of Jativa on Orinoco River basin and as far west as Mic\u00faru (Mit\u00fa) on the Vaup\u00e9s River. He was deeply impressed by the grandeur of the virgin forest, by the variety and beauty of the butterflies and birds, and by his first encounter with Indians on the Vaup\u00e9s River area, an experience he never forgot. During this period, despite having lost almost all of the notes from his South American expedition, he wrote six academic papers (which included \"On the Monkeys of the Amazon\") and two books; Palm Trees of the Amazon and Their Uses and Travels on the Amazon. He also made connections with a number of other British naturalists.Raby, Bright Paradise p. 148.\n\nFrom 1854 to 1862, age 31 to 39, Wallace travelled", "flag": 1, "segments": [[638, 644]], "strength": 5.5}
{"token_count": [2006], "text": "Aachen (; Aachen dialect: Oche ; French and traditional English: Aix-la-Chapelle;  or Aquisgranum; ) is, with around 249,000 inhabitants, the 13th-largest city in North Rhine-Westphalia, and the 28th-largest city of Germany.\n\nIt is the westernmost city in Germany, and borders Belgium and the Netherlands to the west, the Tri-border area. It is located between Maastricht (NL) and Li\u00e8ge (BE) in the west, and Bonn and Cologne, in the east. The Wurm River flows through the city, and together with M\u00f6nchengladbach, Aachen is the only larger German city in the drainage basin of the Meuse. Aachen is the seat of the City Region Aachen ().\n\nAachen developed from a Roman settlement and thermae (bath complex), subsequently becoming the preferred medieval Imperial residence of Emperor Charlemagne of the Frankish Empire, and, from 936 to 1531, the place where 31 Holy Roman Emperors were crowned Kings of the Germans.\n\nOne of Germany's leading institutes of higher education in technology, the RWTH Aachen University (Rheinisch-Westf\u00e4lisch Technische Hochschule Aachen), is located in the city. Its university hospital Uniklinik RWTH Aachen is Europe's largest single-building hospital. Aachen's industries include science, engineering and information technology. In 2009, Aachen was ranked eighth among cities in Germany for innovation.\n\nThe regional dialect spoken in the city is a Central Franconian, Ripuarian variant with strong Limburgish influences from the dialects in the neighbouring Netherlands. As a Rhenish city, Aachen is one of the main centres of carnival celebrations in Germany, along with Cologne, Mainz and D\u00fcsseldorf. The culinary speciality the city is best known for are Aachener Printen, a type of gingerbread.\n\nHistory\n\nEarly history \nFlint quarries on the Lousberg, Schneeberg, and K\u00f6nigsh\u00fcgel, first used during Neolithic times (3000\u20132500 BC), attest to the long occupation of the site of Aachen, as do recent finds under the modern city's Elisengarten pointing to a former settlement from the same period. Bronze Age (around 1600 BC) settlement is evidenced by the remains of barrows (burial mounds) found, for example, on the Klausberg. During the Iron Age, the area was settled by Celtic peoples who were perhaps drawn by the marshy Aachen basin's hot sulphur springs where they worshipped Grannus, god of light and healing.\n\nLater, the 25-hectare Roman spa resort town of Aquae Granni was, according to legend, founded by Grenus, under Hadrian, around 124 AD. Instead, the fictitious founder refers to the Celtic god, and it seems it was the Roman 6th Legion at the start of the 1st century AD that first channelled the hot springs into a spa at B\u00fcchel, adding at the end of the same century the M\u00fcnstertherme spa, two water pipelines, and a probable sanctuary dedicated to Grannus. A kind of forum, surrounded by colonnades, connected the two spa complexes. There was also an extensive residential area, part of it inhabited by a flourishing Jewish community. The Romans built bathhouses near Burtscheid. A temple precinct called Vernenum was built near the modern Kornelim\u00fcnster/Walheim. Today, remains have been found of three bathhouses, including two fountains in the Elisenbrunnen and the Burtscheid bathhouse.\n\nRoman civil administration in Aachen eventually broke down as the baths and other public buildings (along with most of the villae rusticae of the surrounding countryside) were destroyed around AD 375 at the start of the migration period. The last Roman coin finds are from the time of Emperor Gratian (AD 375\u2013383). Rome withdrew its troops from the area, but the town remained populated. By 470, the town came to be ruled by the Ripuarian Franks and subordinated to their capital, Cologne.\n\nEtymology \nThe name Aachen is a modern descendant, like southern German,, meaning \"river\" or \"stream\", from Old High German, meaning \"water\" or \"stream\", which directly translates (and etymologically corresponds) to Latin, referring to the springs. The location has been inhabited by humans since the Neolithic era, about 5,000 years ago, attracted to its warm mineral springs. Latin  figures in Aachen's Roman name, which meant \"waters of Grannus\", referring to the Celtic god of healing who was worshipped at the springs. This word became  in Walloon and  in French, and subsequently  after Charlemagne had his palatine chapel built there in the late 8th century and then made the city his empire's capital.\n\nAs a spa city, Aachen has the right to name itself Bad Aachen, but chooses not to, so it remains on the top of alphabetical lists.\n\nAachen's name in French and German evolved in parallel. The city is known by a variety of different names in other languages:\n\nDialect \nAachen is at the western end of the Benrath line that divides High German to the south from the rest of the West Germanic speech area to the north. Aachen's local dialect is called  and belongs to the Ripuarian language.\n\nMiddle Ages \n\nAfter Roman times, Pepin the Short had a castle residence built in the town, due to the proximity of the hot springs and also for strategic reasons as it is located between the Rhineland and northern France. Einhard mentions that in 765\u20136 Pepin spent both Christmas and Easter at Aquis villa (), (\"and [he] celebrated Christmas in the town Aquis, and similarly Easter\") which must have been sufficiently equipped to support the royal household for several months. In the year of his coronation as king of the Franks, 768, Charlemagne came to spend Christmas at Aachen for the first time. He remained there in a mansion which he may have extended, although there is no source attesting to any significant building activity at Aachen in his time, apart from the building of the Palatine Chapel (since 1930, cathedral) and the Palace. Charlemagne spent most winters in Aachen between 792 and his death in 814. Aachen became the focus of his court and the political centre of his empire. After his death, the king was buried in the church which he had built; his original tomb has been lost, while his alleged remains are preserved in the Karlsschrein, the shrine where he was reburied after being declared a saint; his saintliness, however, was never officially acknowledged by the Roman Curia as such.\n\nIn 936, Otto I was crowned king of East Francia in the collegiate church built by Charlemagne. During the reign of Otto II, the nobles revolted and the West Franks under Lothair raided Aachen in 978. Aachen was attacked again by Odo of Champagne, who attacked the imperial palace while Conrad II was absent. Odo relinquished it quickly and was killed soon afterwards. The palace and town of Aachen had fortifying walls built by order of Emperor Frederick Barbarossa between 1172 and 1176. Over Americans can probably agree there isn the next 500 years, most kings of Germany destined to reign over the Holy Roman Empire were crowned in Aachen. The original audience hall built by Charlemagne was torn down and replaced by the current city hall in 1330. The last king to be crowned here was Ferdinand I in 1531. During the Middle Ages, Aachen remained a city of regional importance, due to its proximity to Flanders; it achieved a modest position in the trade in woollen cloths, favoured by imperial privilege. The city remained a free imperial city, subject to the emperor only, but was politically far too weak to influence the policies of any of its neighbours. The only dominion it had was over Burtscheid, a neighbouring territory ruled by a Benedictine abbess. It was forced to accept that all of its traffic must pass through the \"Aachener Reich\". Even in the late 18th century the Abbess of Burtscheid was prevented from building a road linking her territory to the neighbouring estates of the duke of J\u00fclich; the city of Aachen even deployed its handful of soldiers to chase away the road-diggers.\n\nAs an imperial city, Aachen held certain political privileges that allowed it to remain independent of the troubles of Europe for many years. It remained a direct vassal of the Holy Roman Empire throughout most of the Middle Ages. It was also the site of many important church councils, including the Council of 837 and the Council of 1166, a council convened by the antipope Paschal III.\n\nManuscript production \n\nAachen has proved an important site for the production of historical manuscripts. Under Charlemagne's purview, both the Ada Gospels and the Coronation Gospels may have been produced in Aachen. In addition, quantities of the other texts in the court library were also produced locally. During the reign of", "flag": 1, "segments": [[1607, 1613]], "strength": 5.5}
{"token_count": [2006], "text": "Aspirin, also known as acetylsalicylic acid (ASA), is a medication used to reduce pain, fever, or inflammation. Specific inflammatory conditions which aspirin is used to treat include Kawasaki disease, pericarditis, and rheumatic fever.\n\nAspirin given shortly after a heart attack decreases the risk of death. Aspirin is also used long-term to help prevent further heart attacks, ischaemic strokes, and blood clots in people at high risk. For pain or fever, effects typically begin within 30 minutes. Aspirin is a nonsteroidal anti-inflammatory drug (NSAID) and works similarly to other NSAIDs but also suppresses the normal functioning of platelets. Aspirin, often used as an analgesic, anti-pyretic and non-steroidal anti-inflammatory drug (NSAID), is able to have an anti-platelet effect by inhibiting the COX activity in the platelet to prevent the production of thromboxane A2 which acts to bind platelets together during coagulation as well as cause vasoconstriction and bronchoconstriction.\n\nOne common adverse effect is an upset stomach. More significant side effects include stomach ulcers, stomach bleeding, and worsening asthma. Bleeding risk is greater among those who are older, drink alcohol, take other NSAIDs, or are on other blood thinners. Aspirin is not recommended in the last part of pregnancy. It is not generally recommended in children with infections because of the risk of Reye syndrome. High doses may result in ringing in the ears.\n\nA precursor to aspirin found in leaves from the willow tree (genus Salix) has been used for its health effects for at least 2,400 years. In 1853, chemist Charles Fr\u00e9d\u00e9ric Gerhardt treated the medicine sodium salicylate with acetyl chloride to produce acetylsalicylic acid for the first time. For the next 50 years, other chemists established the chemical structure and devised more efficient production methods.\n\nAspirin is one of the most widely used medications globally, with an estimated  (50 to 120 billion pills) consumed each year. It is on the World Health Organization's List of Essential Medicines. It is available as a generic medication. In 2019, it was the 38th most commonly prescribed medication in the United States, with more than 18million prescriptions.\n\nBrand vs. generic name\nIn 1897, scientists at the Bayer company began studying acetylsalicylic acid as a less-irritating replacement medication for common salicylate medicines. By 1899, Bayer had named it \"Aspirin\" and sold it around the world.\n\nAspirin's popularity grew over the first half of the 20th century, leading to competition between many brands and formulations. The word Aspirin was Bayer's brand name; however, their rights to the trademark were lost or sold in many countries. The name is ultimately a blend of the prefix a(cetyl) + spir  Spiraea, the meadowsweet plant genus from which the acetylsalicylic acid that are still used by Windows was originally derived at Bayer + -in, the common chemical suffix.\n\nChemical properties\nAspirin decomposes rapidly in solutions of ammonium acetate or the acetates, carbonates, citrates, or hydroxides of the alkali metals. It is stable in dry air, but gradually hydrolyses in contact with moisture to acetic and salicylic acids. In solution with alkalis, the hydrolysis proceeds rapidly and the clear solutions formed may consist entirely of acetate and salicylate.\n\nLike flour mills, factories producing aspirin tablets must control the amount of the powder that becomes airborne inside the building, because the powder-air mixture can be explosive. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit in the United States of 5mg/m3 (time-weighted average). In 1989, the Occupational Safety and Health Administration (OSHA) set a legal permissible exposure limit for aspirin of 5mg/m3, but this was vacated by the AFL-CIO v. OSHA decision in 1993.\n\nSynthesis\nThe synthesis of aspirin is classified as an esterification reaction. Salicylic acid is treated with acetic anhydride, an acid derivative, causing a chemical reaction that turns salicylic acid's hydroxyl group into an ester group (R-OH \u2192 R-OCOCH3). This process yields aspirin and acetic acid, which is considered a byproduct of this reaction. Small amounts of sulfuric acid (and occasionally phosphoric acid) are almost always used as a catalyst. This method is commonly demonstrated in undergraduate teaching labs.\n\nReaction mechanism\n\nFormulations containing high concentrations of aspirin often smell like vinegar because aspirin can decompose through hydrolysis in moist conditions, yielding salicylic and acetic acids.\n\nPhysical properties\nAspirin, an acetyl derivative of salicylic acid, is a white, crystalline, weakly acidic substance, with a melting point of, and a boiling point of. Its acid dissociation constant (pKa) is 3.5 at.\n\nPolymorphism\nPolymorphism, or the ability of a substance to form more than one crystal structure, is important in the development of pharmaceutical ingredients. Many drugs receive regulatory approval for only a single crystal form or polymorph. For a long time, only one crystal structure for aspirin was known. That aspirin might have a second crystalline form was suspected since the 1960s. The elusive second polymorph was first discovered by Vishweshwar and coworkers in 2005, and fine structural details were given by Bond et al. A new crystal type was found during experiments after co-crystallization of aspirin and levetiracetam from hot acetonitrile. The form II is only stable at 100K and reverts to form I at ambient temperature. In the (unambiguous) form I, two salicylic molecules form centrosymmetric dimers through the acetyl groups with the (acidic) methyl proton to carbonyl hydrogen bonds, and in the newly claimed form II, each salicylic molecule forms the same hydrogen bonds with two neighboring molecules instead of one. With respect to the hydrogen bonds formed by the carboxylic acid groups, both polymorphs form identical dimer structures.\n\nMechanism of action\n\nDiscovery of the mechanism\nIn 1971, British pharmacologist John Robert Vane, then employed by the Royal College of Surgeons in London, showed aspirin suppressed the production of prostaglandins and thromboxanes. For this discovery he was awarded the 1982 Nobel Prize in Physiology or Medicine, jointly with Sune Bergstr\u00f6m and Bengt Ingemar Samuelsson.\n\nProstaglandins and thromboxanes\nAspirin's ability to suppress the production of prostaglandins and thromboxanes is due to its irreversible inactivation of the cyclooxygenase (COX; officially known as prostaglandin-endoperoxide synthase, PTGS) enzyme required for prostaglandin and thromboxane synthesis. Aspirin acts as an acetylating agent where an acetyl group is covalently attached to a serine residue in the active site of the PTGS enzyme (Suicide inhibition). This makes aspirin different from other NSAIDs (such as diclofenac and ibuprofen), which are reversible inhibitors.\n\nLow-dose aspirin use irreversibly blocks the formation of thromboxane A2 in platelets, producing an inhibitory effect on platelet aggregation during the lifetime of the affected platelet (8\u20139 days). This antithrombotic property makes aspirin useful for reducing the incidence of heart attacks in people who have had a heart attack, unstable angina, ischemic stroke or transient ischemic attack. 40mg of aspirin a day is able to inhibit a large proportion of maximum thromboxane A2 release provoked acutely, with the prostaglandin I2 synthesis being little affected; however, higher doses of aspirin are required to attain further inhibition.\n\nProstaglandins, local hormones produced in the body, have diverse effects, including the transmission of pain information to the brain, modulation of the hypothalamic thermostat, and inflammation. Thromboxanes are responsible for the aggregation of platelets that form blood clots. Heart attacks are caused primarily by blood clots, and low doses of aspirin are seen as an effective medical intervention to prevent a second acute myocardial infarction.\n\nCOX-1 and COX-2 inhibition\nAt least two different types of cyclooxygenases, COX-1 and COX-2, are acted on by aspirin. Aspirin irreversibly inhibits COX-1 and modifies the enzymatic activity of COX-2. COX-2 normally produces prostanoids, most of which are proinflammatory. Aspirin-modified PTGS2 (prostaglandin-endoperoxide synthase 2) produces lipoxins, most of which are anti-inflammatory. Newer NSAID drugs, COX-2 inhibitors (coxibs), have been developed to inhibit only PTGS2, with the intent to reduce the incidence of gastrointestinal side effects.\n\nSeveral COX-2 inhibitors, such as rofecoxib (Vioxx), have been withdrawn from the market, after evidence emerged that PTGS2 inhibitors increase the risk of", "flag": 1, "segments": [[649, 655]], "strength": 5.5}
{"token_count": [2006], "text": "The Ainu are the indigenous people of the lands surrounding the Sea of Okhotsk, including Hokkaido Island, Northeast Honshu Island, Sakhalin Island, the Kuril Islands, the Kamchatka Peninsula and Khabarovsk Krai, before the arrival of the Yamato Japanese and Russians. These regions are referred to as  in historical Japanese texts.\n\nOfficial estimates place the total Ainu population of Japan at 25,000. Unofficial estimates place the total population at 200,000 or higher, as the near-total assimilation of the Ainu into Japanese society has resulted in many individuals of Ainu descent having no knowledge of their ancestry. As of 2000, the number of \"pure\" Ainu was estimated at about 300 people.\n\nIn 1966, there were about 300 native Ainu speakers; in 2008, however, there were about 100 native Ainu speakers.\n\nNames\n\nThis people's most widely known ethnonym, \"Ainu\" (; ; ) means \"human\" in the Ainu language, particularly as opposed to, divine beings. Ainu also identify themselves as \"Utari\" (\"comrade\" or \"people\"). Official documents use both names.\n\nHistory\n\nPre-modern \nThe Ainu are the native people of Hokkaido, Sakhalin and the Kurils. Early Ainu-speaking groups (mostly hunters and fishermen) migrated also into the Kamchatka Peninsula and into Honshu, where their descendants are today known as the Matagi hunters, who still use a large amount of Ainu vocabulary in their dialect. Other evidence for Ainu-speaking hunters and fishermen migrating down from Northern Hokkaido into Honshu is through the Ainu toponyms which are found in several places of northern Honshu, mostly among media covering the Asean the western coast and the T\u014dhoku region. Evidence for Ainu speakers in the Amur region is found through Ainu loanwords in the Uilta and Ulch people.\n\nResearch suggests that Ainu culture originated from a merger of the Okhotsk and Satsumon cultures. According to Lee and Hasegawa, the Ainu-speakers descend from the Okhotsk people which rapidly expanded from northern Hokkaido into the Kurils and Honshu. These early inhabitants did not speak the Japanese language; some were conquered by the Japanese early in the 9th century. In 1264, the Ainu invaded the land of the Nivkh people. The Ainu also started an expedition into the Amur region, which was then controlled by the Yuan Dynasty, resulting in reprisals by the Mongols who invaded Sakhalin. Active contact between the Wa-jin (the ethnically Japanese, also known as Yamato-jin) and the Ainu of Ezogashima (now known as Hokkaid\u014d) began in the 13th century. The Ainu formed a society of hunter-gatherers, surviving mainly by hunting and fishing. They followed a religion which was based on natural phenomena.\n\nDuring the Muromachi period (1336\u20131573), many Ainu were subject to Japanese rule. Disputes between the Japanese and Ainu developed into large-scale violence, Koshamain's Revolt, in 1456. Takeda Nobuhiro killed the Ainu leader, Koshamain.\n\nAfter Manchuria under Yuan rule, Ainu and Nivkh of Sakhalin became tributaries to the Ming dynasty of China after Manchuria came under Ming rule as part of the Nurgan Regional Military Commission. Boluohe, Nanghar and Wuliehe were Yuan posts set up to receive tribute from the Ainu after their war with the Yuan ended in 1308. Ming Chinese outposts in Sakhalin and the Amur river area received animal skin tribute from Ainu on Sakhalin, Uilta and Nivkh in the 15th century after the Tyr based Yongning Temple was set up along with the Nurkan (Nurgan) outposts by the Yongle emperor in 1409. The Ming also held the post at Wuliehe and received marten pelt fur tribute from the assistant commander Alige in 1431 from Sakhalin after the Ming assigned titles like weizhenfu (official charged with subjugation), zhihui qianshi (assistance commander), zhihui tongzhi (vice commander) and Zhihuishi (commander) from Sakhalin indigenous headmen. The Ming received tribute from the headmen Alingge, Tuolingha, Sanchiha and Zhaluha in 1437. The position of headman among Sakhalin indigenous peoples was inherited paternally from father to son and the sons came with their fathers to Wuliehe. Ming officials gave silk uniforms with the appropriate rank to the Sakhalin Ainu, Uilta and Nivkh after they gave tribute. The Maritime Province region had the Ming \"system for subjugated peoples' implementers in it for the Sakhalin indigenous peoples. Sakhalin received iron tools from mainland Asia through this trade as Tungus groups joined in from 1456-1487. Local indigenous hierarchies had Ming Chinese given political offices integrated with them. The Ming system on Sakhalin was imitated by the Qing. Nivkh women in Sakhalin married Han Chinese Ming officials when the Ming took tribute from Sakhalin and the Amur river region. Due to Ming rule in Manchuria, Chinese cultural and religious influence such as Chinese New Year, the \"Chinese god\", Chinese motifs like the dragon, spirals, scrolls, and material goods like agriculture, husbandry, heating, iron cooking pots, silk, and cotton spread among the Amur natives like the Udeghes, Ulchis, and Nanais.\n\nDuring the Edo period (1601\u20131868) the Ainu, who controlled the northern island which is now named Hokkaid\u014d, became increasingly involved in trade with the Japanese who controlled the southern portion of the island. The Tokugawa bakufu (feudal government) granted the Matsumae clan exclusive rights to trade with the Ainu in the northern part of the island. Later, the Matsumae began to lease out trading rights to Japanese merchants, and contact between Japanese and Ainu became more extensive. Throughout this period Ainu groups competed with each other to import goods from the Japanese, and epidemic diseases such as smallpox reduced the population. Although the increased contact created by the trade between the Japanese and the Ainu contributed to increased mutual understanding, it also sometimes led to conflict which occasionally intensified into violent Ainu revolts. The most important was Shakushain's Revolt (1669\u20131672), an Ainu rebellion against Japanese authority. Another large-scale revolt by Ainu against Japanese rule was the Menashi-Kunashir Battle in 1789. Throughout this period and thereafter, however, the Ainu-Japanese relationship continued to be marked by trade and commercial relationships, not conflicts.\n\nFrom 1799 to 1806, the shogunate took direct control of southern Hokkaid\u014d. During this period, Ainu women were separated from their husbands and either subjected to rape or forcibly married to Japanese men, while Ainu men were deported to merchant subcontractors for five and ten-year terms of service. Policies of family separation and assimilation, combined with the impact of smallpox, caused the Ainu population to drop significantly in the early 19th century.\n\nIn the 18th century, there were 80,000 Ainu. In 1868, there were about 15,000 Ainu in Hokkaid\u014d, 2000 in Sakhalin and around 100 in the Kuril islands.\n\nThe Santan Japanese traders seized Rishiri Ainu women when they were trading in Sakhalin to become their  wives.\n\nJapanese annexation of Hokkaido\nIn 1869, the imperial government established Hokkaid\u014d Colonization Office as part of the measures of the Meiji Restoration. Sj\u00f6berg quotes Baba's (1890) account of the Japanese government's reasoning:\n\n... The development of Japan's large northern island had several objectives: First, it was seen as a means to defend Japan from a rapidly developing and expansionist Russia. Second... it offered a solution to the unemployment for the former samurai class... Finally, development promised to yield the needed natural resources for a growing capitalist economy.\n\nAs a result of the Treaty of Saint Petersburg (1875), the Kuril Islands \u2013 along with their Ainu inhabitants \u2013 came under Japanese administration. In 1899, the Japanese government passed an act labelling the Ainu as \"former aborigines\", with the idea they would assimilate\u2014this resulted in the Japanese government taking the land where the Ainu people lived and placing it from then on under Japanese control. Also at this time, the Ainu were granted automatic Japanese citizenship, effectively denying them the status of an indigenous group.\n\nThe Ainu went from being a relatively isolated group of people to having their land, language, religion and customs assimilated into those of the Japanese. Their land was distributed to the Yamato Japanese settlers and to create and maintain farms in the model of Western industrial agriculture. It was known as \"colonization\" (\u62d3\u6b96) at the time, but later by the euphemism \"opening up undeveloped land\" (\u958b\u62d3). As well as this, factories such as flour mills, beer breweries and mining practices resulted in the creation of infrastructure such as roads and railway lines, during a development period that lasted until", "flag": 1, "segments": [[372, 378]], "strength": 5.5}
{"token_count": [2006], "text": "Acupuncture is a form of alternative medicine and a component of traditional Chinese medicine (TCM) in which thin needles are inserted into the body. Acupuncture is a pseudoscience; the theories and practices of TCM are not based on scientific knowledge, and it has been characterized as quackery. There is a range of acupuncture variants which originated in different philosophies, and techniques vary depending on the country in which it is performed, but can be divided into two main foundational philosophical applications and approaches, the first being the modern standardized form called eight principles TCM and the second an older system that is based on the ancient Taoist Wuxing or better known as the five elements or phases in the West. Acupuncture is most often used to attempt pain relief, though acupuncturists say that it can also be used for a wide range of other conditions. Acupuncture is generally used only in combination with other forms of treatment.\n\nThe global acupuncture market was worth US$24.55 billion in 2017. The market was led by Europe with a 32.7% share, followed by Asia-Pacific with a 29.4% share and the Americas with a 25.3% share. It is estimated that the industry will reach a market size of $55bn by 2023.\n\nThe conclusions of trials and systematic reviews of acupuncture are inconsistent, which suggests that it is not effective. An overview of Cochrane reviews found that acupuncture is not effective for a wide range of conditions. A systematic review conducted by medical scientists at the universities of Exeter and Plymouth found little evidence of acupuncture's effectiveness in treating pain. Overall, the evidence suggests that short-term treatment with acupuncture does not produce long-term benefits. Some research results suggest that acupuncture can alleviate some forms of pain, though the majority of research suggests that acupuncture's apparent effects are not caused by the treatment itself. A systematic review concluded that the analgesic effect of acupuncture seemed to lack clinical relevance and could not be clearly distinguished from bias. One meta-analysis found that acupuncture for chronic low back pain was cost-effective as an adjunct to standard care, while a separate systematic review found insufficient evidence for the cost-effectiveness of acupuncture in the treatment of chronic low back pain.\n\nAcupuncture is generally safe when done by appropriately trained practitioners using clean needle technique and single-use needles. When properly delivered, it has a low rate of mostly minor adverse effects. Accidents and infections do occur, though, and are associated with neglect on the part of the practitioner, particularly in the application of sterile techniques. A review conducted in 2013 stated that reports of infection transmission increased significantly in the preceding decade. The most frequently reported adverse events were pneumothorax and infections. Since serious adverse events continue to be reported, it is recommended that acupuncturists be trained sufficiently to reduce the risk.\n\nScientific investigation has not found any histological or physiological evidence for traditional Chinese concepts such as qi, meridians, and acupuncture points, and many modern practitioners no longer support the existence of life force energy (qi) or meridians, which was a major part of early belief systems. Acupuncture is believed to have originated around 100\u00a0BC in China, around the time The Inner Classic of Huang Di (Huangdi Neijing) was published, though some experts suggest it could have been practiced earlier. Over time, conflicting claims and belief systems emerged about the effect of lunar, celestial and earthly cycles, yin and yang energies, and a body's \"rhythm\" on the effectiveness of treatment. Acupuncture fluctuated in popularity in China due to changes in the country's political leadership and the preferential use of rationalism or Western medicine. Acupuncture spread first to Korea in the 6th century AD, then to Japan through medical missionaries, and then to Europe, beginning with France. In the 20th century, as it spread to the United States and Western countries, spiritual elements of acupuncture that conflicted with Western beliefs were sometimes abandoned in favor of simply tapping needles into acupuncture points.\n\nClinical practice \n\nAcupuncture is a form of alternative medicine. It is used most commonly for pain relief, though it is also used to treat a wide range of conditions. Acupuncture is generally only used in combination with other forms of treatment. For example, the American Society of Anesthesiologists states it may be considered in the treatment for nonspecific, noninflammatory low back pain only in conjunction with conventional therapy.\n\nAcupuncture is the insertion of thin needles into the skin. According to the Mayo Foundation for Medical Education and Research (Mayo Clinic), a typical session entails lying still while approximately five to twenty needles are inserted; for the majority of cases, the needles will be left in place for ten to twenty minutes. It can be associated with the application of heat, pressure, or laser light. Classically, acupuncture is individualized and based on philosophy and intuition, and not on scientific research. There is also a non-invasive therapy developed in early 20th century Japan using an elaborate set of instruments other than needles for the treatment of children (sh\u014dnishin or sh\u014dnihari).\n\nClinical practice varies depending on the country. A comparison of the average number of patients treated per hour found significant differences between China (10) and the United States (1.2). Chinese herbs are often used. There is a diverse range of acupuncture approaches, involving different philosophies. Although various different techniques of acupuncture practice have emerged, the method used in traditional Chinese medicine (TCM) seems to be the most widely adopted in the US. Traditional acupuncture involves needle insertion, moxibustion, and cupping therapy, and may be accompanied by other procedures such as feeling the pulse and other parts of the body and examining the tongue. Traditional acupuncture involves the belief that a \"life force\" (qi) circulates within the body in lines called meridians. The main methods practiced in the UK are TCM and Western medical acupuncture. The term Western medical acupuncture is used to indicate an adaptation of TCM-based acupuncture which focuses less on TCM. The Western medical acupuncture approach involves using acupuncture after a medical diagnosis. Limited research has compared the contrasting acupuncture systems used in various countries for determining different acupuncture points and thus there is no defined standard for acupuncture points.\n\nIn traditional acupuncture, the acupuncturist decides which points to treat by observing and questioning the patient to make a diagnosis according to the tradition used. In TCM, the four diagnostic methods are: inspection, auscultation and olfaction, inquiring, and palpation. Inspection focuses on the face and particularly on the tongue, including analysis of the tongue size, shape, tension, color and coating, and the absence or presence of teeth marks around the edge. Auscultation and olfaction involve listening for particular sounds such as wheezing, and observing body odor. Inquiring involves focusing on the \"seven inquiries\": chills and fever; perspiration; appetite, thirst and taste; defecation and urination; pain; sleep; and menses and leukorrhea. Palpation is focusing on feeling the body for tender \"A-shi\" points and feeling the pulse.\n\nNeedles \n\nThe most common mechanism of stimulation of acupuncture points employs penetration of the skin by thin metal needles, which are manipulated manually or the needle may be further stimulated by electrical stimulation (electroacupuncture). Acupuncture needles are typically made of stainless steel, making them flexible and preventing them from rusting or breaking. Needles are usually disposed of after each use to prevent contamination. Reusable needles when used should be sterilized between applications. In many areas, only sterile, single-use acupuncture needles are allowed, including the State of California, USA. Needles vary in length between, with shorter needles used near the face and eyes, and longer needles in areas with thicker tissues; needle diameters vary from 0 to 0, with thicker needles used on more robust patients. Thinner needles may be flexible and require tubes for insertion. The tip of the needle should not be made too sharp to prevent breakage, although blunt needles cause more pain.\n\nApart from the usual filiform needle, other needle types include three-edged needles and the Nine Ancient Needles. Japanese acupuncturists use extremely thin needles that are used superficially, sometimes without penetrating the skin, and surrounded by a guide tube (a.10pm, remains extremely 17th-century invention adopted in China and the West). Korean acupuncture uses copper needles and has a greater focus on the hand.\n\nNeedling technique\n\nInsertion \n\nThe skin is sterilized and needles are inserted, frequently with a plastic guide tube. Needles may be manipulated in various ways, including spinning, flicking, or moving up and down relative to the skin. Since most pain is felt in the superficial layers of the skin, a quick insertion of the needle is recommended. Often the needles are stimulated by hand in order to cause a dull, localized, aching sensation that is called de qi, as well as \"needle grasp,\" a tugging feeling felt by the acupuncturist and generated by a mechanical interaction between the needle and skin. Acupuncture can be painful. The skill level of the acupuncturist may influence how painful the needle insertion is, and a sufficiently skilled practitioner may be able to insert the needles without causing any pain.\n\nDe-qi sensation \n\nDe-qi (; \"arrival of qi\") refers to a claimed sensation of numbness, distension, or electrical tingling at the needling site. If these sensations are not observed then inaccurate location of the acupoint, improper depth of needle insertion, inadequate manual manipulation, are blamed", "flag": 1, "segments": [[1727, 1733]], "strength": 5.5}
{"token_count": [2006], "text": "Andrew Jackson (March 15, 1767\u00a0\u2013 June 8, 1845) was an American lawyer, general, and statesman who served as the seventh president of the United States from 1829 to 1837. Before being elected to the presidency, Jackson gained fame as a general in the United States Army and served in both houses of the U.S. Congress. An expansionist president, Jackson sought to advance the rights of the \"common man\" against a \"corrupt aristocracy\" and to preserve the Union.\n\nBorn in the colonial Carolinas in the decade before the American Revolutionary War, Jackson became a frontier lawyer and married Rachel Donelson Robards. He served briefly in the United States House of Representatives and the United States Senate, representing Tennessee. After resigning, he served as a justice on the Tennessee Supreme Court from 1798 until 1804. Jackson purchased a property later known as The Hermitage, and became a wealthy, slaveowning planter. In 1801, he was appointed colonel of the Tennessee militia and was elected its commander the following year. He led troops during the Creek War of 1813\u20131814, winning the Battle of Horseshoe Bend. The subsequent Treaty of Fort Jackson required the Creek surrender of vast lands in present-day Alabama and Georgia. In the concurrent war against the British, Jackson's victory in 1815 at the Battle of New Orleans made him a national hero. Jackson then led U.S. forces in the First Seminole War, which led to the annexation of Florida from Spain. Jackson briefly served as Florida's first territorial governor before returning to the Senate. He ran for president in 1824, winning a plurality of the popular and electoral vote. As no candidate won an electoral majority, the House of Representatives elected John Quincy Adams in a contingent election. In reaction to the alleged \"corrupt bargain\" between Adams and Henry Clay and the ambitious agenda of President Adams, Jackson's supporters founded the Democratic Party.\n\nJackson ran again in 1828, defeating Adams in a landslide. Jackson faced the threat of secession by South Carolina over what opponents called the \"Tariff of Abominations\". The crisis was defused when the tariff was amended, and Jackson threatened the use of military force if South Carolina attempted to secede. In Congress, Henry Clay led the effort to reauthorize the Second Bank of the United States. Jackson, regarding the Bank as a corrupt institution that benefited the wealthy at the expense of ordinary Americans, vetoed the renewal of its charter. After a lengthy struggle, Jackson and his allies thoroughly dismantled the Bank. In 1835, Jackson became the only president to completely pay off the national debt, fulfilling a longtime goal. While Jackson pursued numerous reforms designed to eliminate waste and corruption, his presidency marked the beginning of the ascendancy of the party \"spoils system\" in American politics. In 1830, Jackson signed the Indian Removal Act, which forcibly removed most members of the major tribes of the Southeast to Indian Territory; these removals were subsequently known as the Trail of Tears. The relocation process dispossessed these nations of their land and resulted in widespread death and disease. Jackson opposed the abolitionist movement, which grew stronger in his second term. In foreign affairs, Jackson's administration concluded a \"most favored nation\" treaty with the United Kingdom, settled claims of damages against France from the Napoleonic Wars, and recognized the Republic of Texas. In January 1835, he survived the first assassination attempt on a sitting president.\n\nIn his retirement, Jackson remained active in Democratic Party politics, supporting the presidencies of Martin Van Buren and James K. Polk. Though fearful of its effects on the slavery debate, Jackson advocated the annexation of Texas, which was accomplished shortly before his death. Jackson has been widely revered in the United States as an advocate for democracy and the common man. Many of his actions proved divisive, garnering both fervent support and strong opposition from many in the country. His reputation has suffered since the 1970s, largely due to his anti-abolitionist views and policy of the forcible removal of Native Americans from their ancestral homelands. However, surveys of historians and scholars have ranked Jackson favorably among U.S. presidents.\n\nEarly life and education\nAndrew Jackson was born on March 15, 1767, in the Waxhaws region of the Carolinas. His parents were Scots-Irish colonists Andrew Jackson and his wife Elizabeth Hutchinson, Presbyterians who had emigrated from Ulster, Ireland, two years earlier. Jackson's father was born in Carrickfergus, County Antrim, around 1738. Jackson's parents lived in the village of Boneybefore, also in County Antrim. His paternal ancestors originated in Killingswold Grove, Yorkshire, England.\n\nWhen they migrated to North America in 1765, Jackson's parents brought two children with them from Ireland, Hugh (born 1763) and Robert (born 1764). The family probably landed in Philadelphia. Most likely they traveled overland through the Appalachian Mountains to the Scots-Irish community in the Waxhaws, straddling the border between North and South Carolina. Jackson's father died in February 1767 at the age of 29, in a logging accident while clearing land, three weeks before his son Andrew was born. Jackson, his mother, and his brothers lived with Jackson's aunt and uncle in the Waxhaws region, and Jackson received schooling from two nearby priests.\n\nJackson's exact birthplace is unclear because of a lack of knowledge of his mother's actions immediately following her husband's funeral. The area was so remote that the border between North and South Carolina had not been officially surveyed. In 1824, Jackson wrote a letter saying he had been born on the plantation of his uncle James Crawford in Lancaster County, South Carolina. Jackson may have claimed to be a South Carolinian because the state was considering nullification of the Tariff of 1824, which he opposed. In the mid-1850s, second-hand evidence indicated that he might have been born at a different uncle's home in North Carolina. As a young boy, Jackson was easily offended and was considered something of a bully. He was, however, also said to have taken a group of younger and weaker boys under his wing and been kind to them.\n\nRevolutionary War service\n \nDuring the Revolutionary War, Jackson's eldest brother, Hugh, died from heat exhaustion after the Battle of Stono Ferry on June 20, 1779. Anti-British sentiment intensified following the Waxhaws Massacre on May 29, 1780. Jackson's mother encouraged him and his elder brother Robert to attend the local militia drills. Soon, they began to help the militia as couriers. They served under Colonel William Richardson Davie at the Battle of Hanging Rock on August 6. Andrew and Robert were captured by the British in April 1781 while staying at the home of the Crawford family. When Andrew refused to clean the boots of a British officer, the officer slashed at the youth with a sword, leaving him with scars on his left hand and head, as well as an intense hatred for the British. Robert also refused to do as commanded and was struck with the sword. The two brothers were held as prisoners, contracted smallpox, and nearly starved to death in captivity.\n\nLater that year, their mother Elizabeth secured the brothers' release. She then began to walk both boys back to their home in the Waxhaws, a distance of some 40 miles (64\u00a0km). Both were in very poor health. Robert, who was far worse, rode on the only horse they had, while Andrew walked behind them. In the final two hours of the journey, a torrential downpour began which worsened the effects of the smallpox. Within two days of arriving back home, Robert was dead and Andrew in mortal danger. After nursing Andrew back to health, Elizabeth volunteered to nurse American prisoners of war on board two British ships in the Charleston harbor, where there had been an outbreak of cholera. In November, she died from the disease and was buried in an unmarked grave. Andrew became an orphan at age 14. He blamed the British personally for the loss of his brothers and mother.\n\nEarly career\n\nLegal career and marriage\nAfter the Revolutionary War, Jackson received a sporadic education in a local Waxhaw school. On bad terms with much of his extended family, he boarded with several different people. In 1781, he worked for a time as a saddle-maker, and eventually taught school. He apparently prospered in neither profession. In 1784, he left the Waxhaws region for Salisbury, North Carolina, where he studied law under attorney Spruce Macay. With the help of various lawyers, he was able to learn enough to qualify for the bar. In September 1787, Jackson was admitted to the North Carolina bar. Shortly thereafter, his friend John McNairy helped him get appointed to a vacant prosecutor position in the Western District of North Carolina, which would later become the state of Tennessee. During his travel west, Jackson bought his first slave, a woman who was older than him. In 1788, having been offended by fellow lawyer Waightstill Avery, Jackson fought his first duel. The duel ended with both men firing into the air, having made a secret agreement to do so before the engagement.\n\nJackson moved to the bag. U.A. small frontier town of Nashville in 1788, where he lived as a boarder with Rachel Stockly Donelson, the widow of John Donelson. Here Jackson became acquainted with their daughter, Rachel Donelson Robards. The younger Rachel was in an unhappy marriage with Captain Lewis Robards; he was subject to fits of jealous rage. The two were separated in 1790. According to Jackson, he married Rachel after hearing that Robards", "flag": 1, "segments": [[1913, 1919]], "strength": 5.5}
{"token_count": [2006], "text": "Andrew Johnson (December 29, 1808July 31, 1875) was the 17th president of the United States, serving from 1865 to 1869. He assumed the presidency as he was vice president at the time of the assassination of Abraham Lincoln. Johnson was a Democrat who ran with Lincoln on the National Union ticket, coming to office as the Civil War concluded. He favored quick restoration of the seceded states to the Union without protection for the former slaves. This led to conflict with the Republican-dominated Congress, culminating in his impeachment by the House of Representatives in 1868. He was acquitted in the Senate by one vote.\n\nJohnson was born into poverty and never attended school. He was apprenticed as a tailor and worked in several frontier towns before settling in Greeneville, Tennessee. He served as alderman and mayor there before being elected to the Tennessee House of Representatives in 1835. After briefly serving in the Tennessee Senate, Johnson was elected to the House of Representatives in 1843, where he served five two-year terms. He became governor of Tennessee for four years, and was elected by the legislature to the Senate in 1857. In his congressional service, he sought passage of the Homestead Bill which was enacted soon after he left his Senate seat in 1862. Southern slave states seceded to form the Confederate States of America, including Tennessee, but Johnson remained firmly with the Union. He was the only sitting senator from a Confederate state who did not resign his seat upon learning of his state's secession. In 1862, Lincoln appointed him as Military Governor of Tennessee after most of it had been retaken. In 1864, Johnson was a logical choice as running mate for Lincoln, who wished to send a message of national unity in his re-election campaign; and became vice president after a victorious election in 1864.\n\nJohnson implemented his own form of Presidential Reconstruction, a series of proclamations directing the seceded states to hold conventions and elections to reform their civil governments. Southern states returned many of their old leaders and passed Black Codes to deprive the freedmen of many civil liberties, but Congressional Republicans refused to seat legislators from those states and advanced legislation to overrule the Southern actions. Johnson vetoed their bills, and Congressional Republicans overrode him, setting a pattern for the remainder of his presidency. Johnson opposed the Fourteenth Amendment which gave citizenship to former slaves. In 1866, he went on an unprecedented national tour promoting his executive policies, seeking to break Republican opposition. As the conflict grew between the branches of government, Congress passed the Tenure of Office Act restricting Johnson's ability to fire Cabinet officials. He persisted in trying to dismiss Secretary of War Edwin Stanton, but ended up being impeached by the House of Representatives and narrowly avoided conviction in the Senate. He did not win the 1868 Democratic presidential nomination and left office the following year.\n\nJohnson returned to Tennessee after his presidency and gained some vindication when he was elected to the Senate in 1875, making him the only former president to serve in the Senate. He died five months into his term. Johnson's strong opposition to federally guaranteed rights for black Americans is widely criticized; he is regarded by many historians as one of the worst presidents in American history.\n\nEarly life and career\n\nChildhood \n\nAndrew Johnson was born in Raleigh, North Carolina, on December 29, 1808, to Jacob Johnson (1778\u20131812) and Mary (\"Polly\") McDonough (1783\u20131856), a laundress. He was of English, Scots-Irish, and Irish ancestry. He had a brother William, four years his senior, and an older sister Elizabeth, who died in childhood. Johnson's birth in a two-room shack was a political asset in the mid-19th century, and he would frequently remind voters of his humble origins. Jacob Johnson was a poor man, as had been his father, William Johnson, but he became town constable of Raleigh before marrying and starting a family. Both Jacob and Mary were illiterate, and had worked as tavern servants, while Johnson never attended school and grew up in poverty. Jacob died of an apparent heart attack while ringing the town bell, shortly after rescuing three drowning men, when his son Andrew was three. Polly Johnson worked as a washerwoman and became the sole support of her family. Her occupation was then looked down on, as it often took her into other homes unaccompanied. Since Andrew did not resemble either of his siblings, there are rumors that he may have been fathered by another man. Polly Johnson eventually remarried to a man named Turner Doughtry, who was as poor as she was.\n\nJohnson's mother apprenticed her son William to a tailor, James Selby. Andrew also became an apprentice in Selby's shop at age ten and was legally bound to serve until his 21st birthday. Johnson lived with his mother for part of his service, and one of Selby's employees taught him rudimentary literacy skills. His education was augmented by citizens who would come to Selby's shop to read to the tailors as they worked. Even before he became an apprentice, Johnson came to listen. The readings caused a lifelong love of learning, and one of his biographers, Annette Gordon-Reed, suggests that Johnson, later a gifted public speaker, learned the art as he threaded needles and cut cloth.\n\nJohnson was not happy at James Selby's, and after about five years, both he and his brother ran away. Selby responded by placing a reward for their return: \"Ten Dollars Reward. Ran away from the subscriber, two apprentice boys, legally bound, named William and Andrew Johnson\u00a0... [payment] to any person who will deliver said apprentices to me in Raleigh, or I will give the above reward for Andrew Johnson alone.\" The brothers went to Carthage, North Carolina, where Andrew Johnson worked as a tailor for several months. Fearing he would be arrested and returned to Raleigh, Johnson moved to Laurens, South Carolina. He found work quickly, met his first love, Mary Wood, and made her a quilt as a gift. However, she rejected his marriage proposal. He returned to Raleigh, hoping to buy out his apprenticeship, but could not come to terms with Selby. Unable to stay in Raleigh, where he risked being apprehended for abandoning Selby, he decided to move west.\n\nMove to Tennessee \n\nJohnson left North Carolina for Tennessee, traveling mostly on foot. After a brief period in Knoxville, he moved to Mooresville, Alabama. He then worked as a tailor in Columbia, Tennessee, but was called back to Raleigh by his mother and stepfather, who saw limited opportunities there and who wished to emigrate west. Johnson and his party traveled through the Blue Ridge Mountains to Greeneville, Tennessee. Andrew Johnson fell in love with the town at first sight, and when he became prosperous purchased the land where he had first camped and planted a tree in commemoration.\n\nIn Greeneville, Johnson established a successful tailoring business in the front of his home. In 1827, at the age of 18, he married 16-year-old Eliza McCardle, the daughter of a local shoemaker. The pair were married by Justice of the Peace Mordecai Lincoln, first cousin of Thomas Lincoln, whose son would become president. The Johnsons were married for almost 50 years and had five children: Martha (1828), Charles (1830), Mary (1832), Robert (1834), and Andrew Jr. (1852). Though she suffered from tuberculosis, Eliza supported her husband's endeavors. She taught him mathematics skills and tutored him to improve his writing. Shy and retiring by nature, Eliza Johnson usually remained in Greeneville during Johnson's political rise. She was not often seen during her husband's presidency; their daughter Martha usually served as official hostess.\n\nJohnson's tailoring business prospered during the early years of the marriage, enabling him to hire help and giving him the funds to invest profitably in real estate. He later boasted of his talents as a tailor, \"my work never ripped or gave way\". He was a voracious reader. Books about famous orators aroused his interest in political dialogue, and he had private debates on the issues of the day with customers who justices have more or less settled held opposing views. He also took part in debates at Greeneville College.\n\nJohnson's slaves \nIn 1843, Johnson purchased his first slave, Dolly, who was 14 years old at the time. Soon after, he purchased Dolly's half-brother Sam. Dolly had three children\u2014Liz, Florence and William. In 1857, Andrew Johnson purchased Henry, who was 13 at the time and would later accompany the Johnson family to the White House. Sam Johnson and his wife Margaret had nine children. Sam became a commissioner of the Freedmen's Bureau and was known for being a proud man who negotiated the nature of his work with the Johnson family. Notably, he received some monetary compensation for his labors and negotiated with Andrew Johnson to receive a tract of land which Andrew Johnson gave him for free in 1867. Ultimately, Johnson owned at least ten slaves.\n\nAndrew Johnson freed his slaves on August 8, 1863; they remained with him as paid servants. A year later, Johnson, as military governor of Tennessee, proclaimed the freedom of Tennessee's slaves. Sam and Margaret, Johnson's former slaves, lived in his tailor shop while he was president, without rent. As a sign of appreciation for proclaiming freedom, Andrew Johnson was given a watch by newly emancipated people in Tennessee inscribed with \"\u2026for his Untiring Energy in the Cause of Freedom\".\n\nPolitical rise\n\nTennessee politician", "flag": 1, "segments": [[1711, 1717]], "strength": 5.5}
{"token_count": [2006], "text": "Aleksandr Isayevich Solzhenitsyn (11 December 1918 \u2013 3 August 2008) was a Russian novelist, philosopher, historian, short story writer, and political prisoner. One of the most famous Soviet dissidents, Solzhenitsyn was an outspoken critic of communism and helped to raise global awareness of political repression in the Soviet Union (USSR), in particular the Gulag system.\n\nSolzhenitsyn was born into a family that defied the Soviet anti-religious campaign in the 1920s and remained devout members of the Russian Orthodox Church. While still young, Solzhenitsyn lost his faith in Christianity and became a firm believer in both atheism and Marxism\u2013Leninism; in his later life, he gradually became a philosophically minded Eastern Orthodox Christian as a result of his experience in prison and the camps. While serving as a captain in the Red Army during World War II, Solzhenitsyn was arrested by the SMERSH and sentenced to eight years in the Gulag and then internal exile for criticizing Soviet leader Joseph Stalin in a private letter.\n\nAs a result of the Khrushchev Thaw, Solzhenitsyn was released and exonerated. After he had returned to the Christian faith of his childhood, he pursued writing novels about repressions in the Soviet Union and his experiences. He published his first novel, One Day in the Life of Ivan Denisovich in 1962, with approval from Soviet leader Nikita Khrushchev, which was an account of Stalinist repressions. Solzhenitsyn's last work to be published in the Soviet Union was Matryona's Place in 1963. Following the removal of Khrushchev from power, the Soviet authorities attempted to discourage him from continuing to write. Solzhenitsyn continued to work on further novels and their publication in other countries including Cancer Ward in 1968, August 1914 in 1971, and The Gulag Archipelago in 1973, the publication of which outraged the Soviet authorities. In 1974 Solzhenitsyn lost his Soviet citizenship and was flown to West Germany. In 1976, he moved with his family to the United States, where he continued to write. In 1990, shortly before the dissolution of the Soviet Union, his citizenship was restored, and four years later he returned to Russia, where he remained until his death in 2008.\n\nHe was awarded the 1970 Nobel Prize in Literature \"for the ethical force with which he has pursued the indispensable traditions of Russian literature\", and The Gulag Archipelago was a highly influential work that \"amounted to a head-on challenge to the Soviet state\", and sold tens of millions of copies.\n\nBiography\n\nEarly years \n\nSolzhenitsyn was born in Kislovodsk (now in Stavropol Krai, Russia). His father was of Russian descent and his mother, Taisiya Zakharovna (n\u00e9e Shcherbak), was of Ukrainian descent. Her father had risen from humble beginnings to become a wealthy landowner, acquiring a large estate in the Kuban region in the northern foothills of the Caucasus. During World War I, Taisiya went to Moscow to study. While there she met and married Isaakiy Semyonovich Solzhenitsyn, a young officer in the Imperial Russian Army of Cossack origin and fellow native of the Caucasus region. The family background of his parents is vividly brought to life in the opening chapters of August 1914, and in the later Red Wheel novels.\n\nIn 1918, Taisiya became pregnant with Aleksandr.  On 15 June, shortly after her pregnancy was confirmed, Isaakiy was killed in a hunting accident.  Aleksandr was raised by his widowed mother and his aunt in lowly circumstances.  His earliest years coincided with the Russian Civil War. By 1930 the family property had been turned into a collective farm. Later, Solzhenitsyn recalled that his mother had fought for survival and that they had to keep his father's background in the old Imperial Army a secret.  His educated mother (who never remarried) encouraged his literary and scientific learnings and raised him in the Russian Orthodox faith; she died in 1944.\n\nAs early as 1936, Solzhenitsyn began developing the characters and concepts for a planned epic work on World War I and the Russian Revolution. This eventually led to the novel August 1914; some of the chapters he wrote then still survive. Solzhenitsyn studied mathematics and physics at Rostov State University. At the same time he took correspondence courses from the Moscow Institute of Philosophy, Literature and History, by this time heavily ideological in scope.  As he himself makes clear, he did not question the state ideology or the superiority of the Soviet Union until he spent time in the camps.\n\nWorld War II \n\nDuring the war, Solzhenitsyn served as the commander of a sound-ranging battery in the Red Army, was involved in major action at the front, and was twice decorated.  He was awarded the Order of the Red Star on 8 July 1944 for sound-ranging two German artillery batteries and adjusting counterbattery fire onto them, resulting in their destruction.\n\nA series of writings published late in his life, including the early uncompleted novel Love the Revolution!, chronicle his wartime experience and growing doubts about the moral foundations of the Soviet regime.\n\nWhile serving as an artillery officer in East Prussia, Solzhenitsyn witnessed war crimes against local German civilians by Soviet military personnel. Of the atrocities, Solzhenitsyn wrote: \"You know very well that we've come to Germany to take our revenge\" for Nazi atrocities committed in the Soviet Union. The noncombatants and the elderly were robbed of their meager possessions and women and girls were gang-raped. A few years later, in the forced labor camp, he memorized a poem titled \"Prussian Nights\" about a woman raped to death in East Prussia. In this poem, which describes the gang-rape of a Polish woman whom the Red Army soldiers mistakenly thought to be a German, the first-person narrator comments on the events with sarcasm and refers to the responsibility of official Soviet writers like Ilya Ehrenburg.\n\nIn The Gulag Archipelago, Solzhenitsyn wrote, \"There is nothing that so assists the awakening of omniscience within us as insistent thoughts about one's own transgressions, errors, mistakes. After the difficult cycles of such ponderings over many years, whenever I mentioned the heartlessness of our highest-ranking bureaucrats, the cruelty of our executioners, I remember myself in my Captain's shoulder boards and the forward march of my battery through East Prussia, enshrouded in fire, and I say: 'So were we any better?'\"\n\nImprisonment \n\nIn February 1945, while serving in East Prussia, Solzhenitsyn was arrested by SMERSH for writing derogatory comments in private letters to a friend, Nikolai Vitkevich, about the conduct of the war by Joseph Stalin, whom he called \"Khozyain\" (\"the boss\"), and \"Balabos\" (Yiddish rendering of Hebrew baal ha-bayit for \"master of the house\"). He also had talks with the same friend about the need for a new organization to replace the Soviet regime.\n\nHe was accused of anti-Soviet propaganda under Article 58 paragraph 10 of the Soviet criminal code, and of \"founding a hostile organization\" under paragraph 11. Solzhenitsyn was taken to the Lubyanka prison in Moscow, where he was interrogated. On 9 May 1945, it was announced that Germany had surrendered and all of Moscow broke out in celebrations with fireworks and searchlights illuminating the sky to celebrate the victory in the Great Patriotic War. From his cell in the Lubyanka, Solzhenitsyn remembered: \"Above the muzzle of our window, and from all the other cells of the Lubyanka, and from all the windows of the Moscow prisons, we too, former prisoners of war and former front-line soldiers, watched the Moscow heavens, patterned with fireworks and crisscrossed with beams of searchlights. There was no rejoicing in our cells and no hugs and no kisses for us. That victory was not ours.\" On 7 July 1945, he was sentenced in his absence by Special Council of the NKVD to anest pepper species and can bear eight-year term in a labour camp.  This was the normal sentence for most crimes under Article 58 at the time.\n\nThe first part of Solzhenitsyn's sentence was served in several work camps; the \"middle phase\", as he later referred to it, was spent in a sharashka (a special scientific research facility run by Ministry of State Security), where he met Lev Kopelev, upon whom he based the character of Lev Rubin in his book The First Circle, published in a self-censored or \"distorted\" version in the West in 1968 (an English translation of the full version was eventually published by Harper Perennial in October 2009). In 1950, he was sent to a \"Special Camp\" for political prisoners.  During his imprisonment at the camp in the town of Ekibastuz in Kazakhstan, he worked as a miner, bricklayer, and foundry foreman. His experiences at Ekibastuz formed the basis for the book One Day in the Life of Ivan Denisovich.  One of his fellow political prisoners, Ion Moraru, remembers that Solzhenitsyn spent some of his time at Ekibastuz writing. While there Solzhenitsyn had a tumor removed. His cancer was not diagnosed at the time.\n\nIn March 1953, after his sentence ended, Solzhenitsyn was sent to internal exile for life at Birlik, a", "flag": 1, "segments": [[1712, 1718]], "strength": 5.5}
{"token_count": [2006], "text": "Aberdeen (;  ;  ; ) is a city in North East Scotland. It is the third most populous city in Scotland, one of Scotland's 32 local government council areas (as Aberdeen City) and the United Kingdom's 39th most populous built-up area, with an official 2018 population estimate of  for the city of Aberdeen and  for the local council area.\n\nDuring the mid-18th to mid-20th centuries, Aberdeen's buildings incorporated locally quarried grey granite, which may sparkle like silver because of its high mica content. Since the discovery of North Sea oil in 1969, Aberdeen has been known as the offshore oil capital of Europe.\nThe area around Aberdeen has been settled for at least 8,000 years, when prehistoric villages lay around the mouths of the rivers Dee and Don. The city has a long, sandy coastline and a marine climate, the latter resulting in chilly summers and mild winters.\n\nAberdeen received Royal burgh status from David I of Scotland (1124\u20131153), transforming the city economically. The city has two universities, the University of Aberdeen, in Old Aberdeen, founded in 1495, and Robert Gordon University, in Garthdee, which was awarded university status in 1992, making Aberdeen the educational centre of north-east Scotland. The traditional industries of fishing, paper-making, shipbuilding, and textiles have been overtaken by the oil industry and Aberdeen's seaport. Aberdeen Heliport is one of the busiest commercial heliports in the world and the seaport is the largest in the north-east of Scotland.\n\nIn 2012, HSBC named Aberdeen as a leading business hub and one of eight'super cities' spearheading the UK's economy, marking it as the only city in Scotland so designated. In 2018, Aberdeen was found to be the best city in the UK to start a business in a study released by card payment firm Paymentsense.\n\nHistory\n\nThe Aberdeen area has seen human settlement for at least 8,000 years. The city began as two separate burghs: Old Aberdeen at the mouth of the river Don; and New Aberdeen, a fishing and trading settlement, where the Denburn waterway entered the river Dee estuary. The earliest charter was granted by William the Lion in 1179 and confirmed the corporate rights granted by David I.\n\nIn 1319, the Great Charter of Robert the Bruce transformed Aberdeen into a property-owning and financially independent community. Granted with it was the nearby Forest of Stocket, whose income formed the basis for the city's Common Good Fund which still benefits Aberdonians.\n\nDuring the Wars of Scottish Independence, Aberdeen was under English rule, so Robert the Bruce laid siege to Aberdeen Castle before destroying it in 1308, followed by executing the English garrison. The city was burned by Edward III of England in 1336, but was rebuilt and extended. The city was strongly fortified to prevent attacks by neighbouring lords, but the gates were removed by 1770.\n\nAberdeen's medieval council registers survive from 1398 onwards and are exceptional for their quantity and continuity among surviving Scottish burgh records. The earliest eight volumes, from 1398 to 1511, have been included in the UNESCO UK Memory of the World Register, and have been edited in a digital edition.\n\nDuring the Wars of the Three Kingdoms of 1644 to 1647 the city was plundered by both sides. In 1644, it was taken and ransacked by Royalist troops after the Battle of Aberdeen and two years later it was stormed by a Royalist force under the command of the Marquis of Huntly. In 1647 an outbreak of bubonic plague killed a quarter of the population. In the 18th century, a new Town Hall was built and the first social services appeared with the Infirmary at Woolmanhill in 1742 and the Lunatic Asylum in 1779. The council began major road improvements at the end of the 18th century with the main thoroughfares of George Street, King Street and Union Street all completed at the beginning of the 19th century.\n\nThe expensive infrastructure works led to the city becoming bankrupt in 1817 during the Post-Napoleonic depression, an economic downturn immediately after the Napoleonic Wars; but the city's prosperity later recovered. The increasing economic importance of Aberdeen and the development of the shipbuilding and fishing industries led to the construction of the present harbour including Victoria Dock and the South Breakwater, and the extension of the North Pier. Gas street lighting arrived in 1824 and an enhanced water supply appeared in 1830 when water was pumped from the Dee to a reservoir in Union Place. An underground sewer system replaced open sewers in 1865. The city was incorporated in 1891. Although Old Aberdeen has a separate history and still holds its ancient charter, it is no longer officially independent. It is an integral part of the city, as is Woodside and the Royal Burgh of Torry to the south of the River Dee.\n\nOver the course of the Second World War Aberdeen was attacked 32 times by the German Luftwaffe. One of the most devastating attacks was on Wednesday 21 April 1943 when 29 Luftwaffe Dornier 217s flying from Stavanger, Norway attacked the city between the hours of 22:17 and 23:04. A total of 98 civilians and 27 servicemen were killed, along with 9,668 houses damaged, after a mixture of 127 Incendiary, High Explosive and Cluster bombs were dropped on the city in one night. It was also the last German raid on a Scottish city during the war.\n\nToponymy\n\nThe name given to Aberdeen translates as'mouth of the river Don', and is recorded as Aberdon in 1172 and Aberden in c. 1180. The first element of the name is the Pictish word aber 'river mouth'. The second element is from the Celtic river goddess Devona.\n\nAberdeen is usually described as within the historical Pictish territory, and became Gaelic-speaking at some time in the medieval period. Old Aberdeen is the approximate location of Aberdon, the first settlement of Aberdeen; this literally means \"the mouth of the Don\". The Celtic word  means \"river mouth\", as in modern Welsh (Aberystwyth, Aberdare, Aberbeeg etc.). The Scottish Gaelic name is  (variation: ;  presumably being a loan from the earlier Pictish; the Gaelic term is ), and in Latin, the Romans referred to the river as. Medieval (or Ecclesiastical) Latin has it as.\n\nGovernance\n\nAberdeen is locally governed by Aberdeen City Council, which comprises forty-five councillors who represent the city's wards and is headed by the Lord Provost. The current Lord Provost is Barney Crockett. From May 2003 until May 2007 the council was run by a Liberal Democrat and Conservative Party coalition. Following the May 2007 local elections, the Liberal Democrats formed a new coalition with the Scottish National Party. After a later SNP by-election gain from the Conservatives, this coalition held 28 of the 43 seats. Following the election of 4 May 2017, the council was controlled by a coalition of Scottish Labour, Scottish Conservatives and independent councillors; the Labour councillors were subsequently suspended by Scottish Labour Party leader, Kezia Dugdale.\n\nAberdeen is represented in the Parliament of the United Kingdom by three constituencies: Aberdeen North and Aberdeen South which are wholly within the Aberdeen City council area, and Gordon, which includes a large area of the Aberdeenshire Council area.\n\nIn the Scottish Parliament, the city is represented by three constituencies with different boundaries: Aberdeen Central and Aberdeen Donside are wholly within the Aberdeen City council area. Aberdeen South and North Kincardine includes the North Kincardine ward of Aberdeenshire Council. A further seven MSPs are elected as part was held in connection with an of the North East Scotland electoral region. In the European Parliament the city was represented by six MEPs as part of the all-inclusive Scotland constituency.\n\nHeraldry\n\nThe arms and banner of the city show three silver towers on red. This motif dates from at least the time of Robert the Bruce and represents the buildings that stood on the three hills of medieval Aberdeen: Aberdeen Castle on Castle Hill (today's Castlegate); the city gate on Port Hill; and a church on St\u00a0Catherine's Hill (now levelled).\n\n\"Bon Accord\" is the motto of the city and is French for \"Good Agreement\". Legend tells that its use dates from a password used by Robert the Bruce during the 14th-century Wars of Scottish Independence, when he and his men laid siege to the English-held Aberdeen Castle before destroying it in 1308. It is still widely present in the city, throughout street names, business names and the city's Bon Accord shopping mall.\n\nThe shield in the coat of arms is supported by two leopards. A local magazine is called the \"Leopard\" and, when Union Bridge was widened in the 20th century, small statues of the creature in a sitting position were cast and placed on top of the railing posts (known locally as Kelly's Cats). The city's toast is \"Happy to meet, sorry to part, happy to meet again\"; this has been commonly misinterpreted as the translation of Bon Accord.\n\nGeography\n\nBeing sited between two river mouths, the city has little natural exposure of bedrock. This leaves local geologists in a slight quandary: despite the high concentration of geoscientists in the area (courtesy of the oil industry), there is only a vague understanding of what underlies the city. To the south side of the city,", "flag": 1, "segments": [[1624, 1630]], "strength": 5.5}
{"token_count": [2006], "text": "Aquaculture (less commonly spelled aquiculture), also known as aquafarming, is the controlled cultivation (\"farming\") of aquatic organisms such as fish, crustaceans, mollusks, algae and other organisms of value such as aquatic plants (e.g. lotus). Aquaculture involves cultivating freshwater, brackish water and saltwater populations under controlled or semi-natural conditions, and can be contrasted with commercial fishing, which is the harvesting of wild fish.  Mariculture, commonly known as marine farming, refers specifically to aquaculture practiced in seawater habitats and lagoons, opposed to in freshwater aquaculture. Pisciculture is a type of aquaculture that consists of the culturing of fish (fish farming) to obtain fish and fish products as food.\n\nAquaculture can be conducted in completely artificial facilities built on land (onshore aquaculture), as in the case of fish tank, ponds, aquaponics or raceways, where the living conditions rely on human control such as water quality (oxygen), feed, temperature. Alternatively, they can be conducted on well-sheltered shallow waters nearshore of a body of water (inshore aquaculture), where the cultivated species are subjected to a relatively more naturalistic environments; or on fenced/enclosed sections of open water away from the shore (offshore aquaculture), where the species are either cultured in cages, racks or bags, and are exposed to more diverse natural conditions such as water currents (such as ocean currents), diel vertical migration and nutrient cycles.\n\nAccording to the Food and Agriculture Organization (FAO), aquaculture \"is understood to mean the farming of aquatic organisms including fish, molluscs, crustaceans and aquatic plants. Farming implies some form of intervention in the rearing process to enhance production, such as regular stocking, feeding, protection from predators, etc. Farming also implies individual or corporate ownership of the stock being cultivated.\" The reported output from global aquaculture operations in 2019 was over 120 million tonnes valued at\u00a0US$274 billion. However, there are issues about the reliability of the reported figures. Further, in current aquaculture practice, products from several pounds of wild fish are used to produce one pound of a piscivorous fish like salmon. Plant and insect-based feeds are also being developed to help reduce wild fish been used for aquaculture feed.\n\nParticular kinds of aquaculture include fish farming, shrimp farming, oyster farming, mariculture, pisciculture, algaculture (such as seaweed farming), and the cultivation of ornamental fish. Particular methods include aquaponics and integrated multi-trophic aquaculture, both of which integrate fish farming and aquatic plant farming. The FAO describes aquaculture as one of the industries most directly affected by climate change and its impacts. Some forms of aquaculture have negative impacts on the environment, such as through nutrient pollution or disease transfer to wild populations.\n\nThe UN SDG 14, Target 14.7 includes aquaculture: \"By 2030, increase the economic benefits to small island developing states and least developed countries from the sustainable use of marine resources, including through sustainable management of fisheries, aquaculture and tourism\". Aquaculture's contribution to GDP is not included in SDG Target 14.7 but methods for quantifying this have been explored by FAO.\n\nOverview\n\nHarvest stagnation in wild fisheries and overexploitation of popular marine species, combined with a growing demand for high-quality protein, encouraged aquaculturists to domesticate other marine species. At the outset of modern aquaculture, many were optimistic that a \"Blue Revolution\" could take place in aquaculture, just as the Green Revolution of the 20th century had revolutionized agriculture. Although land animals had long been domesticated, most seafood species were still caught from the wild. Concerned about the impact of growing demand for seafood on the world's oceans, prominent ocean explorer Jacques Cousteau wrote in 1973: \"With earth's burgeoning human populations to feed, we must turn to the sea with new understanding and new technology.\"\n\nAbout 430 (97%) of the species cultured  were domesticated during the 20th and 21st centuries, of which an estimated 106 came in the decade to 2007. Given the long-term importance of agriculture,  to date, only 0.08% of known land plant species and 0.0002% of known land animal species have been domesticated, compared with 0.17% of known marine plant species and 0.13% of known marine animal species. Domestication typically involves about a decade of scientific research. Domesticating aquatic species involves fewer risks to humans than do land animals, which took a large toll in human lives. Most major human diseases originated in domesticated animals, including diseases such as smallpox and diphtheria, that like most infectious diseases, move to humans from animals. No human pathogens of comparable virulence have yet emerged from marine species. \n\nBiological control methods to manage parasites are already being used, such as cleaner fish (e.g. lumpsuckers and wrasse) to control sea lice populations in salmon farming. Models are being used to help with spatial planning and siting of fish farms in order to minimize impact.\n\nThe decline in wild fish stocks has increased the demand for farmed fish. However, finding alternative sources of protein and oil for fish feed is necessary so the aquaculture industry can grow sustainably; otherwise, it represents a great risk for the over-exploitation of forage fish.\n\nAquaculture production now exceeds capture fishery production and together the relative GDP contribution has ranged from 0.01 to 10%. Singling out aquaculture's relative contribution to GDP, however, is not easily derived due to lack of data.\n\nAnother recent issue following the banning in 2008 of organotins by the International Maritime Organization is the need to find environmentally friendly, but still effective, compounds with antifouling effects.\n\nMany new natural compounds are discovered every year, but producing them on a large enough scale for commercial purposes is almost impossible.\n\nIt is highly probable that future developments in this field will rely on microorganisms, but greater funding and further research is needed to overcome the lack of knowledge in this field.\n\nSpecies groups\n\nAquatic plants\n\nMicroalgae, also referred to as phytoplankton, microphytes, or planktonic algae, constitute the majority of cultivated algae. Macroalgae commonly known as seaweed also have many commercial and industrial uses, but due to their size and specific requirements, they are not easily cultivated on a large scale and are most often taken in the wild.\n\nIn 2016, aquaculture was the source of 96.5 percent by volume of the total 31.2 million tonnes of wild-collected and cultivated aquatic plants combined. Global production of farmed aquatic plants, overwhelmingly dominated by seaweeds, grew in output volume from 13.5 million tonnes in 1995 to just over 30 million tonnes in 2016.\n\nSeaweed farming\n\nFish\n\nThe farming of fish is the most common form of aquaculture. It involves raising fish commercially in tanks, fish ponds, or ocean enclosures, usually for food. A facility that releases juvenile fish into the wild for recreational fishing or to supplement a species' natural numbers is generally referred to as a fish hatchery. Worldwide, the most important fish species used in fish farming are, in order, carp, salmon, tilapia, and catfish.\n\nIn the Mediterranean, young bluefin tuna are netted at sea and towed slowly towards the shore. They are then interned in offshore pens (sometimes made from floating HDPE pipe) where they are further grown for the market. In 2009, researchers in Australia managed for the first time to coax southern bluefin tuna to breed in landlocked tanks. Southern bluefin tuna are also caught in the wild and fattened in grow-out sea cages in southern Spencer Gulf, South Australia.\n\nA similar process is used in the salmon-farming section more young people than the numbers of this industry; juveniles are taken from hatcheries and a variety of methods are used to aid them in their maturation. For example, as stated above, some of the most important fish species in the industry, salmon, can be grown using a cage system. This is done by having netted cages, preferably in open water that has a strong flow, and feeding the salmon a special food mixture that aids their growth. This process allows for year-round growth of the fish, thus a higher harvest during the correct seasons. An additional method, known sometimes as sea ranching, has also been used within the industry. Sea ranching involves raising fish in a hatchery for a brief time and then releasing them into marine waters for further development, whereupon the fish are recaptured when they have matured.\n\nCrustaceans\n\nCommercial shrimp farming began in the 1970s, and production grew steeply thereafter. Global production reached more than 1.6 million tonnes in 2003, worth about US$9 billion. About 75% of farmed shrimp is produced in Asia, in particular in China and Thailand. The other 25% is produced mainly in Latin America, where Brazil is the largest producer. Thailand is the largest exporter.\n\nShrimp farming has changed from its traditional, small-scale form in Southeast Asia into a global industry. Technological advances have led to ever higher densities per unit area, and broodstock is shipped worldwide. Virtually all farmed shrimp are penae", "flag": 1, "segments": [[1697, 1703]], "strength": 5.5}
{"token_count": [2006], "text": "Alfred the Great (848/849 \u2013 26 October 899) was King of the West Saxons from 871 to  and King of the Anglo-Saxons from  until his death in 899. He was the youngest son of King \u00c6thelwulf and his first wife Osburh, who both died when Alfred was young. Three of Alfred's brothers, \u00c6thelbald, \u00c6thelberht and \u00c6thelred, reigned in turn before him. Under Alfred's rule, considerable administrative and military reforms were introduced, prompting lasting change in England.\n\nAfter ascending the throne, Alfred spent several years fighting Viking invasions. He won a decisive victory in the Battle of Edington in 878 and made an agreement with the Vikings, dividing England between Anglo-Saxon territory and the Viking-ruled Danelaw, composed of northern England, the north-east Midlands and East Anglia. Alfred also oversaw the conversion of Viking leader Guthrum to Christianity. He defended his kingdom against the Viking attempt at conquest, becoming the dominant ruler in England. Details of his life are described in a work by 9th-century Welsh scholar and bishop Asser.\n\nAlfred had a reputation as a learned and merciful man of a gracious and level-headed nature who encouraged education, proposing that primary education be conducted in Old English rather than Latin and improving the legal system and military structure and his people's quality of life. He was given the epithet \"the Great\" in the 16th century.\n\nFamily\n\nAlfred was a son of \u00c6thelwulf, king of Wessex, and his wife Osburh. According to his biographer, Asser, writing in 893, \"In the year of our Lord's Incarnation 849 Alfred, King of the Anglo-Saxons\", was born at the royal estate called Wantage, in the district known as Berkshire (which is so called from Berroc Wood, where the box tree grows very abundantly).\" This date has been accepted by the editors of Asser's biography, Simon Keynes and Michael Lapidge, and by other historians such as David Dumville and Richard Huscroft. West Saxon genealogical lists state that Alfred was 23 when he became king in April 871, implying that he was born between April 847 and April 848. This dating is adopted in the biography of Alfred by Alfred Smyth, who regards Asser's biography as fraudulent, an allegation which is rejected by other historians. Richard Abels in his biography discusses both sources but does not decide between them and dates Alfred's birth as 847/849, while Patrick Wormald in his Oxford Dictionary of National Biography article dates it 848/849. Berkshire had been historically disputed between Wessex and Mercia, and as late as 844, a charter showed that it was part of Mercia, but Alfred's birth in the county is evidence that, by the late 840s, control had passed to Wessex.\n\nHe was the youngest of six children. His eldest brother, \u00c6thelstan, was old enough to be appointed sub-king of Kent in 839, almost 10 years before Alfred was born. He died in the early 850s. Alfred's next three brothers were successively kings of Wessex. \u00c6thelbald (858-860) and \u00c6thelberht (860-865) were also much older than Alfred, but \u00c6thelred (865-871) was only a year or two older. Alfred's only known sister, \u00c6thelswith, married Burgred, king of the midland kingdom of Mercia in 853. Most historians think that Osburh was the mother of all \u00c6thelwulf's children, but some suggest that the older ones were born to an unrecorded first wife. Osburh was descended from the rulers of the Isle of Wight. She was described by Alfred's biographer Asser as \"a most religious woman, noble by temperament and noble by birth\". She had died by 856 when \u00c6thelwulf married Judith, daughter of Charles the Bald, king of West Francia.\n\nIn 868, Alfred married Ealhswith, daughter of the Mercian nobleman \u00c6thelred Mucel, ealdorman of the Gaini, and his wife E administration and its followers\u2019adburh, who was of royal Mercian descent. Their children were \u00c6thelfl\u00e6d, who married \u00c6thelred, Lord of the Mercians; Edward the Elder, Alfred's successor as king; \u00c6thelgifu, abbess of Shaftesbury; \u00c6lfthryth, who married Baldwin, count of Flanders; and \u00c6thelweard.\n\nBackground\n\nAlfred's grandfather, Ecgberht, became king of Wessex in 802, and in the view of the historian Richard Abels, it must have seemed very unlikely to contemporaries that he would establish a lasting dynasty. For 200 years, three families had fought for the West Saxon throne, and no son had followed his father as king. No ancestor of Ecgberht had been a king of Wessex since Ceawlin in the late sixth century, but he was believed to be a paternal descendant of Cerdic, the founder of the West Saxon dynasty. This made Ecgberht an \u00e6theling \u2013 a prince eligible for the throne. But after Ecgberht's reign, descent from Cerdic was no longer sufficient to make a man an \u00e6theling. When Ecgberht died in 839, he was succeeded by his son \u00c6thelwulf; all subsequent West Saxon kings were descendants of Ecgberht and \u00c6thelwulf, and were also sons of kings.\n\nAt the beginning of the ninth century, England was almost wholly under the control of the Anglo-Saxons. Mercia dominated southern England, but its supremacy came to an end in 825 when it was decisively defeated by Ecgberht at the Battle of Ellendun. The two kingdoms became allies, which was important in the resistance to Viking attacks. In 853, King Burgred of Mercia requested West Saxon help to suppress a Welsh rebellion, and \u00c6thelwulf led a West Saxon contingent in a successful joint campaign. In the same year Burgred married \u00c6thelwulf's daughter, \u00c6thelswith.\n\nIn 825, Ecgberht sent \u00c6thelwulf to invade the Mercian sub-kingdom of Kent, and its sub-king, Baldred, was driven out shortly afterwards. By 830, Essex, Surrey and Sussex had submitted to Ecgberht, and he had appointed \u00c6thelwulf to rule the south-eastern territories as king of Kent. The Vikings ravaged the Isle of Sheppey in 835, and the following year they defeated Ecgberht at Carhampton in Somerset, but in 838 he was victorious over an alliance of Cornishmen and Vikings at the Battle of Hingston Down, reducing Cornwall to the status of a client kingdom. When \u00c6thelwulf succeeded, he appointed his eldest son \u00c6thelstan as sub-king of Kent. Ecgberht and \u00c6thelwulf may not have intended a permanent union between Wessex and Kent because they both appointed sons as sub-kings, and charters in Wessex were attested (witnessed) by West Saxon magnates, while Kentish charters were witnessed by the Kentish elite; both kings kept overall control, and the sub-kings were not allowed to issue their own coinage.\n\nViking raids increased in the early 840s on both sides of the English Channel, and in 843 \u00c6thelwulf was defeated at Carhampton. In 850, \u00c6thelstan defeated a Danish fleet off Sandwich in the first recorded naval battle in English history. In 851 \u00c6thelwulf and his second son, \u00c6thelbald, defeated the Vikings at the Battle of Aclea and, according to the Anglo-Saxon Chronicle, \"there made the greatest slaughter of a heathen raiding-army that we have heard tell of up to this present day, and there took the victory\". \u00c6thelwulf died in 858 and was succeeded by his oldest surviving son, \u00c6thelbald, as king of Wessex and by his next oldest son, \u00c6thelberht, as king of Kent. \u00c6thelbald only survived his father by two years, and \u00c6thelberht then for the first time united Wessex and Kent into a single kingdom.\n\nChildhood\n\nAccording to Asser, in his childhood Alfred won a beautifully decorated book of English poetry, offered as a prize by his mother to the first of her sons able to memorise it. He must have had it read to him because his mother died when he was about six and he did not learn to read until he was 12. In 853, Alfred is reported by the Anglo-Saxon Chronicle to have been sent to Rome where he was confirmed by Pope Leo IV, who \"anointed him as king\". Victorian writers later interpreted this as an anticipatory coronation in preparation for his eventual succession to the throne of Wessex. This is unlikely; his succession could not have been foreseen at the time because Alfred had three living elder brothers. A letter of Leo IV shows that Alfred was made a \"consul\" and a misinterpretation of this investiture, deliberate or accidental, could explain", "flag": 1, "segments": [[905, 911]], "strength": 5.5}
{"token_count": [2006], "text": "\u1e24asan Ibn al-Haytham, Latinized as Alhazen (; full name  ; ), was a Muslim Arab mathematician, astronomer, and physicist of the Islamic Golden Age. Referred to as \"the father of modern optics\", he made significant contributions to the principles of optics and visual perception in particular. His most influential work is titled Kit\u0101b al-Man\u0101\u1e93ir (Arabic:, \"Book of Optics\"), written during 1011\u20131021, which survived in a Latin edition. A polymath, he also wrote on philosophy, theology and medicine.\n\nIbn al-Haytham was the first to explain that vision occurs when light reflects from an object and then passes to one's eyes. He was also the first to demonstrate that vision occurs in the brain, rather than in the eyes. Ibn al-Haytham was an early proponent of the concept that a hypothesis must be supported by experiments based on confirmable procedures or mathematical evidence\u2014an early pioneer in the scientific method five centuries before Renaissance scientists. On account of this, he is sometimes described as the world's \"first true scientist\".\n\nBorn in Basra, he spent most of his productive period in the Fatimid capital of Cairo and earned his living authoring various treatises and tutoring members of the nobilities. Ibn al-Haytham is sometimes given the byname al-Ba\u1e63r\u012b after his birthplace, or al-Mi\u1e63r\u012b (\"of Egypt\"). Al-Haytham was dubbed the \"Second Ptolemy\" by Abu'l-Hasan Bayhaqi and  \"The Physicist\" by John Peckham. Ibn al-Haytham paved the way for the modern science of physical optics.\n\nBiography \n\nIbn al-Haytham (Alhazen) was born c. 965 to an Arab family in Basra, Iraq,\nwhich was at the time part of the Buyid emirate.\nHis initial influences were in the study of religion and service to the community. At the time, the society had a number of conflicting views of religion that he ultimately sought to step aside from religion. This led to him delving into the study of mathematics and science. He held a position with the title vizier in his native Basra, and made a name for himself for his knowledge of applied mathematics.\nAs he claimed to be able to regulate the flooding of the Nile, he was invited to Fatimid Caliph by al-Hakim in order to realise a hydraulic project at Aswan. However, Ibn al-Haytham was forced to concede the impracticability of his project.\nUpon his return to Cairo, he was given an administrative post. After he proved unable to fulfill this task as well, he contracted the ire of the caliph Al-Hakim bi-Amr Allah, and is said to have been forced into hiding until the caliph's death in 1021, after which his confiscated possessions were returned to him.\nLegend has it that Alhazen feigned madness,106 crore during August this and was kept under house arrest during this period. During this time, he wrote his influential Book of Optics.\nAlhazen continued to live in Cairo, in the neighborhood of the famous University of al-Azhar, and lived from the proceeds of his literary production until his death in c. 1040. (A copy of Apollonius' Conics, written in Ibn al-Haytham's own handwriting exists in Aya Sofya: (MS Aya Sofya 2762, 307 fob., dated Safar 415 a.h. [1024]).)\n\nAmong his students were Sorkhab (Sohrab), a Persian from Semnan, and Abu al-Wafa Mubashir ibn Fatek, an Egyptian prince.\n\nBook of Optics \n\nAlhazen's most famous work is his seven-volume treatise on optics Kitab al-Manazir (Book of Optics), written from 1011 to 1021.\n\nOptics was translated into Latin by an unknown scholar at the end of the 12th century or the beginning of the 13th century. \n\nThis work enjoyed a great reputation during the Middle Ages. The Latin version of De aspectibus was translated at the end of the 14th century into Italian vernacular, under the title De li aspecti.\n\nIt was printed by Friedrich Risner in 1572, with the title Opticae thesaurus: Alhazeni Arabis libri septem, nuncprimum editi; Eiusdem liber De Crepusculis et nubium ascensionibus (English: Treasury of Optics: seven books by the Arab Alhazen, first edition; by the same, on twilight and the height of clouds). \nRisner is also the author of the name variant \"Alhazen\"; before Risner he was known in the west as Alhacen. \nWorks by Alhazen on geometric subjects were discovered in the Biblioth\u00e8que nationale in Paris in 1834 by E. A. Sedillot. In all, A. Mark Smith has accounted for 18 full or near-complete manuscripts, and five fragments, which are preserved in 14 locations, including one in the Bodleian Library at Oxford, and one in the library of Bruges.\n\nTheory of optics \n\nTwo major theories on vision prevailed in classical antiquity. The first theory, the emission theory, was supported by such thinkers as Euclid and Ptolemy, who believed that sight worked by the eye emitting rays of light. The second theory, the intromission theory supported by Aristotle and his followers, had physical forms entering the eye from an object. Previous Islamic writers (such as al-Kindi) had argued essentially on Euclidean, Galenist, or Aristotelian lines. The strongest influence on the Book of Optics was from Ptolemy's Optics, while the description of the anatomy and physiology of the eye was based on Galen's account. Alhazen's achievement was to come up with a theory that successfully combined parts of the mathematical ray arguments of Euclid, the medical tradition of Galen, and the intromission theories of Aristotle. Alhazen's intromission theory followed al-Kindi (and broke with Aristotle) in asserting that \"from each point of every colored body, illuminated by any light, issue light and color along every straight line that can be drawn from that point\". This left him with the problem of explaining how a coherent image was formed from many independent sources of radiation; in particular, every point of an object would send rays to every point on the eye. \n\nWhat Alhazen needed was for each point on an object to correspond to one point only on the eye. He attempted to resolve this by asserting that the eye would only perceive perpendicular rays from the object\u2014for any one point on the eye, only the ray that reached it directly, without being refracted by any other part of the eye, would be perceived. He argued, using a physical analogy, that perpendicular rays were stronger than oblique rays: in the same way that a ball thrown directly at a board might break the board, whereas a ball thrown obliquely at the board would glance off, perpendicular rays were stronger than refracted rays, and it was only perpendicular rays which were perceived by the eye. As there was only one perpendicular ray that would enter the eye at any one point, and all these rays would converge on the centre of the eye in a cone, this allowed him to resolve the problem of each point on an object sending many rays to the eye; if only the perpendicular ray mattered, then he had a one-to-one correspondence and the confusion could be resolved. He later asserted (in book seven of the Optics) that other rays would be refracted through the eye and perceived as if perpendicular. His arguments regarding perpendicular rays do not clearly explain why only perpendicular rays were perceived; why would the weaker oblique rays not be perceived more weakly? His later argument that refracted rays would be perceived as if perpendicular does not seem persuasive. However, despite its weaknesses, no other theory of the time was so comprehensive, and it was enormously influential, particularly in Western Europe. Directly or indirectly, his De Aspectibus (Book of Optics) inspired much activity in optics between the 13th and 17th centuries. Kepler's later theory of the retinal image (which resolved the problem of the correspondence of points on an object and points in the eye) built directly on the conceptual framework of Alhazen.\n\nAlthough only one commentary on Alhazen's optics has survived the Islamic Middle Ages, Geoffrey Chaucer mentions the work in The Canterbury Tales: \n\"They spoke of Alhazen and Vitello,\nAnd Aristotle, who wrote, in their lives,\nOn strange mirrors and optical instruments.\"\n\nIbn al-Haytham was known for his contributions to Optics specifically thereof vision and theory of light. He assumed ray of light was radiated from specific points on the surface. Possibility of light propagation suggest that light was independent of vision. Light also moves at a very fast speed. \n\nAlhazen showed through experiment that light travels in straight lines, and carried out various experiments with lenses, mirrors, refraction, and reflection. His analyses of reflection and refraction considered the vertical and horizontal components of light rays separately.\n\nAlhazen studied the process of", "flag": 1, "segments": [[643, 649]], "strength": 5.5}
{"token_count": [2006], "text": "\u0100nanda (5th4th century BCE) was the primary attendant of the Buddha and one of his ten principal disciples. Among the Buddha's many disciples, \u0100nanda stood out for having the best memory. Most of the texts of the early Buddhist Sutta-Pi\u1e6daka (P\u0101li; ) are attributed to his recollection of the Buddha's teachings during the First Buddhist Council. For that reason, he is known as the Treasurer of the Dhamma, with Dhamma () referring to the Buddha's teaching. In Early Buddhist Texts, \u0100nanda was the first cousin of the Buddha. Although the early texts do not agree on many parts of \u0100nanda's early life, they do agree that \u0100nanda was ordained as a monk and that Pu\u1e47\u1e47a Mant\u0101n\u012bputta () became his teacher. Twenty years in the Buddha's ministry, \u0100nanda became the attendant of the Buddha, when the Buddha selected him for this task. \u0100nanda performed his duties with great devotion and care, and acted as an intermediary between the Buddha and the laypeople, as well as the sa\u1e45gha (). He accompanied the Buddha for the rest of his life, acting not only as an assistant, but also a secretary and a mouthpiece.\n\nScholars are skeptical about the historicity of many events in \u0100nanda's life, especially the First Council, and consensus about this has yet to be established. A traditional account can be drawn from early texts, commentaries, and post-canonical chronicles. \u0100nanda had an important role in establishing the order of bhikkhun\u012bs (), when he requested the Buddha on behalf of the latter's foster-mother Mah\u0101paj\u0101pati Gotam\u012b () to allow her to be ordained. \u0100nanda also accompanied the Buddha in the last year of his life, and therefore was witness to many tenets and principles that the Buddha conveyed before his death, including the well-known principle that the Buddhist community should take his teaching and discipline as their refuge, and that he would not appoint a new leader. The final period of the Buddha's life also shows that \u0100nanda was very much attached to the Buddha's person, and he saw the Buddha's passing with great sorrow.\n\nShortly after the Buddha's death, the First Council was convened, and \u0100nanda managed to attain enlightenment just before the council started, which was a requirement. He had a historical role during the council as the living memory of the Buddha, reciting many of the Buddha's discourses and checking them for accuracy. During the same council, however, he was chastised by Mah\u0101kassapa () and the rest of the sa\u1e45gha for allowing women to be ordained and failing to understand or respect the Buddha at several crucial moments. \u0100nanda continued to teach until the end of his life, passing on his spiritual heritage to his pupils S\u0101\u1e47av\u0101s\u012b () and Majjhantika (), among others, who later assumed leading roles in the Second and Third Councils. \u0100nanda died 20 years after the Buddha packaging, distribution and restaurant sales, and st\u016bpas (monuments) were erected at the river where he died.\n\n\u0100nanda is one of the most loved figures in Buddhism. He was known for his memory, erudition and compassion, and was often praised by the Buddha for these matters. He functioned as a foil to the Buddha, however, in that he still had worldly attachments and was not yet enlightened, as opposed to the Buddha. In the Sanskrit textual traditions, \u0100nanda is considered the patriarch of the Dhamma who stood in a spiritual lineage, receiving the teaching from Mah\u0101kassapa and passing them on to his own pupils. \u0100nanda has been honored by bhikkhun\u012bs since early medieval times for his merits in establishing the nun's order. In recent times, the composer Richard Wagner and Indian poet Rabindranath Tagore were inspired by stories about \u0100nanda in their work.\n\nName \nThe word \u0101nanda means 'bliss, joy' in P\u0101li and in Sanskrit. P\u0101li commentaries explain that when \u0100nanda was born, his relatives were joyous about this. Texts from the M\u016blasarv\u0101stiv\u0101da tradition, however, state that since \u0100nanda was born on the day of the Buddha's enlightenment, there was great rejoicing in the cityhence the name.\n\nAccounts\n\nPrevious lives \nAccording to the texts, in a previous life, \u0100nanda made an aspiration to become a Buddha's attendant. He made this aspiration in the time of a previous Buddha called Padumuttara, many eons (, ) before the present age. He met the attendant of Padumuttara Buddha and aspired to be like him in a future life. After having done many good deeds, he made his resolution known to the Padumuttara Buddha, who confirmed that his wish will come true in a future life. After having been born and reborn throughout many lifetimes, and doing many good deeds, he was born as \u0100nanda in the time of the current Buddha Gotama.\n\nEarly life \n\n\u0100nanda was born in the same time period as the Buddha (formerly Prince Siddhattha), which scholars place at 5th4th centuries BCE. Tradition says that \u0100nanda was the first cousin of the Buddha, his father being the brother of Suddhodana (), the Buddha's father. In the P\u0101li and M\u016blasarv\u0101stiv\u0101da textual traditions, his father was Amitodana (), but the Mah\u0101vastu states that his father was \u015auklodanaboth are brothers of Suddhodana. The Mah\u0101vastu also mentions that \u0100nanda's mother's name was M\u1e5bg\u012b (Sanskrit; lit. 'little deer'; P\u0101li is unknown). The P\u0101li tradition has it that \u0100nanda was born on the same day as Prince Siddhatta (), but texts from the M\u016blasarv\u0101stiv\u0101da and subsequent Mah\u0101y\u0101na traditions state \u0100nanda was born at the same time the Buddha attained enlightenment (when Prince Siddhattha was 35 years old), and was therefore much younger than the Buddha. The latter tradition is corroborated by several instances in the Early Buddhist Texts, in which \u0100nanda appears younger than the Buddha, such as the passage in which the Buddha explained to \u0100nanda how old age was affecting him in body and mind. It is also corroborated by a verse in the P\u0101li text called Therag\u0101th\u0101, in which \u0100nanda stated he was a \"learner\" for twenty-five years, after which he attended to the Buddha for another twenty-five years.Following the P\u0101li, Mah\u012b\u015basaka and Dharmaguptaka textual traditions, \u0100nanda became a monk in the second year of the Buddha's ministry, during the Buddha's visit to Kapilavatthu (). He was ordained by the Buddha himself, together with many other princes of the Buddha's clan (, ), in the mango grove called Anupiya, part of Malla territory. According to a text from the Mah\u0101sa\u1e45ghika tradition, King Suddhodana wanted the Buddha to have more followers of the khattiya caste (), and less from the brahmin (priest) caste. He therefore ordered that any khattiya who had a brother follow the Buddha as a monk, or had his brother do so. \u0100nanda used this opportunity, and asked his brother Devadatta to stay at home, so that he could leave for the monkhood. The later timeline from the M\u016blasarv\u0101stiv\u0101da texts and the P\u0101li Therag\u0101th\u0101, however, have \u0100nanda ordain much later, about twenty-five years before the Buddha's deathin other words, twenty years in the Buddha's ministry. Some Sanskrit sources have him ordain even later. The M\u016blasarv\u0101stiv\u0101da texts on monastic discipline (P\u0101li and ) relate that soothsayers predicted \u0100nanda would be the Buddha's attendant. In order to prevent \u0100nanda from leaving the palace to ordain, his father brought him to Ves\u0101l\u012b () during the Buddha's visit to Kapilavatthu, but later the Buddha met and taught \u0100nanda nonetheless. On a similar note, the Mah\u0101vastu relates, however, that M\u1e5bg\u012b was initially opposed to \u0100nanda joining the holy life, because his brother Devadatta had already ordained and left the palace. \u0100nanda responded to his mother's resistance by moving to Videha () and lived there, taking a vow of silence. This led him to gain the epithet Videhamuni (), meaning 'the silent wise one from Videha'. When \u0100nanda did become ordained, his father had him ordain in Kapilavatthu in the Nigrodh\u0101r\u0101ma monastery () with much ceremony, \u0100nanda's preceptor (; ) being a certain Da\u015bab\u0101la K\u0101\u015byapa.\n\nAccording to the P\u0101li tradition, \u0100nanda's first teachers were Bela\u1e6d\u1e6dhas\u012bsa and Pu\u1e47\u1e47a Mant\u0101n\u012bput", "flag": 1, "segments": [[655, 661]], "strength": 5.5}
{"token_count": [2006], "text": "Apollo 13 (April 1117, 1970) was the seventh crewed mission in the Apollo space program and the third meant to land on the Moon. The craft was launched from Kennedy Space Center on April\u00a011, 1970, but the lunar landing was aborted after an oxygen tank in the service module (SM) failed two days into the mission. The crew instead looped around the Moon and returned safely to Earth on April\u00a017. The mission was commanded by Jim Lovell, with Jack Swigert as command module (CM) pilot and Fred Haise as Lunar Module (LM) pilot. Swigert was a late replacement for Ken Mattingly, who was grounded after exposure to rubella.\n\nA routine stir of an oxygen tank ignited damaged wire insulation inside it, causing an explosion that vented the contents of both of the SM's oxygen tanks to space. Without oxygen, needed for breathing and for generating electric power, the SM's propulsion and life support systems could not operate. The CM's systems had to be shut down to conserve its remaining resources for reentry, forcing the crew to transfer to the LM as a lifeboat. With the lunar landing canceled, mission controllers worked to bring the crew home alive.\n\nAlthough the LM technology develops, but they will was designed to support two men on the lunar surface for two days, Mission Control in Houston improvised new procedures so it could support three men for four days. The crew experienced great hardship, caused by limited power, a chilly and wet cabin and a shortage of potable water. There was a critical need to adapt the CM's cartridges for the carbon dioxide scrubber system to work in the LM; the crew and mission controllers were successful in improvising a solution. The astronauts' peril briefly renewed public interest in the Apollo program; tens of millions watched the splashdown in the South Pacific Ocean on television.\n\nAn investigative review board found fault with preflight testing of the oxygen tank and Teflon being placed inside it. The board recommended changes, including minimizing the use of potentially combustible items inside the tank; this was done for Apollo 14. The story of Apollo\u00a013 has been dramatized several times, most notably in the 1995 film Apollo\u00a013 \u2013 based on Lost Moon, the 1994 memoir co-authored by Lovell \u2013 and an episode of the 1998 miniseries From the Earth to the Moon.\n\nBackground \nIn 1961, U.S. President John F. Kennedy challenged his nation to land an astronaut on the Moon by the end of the decade, with a safe return to Earth. NASA worked towards this goal incrementally, sending astronauts into space during Project Mercury and Project Gemini, leading up to the Apollo program. The goal was achieved with Apollo 11, which landed on the Moon on July\u00a020, 1969. Neil Armstrong and Buzz Aldrin walked on the lunar surface while Michael Collins orbited the Moon in Command Module Columbia. The mission returned to Earth on July\u00a024, 1969, fulfilling Kennedy's challenge.\n\nNASA had contracted for fifteen Saturn\u00a0V rockets to achieve the goal; at the time no one knew how many missions this would require. Since success was obtained in 1969 with the sixth SaturnV on Apollo\u00a011, nine rockets remained available for a hoped-for total of ten landings. After the excitement of Apollo\u00a011, the general public grew apathetic towards the space program and Congress continued to cut NASA's budget; Apollo 20 was canceled. Despite the successful lunar landing, the missions were considered so risky that astronauts could not afford life insurance to provide for their families if they died in space.\n\nEven before the first U.S. astronaut entered space in 1961, planning for a centralized facility to communicate with the spacecraft and monitor its performance had begun, for the most part the brainchild of Christopher C. Kraft Jr., who became NASA's first flight director. During John Glenn's Mercury Friendship 7 flight in February 1962 (the first crewed orbital flight by the U.S.), one of Kraft's decisions was overruled by NASA managers. He was vindicated by post-mission analysis and implemented a rule that, during the mission, the flight director's word was absolute \u2013 to overrule him, NASA would have to fire him on the spot. Flight directors during Apollo had a one-sentence job description, \"The flight director may take any actions necessary for crew safety and mission success.\"\n\nIn 1965, Houston's Mission Control Center opened, in part designed by Kraft and now named for him.  In Mission Control, each flight controller, in addition to monitoring telemetry from the spacecraft, was in communication via voice loop to specialists in a Staff Support Room (or \"back room\"), who focused on specific spacecraft systems.\n\nApollo\u00a013 was to be the second H mission, meant to demonstrate precision lunar landings and explore specific sites on the Moon. With Kennedy's goal accomplished by Apollo\u00a011, and Apollo 12 demonstrating that the astronauts could perform a precision landing, mission planners were able to focus on more than just landing safely and having astronauts minimally trained in geology gather lunar samples to take home to Earth. There was a greater role for science on Apollo\u00a013, especially for geology, something emphasized by the mission's motto, Ex luna, scientia (From the Moon, knowledge).\n\nAstronauts and key Mission Control personnel \n\nApollo\u00a013's mission commander, Jim Lovell, was 42 years old at the time of the spaceflight. He was a graduate of the United States Naval Academy and had been a naval aviator and test pilot before being selected for the second group of astronauts in 1962; he flew with Frank Borman in Gemini\u00a07 in 1965 and Buzz Aldrin in Gemini\u00a012 the following year before flying in Apollo 8 in 1968, the first spacecraft to orbit the Moon. At the time of Apollo 13, Lovell was the NASA astronaut with the most time in space, with 572 hours over the three missions.\n\nJack Swigert, the command module pilot (CMP), was 38\u00a0years old and held a B.S. in mechanical engineering and an M.S. in aerospace science; he had served in the Air Force and in state Air National Guards and was an engineering test pilot before being selected for the fifth group of astronauts in 1966. Fred Haise, the lunar module pilot (LMP), was 35 years old. He held a B.S. in aeronautical engineering, had been a Marine Corps fighter pilot, and was a civilian research pilot for NASA when he was selected as a Group5 astronaut.\n\nAccording to the standard Apollo crew rotation, the prime crew for Apollo\u00a013 would have been the backup crew for Apollo 10, with Mercury and Gemini veteran Gordon Cooper in command, Donn F. Eisele as CMP and Edgar Mitchell as LMP. Deke Slayton, NASA's Director of Flight Crew Operations, never intended to rotate Cooper and Eisele to a prime crew assignment, as both were out of favorCooper for his lax attitude towards training, and Eisele for incidents aboard Apollo7 and an extramarital affair. He assigned them to the backup crew because no other veteran astronauts were available. Slayton's original choices for Apollo\u00a013 were Alan Shepard as commander, Stuart Roosa as CMP, and Mitchell as LMP. However, management felt Shepard needed more training time, as he had only recently resumed active status after surgery for an inner ear disorder and had not flown since 1961. Thus, Lovell's crew (himself, Haise and Ken Mattingly), having all backed up Apollo 11 and being slated for Apollo 14, was swapped with Shepard's.\n\nSwigert was originally CMP of Apollo\u00a013's backup crew, with John Young as commander and Charles Duke as lunar module pilot. Seven days before launch, Duke contracted rubella from a friend of his son. This exposed both the prime and backup crews, who trained together. Of the five, only Mattingly was not immune through prior exposure. Normally, if any member of the prime crew had to be grounded, the remaining crew would be replaced as well, and the backup crew substituted, but Duke's illness ruled this out, so two days before launch, Mattingly was replaced by Swigert. Mattingly never developed rubella and later flew on Apollo 16.\n\nFor Apollo, a third crew of astronauts, known as the support crew, was designated in addition to the prime and backup crews used on projects Mercury and Gemini. Slayton created the support crews because James McDivitt, who would command Apollo 9, believed that, with preparation going on in facilities across the US, meetings that needed a member of the flight crew would be missed. Support crew members were to assist as directed by the mission commander. Usually low in seniority, they assembled the mission's rules, flight plan, and checklists, and kept them updated; for Apollo\u00a013, they were Vance D. Brand, Jack Lousma and either William Pogue or Joseph Kerwin.\n\nFor Apollo\u00a013, flight directors were Gene Kranz, White team (the lead flight director); Glynn Lunney, Black team; Milton Windler, Maroon team and Gerry Griffin, Gold team. The CAPCOMs (the person in Mission Control, during the Apollo program an astronaut, who was responsible for voice communications with the crew) for Apollo\u00a013 were Kerwin, Brand, Lousma, Young and Mattingly.\n\nMission insignia and call signs \n\nThe Apollo\u00a013 mission insignia depicts the Greek god of the Sun, Apollo, with three horses pulling his chariot across the face of the Moon, and the Earth seen in the distance. This is meant to symbolize the", "flag": 1, "segments": [[254, 260]], "strength": 5.5}
{"token_count": [2006], "text": "Arnold Alois Schwarzenegger (; ; born July 30, 1947) is an Austrian-American actor, former bodybuilder, film producer, businessman, and former politician who served as the 38th governor of California from 2003 to 2011. As of 2022, he is the most recent Republican governor of California.\n\nSchwarzenegger began lifting weights at the age of 15 and went on to win the Mr. Universe title at age 20, subsequently winning the Mr. Olympia contest seven times; he remains a prominent figure in bodybuilding, and has written many books and articles on it. The Arnold Sports Festival, considered the second-most important bodybuilding event after Mr. Olympia, is named after him. He appeared in the bodybuilding documentary Pumping Iron (1977). Schwarzenegger retired from bodybuilding and gained worldwide fame as a Hollywood action star, with his breakthrough the sword and sorcery epic Conan the Barbarian (1982), a box-office hit with a sequel in 1984. After playing the title character in the science fiction film The Terminator (1984), he starred in the sequels Terminator 2: Judgment Day (1991), Terminator 3: Rise of the Machines (2003), Terminator Genisys (2015), and Terminator: Dark Fate (2019). His other successful action films included Commando (1985), The Running Man (1987), Predator (1987), Red Heat (1988), Total Recall (1990), and True Lies (1994), in addition to comedy films such as Twins (1988), Kindergarten Cop (1990), Junior (1994), and Jingle All the Way (1996). He is the founder of the film production company Oak Productions.\n\nAs a Republican candidate, Schwarzenegger was first elected on October 7, 2003, in a special recall election to replace then-Governor Gray Davis. He received 48.6% of the vote, 17 points ahead of Democrat runner-up Cruz Bustamante. He was sworn in on November 17 to serve the remainder of Davis' term, and was re-elected in the 2006 California gubernatorial election with an increased vote share of 55.9% to serve a full term as governor. In 2011, he reached his term limit as Governor and returned to acting.\n\nSchwarzenegger was nicknamed the \"Austrian Oak\" in his bodybuilding days, \"Arnie\" or \"Schwarzy\" during his acting career, and \"The Governator\" (a portmanteau of \"Governor\" and \"Terminator\") during his political career. He married Maria Shriver, a niece of President John F. Kennedy, in 1986. They separated in 2011 after he admitted to having fathered a child with their housemaid in 1997; their divorce was finalized in 2021.\n\nEarly life \n\nArnold Alois Schwarzenegger was born in Thal, Austria on July 30, 1947, the second son of Gustav Schwarzenegger and his wife, Aurelia (n\u00e9e Jadrny). His mother was of Czech descent, while his paternal great-grandfather, Wenzel Mach, was also Czech and came from the village of Chocov near Mlad\u00e1 Vo\u017eice. Wenzel had a child out of wedlock with Kunigunde Schwarzenegger, and the child (Schwarzenegger's paternal grandfather) was originally named Carl Mach but later adopted his mother's surname Schwarzenegger.\n\nSchwarzenegger's father was the local chief of police. After the Anschluss in 1938, he joined the Nazi Party and, in 1939 the Sturmabteilung (SA). In World War II, he served as a military policeman in the invasions of Poland, France and the Soviet Union, including the siege of Leningrad, rising to the rank of Hauptfeldwebel. He was wounded in the Battle of Stalingrad, and was discharged in 1943 following a bout of malaria. According to Holocaust scholar Michael Berenbaum, Gustav Schwarzenegger served \"in theaters of the war where atrocities were committed. But there is no way to know from the documents whether he played a role.\" Gustav's background received wide press attention during the 2003 California gubernatorial recall election in which Schwarzenegger was elected governor.\n\nGustav Schwarzenegger married Aurelia on October 20, 1945; he was 38 and she was 23. According to Schwarzenegger, his parents were very strict: \"Back then in Austria it was a very different world [...] if we did something bad or we disobeyed our parents, the rod was not spared.\" He grew up in a Catholic family. Gustav preferred his elder son, Meinhard, over Arnold. His favoritism was \"strong and blatant\", which stemmed from unfounded suspicion that Arnold was not his biological child. Schwarzenegger has said that his father had \"no patience for listening or understanding your problems\". He had a good relationship with his mother, with whom he kept in touch until her death.\n\nEarly education and bodybuilding beginnings \nAt school, Schwarzenegger was reportedly academically average but stood out for his \"cheerful, good-humored, and exuberant\" character. Money was a problem in their household; Schwarzenegger recalled that one of the highlights of his youth was when the family bought a refrigerator. Schwarzenegger's father Gustav was an athlete, and wished for his sons to become a champion in Bavarian curling. Influenced by his father, Schwarzenegger played several sports as a boy.\n\nSchwarzenegger began weight training in 1960 when his football coach took his team to a local gym. At the age of 14, he chose bodybuilding over football as a career. He later said, \"I actually started weight training when I was 15, but I'd been participating in sports, like soccer, for years, so I felt that although I was slim, I was well-developed, at least enough so that I could start going to the gym and start Olympic lifting.\" However, his official website biography claims that \"at 14, he started an intensive training program with Dan Farmer, studied psychology at 15 (to learn more about the power of mind over body) and at 17, officially started his competitive career.\" During a speech in 2001, he said, \"My own plan formed when I was 14 years old. My father had wanted me to be a police officer like he was. My mother wanted me to go to trade school.\"\n\nSchwarzenegger took to visiting a gym in Graz, where he also frequented the local movie theaters to see bodybuilding idols such as Reg Park, Steve Reeves, and Johnny Weissmuller on the big screen. When Reeves died in 2000, Schwarzenegger fondly remembered him: \"As a teenager, I grew up with Steve Reeves. His remarkable accomplishments allowed me a sense of what was possible when others around me didn't always understand my dreams. Steve Reeves has been part of everything I've ever been fortunate enough to achieve.\" In 1961, Schwarzenegger met former Mr. Austria Kurt Marnul, who invited him to train at the gym in Graz. He was so dedicated as a youngster that he broke into the local gym on weekends it somehow ended as a wardrobe in order to train even when it was closed. \"It would make me sick to miss a workout... I knew I couldn't look at myself in the mirror the next morning if I didn't do it.\" When Schwarzenegger was asked about his first cinema experience as a boy, he replied: \"I was very young, but I remember my father taking me to the Austrian theaters and seeing some newsreels. The first real movie I saw, that I distinctly remember, was a John Wayne movie.\" In Graz, Schwarzenegger was mentored by Alfred Gerstl, who had Jewish ancestry and later became president of the Federal Council, and befriended his son Karl.\n\nSchwarzenegger's brother, Meinhard, died in a car crash on May 20, 1971. He was driving drunk and died instantly. Schwarzenegger did not attend his funeral. Meinhard was engaged to Erika Knapp, and they had a three-year-old son named Patrick. Schwarzenegger paid for Patrick's education and helped him to move to the U.S. Gustav died of a stroke on December 13, 1972. In Pumping Iron, Schwarzenegger claimed that he did not attend his father's funeral because he was training for a bodybuilding contest. Later, he and the film's producer said this story was taken from another bodybuilder to show the extremes some would go to for their sport and to make Schwarzenegger's image colder to create controversy for the film. However, Barbara Baker, his first serious girlfriend, recalled that he informed her of his father's death without emotion and that he never spoke of his brother. Over time, he has given at least three versions of why he was absent from his father's funeral.\n\nIn an interview with Fortune in 2004, Schwarzenegger told how he suffered what \"would now be called child abuse\" at the hands of his father: \"My hair was pulled. I was hit with belts. So was the kid next door. It was just the way it was. Many of the children I've seen were broken by their parents, which was the German-Austrian mentality. They didn't want to create an individual. It was all about conforming. I was one who did not conform, and whose will could not be broken. Therefore, I became a rebel. Every time I got hit, and every time someone said, 'You can't do this,' I said, 'This is not going to be for much longer because I'm going to move out of here. I want to be rich. I want to be somebody.'\"\n\nSchwarzenegger served in the Austrian Army in 1965 to fulfill the one year of service required at the time of all 18-year-old Austrian males. During his army service, he won the Junior Mr. Europe contest", "flag": 1, "segments": [[1435, 1441]], "strength": 5.5}
{"token_count": [2006], "text": "Adam Smith  (baptized  1723 \u2013 17 July 1790) was a Scottish economist and philosopher who was a pioneer of political economy and key figure during the Scottish Enlightenment. Also known as \"The Father of Economics\" or \"The Father of Capitalism\", he wrote two classic works, The Theory of Moral Sentiments (1759) and An Inquiry into the Nature and Causes of the Wealth of Nations (1776). The latter, often abbreviated as The Wealth of Nations, is considered his magnum opus and the first modern work of economics. In his work, Smith introduced his theory of absolute advantage.\n\nSmith studied social philosophy at the University of Glasgow and at Balliol College, Oxford, where he was one of the first students to benefit from scholarships set up by fellow Scot John Snell. After graduating, he delivered a successful series of public lectures at the University of Edinburgh, leading him to collaborate with David Hume during the Scottish Enlightenment. Smith obtained a professorship at Glasgow, teaching moral philosophy and during this time, wrote and published The Theory of Moral Sentiments. In his later life, he took a tutoring position that allowed him to travel throughout Europe, where he met other intellectual leaders of his day.\n\nSmith laid the foundations of classical free market economic theory. The Wealth of Nations was a precursor to the modern academic discipline of economics. In this and other works, he developed the concept of division of labour and expounded upon how rational self-interest and competition can lead to economic prosperity. Smith was controversial in his own day and his general approach and writing style were often satirised by writers such as Horace Walpole.\n\nBiography\n\nEarly life\n\nSmith was born in Kirkcaldy, in Fife, Scotland. His father, also Adam Smith, was a Scottish Writer to the Signet (senior solicitor), advocate and prosecutor (judge advocate) and also served as comptroller of the customs in Kirkcaldy. Smith's mother was born Margaret Douglas, daughter of the landed Robert Douglas of Strathendry, also in Fife; she married Smith's father in 1720. Two months before Smith was born, his father died, leaving his mother a widow. The date of Smith's baptism into the Church of Scotland at Kirkcaldy was 5 June 1723 and this has often been treated as if it were also his date of birth, which is unknown.\n\nAlthough few events in Smith's early childhood are known, the Scottish journalist John Rae, Smith's biographer, recorded that Smith was abducted by Romani at the age of three and released when others went to rescue him. Smith was close to his mother, who probably encouraged him to pursue his scholarly ambitions. He attended the Burgh School of Kirkcaldy\u2014characterised by Rae as \"one of the best secondary schools of Scotland at that period\"\u2014from 1729 to 1737, he learned Latin, mathematics, history, and writing.\n\nFormal education\n\nSmith entered the University of Glasgow when he was 14 and studied moral philosophy under Francis Hutcheson. Here he developed his passion for liberty, reason, and free speech. In 1740, he was the graduate scholar presented to undertake postgraduate studies at Balliol College, Oxford, under the Snell Exhibition.\n\nSmith considered the teaching at Glasgow to be far superior to that at Oxford, which he found intellectually stifling. In Book V, Chapter II of The Wealth of Nations, he wrote: \"In the University of Oxford, the greater part of the public professors have, for these many years, given up altogether even the pretence of teaching.\"\nSmith is also reported to have complained to friends that Oxford officials once discovered him reading a copy of David Hume's A Treatise of Human Nature, and they subsequently confiscated his book and punished him severely for reading it. According to William Robert Scott, \"The Oxford of [Smith's] time gave little if any help towards what was to be his lifework.\" Nevertheless, he took the opportunity while at Oxford to teach himself several subjects by reading many books from the shelves of the large Bodleian Library. When Smith was not studying on his own, his time at Oxford was not a happy one, according to his letters. Near the end of his time there, he began suffering from shaking fits, probably theade property could be used for symptoms of a nervous breakdown. He left Oxford University in 1746, before his scholarship ended.\n\nIn Book V of The Wealth of Nations, Smith comments on the low quality of instruction and the meager intellectual activity at English universities, when compared to their Scottish counterparts. He attributes this both to the rich endowments of the colleges at Oxford and Cambridge, which made the income of professors independent of their ability to attract students, and to the fact that distinguished men of letters could make an even more comfortable living as ministers of the Church of England.\n\nSmith's discontent at Oxford might be in part due to the absence of his beloved teacher in Glasgow, Francis Hutcheson, who was well regarded as one of the most prominent lecturers at the University of Glasgow in his day and earned the approbation of students, colleagues, and even ordinary residents with the fervor and earnestness of his orations (which he sometimes opened to the public). His lectures endeavoured not merely to teach philosophy, but also to make his students embody that philosophy in their lives, appropriately acquiring the epithet, the preacher of philosophy. Unlike Smith, Hutcheson was not a system builder; rather, his magnetic personality and method of lecturing so influenced his students and caused the greatest of those to reverentially refer to him as \"the never to be forgotten Hutcheson\"\u2014a title that Smith in all his correspondence used to describe only two people, his good friend David Hume and influential mentor Francis Hutcheson.\n\nTeaching career\nSmith began delivering public lectures in 1748 at the University of Edinburgh, sponsored by the Philosophical Society of Edinburgh under the patronage of Lord Kames. His lecture topics included rhetoric and belles-lettres, and later the subject of \"the progress of opulence\". On this latter topic, he first expounded his economic philosophy of \"the obvious and simple system of natural liberty\". While Smith was not adept at public speaking, his lectures met with success.\n\nIn 1750, Smith met the philosopher David Hume, who was his senior by more than a decade. In their writings covering history, politics, philosophy, economics, and religion, Smith and Hume shared closer intellectual and personal bonds than with other important figures of the Scottish Enlightenment.\n\nIn 1751, Smith earned a professorship at Glasgow University teaching logic courses, and in 1752, he was elected a member of the Philosophical Society of Edinburgh, having been introduced to the society by Lord Kames. When the head of Moral Philosophy in Glasgow died the next year, Smith took over the position. He worked as an academic for the next 13 years, which he characterised as \"by far the most useful and therefore by far the happiest and most honorable period [of his life]\".\n\nSmith published The Theory of Moral Sentiments in 1759, embodying some of his Glasgow lectures. This work was concerned with how human morality depends on sympathy between agent and spectator, or the individual and other members of society. Smith defined \"mutual sympathy\" as the basis of moral sentiments. He based his explanation, not on a special \"moral sense\" as the Third Lord Shaftesbury and Hutcheson had done, nor on utility as Hume did, but on mutual sympathy, a term best captured in modern parlance by the 20th-century concept of empathy, the capacity to recognise feelings that are being experienced by another being.\n\nFollowing the publication of The Theory of Moral Sentiments, Smith became so popular that many wealthy students left their schools in other countries to enroll at Glasgow to learn under Smith. After the publication of The Theory of Moral Sentiments, Smith began to give more attention to jurisprudence and economics in his lectures and less to his theories of morals. For example, Smith lectured that the cause of increase in national wealth is labour, rather than the nation's quantity of gold or silver, which is the basis for mercantilism, the economic theory that dominated Western European economic policies at the time.\n\nIn 1762, the University of Glasgow conferred on Smith the title of Doctor of Laws (LL.D.). At the end of 1763, he obtained an offer from Charles Townshend\u2014who had been introduced to Smith by David Hume\u2014to tutor his stepson, Henry Scott, the young Duke of Buccleuch. Smith resigned from his professorship in 1764 to take the tutoring position. He subsequently attempted to return the fees he had collected from his students because he had resigned partway through the term, but his students refused.\n\nTutoring and travels\nSmith's tutoring job entailed touring Europe with Scott, during which time he educated Scott on a variety of subjects, such as etiquette and manners. He was paid \u00a3300 per year (plus expenses) along with a \u00a3300 per year pension; roughly twice his former income as a teacher. Smith first travelled as a tutor to Toulouse, France, where he stayed for a year and a half. According to his own account, he found Toulouse to be somewhat boring, having written to Hume that he \"had begun to write a book to pass away the time\". After touring the south of France, the group moved to Geneva, where Smith met with the philosopher Voltaire.\n\nFrom Geneva, the party moved to Paris. Here, Smith met Benjamin Franklin, and discovered the Physiocracy school founded by Fran\u00e7ois Quesnay. Physiocrats were", "flag": 1, "segments": [[887, 893]], "strength": 5.5}
{"token_count": [2006], "text": "Arizona State University (Arizona State or ASU) is a public research university in the Phoenix metropolitan area. Founded in 1885 by the 13th Arizona Territorial Legislature, ASU is one of the largest public universities by enrollment in the U.S.\n\nOne of three universities governed by the Arizona Board of Regents, ASU is a member of the Universities Research Association and classified among \"R1: Doctoral Universities \u2013 Very High Research Activity\". ASU has nearly 150,000 students attending classes, with more than 38,000 students attending online, and 90,000 undergraduates and more nearly 20,000 postgraduates across its five campuses and four regional learning centers throughout Arizona. ASU offers 350 degree options from its 17 colleges and more than 170 cross-discipline centers and institutes for undergraduates students, as well as more than 400 graduate degree and certificate programs. The Arizona State Sun Devils compete in 26 varsity-level sports in the NCAA Division I Pac-12 Conference and is home to over 1,100 registered student organizations.\n\nASU's charter, approved by the board of regents in 2014, is based on the New American University model created by ASU President Michael M. Crow upon his appointment as the institution's 16th president in 2002. It defines ASU as \"a comprehensive public research university, measured not by whom it excludes, but rather by whom it includes and how they succeed; advancing research and discovery of public value; and assuming fundamental responsibility for the economic, social, cultural and overall health of the communities it serves.\" The model is widely credited with boosting ASU's acceptance rate and increasing class size.\n\nAs of January, 2022, ASU reported that its faculty of more than 4,700 scholars included 5 Nobel laureates, 6 MacArthur Fellows, 9 Pulitzer Prize winners, 9 National Academy of Engineering members, 23 National Academy of Sciences members, 26 American Academy of Arts and Sciences members, 40 Guggenheim fellows, 149 National Endowment for the Humanities fellows, and 270 Fulbright Program American Scholars.\n\nHistory\n\n1885\u20131929\n\nArizona State University was established as the Territorial Normal School at Tempe on March 12, 1885, when the 13th Arizona Territorial Legislature passed an act to create a normal school to train teachers for the Arizona Territory. The campus consisted of a single, four-room schoolhouse on billion, the CBK managing a 20-acre plot largely donated by Tempe residents George and Martha Wilson. Classes began with 33 students on February 8, 1886. The curriculum evolved over the years and the name was changed several times; the institution was also known as Tempe Normal School of Arizona (1889\u20131903), Tempe Normal School (1903\u20131925), Tempe State Teachers College (1925\u20131929), Arizona State Teachers College (1929\u20131945), Arizona State College (1945\u20131958) and, by a 2\u20131 margin of the state's voters, Arizona State University in 1958.\n\nIn 1923, the school stopped offering high school courses and added a high school diploma to the admissions requirements. In 1925, the school became the Tempe State Teachers College and offered four-year Bachelor of Education degrees as well as two-year teaching certificates. In 1929, the 9th Arizona State Legislature authorized Bachelor of Arts in Education degrees as well, and the school was renamed the Arizona State Teachers College. Under the 30-year tenure of president Arthur John Matthews (1900\u20131930), the school was given all-college student status. The first dormitories built in the state were constructed under his supervision in 1902. Of the 18 buildings constructed while Matthews was president, six are still in use. Matthews envisioned an \"evergreen campus\", with many shrubs brought to the campus, and implemented the planting of 110 Mexican Fan Palms on what is now known as Palm Walk, a century-old landmark of the Tempe campus.\n\nDuring the Great Depression, Ralph Waldo Swetman was hired to succeed President Matthews, coming to Arizona State Teachers College in 1930 from Humboldt State Teachers College where he had served as president. He served a three-year term, during which he focused on improving teacher-training programs. During his tenure, enrollment at the college doubled, topping the 1,000 mark for the first time. Matthews also conceived of a self-supported summer session at the school at Arizona State Teachers College, a first for the school.\n\n1930\u20131989\n\nIn 1933, Grady Gammage, then president of Arizona State Teachers College at Flagstaff, became president of Arizona State Teachers College at Tempe, beginning a tenure that would last for nearly 28 years, second only to Swetman's 30 years at the college's helm. Like President Arthur John Matthews before him, Gammage oversaw the construction of several buildings on the Tempe campus. He also guided the development of the university's graduate programs; the first Master of Arts in Education was awarded in 1938, the first Doctor of Education degree in 1954 and 10 non-teaching master's degrees were approved by the Arizona Board of Regents in 1956. During his presidency, the school's name was changed to Arizona State College in 1945, and finally to Arizona State University in 1958. At the time, two other names were considered: Tempe University and State University at Tempe. Among Gammage's greatest achievements in Tempe was the Frank Lloyd Wright-designed construction of what is Grady Gammage Memorial Auditorium/ASU Gammage. One of the university's hallmark buildings, ASU Gammage was completed in 1964, five years after the president's (and Wright's) death.\n\nGammage was succeeded by Harold D. Richardson, who had served the school earlier in a variety of roles beginning in 1939, including director of graduate studies, college registrar, dean of instruction, dean of the College of Education and academic vice president. Although filling the role of acting president of the university for just nine months (Dec. 1959 to Sept. 1960), Richardson laid the groundwork for the future recruitment and appointment of well-credentialed research science faculty.\n\nBy the 1960s, under G. Homer Durham, the university's 11th president, ASU began to expand its curriculum by establishing several new colleges and, in 1961, the Arizona Board of Regents authorized doctoral degree programs in six fields, including Doctor of Philosophy. By the end of his nine-year tenure, ASU had more than doubled enrollment, reporting 23,000 in 1969.\n\nThe next three presidents\u2014Harry K. Newburn (1969\u201371), John W. Schwada (1971\u201381) and J. Russell Nelson (1981\u201389), including and Interim President Richard Peck (1989)\u2014led the university to increased academic stature, the establishment of the ASU West campus in 1984 and its subsequent construction in 1986, a focus on computer-assisted learning and research, and rising enrollment.\n\n1990\u2013present\nUnder the leadership of Lattie F. Coor, president from 1990 to 2002, ASU grew through the creation of the Polytechnic campus and extended education sites. Increased commitment to diversity, quality in undergraduate education, research, and economic development occurred over his 12-year tenure. Part of Coor's legacy to the university was a successful fundraising campaign: through private donations, more than $500\u00a0million was invested in areas that would significantly impact the future of ASU. Among the campaign's achievements were the naming and endowing of Barrett, The Honors College, and the Herberger Institute for Design and the Arts; the creation of many new endowed faculty positions; and hundreds of new scholarships and fellowships.\n\nIn 2002, Michael M. Crow became the university's 16th president. At his inauguration, he outlined his vision for transforming ASU into a \"New American University\"\u2014one that would be open and inclusive, and set a goal for the university to meet Association of American Universities criteria and to become a member. Crow initiated the idea of transforming ASU into \"One university in many places\"\u2014a single institution comprising several campuses, sharing students, faculty, staff and accreditation. Subsequent reorganizations combined academic departments, consolidated colleges and schools, and reduced staff and administration as the university expanded its West and Polytechnic campuses. ASU's Downtown Phoenix campus was also expanded, with several colleges and schools relocating there. The university established learning centers throughout the state, including the ASU Colleges at Lake Havasu City and programs in Thatcher, Yuma, and Tucson. Students at these centers can choose from several ASU degree and certificate programs.\n\nDuring Crow's tenure, and aided by hundreds of millions of dollars in donations, ASU began a years-long research facility capital building effort that led to the establishment of the Biodesign Institute at Arizona State University, the Julie Ann Wrigley Global Institute of Sustainability, and several large interdisciplinary research buildings. Along with the research facilities, the university faculty was expanded, including the addition of five Nobel Laureates. Since 2002, the university's research expenditures have tripled and more than 1.5\u00a0million square feet of space has been added to the university's research facilities.\n\nThe economic downturn that began in 2008 took a particularly hard toll on Arizona, resulting in large cuts to ASU's budget. In response to these cuts, ASU capped enrollment, closed some four dozen academic programs, combined academic departments, consolidated colleges and schools, and reduced university faculty, staff and administrators; however, with an economic recovery underway in 2011, the university continued its campaign to expand the West and Polytechnic Campuses, and establish a low-cost, teaching-focused extension campus in Lake Havasu City.\n", "flag": 1, "segments": [[491, 497]], "strength": 5.5}
{"token_count": [2006], "text": "Art Deco, sometimes referred to as Deco, is a style of visual arts, architecture and design that first appeared in France just before World War I. It influenced the design of buildings, furniture, jewellery, fashion, cars, cinemas, trains, ocean liners, and everyday objects such as radios and vacuum cleaners. It took its name, short for Arts D\u00e9coratifs, from the Exposition internationale des arts d\u00e9coratifs et industriels modernes (International Exhibition of Modern Decorative and Industrial Arts) held in Paris in 1925.\n\nArt Deco combined modern styles with fine craftsmanship and rich materials. During its heyday, it represented luxury, glamour, exuberance, and faith in social and technological progress.\n\nFrom its outset, Art Deco was influenced by the bold geometric forms of Cubism and the Vienna Secession; the bright colours of Fauvism and of the Ballets Russes; the updated craftsmanship of the furniture of the eras of Louis Philippe I and Louis XVI; and the exoticized styles of China and Japan, India, Persia, ancient Egypt and Maya art. It featured rare and expensive materials, such as ebony and ivory, and exquisite craftsmanship. The Empire State Building, Chrysler Building, and other skyscrapers of New York City built during the 1920s and 1930s are monuments to the style.\n\nIn the 1930s, during the Great Depression, Art Deco became more subdued. New materials arrived, including chrome plating, stainless steel and plastic. A sleeker form of the style, called Streamline Moderne, appeared in the 1930s, featuring curving forms and smooth, polished surfaces. Art Deco is one of the first truly international styles, but its dominance ended with the beginning of World War II and the rise of the strictly functional and unadorned styles of modern architecture and the International Style of architecture that followed.\n\nEtymology\nArt Deco took its name, short for arts d\u00e9coratifs, from the Exposition Internationale des Arts D\u00e9coratifs et Industriels Modernes held in Paris in 1925, though the diverse styles that characterised it had already appeared in Paris and Brussels before World War I.\n\nArts d\u00e9coratifs was first used in France in 1858 in the Bulletin de la Soci\u00e9t\u00e9 fran\u00e7aise de photographie. In 1868, the Le Figaro newspaper used the term objets d'art d\u00e9coratifs for objects for stage scenery created for the Th\u00e9\u00e2tre de l'Op\u00e9ra. In 1875, furniture designers, textile, jewellers, glass-workers, and other craftsmen were officially given the status of artists by the French government. In response, the \u00c9cole royale gratuite de dessin (Royal Free School of Design), founded in 1766 under King Louis XVI to train artists and artisans in crafts relating to the fine arts, was renamed the \u00c9cole nationale des arts d\u00e9coratifs (National School of Decorative Arts). It took its present name, ENSAD (\u00c9cole nationale sup\u00e9rieure des arts d\u00e9coratifs), in 1927.\n\nAt the 1925 Exposition, architect Le Corbusier wrote a series of articles about the exhibition for his magazine L'Esprit Nouveau, under the title \"1925 EXPO. ARTS. D\u00c9CO.\", which were combined into a book, L'art d\u00e9coratif d'aujourd'hui (Decorative Art Today). The book was a spirited attack on the excesses of the colourful, lavish objects at the Exposition, and on the idea that practical objects such as furniture should not have any decoration at all; his conclusion was that \"Modern decoration has no decoration\".\n\nThe actual term art d\u00e9co did not appear in print until 1966, in the title of the first modern exhibition on the subject, held by the Museum of Decorative Arts in Paris, Les Ann\u00e9es 25 : Art d\u00e9co, Bauhaus, Stijl, Esprit nouveau, which covered the variety of major styles in the 1920s and 1930s. The term was then used in a 1966 newspaper article by Hillary Gelson in The Times (London, 12 November), describing the different styles at the exhibit.\n\nArt Deco gained currency as a broadly applied stylistic label in 1968 when historian Bevis Hillier published the first major academic book on it, Art Deco of the 20s and 30s. He noted that the term was already being used by art dealers, and cites The Times (2 November 1966) and an essay named Les Arts D\u00e9co in Elle magazine (November 1967) as examples. In 1971, he organized an exhibition at the Minneapolis Institute of Arts, which he details in his book The World of Art Deco.\n\nOrigins\n\nSociety of Decorative Artists (1901\u20131913)\nThe emergence of Art Deco was closely connected with the rise in status of decorative artists, who until late in the 19th century were considered simply as artisans. The term arts d\u00e9coratifs had been invented in 1875, giving the designers of furniture, textiles, and other decoration official status. The Soci\u00e9t\u00e9 des artistes d\u00e9corateurs (Society of Decorative Artists), or SAD, was founded in 1901, and decorative artists were given the same rights of authorship as painters and sculptors. A similar movement developed in Italy. The first international exhibition devoted entirely to the decorative arts, the Esposizione Internazionale d'Arte Decorativa Moderna, was held in Turin in 1902. Several new magazines devoted to decorative arts were founded in Paris, including Arts et d\u00e9coration and L'Art d\u00e9coratif moderne. Decorative arts sections were introduced into the annual salons of the Soci\u00e9te des artistes fran\u00e7ais, and later in the Salon d'Automne. French nationalism also played a part in the resurgence of decorative arts, as French designers felt challenged by the increasing exports of less expensive German furnishings. In 1911, SAD proposed a major new international exposition of decorative arts in 1912. No copies of old styles would be permitted, only modern works. The exhibit was postponed until 1914; and then, because of the war, until 1925, when it gave its name to the whole family of styles known as \"D\u00e9co\".\n\nParisian department stores and fashion designers also played an important part in the rise of Art Deco. Prominent businesses such as silverware firm Christofle, glass designer Ren\u00e9 Lalique, and the jewellers Louis Cartier and Boucheron began designing products in more modern styles. Beginning in 1900, department stores recruited decorative artists to work in their design studios. The decoration of the 1912 Salon d'Automne was entrusted to the department store Printemps, and that year it created its own workshop, Primavera. By 1920 Primavera employed more than 300 artists, whose styles ranged from updated versions of Louis XIV, Louis XVI, and especially Louis Philippe furniture made by Louis S\u00fce and the Primavera workshop, to more modern forms from the workshop of the Au Louvre department store. Other designers, including \u00c9mile-Jacques Ruhlmann and Paul Follot, refused to use mass production, insisting that each piece be made individually. The early Art Deco style featured luxurious and exotic materials such as ebony, ivory and silk, very bright colours and stylized motifs, particularly baskets and bouquets of flowers of all colours, giving a modernist look.\n\nVienna Secession and Wiener Werkst\u00e4tte (1905\u20131911)\nThe architects of the Vienna Secession (formed 1897), especially Josef Hoffmann, had a notable influence on Art Deco. His Stoclet Palace, in Brussels (1905\u20131911), was a prototype of the Art Deco style, featuring geometric volumes, symmetry, straight lines, concrete covered with marble plaques, finely-sculpted ornament, and lavish interiors, including mosaic friezes by Gustav Klimt. Hoffmann was also a founder of the Wiener Werkst\u00e4tte (1903\u20131932), an association of craftsmen and interior designers working in the new style. This became the model for the Compagnie des arts fran\u00e7ais, created in 1919, which brought together And exciting driving session where your carr\u00e9 Mare, and Louis S\u00fce, the first leading French Art Deco designers and decorators.\n\nNew materials and technologies\nNew materials and technologies, especially reinforced concrete, were key to the development and appearance of Art Deco. The first concrete house was built in 1853 in the Paris suburbs by Fran\u00e7ois Coignet. In 1877 Joseph Monier introduced the idea of strengthening the concrete with a mesh of iron rods in a grill pattern. In 1893 Auguste Perret built the first concrete garage in Paris, then an apartment building, house, then, in 1913, the Th\u00e9\u00e2tre des Champs-\u00c9lys\u00e9es. The theatre was denounced by one critic as the \"Zeppelin of Avenue Montaigne\", an alleged Germanic influence, copied from the Vienna Secession. Thereafter, the majority of Art Deco buildings were made of reinforced concrete, which gave greater freedom of form and less need for reinforcing pillars and columns. Perret was also a pioneer in covering the concrete with ceramic tiles, both for protection and decoration. The architect Le Corbusier first learned the uses of reinforced", "flag": 1, "segments": [[1774, 1780]], "strength": 5.5}
{"token_count": [2006], "text": "Antimicrobial resistance (AMR) occurs when microbes evolve mechanisms that protect them from the effects of antimicrobials. Antibiotic resistance is a subset of AMR, that applies specifically to bacteria that become resistant to antibiotics. \n\nInfections due to AMR cause millions of deaths each year. Infections caused by resistant microbes are more difficult to treat, requiring higher doses of antimicrobial drugs, or alternative medications which may prove more toxic. These approaches may also be more expensive. Microbes resistant to multiple antimicrobials are called multidrug resistant (MDR).\n\nAll classes of microbes can evolve resistance. Fungi evolve antifungal resistance. Viruses evolve antiviral resistance. Protozoa evolve antiprotozoal resistance, and bacteria evolve antibiotic resistance. Those bacteria that are considered extensively drug resistant (XDR) or totally drug-resistant (TDR) are sometimes called \"superbugs\". Resistance in bacteria can arise naturally by genetic mutation, or by one species acquiring resistance from another. Resistance can appear spontaneously because of random mutations. However, extended use of antimicrobials appears to encourage selection for mutations which can render antimicrobials ineffective.\n\nThe prevention of antibiotic misuse, which can lead to antibiotic resistance, includes taking antibiotics only when prescribed. Narrow-spectrum antibiotics are preferred over broad-spectrum antibiotics when possible, as effectively and accurately targeting specific organisms is less likely to cause resistance, as well as side effects. For people who take these medications at home, education about proper use is essential. Health care providers can minimize spread of resistant infections by use of proper sanitation and hygiene, including handwashing and disinfecting between patients, and should encourage the same of the patient, visitors, and family members.\n\nRising drug resistance is caused mainly by use of antimicrobials in humans and other animals, and spread of resistant strains between the two. Growing resistance has also been linked to releasing inadequately treated effluents from the pharmaceutical industry, especially in countries where bulk drugs are manufactured. Antibiotics increase selective pressure in bacterial populations, causing vulnerable bacteria to die; this increases the percentage of resistant bacteria which continue growing. Even at very low levels of antibiotic, resistant bacteria can have a growth advantage and grow faster than vulnerable bacteria. As resistance to antibiotics becomes more common there is greater need for alternative treatments. Calls for new antibiotic therapies have been issued, but new drug development is becoming rarer.\n\nAntimicrobial resistance is increasing globally due to increased prescription and dispensing of antibiotic drugs in developing countries. Estimates are that 700,000 to several million deaths result per year and continues to pose a major public health threat worldwide. Each year in the United States, at least 2.8\u00a0million people become infected with bacteria that are resistant to antibiotics and at least 35,000 people die and US$55 billion in increased health care costs and lost productivity. According to World Health Organization (WHO) estimates, 350 million deaths could be caused by AMR by 2050. By then, the yearly death toll will be 10 million, according to pale if the weather allows, a United Nations report.\n\nThere are public calls for global collective action to address the threat that include proposals for international treaties on antimicrobial resistance. Worldwide antibiotic resistance is not completely identified, but poorer countries with weaker healthcare systems are more affected. During the COVID-19 pandemic, action against antimicrobial resistance slowed due to scientists focusing more on SARS-CoV-2 research.\n\nDefinition\n\nThe WHO defines antimicrobial resistance as a microorganism's resistance to an antimicrobial drug that was once able to treat an infection by that microorganism. A person cannot become resistant to antibiotics. Resistance is a property of the microbe, not a person or other organism infected by a microbe.\n\nAntibiotic resistance is a subset of antimicrobial resistance.\u00a0This more specified resistance is linked to pathogenic bacteria and thus broken down into two further subsets, microbiological and clinical. Resistance linked microbiologically is the most common and occurs from genes, mutated or inherited, that allow the bacteria to resist the mechanism associated with certain antibiotics.\u00a0Clinical resistance is shown through the failure of many therapeutic techniques where the bacteria that are normally susceptible to a treatment become resistant after surviving the outcome of the treatment. In both cases of acquired resistance, the bacteria can pass the genetic catalyst for resistance through conjugation, transduction, or transformation.\u00a0This allows the resistance to spread across the same pathogen or even similar bacterial pathogens.\n\nOverview \nWHO report released April 2014 stated, \"this serious threat is no longer a prediction for the future, it is happening right now in every region of the world and has the potential to affect anyone, of any age, in any country. Antibiotic resistance\u2014when bacteria change so antibiotics no longer work in people who need them to treat infections\u2014is now a major threat to public health.\" \n\nGlobal deaths attributable to AMR numbered 1.27 million in 2019. That year, AMR may have contributed to 5 million deaths and one in five people who died due to AMR were children under five years old.\n\nIn 2018, WHO considered antibiotic resistance to be one of the biggest threats to global health, food security and development. Deaths attributable to AMR vary by area:\n\nThe European Centre for Disease Prevention and Control calculated that in 2015 there were 671,689 infections in the EU and European Economic Area caused by antibiotic-resistant bacteria, resulting in 33,110 deaths. Most were acquired in healthcare settings.\n\nCauses \nAntimicrobial resistance is mainly caused by the overuse of antimicrobials. This leads to microbes either evolving a defense against drugs used to treat them, or certain strains of microbes that have a natural resistance to antimicrobials becoming much more prevalent than the ones that are easily defeated with medication.\u00a0 While antimicrobial resistance does occur naturally over time, the use of antimicrobial agents in a variety of settings both within the healthcare industry and outside of has led to antimicrobial resistance becoming increasingly more prevalent.\n\nNatural occurrence \n\nAntimicrobial resistance can evolve naturally due to continued exposure to antimicrobials. Natural selection means that organisms that are able to adapt to their environment, survive, and continue to produce offspring. As a result, the types of microorganisms that are able to survive over time with continued attack by certain antimicrobial agents will naturally become more prevalent in the environment, and those without this resistance will become obsolete.\n\nSome contemporary antibiotic resistances have also evolved naturally before the use of antibiotics or human clinical use of respective antimicrobials. For instance, methicillin-resistance evolved in a pathogen of hedgehogs, possibly as a co-evolutionary adaptation of the pathogen to hedgehogs that are infected by a dermatophyte that naturally produces antibiotics.\n\nOver time, most of the strains of bacteria and infections present will be the type resistant to the antimicrobial agent being used to treat them, making this agent now ineffective to defeat most microbes. With the increased use of antimicrobial agents, there is a speeding up of this natural process.\n\nSelf-medication \nSelf-medication by consumers is defined as \"the taking of medicines on one's own initiative or on another person's suggestion, who is not a certified medical professional\", and it has been identified as one of the primary reasons for the evolution of antimicrobial resistance. In an effort to manage their own illness, patients take the advice of false media sources, friends, and family causing them to take antimicrobials unnecessarily or in excess. Many people resort to this out of necessity, when they have a limited amount of money to see a doctor, or in many developing countries a poorly developed economy and lack of doctors are the cause of self-medication. In these developing countries, governments resort to allowing the sale of antimicrobials as over the counter medications so people could have access to them without having to find or pay to see a medical professional. This increased access makes it extremely easy to obtain antimicrobials without the advice of a physician, and as a result many antimicrobials are taken incorrectly leading to resistant microbial strains. One major example of a place that faces these challenges is India, where in the state of Punjab 73% of the population resorted to treating their minor health issues and chronic illnesses through self-medication.\n\nThe major issue with self-medication is the lack of knowledge of the public on the dangerous effects of antimicrobial resistance, and how they can contribute to it through mistreating or misdiagnosing themselves.\u00a0 In order to determine the public's knowledge and preconceived notions on antibiotic resistance, a major type of antimicrobial resistance, a screening of 3537 articles published in Europe, Asia, and North America was done.\u00a0 Of the 55,225 total people surveyed, 70% had heard of antibiotic resistance previously, but 88% of those people thought it referred to some type of physical change in the body.\u00a0 With so many people around the world with the ability to self-medicate using antibiotics, and a vast majority unaware of what antimicrobial resistance is, it makes the increase of antimicrobial resistance much more likely.\n\nClinical misuse \nClinical misuse by healthcare professionals is another cause leading to increased antimicrobial resistance. Studies done by the CDC show that the indication for treatment of antibiotics, choice of the agent used, and the duration of therapy was incorrect in up to 50% of the cases studied.\u00a0 In another study done in an intensive care unit in a major hospital in France, it was shown that 30% to 60% of prescribed antibiotics were unnecessary. These inappropriate uses of antimicrobial agents promote the evolution of antimicrobial resistance by supporting", "flag": 1, "segments": [[630, 636]], "strength": 5.5}
{"token_count": [2006], "text": "Al-Qaeda (; ,, translation: \"the Base\", \"the Foundation\", alternatively spelled al-Qaida and al-Qa'ida), officially known as Qaedat al-Jihad, is a multinational militant Sunni Islamic extremist network composed of Salafist jihadists. It was founded in 1988 by Osama bin Laden, Abdullah Azzam, and several other Arab volunteers during the Soviet\u2013Afghan War.\n\nAl-Qaeda has been designated as a terrorist group by the United Nations Security Council (the permament members of which are China, France, Russia, the United Kingdom and the United States), the North Atlantic Treaty Organization (NATO), the European Union, India and various other countries (see below). Al-Qaeda at CERN's Neut has mounted attacks on non-military and military targets in various countries, including the 1998 United States embassy bombings, the September 11 attacks, and the 2002 Bali bombings.\n\nThe United States government responded to the September 11 attacks by launching the \"war on terror\", which sought to undermine al-Qaeda and its allies. The deaths of key leaders, including that of Osama bin Laden, have led al-Qaeda's operations to shift from top-down organization and planning of attacks, to the planning of attacks which are carried out by a loose network of associated groups and lone-wolf operators. Al-Qaeda characteristically organises attacks which include suicide attacks and the simultaneous bombing of several targets. Al-Qaeda ideologues envision the violent removal of all foreign and secular influences in Muslim countries, which it perceives as corrupt deviations.\n\nAl-Qaeda members believe a Christian\u2013Jewish alliance (led by the United States) is conspiring to be at war against Islam and destroy Islam. As Salafist jihadists, members of al-Qaeda believe that killing non-combatants is religiously sanctioned. Al-Qaeda also opposes what it regards as man-made laws, and wants to replace them exclusively with a strict form of shar\u012b\u02bfa (Islamic religious law which is perceived as divine law).\n\nAl-Qaeda has carried out many attacks on people whom it considers k\u0101fir. It is also responsible for instigating sectarian violence among Muslims. Al-Qaeda regards liberal Muslims, Shias, Sufis, and other Islamic sects as heretical and its members and sympathizers have attacked their mosques, shrines, and gatherings. Examples of sectarian attacks include the 2004 Ashoura massacre, the 2006 Sadr City bombings, the April 2007 Baghdad bombings and the 2007 Yazidi community bombings.\n\nFollowing the death of Osama bin Laden in 2011, the group has been led by Egyptian Ayman al-Zawahiri, and as of 2021 has reportedly suffered from a deterioration of central command over its regional operations.\n\nOrganization\nAl-Qaeda only indirectly controls its day-to-day operations. Its philosophy calls for the centralization of decision making, while allowing for the decentralization of execution. Al-Qaeda's top leaders have defined the organization's ideology and guiding strategy, and they have also articulated simple and easy-to-receive messages. At the same time, mid-level organizations were given autonomy, but they had to consult with top management before large-scale attacks and assassinations. Top management included the shura council as well as committees on military operations, finance, and information sharing. Through al-Qaeda's information committees, he placed special emphasis on communicating with his groups. However, after the War on Terror, al-Qaeda's leadership has become isolated. As a result, the leadership has become decentralized, and the organization has become regionalized into several al-Qaeda groups.\n\nMany terrorism experts do not believe that the global jihadist movement is driven at every level by al-Qaeda's leadership. However, bin Laden held considerable ideological sway over some Muslim extremists before his death. Experts argue that al-Qaeda has fragmented into a number of disparate regional movements, and that these groups bear little connection with one another.\n\nThis view mirrors the account given by Osama bin Laden in his October 2001 interview with Tayseer Allouni:\n\nBruce Hoffman, however, sees al-Qaeda as a cohesive network that is strongly led from the Pakistani tribal areas.\n\nAffiliates   \nAl-Qaeda has the following direct affiliates:\n\n Al-Qaeda in the Arabian Peninsula (AQAP)\n Al-Qaeda in the Indian Subcontinent (AQIS)\n Al-Qaeda in the Islamic Maghreb (AQIM)\n al-Shabaab\n Jama'at Nasr al-Islam wal Muslimin (JNIM)\n Al-Qaeda in Bosnia and Herzegovina\n Al-Qaeda in Caucasus and Russia\n Al-Qaeda in Gaza\n Al-Qaeda in Kurdistan\n Al-Qaeda in Lebanon\n Al Qaeda in Spain\n Al-Qaeda in the Malay Archipelago\n Al-Qaeda in the Sinai Peninsula\n Guardians of Religion Organization\nAl-Qaeda in the Land of the Two Niles (AQTN).\n\nThe following are presently believed to be indirect affiliates of al-Qaeda:\n\n Caucasus Emirate (factions)\n Fatah al-Islam\n Islamic Jihad Union\n Islamic Movement of Uzbekistan\n Jaish-e-Mohammed\n Jemaah Islamiyah\n Lashkar-e-Taiba\n Moroccan Islamic Combatant Group\n\nAl-Qaeda's former affiliates include the following:\n\n Abu Sayyaf (pledged allegiance to ISIL in 2014)\n Al-Mourabitoun (joined JNIM in 2017)\n Al-Qaeda in Iraq (became the Islamic State of Iraq, which later seceded from al-Qaeda and became ISIL)\n Al-Qaeda in the Lands Beyond the Sahel (inactive since 2015)\n Ansar al-Islam (majority merged with ISIL in 2014)\n Ansar Dine (joined JNIM in 2017)\n Islamic Jihad of Yemen (became AQAP)\n Jund al-Aqsa (defunct)\n Movement for Oneness and Jihad in West Africa (merged with Al-Mulathameen to form Al-Mourabitoun in 2013)\n Rajah Sulaiman movement  (defunct)\n Al-Nusra Front (became Hayat Tahrir al-Sham and split ties in 2017, disputed)\n Ansar Bait al-Maqdis (pledged alliance to ISIL and adopted the name Sinai Province)\n\nLeadership\n\nOsama bin Laden (1988 \u2013 May 2011)\n\nOsama bin Laden served as the emir of al-Qaeda from the organization's founding in 1988 until his assassination by US forces on May 1, 2011. Atiyah Abd al-Rahman was alleged to be second in command prior to his death on August 22, 2011.\n\nBin Laden was advised by a Shura Council, which consists of senior al-Qaeda members. The group was estimated to consist of 20\u201330 people.\n\nAfter May 2011\nAyman al-Zawahiri had been al-Qaeda's deputy emir and assumed the role of emir following bin Laden's death. Al-Zawahiri replaced Saif al-Adel, who had served as interim commander.\n\nOn June 5, 2012, Pakistani intelligence officials announced that al-Rahman's alleged successor as second in command, Abu Yahya al-Libi, had been killed in Pakistan.\n\nNasir al-Wuhayshi was alleged to have become al-Qaeda's overall second in command and general manager in 2013. He was concurrently the leader of al-Qaeda in the Arabian Peninsula (AQAP) until he was killed by a US airstrike in Yemen in June 2015. Abu Khayr al-Masri, Wuhayshi's alleged successor as the deputy to Ayman al-Zawahiri, was killed by a US airstrike in Syria in February 2017.\n\nAl-Qaeda's network was built from scratch as a conspiratorial network which drew upon the leadership of a number of regional nodes. The organization divided itself into several committees, which include:\n The Military Committee, which is responsible for training operatives, acquiring weapons, and planning attacks.\n The Money/Business Committee, which funds the recruitment and training of operatives through the hawala banking system. US-led efforts to eradicate the sources of \"terrorist financing\" were most successful in the year immediately following the September 11 attacks. Al-Qaeda continues to operate through unregulated banks, such as the 1,000 or so hawaladars in Pakistan, some of which can handle deals of up to million. The committee also procures false passports, pays al-Qaeda members, and oversees profit-driven businesses. In the 9/11 Commission Report, it was estimated that al-Qaeda required $30million per year to conduct its operations.\n The Law Committee reviews Sharia law, and decides upon courses of action conform to it.\n The Islamic Study/Fatwah Committee issues religious edicts, such as an edict in 1998 telling Muslims to kill Americans.\n The Media Committee ran the now-defunct newspaper Nashrat al Akhbar () and handled public relations.\n In 2005, al-Qaeda formed As-Sahab, a media production house, to supply its video and audio materials.\n\nCommand structure\nMost of Al Qaeda's top leaders and operational directors were veterans who fought against the Soviet invasion of Afghanistan in the 1980s. Osama bin Laden and his deputy, Ayman al-Zawahiri, were the leaders who were considered the operational commanders of the organization. Nevertheless, Al-Qaeda is not operationally managed by Ayman al-Zawahiri. Several operational groups exist, which consult with the leadership in situations where attacks are", "flag": 1, "segments": [[149, 155]], "strength": 5.5}
{"token_count": [2006], "text": "Arkansas () is a landlocked state in the South Central region of the United States, home to more than three million people as of 2018. Its name is from the Osage language, a Dhegiha Siouan language, and referred to their relatives, the Quapaw people. The state's diverse geography ranges from the mountainous regions of the Ozark and Ouachita Mountains, which make up the U.S. Interior Highlands, to the densely forested land in the south known as the Arkansas Timberlands, to the eastern lowlands along the Mississippi River and the Arkansas Delta.\n\nArkansas is the 29th largest by area and the 33rd most populous U.S. state. The capital and most populous city is Little Rock, in the central part of the state, a hub for transportation, business, culture, and government. The northwestern corner of the state, including the Fayetteville\u2013Springdale\u2013Rogers Metropolitan Area and Fort Smith metropolitan area, is a population, education, and economic center. The largest city in the state's eastern part is Jonesboro. The largest city in the state's southeastern part is Pine Bluff.\n\nPreviously part of French Louisiana and the Louisiana Purchase, the Territory of Arkansas was admitted to the Union as the 25th state on June 15, 1836. Much of the Delta had been developed for cotton plantations, and landowners there largely depended on enslaved African Americans' labor. In 1861, Arkansas seceded from the United States and joined the Confederate States of America during the American Civil War. On returning to the Union in 1868, Arkansas continued to suffer economically, due to its overreliance on the large-scale plantation economy. Cotton remained the leading commodity crop, and the cotton market declined. Because farmers and businessmen did not diversify and there was little industrial investment, the state fell behind in economic opportunity. In the late 19th century, the state instituted various Jim Crow laws to disenfranchise and segregate the African-American population. During the civil rights movement of the 1950s and 1960s, Arkansas and particularly Little Rock were major battlegrounds for efforts to integrate schools.\n\nWhite interests dominated Arkansas's politics, with disfranchisement of African Americans and refusal to reapportion the legislature. Only after the civil rights movement and federal legislation passed were more African Americans able to vote. The Supreme Court overturned rural domination in the South and other states that had refused to reapportion their state legislatures or retained rules based on geographic districts. In the landmark ruling of one man, one vote, it held that states had to organize their legislatures by districts that held approximately equal populations, and that these had to be redefined as necessary after each decade's census.\n\nFollowing World War II in the 1940s, Arkansas began to diversify its economy and see prosperity. During the 1960s, the state became the base of the Walmart corporation, the world's largest company by revenue, headquartered in Bentonville. In the 21st century, Arkansas's economy is based on service industries, aircraft, poultry, steel, and tourism, along with important commodity crops of cotton, soybeans and rice.\n\nArkansas's culture is observable in museums, theaters, novels, television shows, restaurants, and athletic venues across the state. Notable people from the state include politician and educational advocate William Fulbright; former president Bill Clinton, who also served as the 40th and 42nd governor of Arkansas; general Wesley Clark, former NATO Supreme Allied Commander; Walmart founder and magnate Sam Walton; singer-songwriters Johnny Cash, Charlie Rich, Jimmy Driftwood, and Glen Campbell; actor-filmmaker Billy Bob Thornton; poet C. D. Wright; physicist William L. McMillan, a pioneer in superconductor research; poet laureate Maya Angelou; Douglas MacArthur; famous musician Al Green; actor Alan Ladd; basketball player Scottie Pippen; singer Ne-Yo; Chelsea Clinton; actress Sheryl Underwood; and author John Grisham.\n\nEtymology\n\nThe name Arkansas initially applied to the Arkansas River. It derives from a French term, Arcansas, their plural term for their transliteration of akansa, an Algonquian term for the Quapaw people. These were a Dhegiha Siouan-speaking people who settled in Arkansas around the 13th century. Akansa is likely also the root term for Kansas, which was named after the related Kaw people.\n\nThe name has been pronounced and spelled in a variety of ways. In 1881, the state legislature defined the official pronunciation of Arkansas as having the final \"s\" be silent (as it would be in French). A dispute had arisen between the state's two senators over the pronunciation issue. One favored  (), the other  ().\n\nIn 2007, the state legislature passed a non-binding resolution declaring that the possessive form of the state's name is Arkansas's, which the state government has increasingly followed.\n\nHistory\n\nEarly Arkansas\n\nBefore European settlement of North America, Arkansas, was inhabited by indigenous peoples for thousands of years. The Caddo, Osage, and Quapaw peoples encountered European explorers. The first of these Europeans was Spanish explorer Hernando de Soto in 1541, who crossed the Mississippi and marched across central Arkansas and the Ozark Mountains. After finding nothing he considered of value and encountering native resistance the entire way, he and his men returned to the Mississippi River where de Soto fell ill. From his deathbed he ordered his men to massacre all the men of the nearby village of Anilco, who he feared had been plotting with a powerful polity down the Mississippi River, Quigualtam. His men obeyed and did not stop with the men, but were said to have massacred women and children as well. He died the following day in what is believed to be the vicinity of modern-day McArthur, Arkansas, in May 1542. His body was weighted down with sand and he was consigned to a watery grave in the Mississippi River under cover of darkness by his men. De Soto had attempted to deceive the native population into thinking he was an immortal deity, sun of the sun, in order to forestall attack by outraged Native Americans on his by then weakened and bedraggled army. In order to keep the ruse up, his men informed the locals that de Soto had ascended into the sky. His will at the time of his death listed \"four Indian slaves, three horses and 700 hogs\" which were auctioned off. The starving men, who had been living off maize stolen from natives, immediately started butchering the hogs and later, commanded by former aide-de-camp Moscoso, attempted an overland return to Mexico. They made it as far as Texas before running into territory too dry for maize farming and too thinly populated to sustain themselves by stealing food from the locals. The expedition promptly backtracked to Arkansas. After building a small fleet of boats they then headed down the Mississippi River and eventually on to Mexico by water.\n\nLater explorers included the French Jacques Marquette and Louis Jolliet in 1673, and Frenchmen Robert La Salle and Henri de Tonti in 1681. Tonti established Arkansas Post at a Quapaw village in 1686, making it the first European settlement in the territory. The early Spanish or French explorers of the state gave it its name,The chief executive and vice chairman which is probably a phonetic spelling of the Illinois tribe's name for the Quapaw people, who lived downriver from them. The name Arkansas has been pronounced and spelled in a variety of fashions. The region was organized as the Territory of Arkansaw on July 4, 1819, with the territory admitted to the United States as the state of Arkansas on June 15, 1836. The name was historically,, and several other variants. Historically and modernly, the people of Arkansas call themselves either \"Arkansans\" or \"Arkansawyers\". In 1881, the Arkansas General Assembly passed Arkansas Code 1-4-105 (official text):\nWhereas, confusion of practice has arisen in the pronunciation of the name of our state and it is deemed important that the true pronunciation should be determined for use in oral official proceedings.\nAnd, whereas, the matter has been thoroughly investigated by the State Historical Society and the Eclectic Society of Little Rock, which have agreed upon the correct pronunciation as derived from history, and the early usage of the American immigrants.\nBe it therefore resolved by both houses of the General Assembly, that the only true pronunciation of the name of the state, in the opinion of this body, is that received by the French from the native Indians and committed to writing in the French word representing the sound. It should be pronounced in three (3) syllables, with the final \"s\" silent, the \"a\" in each syllable with the Italian sound, and the accent on the first and last syllables. The pronunciation with the accent on the second syllable with the sound of \"a\" in \"man\" and the sounding of the terminal \"s\" is an innovation to be discouraged.\nCitizens of the state of Kansas often pronounce the Arkansas River as, in a manner similar to the common pronunciation of the name of their state.\n\nSettlers, such as fur trappers, moved to Arkansas in the early 18th century. These people used Arkansas Post as a home base and entrep\u00f4t. During the colonial period, Arkansas changed hands between France and Spain following the Seven Years' War, although neither showed interest in the remote settlement of Arkansas Post. In April 1783, Arkansas saw its only battle of the American Revolutionary War, a brief siege of", "flag": 1, "segments": [[1530, 1536]], "strength": 5.5}
{"token_count": [2006], "text": "Andrew Carnegie (, English approximation:  ; November 25, 1835August 11, 1919) was a Scottish-American industrialist and philanthropist. Carnegie led the expansion of the American steel industry in the late 19th century and became one of the richest Americans in history. He became a leading philanthropist in the United States and in the British Empire. During the last 18 years of his life, he gave away around $350 million (roughly $\u00a0billion in ), almost 90 percent of his fortune, to charities, foundations and universities. His 1889 article proclaiming \"The Gospel of Wealth\" called on the rich to use their wealth to improve society, expressed support for progressive taxation and an estate tax, and stimulated a wave of philanthropy.\n\nCarnegie was born in Dunfermline, Scotland, and emigrated to the United States with his parents in 1848 at age 12. Carnegie started work as a telegrapher, and by the 1860s had investments in railroads, railroad sleeping cars, bridges, and oil derricks. He accumulated further wealth as a bond salesman, raising money for American enterprise in Europe. He built Pittsburgh's Carnegie Steel Company, which he sold to J. P. Morgan in 1901 for $303,450,000; it formed the basis of the U.S. Steel Corporation. After selling Carnegie Steel, he surpassed John D. Rockefeller as the richest American for the next several years.\n\nCarnegie devoted the remainder of his life to large-scale philanthropy, with special emphasis on local libraries, world peace, education, and scientific research. With the fortune he made from business, he built Carnegie Hall in New York, NY, and the Peace Palace and founded the Carnegie Corporation of New York, Carnegie Endowment for International Peace, Carnegie Institution for Science, Carnegie Trust for the Universities of Scotland, Carnegie Hero Fund, Carnegie Mellon University, and the Carnegie Museums of Pittsburgh, among others.\n\nBiography\n\nEarly life\n\nAndrew Carnegie was born to Margaret Morrison Carnegie and William Carnegie in Dunfermline, Scotland, in a typical weaver's cottage with only one main room, consisting of half the ground floor, which was shared with the neighboring weaver's family. The main room served as a living room, dining room and bedroom. He was named after his paternal grandfather. In 1836, the family moved to a larger house in Edgar Street (opposite Reid's Park), following the demand for more heavy damask, from which his father benefited. He was educated at the Free School in Dunfermline, a gift to the town from the philanthropist Adam Rolland of Gask.\n\nCarnegie's maternal uncle, Scottish political leader George Lauder, Sr., deeply influenced him as a boy by introducing him to Robert Burns' writings and historical Scottish heroes such as Robert the Bruce, William Wallace, and Rob Roy. Lauder's son, also named George Lauder, grew up with Carnegie and became his business partner. When Carnegie was 12, his father had fallen on very hard times as a handloom weaver; making matters worse, the country was in starvation. His mother helped support the family by assisting her brother and by selling potted meats at her \"sweetie shop\", leaving her as the primary breadwinner. Struggling to make ends meet, the Carnegies then decided to borrow money from George Lauder, Sr. and move to Allegheny, Pennsylvania, in the United States in 1848 for the prospect of a better life. Carnegie's migration to America would be his second journey outside Dunfermline \u2013 the first being an outing to Edinburgh to see Queen Victoria.\n\nIn September 1848, Carnegie arrived with his family in Allegheny. Carnegie's father struggled to sell his product on his own. Eventually, the father and son both received job offers at the same Scottish-owned cotton mill, Anchor Cotton Mills. Carnegie's first job in 1848 was as a bobbin boy, changing spools of thread in a cotton mill 12 hours a day, 6 days a week in a Pittsburgh cotton factory. His starting wage was $1.20 per week ($ by  inflation).\n\nHis father quit his position at the cotton mill soon after, returning to his loom and removing him as breadwinner once again. But Carnegie attracted the attention of John Hay, a Scottish manufacturer of bobbins, who offered him a job for $2.00 per week ($ by  inflation). In his autobiography, Carnegie writes about the hardships he had to endure with this new job.\n\nTelegraph\n\nIn 1849, Carnegie became a telegraph messenger boy in the Pittsburgh Office of the Ohio Telegraph Company, at $2.50 per week ($ by  inflation) following the recommendation of his uncle. He was a hard worker and would memorize all of the locations of Pittsburgh's businesses and the faces of important men. He made many connections this way. He also paid close attention to his work and quickly learned to distinguish the different sounds the incoming telegraph signals produced. He developed the ability to translate signals by ear, without using the paper slip, and within a year was promoted to an operator. Carnegie's education and passion for reading were given a boost by Colonel James Anderson, who opened his personal library of 400 volumes to working boys each Saturday night. Carnegie was a consistent borrower and a \"self-made man\" in both his economic development and his intellectual and cultural development. He was so grateful to Colonel Anderson for the use of his library that he \"resolved, if ever wealth came to me, [to see to it] that other poor boys might receive opportunities similar to those for which we were indebted to the nobleman\". His capacity, his willingness for hard work, his perseverance and his alertness soon brought him opportunities.\n\nRailroads\nStarting in 1853, when Carnegie was around 18 years old, Thomas A. Scott of the Pennsylvania Railroad Company employed him as a secretary/telegraph operator at a salary of $4.00 per week ($ by  inflation). Carnegie accepted the job with the railroad as he saw more prospects for career growth and experience there than with the telegraph company. At age 24, Scott asked Carnegie if he could handle being superintendent of the Western Division of the Pennsylvania Railroad. On December 1, 1859, Carnegie officially became superintendent of the Western Division. Carnegie then hired his sixteen-year-old brother, Tom, to be his personal secretary and telegraph company they founded in 2015 that operator. Not only did Carnegie hire his brother, but he also hired his cousin, Maria Hogan, who became the first female telegraph operator in the country. As superintendent Carnegie made a salary of fifteen hundred dollars a year ($ by  inflation). His employment by the Pennsylvania Railroad Company would be vital to his later success. The railroads were the first big businesses in America, and the Pennsylvania was one of the largest of them all. Carnegie learned much about management and cost control during these years, and from Scott in particular.\n\nScott also helped him with his first investments. Many of these were part of the corruption indulged in by Scott and the president of Pennsylvania Railroad, John Edgar Thomson, which consisted of inside trading in companies that the railroad did business with, or payoffs made by contracting parties \"as part of a quid pro quo\". In 1855, Scott made it possible for Carnegie to invest $500 in the Adams Express, which contracted with the Pennsylvania to carry its messengers. The money was secured by his mother's placing of a $600 mortgage on the family's $700 home, but the opportunity was available only because of Carnegie's close relationship with Scott. A few years later, he received a few shares in Theodore Tuttle Woodruff's sleeping car company, as a reward for holding shares that Woodruff had given to Scott and Thomson, as a payoff. Reinvesting his returns in such inside investments in railroad-related industries: (iron, bridges, and rails), Carnegie slowly accumulated capital, the basis for his later success. Throughout his later career, he made use of his close connections to Thomson and Scott, as he established businesses that supplied rails and bridges to the railroad, offering the two men a stake in his enterprises.\n\n1860\u20131865: The Civil War\n\nBefore the Civil War, Carnegie arranged a merger between Woodruff's company and that of George Pullman, the inventor of a the sleeping car for first class travel, which facilitated business travel at distances over. The investment proved a success and a source of profit for Woodruff and Carnegie. The young Carnegie continued to work for the Pennsylvania's Tom Scott, and introduced several improvements in the service.\n\nIn spring 1861, Carnegie was appointed by Scott, who was now Assistant Secretary of War in charge of military transportation, as Superintendent of the Military Railways and the Union Government's telegraph lines in the East. Carnegie helped open the rail lines into Washington D.C. that the rebels had cut; he rode the locomotive pulling the first brigade of Union troops to reach Washington D.C. Following the defeat of Union forces at Bull Run, he personally supervised the transportation of the defeated forces. Under his organization, the telegraph service rendered efficient service to the Union cause and significantly assisted in the eventual victory. Carnegie later joked that he was \"the first casualty of the war\" when he gained a scar on his cheek from freeing a trapped telegraph wire.\n\nThe defeat of the Confederacy required vast supplies of munitions, as well as railroads (and telegraph lines) to deliver the goods. The war demonstrated how integral the industries were to American success.\n\nKeystone Bridge Company\n\nIn 1864, Carnegie was one of the early investors in the Columbia Oil Company in Venango County, Pennsylvania. In one year, the farm yielded over $1,000", "flag": 1, "segments": [[1317, 1323]], "strength": 5.5}
{"token_count": [2006], "text": "An airline is a company that provides air transport services for traveling passengers and freight. Airlines use aircraft to supply these services and may form partnerships or alliances with other airlines for codeshare agreements, in which they both offer and operate the same flight. Generally, airline companies are recognized with an air operating certificate or license issued by a governmental aviation body. Airlines may be scheduled or charter operators.\n\nThe first airline was the German airship company DELAG, founded on 16 November 1909. The four oldest non-airship airlines that still exist are the Netherlands' KLM (1919), Colombia's Avianca (1919), Australia's Qantas (1920) and the Czech Republic's Czech Airlines (1923).\n\nAirline ownership has seen a shift from mostly personal ownership until the 1930s to government-ownership of major airlines from the 1940s to 1980s and back to large-scale privatization following the mid-1980s. Since the 1980s, there has also been a trend of major airline mergers and the formation of airline alliances. The largest alliances are Star Alliance, SkyTeam and Oneworld, and these three collectively accounted for more than 60% of global commercial air traffic in 2015. Airline alliances coordinate their passenger service programs (such as lounges and frequent-flyer programs), offer special interline tickets and often engage in extensive codesharing (sometimes systemwide).\n\n, the largest airline by passengers carried and fleet size was the American Airlines Group, while Delta Air Lines was the largest by revenue. Lufthansa Group was the largest by number of employees, FedEx Express by freight tonne-kilometres, Turkish Airlines by number of countries served and UPS Airlines by number of destinations served (though United Airlines was the largest passenger airline by number of destinations served).\n\nHistory\n\nThe first airlines\nDELAG, Deutsche Luftschiffahrts-Aktiengesellschaft I was the world's first airline. It was founded on November 16, 1909, with government assistance, and operated airships manufactured by The Zeppelin Corporation. Its headquarters were in Frankfurt. The first fixed-wing scheduled airline was started on January 1, 1914, from St. Petersburg, Florida, to Tampa, Florida, operated by the St. Petersburg\u2013Tampa Airboat Line. The four oldest non-dirigible airlines that still exist are the Netherlands' KLM (1919), Colombia's Avianca (1919), Australia's Qantas (1921), and the Czech Republic's Czech Airlines (1923).\n\nEurope\n\nBeginnings\n\nThe earliest fixed wing airline in Europe was Aircraft Transport and Travel, formed by George Holt Thomas in 1916; via a series of takeovers and mergers, this company is an ancestor of modern-day British Airways. Using a fleet of former military Airco DH.4A biplanes that had been modified to carry two passengers in the fuselage, it operated relief flights between Folkestone and Ghent. On 15 July 1919, the company flew a proving flight across the English Channel, despite a lack of support from the British government. Flown by Lt. H Shaw in an Airco DH.9 between RAF Hendon and Paris \u2013 Le Bourget Airport, the flight took 2 hours and 30 minutes at \u00a321 Anna Faris on the big per passenger.\n\nOn 25 August 1919, the company used DH.16s to pioneer a regular service from Hounslow Heath Aerodrome to Le Bourget, the first regular international service in the world. The airline soon gained a reputation for reliability, despite problems with bad weather, and began to attract European competition. In November 1919, it won the first British civil airmail contract. Six Royal Air Force Airco DH.9A aircraft were lent to the company, to operate the airmail service between Hawkinge and Cologne. In 1920, they were returned to the Royal Air Force.\n\nOther British competitors were quick to follow \u2013 Handley Page Transport was established in 1919 and used the company's converted wartime Type O/400 bombers with a capacity for 12 passengers, to run a London-Paris passenger service.\n\nThe first French airline was Soci\u00e9t\u00e9 des lignes Lat\u00e9co\u00e8re, later known as A\u00e9ropostale, which started its first service in late 1918 to Spain. The Soci\u00e9t\u00e9 G\u00e9n\u00e9rale des Transports A\u00e9riens was created in late 1919, by the Farman brothers and the Farman F.60 Goliath plane flew scheduled services from Toussus-le-Noble to Kenley, near Croydon, England. Another early French airline was the Compagnie des Messageries A\u00e9riennes, established in 1919 by Louis-Charles Breguet, offering a mail and freight service between Le Bourget Airport, Paris and Lesquin Airport, Lille.\n\nThe first German airline to use heavier than air aircraft was Deutsche Luft-Reederei established in 1917 which started operating in February 1919. In its first year, the D.L.R. operated regularly scheduled flights on routes with a combined length of nearly 1000 miles. By 1921 the D.L.R. network was more than 3000\u00a0km (1865 miles) long, and included destinations in the Netherlands, Scandinavia and the Baltic Republics. Another important German airline was Junkers Luftverkehr, which began operations in 1921. It was a division of the aircraft manufacturer Junkers, which became a separate company in 1924. It operated joint-venture airlines in Austria, Denmark, Estonia, Finland, Hungary, Latvia, Norway, Poland, Sweden and Switzerland.\n\nThe Dutch airline KLM made its first flight in 1920, and is the oldest continuously operating airline in the world. Established by aviator Albert Plesman, it was immediately awarded a \"Royal\" predicate from Queen Wilhelmina. Its first flight was from Croydon Airport, London to Amsterdam, using a leased Aircraft Transport and Travel DH-16, and carrying two British journalists and a number of newspapers. In 1921, KLM started scheduled services.\n\nIn Finland, the charter establishing Aero O/Y (now Finnair) was signed in the city of Helsinki on September 12, 1923. Junkers F.13 D-335 became the first aircraft of the company, when Aero took delivery of it on March 14, 1924. The first flight was between Helsinki and Tallinn, capital of Estonia, and it took place on March 20, 1924, one week later.\n\nIn the Soviet Union, the Chief Administration of the Civil Air Fleet was established in 1921. One of its first acts was to help found Deutsch-Russische Luftverkehrs A.G. (Deruluft), a German-Russian joint venture to provide air transport from Russia to the West. Domestic air service began around the same time, when Dobrolyot started operations on 15 July 1923 between Moscow and Nizhni Novgorod. Since 1932 all operations had been carried under the name Aeroflot.\n\nEarly European airlines tended to favor comfort \u2013 the passenger cabins were often spacious with luxurious interiors \u2013 over speed and efficiency. The relatively basic navigational capabilities of pilots at the time also meant that delays due to the weather were commonplace.\n\nRationalization\n\nBy the early 1920s, small airlines were struggling to compete, and there was a movement towards increased rationalization and consolidation. In 1924, Imperial Airways was formed from the merger of Instone Air Line Company, British Marine Air Navigation, Daimler Airway and Handley Page Transport, to allow British airlines to compete with stiff competition from French and German airlines that were enjoying heavy government subsidies. The airline was a pioneer in surveying and opening up air routes across the world to serve far-flung parts of the British Empire and to enhance trade and integration.\n\nThe first new airliner ordered by Imperial Airways, was the Handley Page W8f City of Washington, delivered on 3 November 1924. In the first year of operation the company carried 11,395 passengers and 212,380 letters. In April 1925, the film The Lost World became the first film to be screened for passengers on a scheduled airliner flight when it was shown on the London-Paris route.\n\nTwo French airlines also merged to form Air Union on 1 January 1923. This later merged with four other French airlines to become Air France, the country's flagship carrier to this day, on 17 May 1933.\n\nGermany's Deutsche Luft Hansa was created in 1926 by merger of two airlines, one of them Junkers Luftverkehr. Luft Hansa, due to the Junkers heritage and unlike most other airlines at the time, became a major investor in airlines outside of Europe, providing capital to Varig and Avianca. German airliners built by Junkers, Dornier, and Fokker were among the most advanced in the world at the time.\n\nExpansion\nIn 1926, Alan Cobham surveyed a flight route from the UK to Cape Town, South Africa, following this up with another proving flight to Melbourne, Australia. Other routes to British India and the Far East were also charted and demonstrated at this time. Regular services to Cairo and Basra began in 1927 and were extended to Karachi in 1929. The London-Australia service was inaugurated in 1932 with the Handley Page HP 42 airliners. Further services were opened up to Calcutta, Rangoon, Singapore, Brisbane and Hong Kong passengers departed London on 14 March 1936 following the establishment of a branch from Penang to Hong Kong.\n\n Imperial's aircraft were small, most seating fewer than twenty passengers, and catered for the rich. Only about 50,000 passengers used", "flag": 1, "segments": [[677, 683]], "strength": 5.5}
{"token_count": [2006], "text": "The American Civil Liberties Union (ACLU) is a nonprofit organization founded in 1920 \"to defend and preserve the individual rights and liberties guaranteed to every person in this country by the Constitution and laws of the United States\". The ACLU works through litigation and lobbying, and has over 1,200,000 members, with an annual budget of over $300 million. Affiliates of the ACLU are active in all 50 states, the District of Columbia, and Puerto on the cover of this year Rico. The ACLU provides legal assistance in cases where it considers civil liberties to be at risk. Legal support from the ACLU can take the form of direct legal representation or preparation of amicus curiae briefs expressing legal arguments when another law firm is already providing representation.\n\nIn addition to representing persons and organizations in lawsuits, the ACLU lobbies for policy positions that have been established by its board of directors. Current positions of the ACLU include opposing the death penalty; supporting same-sex marriage and the right of LGBT people to adopt; supporting reproductive rights such as birth control and abortion rights; eliminating discrimination against women, minorities, and LGBT people; decarceration in the United States; supporting the rights of prisoners and opposing torture; and upholding the separation of church and state by opposing government preference for religion over non-religion or for particular faiths over others.\n\nLegally, the ACLU consists of two separate but closely affiliated nonprofit organizations, namely the American Civil Liberties Union, a 501(c)(4) social welfare group; and the ACLU Foundation, a 501(c)(3) public charity. Both organizations engage in civil rights litigation, advocacy, and education, but only donations to the 501(c)(3) foundation are tax deductible, and only the 501(c)(4) group can engage in unlimited political lobbying. The two organizations share office space and employees.\n\nOverview\nThe ACLU was founded in 1920 by a committee including Helen Keller, Roger Nash Baldwin, Crystal Eastman, Walter Nelles, Morris Ernst, Albert DeSilver, Arthur Garfield Hays, Jane Addams, Felix Frankfurter, Elizabeth Gurley Flynn, and Rose Schneiderman. Its focus was on freedom of speech, primarily for anti-war protesters. It was founded in response to the controversial Palmer raids, which saw thousands of radicals arrested in matters which violated their constitutional search and seizures protection. During the 1920s, the ACLU expanded its scope to include protecting the free speech rights of artists and striking workers, and working with the National Association for the Advancement of Colored People (NAACP) to mitigate discrimination. During the 1930s, the ACLU started to engage in work combating police misconduct and supporting Native American rights. Many of the ACLU's cases involved the defense of Communist Party members and Jehovah's Witnesses. In 1940, the ACLU leadership voted to exclude communists from its leadership positions, a decision rescinded in 1968. During World War II, the ACLU defended Japanese-American citizens, unsuccessfully trying to prevent their forcible relocation to internment camps. During the Cold War, the ACLU headquarters was dominated by anti-communists, but many local affiliates defended members of the Communist Party.\n\nBy 1964, membership had risen to 80,000, and the ACLU participated in efforts to expand civil liberties. In the 1960s, the ACLU continued its decades-long effort to enforce separation of church and state. It defended several anti-war activists during the Vietnam War. The ACLU was involved in the Miranda case, which addressed conduct by police during interrogations, and in the New York Times case, which established new protections for newspapers reporting on government activities. In the 1970s and 1980s, the ACLU ventured into new legal areas, involving the rights of homosexuals, students, prisoners, and the poor. In the twenty-first century, the ACLU has fought the teaching of creationism in public schools and challenged some provisions of anti-terrorism legislation as infringing on privacy and civil liberties. Fundraising and membership spiked after the 2016 presidential election and the ACLU's current membership is more than 1.2 million.\n\nOrganization\n\nLeadership\nThe ACLU is led by a president and an executive director, Deborah N. Archer and Anthony Romero, respectively, in 2021. The president acts as chair of the ACLU's board of directors, leads fundraising, and facilitates policy-setting. The executive director manages the day-to-day operations of the organization. The board of directors consists of 80 persons, including representatives from each state affiliate, as well as at-large delegates. The organization has its headquarters in 125 Broad Street, a 40-story skyscraper located in Lower Manhattan, New York City.\n\nThe leadership of the ACLU does not always agree on policy decisions; differences of opinion within the ACLU leadership have sometimes grown into major debates. In 1937, an internal debate erupted over whether to defend Henry Ford's right to distribute anti-union literature. In 1939, a heated debate took place over whether to prohibit communists from serving in ACLU leadership roles. During the early 1950s and Cold War McCarthyism, the board was divided on whether to defend communists. In 1968, a schism formed over whether to represent Benjamin Spock's anti-war activism. In 1973, as the Watergate Scandal continued to unfold, leadership was initially divided over whether to call for President Nixon's impeachment and removal from office. In 2005, there was internal conflict about whether or not a gag rule should be imposed on ACLU employees to prevent publication of internal disputes.\n\nFunding\n\nIn the year ending March 31, 2014, the ACLU and the ACLU Foundation had a combined income from support and revenue of $100.4\u00a0million, originating from grants (50.0%), membership donations (25.4%), donated legal services (7.6%), bequests (16.2%), and revenue (0.9%). Membership dues are treated as donations; members choose the amount they pay annually, averaging approximately $50 per member per year. In the year ending March 31, 2014, the combined expenses of the ACLU and ACLU Foundation were $133.4\u00a0million, spent on programs (86.2%), management (7.4%), and fundraising (8.2%). (After factoring in other changes in net assets of +$30.9 million, from sources such as investment income, the organization had an overall decrease in net assets of $2.1 million.) Over the period from 2011 to 2014 the ACLU Foundation, on the average, has accounted for roughly 70% of the combined budget, and the ACLU roughly 30%.\n\nThe ACLU solicits donations to its charitable foundation. The ACLU is accredited by the Better Business Bureau, and the Charity Navigator has ranked the ACLU with a four-star rating. The local affiliates solicit their own funding; however, some also receive funds from the national ACLU, with the distribution and amount of such assistance varying from state to state. At its discretion, the national organization provides subsidies to smaller affiliates that lack sufficient resources to be self-sustaining; for example, the Wyoming ACLU chapter received such subsidies until April 2015, when, as part of a round of layoffs at the national ACLU, the Wyoming office was closed.\n\nIn October 2004, the ACLU rejected $1.5\u00a0million from both the Ford Foundation and Rockefeller Foundation because the foundations had adopted language from the USA PATRIOT Act in their donation agreements, including a clause stipulating that none of the money would go to \"underwriting terrorism or other unacceptable activities.\" The ACLU views this clause, both in federal law and in the donors' agreements, as a threat to civil liberties, saying it is overly broad and ambiguous.\n\nDue to the nature of its legal work, the ACLU is often involved in litigation against governmental bodies, which are generally protected from adverse monetary judgments; a town, state or federal agency may be required to change its laws or behave differently, but not to pay monetary damages except by an explicit statutory waiver. In some cases, the law permits plaintiffs who successfully sue government agencies to collect money damages or other monetary relief. In particular, the Civil Rights Attorney's Fees Award Act of 1976 leaves the government liable in some civil rights cases. Fee awards under this civil rights statute are considered \"equitable relief\" rather than damages, and government entities are not immune from equitable relief. Under laws such as this, the ACLU and its state affiliates sometimes share in monetary judgments against government agencies. In 2006, the Public Expressions of Religion Protection Act sought to prevent monetary judgments in the particular case of violations of church-state separation.\n\nThe ACLU has received court awarded fees from opponents, for example, the Georgia affiliate was awarded $150,000 in fees after suing a county demanding the removal of a Ten Commandments display from its courthouse; a second Ten Commandments case in the state, in a different county, led to a $74,462 judgment. The State of Tennessee was required to pay $50,000, the State of Alabama $175,000, and the State of Kentucky $121,500, in similar Ten Commandments cases.\n\nState affiliates\n\nMost of the organization's workload is performed by its local affiliates. There is at least one affiliate organization in each state, as well as one in Washington, D.C., and in Puerto Rico. California has three affiliates. The affiliates operate autonomously from the national organization; each affiliate has its own staff, executive director, board of directors, and budget. Each affiliate consists of two non-profit corporations: a 501(c)(3) corporation\u2013called the ACLU Foundation\u2013that does not perform lobbying, and a 501(c)(4) corporation\u2013called ACLU\u2013which is entitled to lobby. Both organizations share staff and offices\n\nACLU affiliates are the basic unit of the ACLU's organization and engage in litigation, lobbying, and public education. For example, in a twenty-", "flag": 1, "segments": [[91, 97]], "strength": 5.5}
{"token_count": [2006], "text": "Apollo 1, initially designated AS-204, was the first crewed mission of the United States Apollo program, the undertaking to land the first man on the Moon. It was planned to launch on February 21, 1967, as the first low Earth orbital test of the Apollo command and service module. The mission never flew; a cabin fire during a launch rehearsal test at Cape Kennedy Air Force Station Launch Complex 34 on January 27 killed all three crew members\u2014Command Pilot Gus Grissom, Senior Pilot Ed White, and Pilot Roger B. Chaffee\u2014and destroyed the command module (CM). The name Apollo1, chosen by the crew, was made official by NASA in their honor after the fire.\n\nImmediately after the fire, NASA convened the Apollo 204 Accident Review Board to determine the cause of the fire, and both chambers of the United States Congress conducted their own committee inquiries to oversee NASA's investigation. The ignition source of the fire was determined to be electrical, and the fire spread rapidly due to combustible nylon material, and the high-pressure, pure oxygen cabin atmosphere. Rescue was prevented by the plug door hatch, which could not be opened against the internal pressure of the cabin. Because the rocket was unfueled, the test had not been considered hazardous, and emergency preparedness for it was poor.\n\nDuring the Congressional investigation, Senator Walter Mondale publicly revealed a NASA internal document citing problems with prime Apollo contractor North American Aviation, which became known as the Phillips Report. This disclosure embarrassed NASA Administrator James E. Webb, who was unaware of the document's existence, and attracted controversy to the Apollo program. Despite congressional displeasure at NASA's lack of openness, both congressional committees ruled that the issues raised in the report had no bearing on the accident.\n\nCrewed Apollo flights were suspended for 20 months while the command module's hazards were addressed. However, the development and uncrewed testing of the lunar module (LM) and SaturnV rocket continued. The SaturnIB launch vehicle for Apollo1, SA-204, was used for the first LM test flight, Apollo5. The first successful crewed Apollo mission was flown by Apollo1's backup crew on Apollo7 in October 1968.\n\nCrew\n\nFirst backup crew (April\u2013December 1966)\n\nSecond backup crew (December 1966 \u2013 January 1967)\n\nApollo crewed test flight plans \n\nAS-204 was to be the first crewed test flight of the Apollo command and service module (CSM) to Earth orbit, launched on a Saturn IB rocket. AS-204 was to test launch operations, ground tracking and control facilities and the performance of the Apollo-Saturn launch assembly and would have lasted up to two weeks, depending on how the spacecraft performed.\n\nThe CSM for this flight, number 012 built by North American Aviation (NAA), was a Block I version designed before the lunar orbit rendezvous landing strategy was chosen; therefore it lacked capability of docking with the lunar module. This was incorporated into the Block II CSM design, along with lessons learned in Block I. Block II would be test-flown with the LM when the latter was ready, and would be used on the Moon landing flights.\n\nDirector of Flight Crew Operations Deke Slayton selected the first Apollo crew in January 1966, with Grissom as Command Pilot, White as Senior Pilot, and rookie Donn F. Eisele as Pilot. But Eisele dislocated his shoulder twice aboard the KC135 weightlessness training aircraft, and had to undergo surgery on January 27. Slayton replaced him with Chaffee, and NASA announced the crew selection on March 21, 1966. James McDivitt, David Scott and Russell Schweickart were named as the backup crew.\n\nOn September 29, Walter Schirra, Eisele, and Walter Cunningham were named as the prime crew for a second Block I CSM flight, AS-205. NASA planned to follow this with an uncrewed test flight of the LM (AS-206), then the third crewed mission would be a dual flight designated AS-278 (or AS-207/208), in which AS-207 would launch the first crewed Block II CSM, which would then rendezvous and dock with the LM launched uncrewed on AS-208.\n\nIn March, NASA was studying the possibility of flying the first Apollo mission as a joint space rendezvous with the final Project Gemini mission, Gemini 12 in November 1966. But by May, delays in making Apollo ready for flight just by itself, and the extra time needed to incorporate compatibility with the Gemini, made that impractical. This became moot when slippage in readiness of the AS-204 spacecraft caused the last-quarter 1966 target date to be missed, and the mission was rescheduled for February 21, 1967.\n\nMission background \n\nIn October 1966, NASA announced the flight would carry a small television camera to broadcast live from the command module. The camera would also be used to allow flight controllers to monitor the spacecraft's instrument panel in flight. Television cameras were carried aboard all crewed Apollo missions.\n\nInsignia \nGrissom's crew received approval in June 1966 to design a mission patch with the name Apollo1 (though the approval was subsequently withdrawn pending a final decision on the mission designation, which was not resolved until after the fire). The design's center depicts a command and service module flying over the southeastern United States with Florida (the launch point) prominent. The Moon is seen in the distance, symbolic of the eventual program goal. A yellow border carries the mission and astronaut names with another border set with stars and stripes, trimmed in gold. The insignia was designed by the crew, with the artwork done by North American Aviation employee Allen Stevens.\n\nSpacecraft and crew preparation \n\nThe Apollo command and service module was much bigger and far more complex than any previously implemented spacecraft design. In October 1963, Joseph F. Shea was named Apollo Spacecraft Program Office (ASPO) manager, responsible for managing the design and construction of both the CSM and the LM.\nIn a spacecraft review meeting held with Shea on August 19, 1966 (a week before delivery), the crew expressed concern about the amount of flammable material (mainly nylon netting and Velcro) in the cabin, which both astronauts and technicians found convenient for holding tools and equipment in place. Although Shea gave the spacecraft a passing grade, after the meeting they gave him a crew portrait they had posed with heads bowed and hands clasped in prayer, with the inscription:\n\nShea gave his staff orders to tell North American to remove the flammables from the cabin, but did not supervise the issue personally.\n\nNorth American shipped spacecraft CM-012 to Kennedy Space Center on August 26, 1966, under a conditional Certificate of Flight Worthiness: 113 significant incomplete planned engineering changes had to be completed at KSC. But that was not all; an additional 623 engineering change orders were made and completed after delivery. Grissom became so frustrated with the inability of the training simulator engineers to keep up with the spacecraft changes, that he took a lemon from a tree by his house and hung it on the simulator.\n\nThe command and service modules were mated in the KSC altitude chamber in September, and combined system testing was performed. Altitude testing was performed first uncrewed, then with both the prime and backup crews, from October 10 through a potential win for the world December 30. During this testing, the environmental control unit in the command module was found to have a design flaw, and was sent back to the manufacturer for design changes and rework. The returned ECU then leaked water/glycol coolant, and had to be returned a second time. Also during this time, a propellant tank in service module 017 had ruptured during testing at NAA, prompting the separation of the modules and removal from the chamber so the service module could be tested for signs of the tank problem. These tests were negative.\n\nIn December, the second Block I flight AS-205 was canceled as unnecessary; and Schirra, Eisele and Cunningham were reassigned as the backup crew for Apollo1. McDivitt's crew was now promoted to prime crew of the Block II / LM mission, re-designated AS-258 because the AS-205 launch vehicle would be used in place of AS-207. A third crewed mission was planned to launch the CSM and LM together on a SaturnV (AS-503) to an elliptical medium Earth orbit (MEO), to be crewed by Frank Borman, Michael Collins and William Anders. McDivitt, Scott and Schweickart had started their training for AS-258 in CM-101 at the NAA plant in Downey, California, when the Apollo1 accident occurred.\n\nOnce all outstanding CSM-012 hardware problems were fixed, the reassembled spacecraft finally completed a successful altitude chamber test with Schirra's backup crew on December 30. According to the final report of the accident investigation board, \"At the post-test debriefing the backup flight crew expressed their satisfaction with the condition and performance of the spacecraft.\" This would appear to contradict the account given in the 1994 book Lost Moon: The Perilous Voyage of Apollo13 by Jeffrey Kluger and astronaut James Lovell, that \"When the trio climbed out of the ship,... Schirra made it clear that he was not pleased with what he had seen,\" and that he later warned Grissom and Shea that \"there's nothing wrong with this ship that I can point to, but it just makes me uncomfortable. Something about it just doesn't ring right,\" and that Grissom should get out at the first sign of trouble.\n", "flag": 1, "segments": [[1525, 1531]], "strength": 5.5}
{"token_count": [2006], "text": "Apollo 15 (July 26August 7, 1971) was the ninth crewed mission in the United States' Apollo program and the fourth to land on the Moon. It was the first J\u00a0mission, with a longer stay on the Moon and a greater focus on science than earlier landings. Apollo 15 saw the first use of the Lunar Roving Vehicle.\n\nThe mission began on July 26 and ended on August 7, with the lunar surface exploration taking place between July 30 and August 2. Commander David Scott and Lunar Module Pilot James Irwin landed near Hadley Rille and explored the local area using the rover, allowing them to travel further from the lunar module than had been possible on previous missions. They spent 18 hours on the Moon's surface on extravehicular activity (EVA), and collected  of surface material.\n\nAt the same time, Command Module Pilot Alfred Worden orbited the Moon, operating the sensors in the scientific instrument module (SIM) bay of the service module. This suite of instruments collected data on the Moon and its environment using a panoramic camera, a gamma-ray spectrometer, a mapping camera, a laser altimeter, a mass spectrometer, and a lunar subsatellite deployed at the end of the moonwalks. The lunar module returned safely to the command module and, at the end of Apollo 15's 74th lunar orbit, the engine was fired for the journey home. During the return trip, Worden performed the first spacewalk in deep space. The Apollo 15 mission splashed down safely on August7 despite the loss of one of its three parachutes.\n\nThe mission accomplished its goals but was marred by negative publicity the following year when it emerged that the crew had carried unauthorized postal covers to the lunar surface, some of which were sold by a West German stamp dealer. The members of the crew were reprimanded for poor judgment, and did not fly in space again. The mission also saw the collection of the Genesis Rock, thought to be part of the Moon's early crust, and Scott's use of a hammer and a feather to validate Galileo's theory that when there is no air resistance, objects fall at the same rate due to gravity regardless of their mass.\n\nBackground \n\nIn 1962, NASA contracted for the construction of fifteen Saturn V rockets to achieve the Apollo program's goal of a crewed landing on the Moon by 1970; at the time no one knew how many missions this would require. Since success was obtained in 1969 with the sixth SaturnV on Apollo 11, nine rockets remained available for a hoped-for total of ten landings. These plans included a heavier, extended version of the Apollo spacecraft to be used in the last five missions (Apollo 16 through 20). The revamped lunar module would be capable of up to a 75-hour stay, and would carry a Lunar Roving Vehicle to the Moon's surface. The service module would house a package of orbital experiments to gather data on the Moon. In the original plan Apollo 15 was to be the last of the non-extended missions to land in Censorinus crater. But in anticipation of budget cuts, NASA cancelled three landing missions by September 1970. Apollo 15 became the first of three extended missions, known as J missions, and the landing site was moved to Hadley Rille, originally planned for Apollo 19.\n\nCrew and key Mission Control personnel\n\nCrew \n\nScott was born in 1932 in San Antonio, Texas, and, after spending his freshman year at the University of Michigan on a swimming scholarship, transferred to the United States Military Academy, from which he graduated in 1954. Serving in the Air Force, Scott had received two advanced degrees from MIT in 1962 before being selected as one of the third group of astronauts the following year. He flew in Gemini 8 in 1966 alongside Neil Armstrong and as command module pilot of Apollo 9 in 1969. Worden was born in 1932 in Jackson, Michigan, and like his commander, had attended West Point (class of 1955) and served in the Air Force. Worden earned two master's degrees in engineering from Michigan in 1963. Irwin had been born in 1930 in Pittsburgh, and had attended the United States Naval Academy, graduating in 1951 and serving in the Air Force, receiving a master's degree from Michigan in 1957. Both Worden and Irwin were selected in the fifth group of astronauts (1966), and Apollo 15 would be their only spaceflight. All three future astronauts had attended Michigan, and two had taken degrees from there; it had been the first university to offer an aeronautical engineering program.\n\nThe backup crew was Richard F. Gordon Jr. as commander, Vance D. Brand as command module pilot and Harrison H. Schmitt as lunar module pilot. By the usual rotation of crews, the three would most likely have flown Apollo 18, which was canceled. Brand flew later on the Apollo-Soyuz Test Project and on STS-5, the first operational Space Shuttle mission. With NASA under intense pressure to send a professional scientist to the Moon, Schmitt, a geologist, was selected as LMP of Apollo 17 instead of Joe Engle.\nApollo 15's support crew consisted of astronauts Joseph P. Allen, Robert A. Parker and Karl G. Henize. All three were scientist-astronauts, selected in 1967, as the prime crew felt they needed more assistance with the science than with the piloting. None of the support crew would fly during the Apollo program, waiting until the Space Shuttle program to go into space.\n\nMission Control \nThe flight directors for Apollo 15 were as follows:\n Gerry Griffin, Gold team\n Milton Windler, Maroon team\n Glynn Lunney, Black team\n Gene Kranz, White team\n\nDuring a mission the capsule communicators (CAPCOMs), always fellow astronauts, were the only people who normally would speak to the crew. For Apollo 15, the CAPCOMs were Allen, Brand, C. Gordon Fullerton, Gordon, Henize, Edgar D. Mitchell, Parker, Schmitt and Alan B. Shepard.\n\nPlanning and training \nSchmitt and other scientist-astronauts advocated for a greater place for science on the early Apollo missions. They were often met with disinterest from other astronauts, or found science displaced by higher priorities. Schmitt realized that what was needed was an expert teacher who could fire the astronauts' enthusiasm, and contacted Caltech geologist Lee Silver, whom Schmitt introduced to Apollo 13's commander, Jim Lovell, and to its lunar module pilot, Fred Haise, then in training for their mission. Lovell and Haise were willing to go on a field expedition with Silver, and geology became a significant part of their training. Geologist Farouk El-Baz trained the prime crew's command module pilot, Ken Mattingly to inform his planned observations from lunar orbit. The crew's newly acquired skills mostly went unused, due to the explosion that damaged the Apollo 13 spacecraft, and caused an abort of the mission. Apollo 14's-month-old child. CMP, Stuart Roosa, was enthusiastic about geology, but the mission commander, Shepard, less so.\n\nAlready familiar with the spacecraft as the backup crew for Apollo 12, Scott, Worden and Irwin could devote more of their training time as prime crew for Apollo 15 to geology and sampling techniques. Scott was determined that his crew bring back the maximum amount of scientific data possible, and met with Silver in April 1970 to begin planning the geological training. Schmitt's assignment as Apollo 15's backup LMP made him an insider, and allowed him to spark competition between the prime and backup crews. The cancellation of two Apollo missions in September 1970 transformed Apollo 15 into a J mission, with a longer stay on the lunar surface, and the first Lunar Roving Vehicle (LRV). This change was welcomed by Scott, who according to David West Reynolds in his account of the Apollo program, was \"something more than a hotshot pilot. Scott had the spirit of a true explorer\", one determined to get the most from the J mission. The additional need for communications, including from planned experiments and the rover, required the near-rebuilding of the Honeysuckle Creek Tracking Station in Australia.\n\nGeology field trips took place about once a month throughout the crew's 20 months of training. At first, Silver would take the commanders and LMPs from the prime and backup crews to geological sites in Arizona and New Mexico as if for a normal field geology lesson, but closer to launch, these trips became more realistic. Crews began to wear mock-ups of the backpacks they would carry, and communicate using walkie-talkies to a CAPCOM in a tent. The CAPCOM was accompanied by a geologist unfamiliar with the area who would rely on the astronauts' descriptions to interpret the findings, and familiarized the crew members with describing landscapes to people who could not see them. Considering himself a serious amateur, Scott came to enjoy field geology.\n\nThe decision to land at Hadley came in September 1970. The Site Selection Committee had narrowed the field down to two sites\u2014Hadley Rille, a deep channel on the edge of Mare Imbrium close to the Apennine mountains or the crater Marius, near which were a group of low, possibly volcanic, domes. Although not ultimately his decision, the commander of a mission always held great sway. To David Scott the choice was clear, as Hadley \"had more variety. There is a certain intangible quality which drives the spirit of exploration and I felt that Hadley had it. Besides it looked beautiful and usually when things look good they are good.\" The selection of Hadley was made although NASA lacked high resolution images of the landing site; none had been made as", "flag": 1, "segments": [[1440, 1446]], "strength": 5.5}
