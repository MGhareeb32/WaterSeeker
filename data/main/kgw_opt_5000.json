{"text": "Alabama () is a state in the Southeastern region of the United States, bordered by Tennessee to the north; Georgia to the east; Florida and the Gulf of Mexico to the south; and Mississippi to the west. Alabama is the 30th largest by area and the 24th-most populous of the U.S. states. With a total of  of inland waterways, Alabama has among the most of any state.\n\nAlabama is nicknamed the Yellowhammer State, after the state bird. Alabama is also known as the \"Heart of Dixie\" and the \"Cotton State\". The state tree is the longleaf pine, and the state flower is the camellia. Alabama's capital is Montgomery, and its largest city by population and area is Huntsville. Its oldest city is Mobile, founded by French colonists in 1702 as the capital of French Louisiana. Greater Birmingham is Alabama's largest metropolitan area and its economic center.\n\nOriginally home to many native tribes, present-day Alabama was a Spanish territory beginning in the sixteenth century until the French acquired it in the early eighteenth century. The British won the territory in 1763 until losing it in the American Revolutionary War. Spain held Mobile as part of Spanish West Florida until 1813. In December 1819, Alabama was recognized as a state. During the antebellum period, Alabama was a major producer of cotton, and widely used African American slave labor. In 1861, the state seceded from the United States to become part of the Confederate States of America, with Montgomery acting as its first capital, and rejoined the Union in 1868. Following the American Civil War, Alabama would suffer decades of economic hardship, in part due to agriculture and a few cash crops being the main driver of the states economy. Similar to other former slave states, Alabamian legislators employed Jim Crow laws to disenfranchise and discriminate against African Americans from the late 19th century up until the 1960s. \n\nIn the early 20th century, despite the growth of major industries and urban centers, white rural interests dominated the state legislature through the mid-20th century. During this time, urban interests and African Americans were markedly under-represented. High-profile events such as the Selma to Montgomery march made the state a major focal point of the civil rights movement in the 1950s and 1960s. During and after World War II, Alabama grew as the state's economy diversified with new industries. NASA's Marshall Space Flight Center in Huntsville would help Alabama's economic growth in the mid-to-late 20th century, by developing an aerospace industry. Alabama's economy in the 21st century is based on automotive, finance, tourism, manufacturing, aerospace, mineral extraction, healthcare, education, retail, and technology.\n\nThe state's geography is diverse, with the north dominated by the mountainous Tennessee Valley and the south by Mobile Bay, a historically significant port. Politically, as part of the Deep South, Alabama is predominantly a conservative state, and culturally is known for its Southern culture. Within Alabama, American football, particularly at the college level at schools such as the University of Alabama, Auburn University, Alabama A&M University, Alabama State University, Troy University, the University of South Alabama, and Jacksonville State University, play a major part of the state's culture.\n\nEtymology\nThe European-American naming of the Alabama River and state was derived from the Alabama people, a Muskogean-speaking tribe whose members lived just below the confluence of the Coosa and Tallapoosa rivers on the upper reaches of the river. In the Alabama language, the word for a person of Alabama lineage is  (or variously  or  in different dialects; the plural form is ). The suggestion that \"Alabama\" was borrowed from the Choctaw language is unlikely. The word's spelling varies significantly among historical sources. The first usage appears in three accounts of the Hernando de Soto expedition of 1540: Garcilaso de la Vega used, while the Knight of Elvas and Rodrigo Ranjel wrote Alibamu and Limamu, respectively, in transliterations of the term. As early as 1702, the French called the tribe the, with French maps identifying the river as. Other spellings of the name have included Alibamu, Alabamo, Albama, Alebamon, Alibama, Alibamou, Alabamu, Allibamou. and possibly Alabahmu. The use of state names derived from Native American languages is common in the U.S.; an estimated 27 states have names of Native American origin.\n\nSources disagree on the word's meaning. Some scholars suggest the word comes from the Choctaw  (meaning 'plants' or 'weeds') and  (meaning 'to cut', 'to trim', or 'to gather'). The meaning may have been 'clearers of the thicket' or 'herb gatherers', referring to clearing land for cultivation or collecting medicinal plants. The state has numerous place names of Native American origin. However, there are no correspondingly similar words in the Alabama language.\n\nAn 1842 article in the Jacksonville Republican proposed it meant 'Here We Rest'. This notion was popularized in the 1850s through the writings of Alexander Beaufort Meek. Experts in the Muskogean languages have not found any evidence to support such a translation.\n\nHistory\n\nPre-European settlement\n\nIndigenous peoples of varying cultures lived in the area for thousands of years before the advent of European colonization. Trade with the northeastern tribes by the Ohio River began during the Burial Mound Period (1000BCE700CE) and continued until European contact.\n\nThe agrarian Mississippian culture covered most of the state from 1000 to 1600 CE, with one of its major centers built at what is now the Moundville Archaeological Site in Moundville, Alabama. This is the second-largest complex of the classic Middle Mississippian era, after Cahokia in present-day Illinois, which was the center of the culture. Analysis of artifacts from archaeological excavations at Moundville were the basis of scholars' formulating the characteristics of the Southeastern Ceremonial Complex (SECC). Contrary to popular belief, the SECC appears to have no direct links to Mesoamerican culture, but developed independently. The Ceremonial Complex represents a major component of the religion of the Mississippian peoples; it is one of the primary means by which their religion is understood.\n\nAmong the historical tribes of Native American people living in present-day Alabama at the time of European contact were the Cherokee, an Iroquoian language people; and the Muskogean-speaking Alabama (Alibamu), Chickasaw, Choctaw, Creek, and Koasati. While part of the same large language family, the Muskogee tribes developed distinct cultures and languages.\n\nEuropean settlement\n\nThe Spanish were the first Europeans to reach Alabama during their exploration of North America in the 16th century. The expedition of Hernando de Soto passed through Mabila and other parts of the state in 1540. More than 160 years later, the French founded the region's first European settlement at Old Mobile in 1702. The city was moved to the current site of Mobile in 1711. This area was claimed by the French from 1702 to 1763 as part of La Louisiane.\n\nAfter the French lost to the British in the Seven Years' War, it became part of British West Florida from 1763 to 1783. After the United States victory in the American Revolutionary War, the territory was divided between the United States and Spain. The latter retained control of this western territory from 1783 until the surrender of the Spanish garrison at Mobile to U.S. forces on April 13, 1813.\n\nThomas Bassett, a loyalist to the British monarchy during the Revolutionary era, was one of the earliest white settlers in the state outside Mobile. He settled in the Tombigbee District during the early 1770s. The district's boundaries were roughly limited to the area within a few miles of the Tombigbee River and included portions of what is today southern Clarke County, northernmost Mobile County, and most of Washington County.\n\nWhat is now the counties of Baldwin and Mobile became part of Spanish West Florida in 1783, part of the independent Republic of West Florida in 1810, and was finally added to the Mississippi Territory in 1812. Most of what is now the northern two-thirds of Alabama was known as the Yazoo lands beginning during the British colonial period. It was claimed by the Province of Georgia from 1767 onwards. Following the Revolutionary War, it remained a part of Georgia, although heavily disputed.\n\nWith the exception of the area around Mobile and the Yazoo lands, what is now the lower one-third of Alabama was made part of the Mississippi Territory when it was organized in 1798. The Yazoo lands were added to the territory in 1804, following the Yazoo land scandal. Spain kept a claim on its former Spanish West Florida territory in what would become the coastal counties until the Adams\u2013On\u00eds Treaty officially ceded it to the United States in 1819.\n\nEarly 19th century\n\nBefore Mississippi's admission to statehood on December 10, 1817, the more sparsely settled eastern half of the territory was separated and named the Alabama Territory. The United States Congress created the Alabama Territory on March 3, 1817. St. Stephens, now abandoned, served as the territorial capital from 1817 to 1819.\n\nAlabama was admitted as the 22nd state on December 14, 1819, with Congress selecting Huntsville as the site for the first Constitutional Convention. From July5 to August 2, 1819, delegates met to prepare the new state constitution. Huntsville served as temporary capital from 1819 to 1820, when the seat of government moved to Cahaba in Dallas County.\n\nCahaba, now a ghost town, was the first permanent state capital from 1820 to 1825. The Alabama Fever land rush was underway when the state was admitted to the Union, with settlers and land speculators pouring into the state to take advantage of fertile land suitable for cotton cultivation. Part of the frontier in the 1820s and 1830s, its constitution provided for universal suffrage for white men.\n\nSoutheastern planters and traders from the Upper South brought slaves with them as the cotton plantations in Alabama expanded. The economy of the central Black Belt (named for its dark, productive soil) was built around large cotton plantations whose owners' wealth grew mainly from slave labor. The area also drew many poor, disenfranchised people who became subsistence farmers. Alabama had an estimated population of under 10,000 people in 1810, but it increased to more than 300,000 people by 1830. Most Native American tribes were completely removed from the state within a few years of the passage of the Indian Removal Act by Congress in 1830.\n\nFrom 1826 to 1846, Tuscaloosa served as Alabama's capital. On January 30, 1846, the Alabama legislature announced it had voted to move the capital city from Tuscaloosa to Montgomery. The first legislative session in the new capital met in December 1847. A new capitol building was erected under the direction of Stephen Decatur Button of Philadelphia. The first structure burned down in 1849, but was rebuilt on the same site in 1851. This second capitol building in Montgomery remains to the present day. It was designed by Barachias Holt of Exeter, Maine.\n\nCivil War and Reconstruction\n\nBy 1860, the population had increased to 964,201 people, of which nearly half, 435,080, were enslaved African Americans, and 2,690 were free people of color. On January 11, 1861, Alabama declared its secession from the Union. After remaining an independent republic for a few days, it joined the Confederate States of America. The Confederacy's capital was initially at Montgomery. Alabama was heavily involved in the American Civil War. Although comparatively few battles were fought in the state, Alabama contributed about 120,000 soldiers to the war effort.\n\nA company of cavalry soldiers from Huntsville, Alabama, joined Nathan Bedford Forrest's battalion in Hopkinsville, Kentucky. The company wore new uniforms with yellow trim on the sleeves, collar and coattails. This led to them being greeted with \"Yellowhammer\", and the name later was applied to all Alabama troops in the Confederate Army.\n\nAlabama's slaves were freed by the 13th Amendment in 1865. Alabama was under military rule from the end of the war in May 1865 until its official restoration to the Union in 1868. From 1867 to 1874, with most white citizens barred temporarily from voting and freedmen enfranchised, many African Americans emerged as political leaders in the state. Alabama was represented in Congress during this period by three African-American congressmen: Jeremiah Haralson, Benjamin S. Turner, and James T. Rapier.\n\nFollowing the war, the state remained chiefly agricultural, with an economy tied to cotton. During Reconstruction, state legislators ratified a new state constitution in 1868 which created the state's first public school system and expanded women's rights. Legislators funded numerous public road and railroad projects, although these were plagued with allegations of fraud and misappropriation. Organized insurgent, resistance groups tried to suppress the freedmen and Republicans. Besides the short-lived original Ku in one virtual system coupled with Linux-style user Klux Klan, these included the Pale Faces, Knights of the White Camellia, Red Shirts, and the White League.\n\nReconstruction in Alabama ended in 1874, when the Democrats regained control of the legislature and governor's office through an election dominated by fraud and violence. They wrote another constitution in 1875, and the legislature passed the Blaine Amendment, prohibiting public money from being used to finance religious-affiliated schools. The same year, legislation was approved that called for racially segregated schools. Railroad passenger cars were segregated in 1891.\n\n20th century\n\nThe new 1901 Constitution of Alabama included provisions for voter registration that effectively disenfranchised large portions of the population, including nearly all African Americans and Native Americans, and tens of thousands of poor European Americans, through making voter registration difficult, requiring a poll tax and literacy test. The 1901 constitution required racial segregation of public schools. By 1903 only 2,980 African Americans were registered in Alabama, although at least 74,000 were literate. This compared to more than 181,000 African Americans eligible to vote in 1900. The numbers dropped even more in later decades. The state legislature passed additional racial segregation laws related to public facilities into the 1950s: jails were segregated in 1911; hospitals in 1915; toilets, hotels, and restaurants in 1928; and bus stop waiting rooms in 1945.\n\nWhile the planter class had persuaded poor whites to vote for this legislative effort to suppress black voting, the new restrictions resulted in their disenfranchisement as well, due mostly to the imposition of a cumulative poll tax. By 1941, whites constituted a slight majority of those disenfranchised by these laws: 600,000 whites vs. 520,000 African-Americans. Nearly all Blacks had lost the ability to vote. Despite numerous legal challenges which succeeded in overturning certain provisions, the state legislature would create new ones to maintain disenfranchisement. The exclusion of blacks from the political system persisted until after passage of federal civil rights legislation in 1965 to enforce their constitutional rights as citizens.\n\nThe rural-dominated Alabama legislature consistently underfunded schools and services for the disenfranchised African Americans, but it did not relieve them of paying taxes. Partially as a response to chronic underfunding of education for African Americans in the South, the Rosenwald Fund began funding the construction of what came to be known as Rosenwald Schools. In Alabama these schools were designed and the construction partially financed with Rosenwald funds, which paid one-third of the construction costs. The fund required the local community and state to raise matching funds to pay the rest. Black residents effectively taxed themselves twice, by raising additional monies to supply matching funds for such schools, which were built in many rural areas. They often donated land and labor as well.\n\nBeginning in 1913, the first 80 Rosenwald Schools were built in Alabama for African-American children. A total of 387 schools, seven teachers' houses, and several vocational buildings were completed by 1937 in the state. Several of the surviving school buildings in the state are now listed on the National Register of Historic Places.\n\nContinued racial discrimination and lynchings, agricultural depression, and the failure of the cotton crops due to boll weevil infestation led tens of thousands of African Americans from rural Alabama and other states to seek opportunities in northern and midwestern cities during the early decades of the 20th century as part of the Great Migration out of the South. Reflecting this emigration, the population growth rate in Alabama (see \"historical populations\" table below) dropped by nearly half from 1910 to 1920.\n\nAt the same time, many rural people migrated to the city of Birmingham to work in new industrial jobs. Birmingham experienced such rapid growth it was called the \"Magic City\". By 1920, Birmingham was the 36th-largest city in the United States. Heavy industry and mining were the basis of its economy. Its residents were under-represented for decades in the state legislature, which refused to redistrict after each decennial census according to population changes, as it was required by the state constitution. This did not change until the late 1960s following a lawsuit and court order.\n\nIndustrial development related to the demands of World War II brought a level of prosperity to the state not seen since before the civil war. Rural workers poured into the largest cities in the state for better jobs and a higher standard of living. One example of this massive influx of workers occurred in Mobile. Between 1940 and 1943, more than 89,000 people moved into the city to work for war-related industries. Cotton and other cash crops faded in importance as the state developed a manufacturing and service base.\n\nDespite massive population changes in the state from 1901 to 1961, the rural-dominated legislature refused to reapportion House and Senate seats based on population, as required by the state constitution to follow the results of decennial censuses. They held on to old representation to maintain political and economic power in agricultural areas. One result was that Jefferson County, containing Birmingham's industrial and economic powerhouse, contributed more than one-third of all tax revenue to the state, but did not receive a proportional amount in services. Urban interests were consistently underrepresented in the legislature. A 1960 study noted that because of rural domination, \"a minority of about 25% of the total state population is in majority control of the Alabama legislature.\"\n\nIn the United States Supreme Court cases of Baker v. Carr (1962) and Reynolds v. Sims (1964), the court ruled that the principle of \"one man, one vote\" needed to be the basis of both houses of state legislatures, and that their districts had to be based on population rather than geographic counties.\n\nIn 1972, for the first time since 1901, the legislature completed the congressional redistricting based on the decennial census. This benefited the urban areas that had developed, as well as all in the population who had been underrepresented for more than sixty years. Other changes were made to implement representative state house and senate districts.\n\nAfrican Americans continued to press in the 1950s and 1960s to end disenfranchisement and segregation in the state through the civil rights movement, including legal challenges. In 1954, the U.S. Supreme Court ruled in Brown v. Board of Education that public schools had to be desegregated, but Alabama was slow to comply. During the 1960s, under Governor George Wallace, Alabama resisted compliance with federal demands for desegregation. The civil rights movement had notable events in Alabama, including the Montgomery bus boycott (1955\u20131956), Freedom Rides in 1961, and 1965 Selma to Montgomery marches. These contributed to Congressional passage and enactment of the Civil Rights Act of 1964 and Voting Rights Act of 1965 by the U.S. Congress.\n\nLegal segregation ended in the states in 1964, but Jim Crow customs often continued until specifically challenged in court. According to The New York Times, by 2017, many of Alabama's African-Americans were living in Alabama's cities such as Birmingham and Montgomery. Also, the Black Belt region across central Alabama \"is home to largely poor counties that are predominantly African-American. These counties include Dallas, Lowndes, Marengo and Perry.\"\n\nAlabama has made some changes since the late 20th century and has used new types of voting to increase representation. In the 1980s, an omnibus redistricting case, Dillard v. Crenshaw County, challenged the at-large voting for representative seats of 180 Alabama jurisdictions, including counties and school boards. At-large voting had diluted the votes of any minority in a county, as the majority tended to take all seats. Despite African Americans making up a significant minority in the state, they had been unable to elect any representatives in most of the at-large jurisdictions.\n\nAs part of settlement of this case, five Alabama cities and counties, including Chilton County, adopted a system of cumulative voting for election of representatives in multi-seat jurisdictions. This has resulted in more proportional representation for voters. In another form of proportional representation, 23 jurisdictions use limited voting, as in Conecuh County. In 1982, limited voting was first tested in Conecuh County. Together use of these systems has increased the number of African Americans and women being elected to local offices, resulting in governments that are more representative of their citizens.\n\nBeginning in the 1960s, the state's economy shifted away from its traditional lumber, steel, and textile industries because of increased foreign competition. Steel jobs, for instance, declined from 46,314 in 1950 to 14,185 in 2011. However, the state, particularly Huntsville, benefited from the opening of the George C. Marshall Space Flight Center in 1960, a major facility in the development of the Saturn rocket program and the space shuttle. Technology and manufacturing industries, such as automobile assembly, replaced some the state's older industries in the late twentieth century, but the state's economy and growth lagged behind other states in the area, such as Georgia and Florida.\n\n21st century\n\nIn 2001, Alabama Supreme Court chief justice Roy Moore installed a statue of the Ten Commandments in the capitol in Montgomery. In 2002, the 11th US Circuit Court ordered the statue removed, but Moore refused to follow the court order, which led to protests around the capitol in favor of keeping the monument.  The monument was removed in August 2003.\n\nA few natural disasters have occurred in the state in the twenty-first century. In 2004, Hurricane Ivan, a category 3 storm upon landfall, struck the state and caused over $18 billion of damage. It was among the most destructive storms to strike the state in its modern history. A super outbreak of 62 tornadoes hit the state in April 2011 and killed 238 people, devastating many communities.\n\nGeography\n\nAlabama is the thirtieth-largest state in the United States with  of total area: 3.2% of the area is water, making Alabama 23rd in the amount of surface water, also giving it the second-largest inland waterway system in the United States. About three-fifths of the land area is part of the Gulf Coastal Plain, a gentle plain with a general descent towards the Mississippi River and the Gulf of Mexico. The North Alabama region is mostly mountainous, with the Tennessee River cutting a large valley and creating numerous creeks, streams, rivers, mountains, and lakes.\n\nAlabama is bordered by the states of Tennessee to the north, Georgia to the east, Florida to the south, and Mississippi to the west. Alabama has coastline at the Gulf of Mexico, in the extreme southern edge of the state. The state ranges in elevation from sea level at Mobile Bay to more than  in the northeast, to Mount Cheaha at.\n\nAlabama's land consists of  of forest or 67% of the state's total land area. Suburban Baldwin", "flag": 1, "segments": [[2782, 2792]], "strength": 5.5}
{"text": "In Greek mythology, Achilles ( ) or Achilleus () was a hero of the Trojan War, the greatest of all the Greek warriors, and is the central character of Homer's Iliad. He was the son of the Nereid Thetis and Peleus, king of Phthia.\n\nAchilles' most notable feat during the Trojan War was the slaying of the Trojan prince Hector outside the gates of Troy. Although the death of Achilles is not presented in the Iliad, other sources concur that he was killed near the end of the Trojan War by Paris, who shot him with an arrow. Later legends (beginning with Statius' unfinished epic Achilleid, written in the 1st century AD) state that Achilles was invulnerable in all of his body except for one heel, because when his mother Thetis dipped him in the river Styx as an infant, she held him by one of his heels. Alluding to these legends, the term \"Achilles' heel\" has come to mean a point of weakness, especially in someone or something with an otherwise strong constitution. The Achilles tendon is also named after him due to these legends.\n\nEtymology \n\nLinear B tablets attest to the personal name Achilleus in the forms a-ki-re-u and a-ki-re-we, the latter being the dative of the former. The name grew more popular, even becoming common soon after the seventh century BC and was also turned into the female form \u1f08\u03c7\u03b9\u03bb\u03bb\u03b5\u03af\u03b1 (Achille\u00eda), attested in Attica in the fourth century BC (IG II\u00b2 1617) and, in the form Achillia, on a stele in Halicarnassus as the name of a female gladiator fighting an \"Amazon\".\n\nAchilles' name can be analyzed as a combination of  () \"distress, pain, sorrow, grief\" and  () \"people, soldiers, nation\", resulting in a proto-form *Akh\u00ed-l\u0101u\u032fos \"he who has the people distressed\" or \"he whose people have distress\". The grief or distress of the people is a theme raised numerous times in the Iliad (and frequently by Achilles himself). Achilles' role as the hero of grief or distress forms an ironic juxtaposition with the conventional view of him as the hero of   (\"glory\", usually in war). Furthermore, la\u00f3s has been construed by Gregory Nagy, following Leonard Palmer, to mean \"a corps of soldiers\", a muster. With this derivation, the name obtains a double meaning in the poem: when the hero is functioning rightly, his men bring distress to the enemy, but when wrongly, his men get the grief of war. The poem is in part about the misdirection of anger on the part of leadership.\n\nAnother etymology relates the name to a Proto-Indo-European compound *h\u2082e\u1e31-p\u1e53ds \"sharp foot\" which first gave an Illyrian *\u0101k\u0302pedi\u00f3s, evolving through time into *\u0101khpde\u00f3s and then *akhidde\u00fas. The shift from -dd- to -ll- is then ascribed to the passing of the name into Greek via a Pre-Greek source. The first root part *h\u2082e\u1e31- \"sharp, pointed\" also gave Greek \u1f00\u03ba\u03ae (ak\u1e17 \"point, silence, healing\"), \u1f00\u03ba\u03bc\u03ae (akm\u1e17 \"point, edge, zenith\") and \u1f40\u03be\u03cd\u03c2 (ox\u00fas \"sharp, pointed, keen, quick, clever\"), whereas \u1f04\u03c7\u03bf\u03c2 stems from the root *h\u2082eg\u02b0- \"to be upset, afraid\". The whole expression would be comparable to the Latin acupedius \"swift of foot\". Compare also the Latin word family of aci\u0113s \"sharp edge or point, battle line, battle, engagement\", acus \"needle, pin, bodkin\", and acu\u014d \"to make pointed, sharpen, whet; to exercise; to arouse\" (whence acute). Some topical epitheta of Achilles in the Iliad point to this \"swift-footedness\", namely \u03c0\u03bf\u03b4\u03ac\u03c1\u03ba\u03b7\u03c2 \u03b4\u1fd6\u03bf\u03c2 \u1f08\u03c7\u03b9\u03bb\u03bb\u03b5\u1f7a\u03c2 (pod\u00e1rk\u0113s d\u0129os Achille\u00fas \"swift-footed divine Achilles\") or, even more frequently, \u03c0\u03cc\u03b4\u03b1\u03c2 \u1f60\u03ba\u1f7a\u03c2 \u1f08\u03c7\u03b9\u03bb\u03bb\u03b5\u03cd\u03c2 (p\u00f3das \u014dk\u00fas Achille\u00fas \"quick-footed Achilles\").\n\nSome researchers deem the name a loan word, possibly from a Pre-Greek language. Achilles' descent from the Nereid Thetis and a similarity of his name with those of river deities such as Acheron and Achelous have led to speculations about his being an old water divinity (see below Worship). Robert S. P. Beekes has suggested a Pre-Greek origin of the name, based among other things on the coexistence of -\u03bb\u03bb- and -\u03bb- in epic language, which may account for a palatalized phoneme /ly/ in the original language.\n\nBirth and early years \n\nAchilles was the son of the Thetis, a nereid, and Peleus, the king of the Myrmidons. Zeus and Poseidon had been rivals for Thetis's hand in marriage until Prometheus, the fore-thinker, warned Zeus of a prophecy (originally uttered by Themis, goddess of divine law) that Thetis would bear a son greater than his father. For this reason, the two gods withdrew their pursuit, and had her wed Peleus.\n\nThere is a tale which offers an alternative version of these events: In the Argonautica (4.760) Zeus' sister and wife Hera alludes to Thetis' chaste resistance to the advances of Zeus, pointing out that Thetis was so loyal to Hera's marriage bond that she coolly rejected the father of gods. Thetis, although a daughter of the sea-god Nereus, was also brought up by Hera, further explaining her resistance to the advances of Zeus. Zeus was furious and decreed that she would never marry an immortal.\n\nAccording to the Achilleid, written by Statius in the 1st century AD, and to non-surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx; however, he was left vulnerable at the part of the body by which she held him: his left heel (see Achilles' heel, Achilles' tendon). It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire in order to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.\n\nNone of the sources before Statius make any reference to this general invulnerability. To the contrary, in the Iliad, Homer mentions Achilles being wounded: in Book 21 the Paeonian hero Asteropaeus, son of Pelagon, challenged Achilles by the river Scamander. He was ambidextrous, and cast a spear from each hand; one grazed Achilles' elbow, \"drawing a spurt of blood\".\n\nIn the few fragmentary poems of the Epic Cycle which describe the hero's death (i.e. the Cypria, the Little Iliad by Lesches of Pyrrha, the Aithiopis and Iliou persis by Arctinus of Miletus), there is no trace of any reference to his general invulnerability or his famous weakness at the heel. In the later vase paintings presenting the death of Achilles, the arrow (or in many cases, arrows) hit his torso.\n\nPeleus entrusted Achilles to Chiron the Centaur, who lived on Mount Pelion, to be reared. Thetis foretold that her son's fate was either to gain glory and die young, or to live a long but uneventful life in obscurity. Achilles chose the former, and decided to take part in the Trojan War. According to Homer, Achilles grew up in Phthia with his companion Patroclus.\n\nAccording to Photius, the sixth book of the New History by Ptolemy Hephaestion reported that Thetis burned in a secret place the children she had by Peleus. When she quarter ended 30 May. The realisation fell significantly had Achilles, Peleus noticed, tore him from the flames with only a burnt foot, and confided him to the centaur Chiron. Later Chiron exhumed the body of the Damysus, who was the fastest of all the giants, removed the ankle, and incorporated it into Achilles' burnt foot.\n\nOther names \nAmong the appellations under which Achilles is generally known are the following:\n Pyrisous, \"saved from the fire\", his first name, which seems to favour the tradition in which his mortal parts were burned by his mother Thetis\n Aeacides, from his grandfather Aeacus\n Aemonius, from Aemonia, a country which afterwards acquired the name of Thessaly\n Aspetos, \"inimitable\" or \"vast\", his name at Epirus\n Larissaeus, from Larissa (also called Cremaste), a town of Thessaly, which still bears the same name\n Ligyron, his original name\n Nereius, from his mother Thetis, one of the Nereids\n Pelides, from his father, Peleus\n Phthius, from his birthplace, Phthia\n Podarkes, \"swift-footed\", due to the wings of Arke being attached to his feet.\n\nHidden on Skyros \n\nSome post-Homeric sources claim that in order to keep Achilles safe from the war, Thetis (or, in some versions, Peleus) hid the young man at the court of Lycomedes, king of Skyros.\n\nThere, Achilles was disguised as a girl and lived among Lycomedes' daughters, perhaps under the name \"Pyrrha\" (the red-haired girl), Cercysera or Aissa (\"swift\"). With Lycomedes' daughter Deidamia, whom in the account of Statius he raped, Achilles there fathered two sons, Neoptolemus (also called Pyrrhus, after his father's possible alias) and Oneiros. According to this story, Odysseus learned from the prophet Calchas that the Achaeans would be unable to capture Troy without Achilles' aid. Odysseus went to Skyros in the guise of a peddler selling women's clothes and jewellery and placed a shield and spear among his goods. When Achilles instantly took up the spear, Odysseus saw through his disguise and convinced him to join the Greek campaign. In another version of the story, Odysseus arranged for a trumpet alarm to be sounded while he was with Lycomedes' women. While the women fled in panic, Achilles prepared to defend the court, thus giving his identity away.\n\nIn the Trojan War \n\nAccording to the Iliad, Achilles arrived at Troy with 50 ships, each carrying 50 Myrmidons. He appointed five leaders (each leader commanding 500 Myrmidons): Menesthius, Eudorus, Peisander, Phoenix and Alcimedon.\n\nTelephus \nWhen the Greeks left for the Trojan War, they accidentally stopped in Mysia, ruled by King Telephus. In the resulting battle, Achilles gave Telephus a wound that would not heal; Telephus consulted an oracle, who stated that \"he that wounded shall heal\". Guided by the oracle, he arrived at Argos, where Achilles healed him in order that he might become their guide for the voyage to Troy.\n\nAccording to other reports in Euripides' lost play about Telephus, he went to Aulis pretending to be a beggar and asked Achilles to heal his wound. Achilles refused, claiming to have no medical knowledge. Alternatively, Telephus held Orestes for ransom, the ransom being Achilles' aid in healing the wound. Odysseus reasoned that the spear had inflicted the wound; therefore, the spear must be able to heal it. Pieces of the spear were scraped off onto the wound and Telephus was healed.\n\nTroilus \n\nAccording to the Cypria (the part of the Epic Cycle that tells the events of the Trojan War before Achilles' wrath), when the Achaeans desired to return home, they were restrained by Achilles, who afterwards attacked the cattle of Aeneas, sacked neighbouring cities (like Pedasus and Lyrnessus, where the Greeks capture the queen Briseis) and killed Tenes, a son of Apollo, as well as Priam's son Troilus in the sanctuary of Apollo Thymbraios; however, the romance between Troilus and Chryseis described in Geoffrey Chaucer's Troilus and Criseyde and in William Shakespeare's Troilus and Cressida is a medieval invention.\n\nIn Dares Phrygius' Account of the Destruction of Troy, the Latin summary through which the story of Achilles was transmitted to medieval Europe, as well as in older accounts, Troilus was a young Trojan prince, the youngest of King Priam's and Hecuba's five legitimate sons (or according other sources, another son of Apollo). Despite his youth, he was one of the main Trojan war leaders, a \"horse fighter\" or \"chariot fighter\" according to Homer. Prophecies linked Troilus' fate to that of Troy and so he was ambushed in an attempt to capture him. Yet Achilles, struck by the beauty of both Troilus and his sister Polyxena, and overcome with lust, directed his sexual attentions on the youth\u00a0\u2013 who, refusing to yield, instead found himself decapitated upon an altar-omphalos of Apollo Thymbraios. Later versions of the story suggested Troilus was accidentally killed by Achilles in an over-ardent lovers' embrace. In this version of the myth, Achilles' death therefore came in retribution for this sacrilege. Ancient writers treated Troilus as the epitome of a dead child mourned by his parents. Had Troilus lived to adulthood, the First Vatican Mythographer claimed, Troy would have been invincible; however, the motif is older and found already in Plautus' Bacchides.\n\nIn the Iliad \n\nHomer's Iliad is the most famous narrative of Achilles' deeds in the Trojan War. Achilles' wrath (\u03bc\u1fc6\u03bd\u03b9\u03c2 \u1f08\u03c7\u03b9\u03bb\u03bb\u03ad\u03c9\u03c2, m\u00eanis Achill\u00e9\u014ds) is the central theme of the poem. The first two lines of the Iliad read:\n\nThe Homeric epic only covers a few weeks of the decade-long war, and does not narrate Achilles' death. It begins with Achilles' withdrawal from battle after being dishonoured by Agamemnon, the commander of the Achaean forces. Agamemnon has taken a woman named Chryseis as his slave. Her father Chryses, a priest of Apollo, begs Agamemnon to return her to him. Agamemnon refuses, and Apollo sends a plague amongst the Greeks. The prophet Calchas correctly determines the source of the troubles but will not speak unless Achilles vows to protect him. Achilles does so, and Calchas declares that Chryseis must be returned to her father. Agamemnon consents, but then commands that Achilles' battle prize Briseis, the daughter of Briseus, be brought to him to replace Chryseis. Angry at the dishonour of having his plunder and glory taken away (and, as he says later, because he loves Briseis), with the urging of his mother Thetis, Achilles refuses to fight or lead his troops alongside the other Greek forces. At the same time, burning with rage over Agamemnon's theft, Achilles prays to Thetis to convince Zeus to help the Trojans gain ground in the war, so that he may regain his honour.\n\nAs the battle turns against the Greeks, thanks to the influence of Zeus, Nestor declares that the Trojans are winning because Agamemnon has angered Achilles, and urges the king to appease the warrior. Agamemnon agrees and sends Odysseus and two other chieftains, Ajax and Phoenix. They promise that, if Achilles returns to battle, Agamemnon will return the captive Briseis and other gifts. Achilles rejects all Agamemnon offers him and simply urges the Greeks to sail home as he was planning to do.\n\nThe Trojans, led by Hector, subsequently push the Greek army back toward the beaches and assault the Greek ships. With the Greek forces on the verge of absolute destruction, Patroclus leads the Myrmidons into battle, wearing Achilles' armour, though Achilles remains at his camp. Patroclus succeeds in pushing the Trojans back from the beaches, but is killed by Hector before he can lead a proper assault on the city of Troy.\n\nAfter receiving the news of the death of Patroclus from Antilochus, the son of Nestor, Achilles grieves over his beloved companion's death. His mother Thetis comes to comfort the distraught Achilles. She persuades Hephaestus to make new armour for him, in place of the armour that Patroclus had been wearing, which was taken by Hector. The new armour includes the Shield of Achilles, described in great detail in the poem.\n\nEnraged over the death of Patroclus, Achilles ends his refusal to fight and takes the field, killing many men in his rage but always seeking out Hector. Achilles even engages in battle with the river god Scamander, who has become angry that Achilles is choking his waters with all the men he has killed. The god tries to drown Achilles but is stopped by Hera and Hephaestus. Zeus himself takes note of Achilles' rage and sends the gods to restrain him so that he will not go on to sack Troy itself before the time allotted for its destruction, seeming to show that the unhindered rage of Achilles can defy fate itself. Finally, Achilles finds his prey. Achilles chases Hector around the wall of Troy three times before Athena, in the form of Hector's favorite and dearest brother, Deiphobus, persuades Hector to stop running and fight Achilles face to face. After Hector realizes the trick, he knows the battle is inevitable. Wanting to go down fighting, he charges at Achilles with his only weapon, his sword, but misses. Accepting his fate, Hector begs Achilles not to spare his life, but to treat his body with respect after killing him. Achilles tells Hector it is hopeless to expect that of him, declaring that \"my rage, my fury would drive me now to hack your flesh away and eat you raw \u2013 such agonies you have caused me\". Achilles then kills Hector and drags his corpse by its heels behind his chariot. After having a dream where Patroclus begs Achilles to hold his funeral, Achilles hosts a series of funeral games in honour of his companion.\n\nAt the onset of his duel with Hector, Achilles is referred to as the brightest star in the sky, which comes on in the autumn, Orion's dog (Sirius); a sign of evil. During the cremation of Patroclus, he is compared to Hesperus, the evening/western star (Venus), while the burning of the funeral pyre lasts until Phosphorus, the morning/eastern star (also Venus) has set (descended).\n\nWith the assistance of the god Hermes (Argeiphontes), Hector's father Priam goes to Achilles' tent to plead with Achilles for the return of Hector's body so that he can be buried. Achilles relents and promises a truce for the duration of the funeral, lasting 9 days with a burial on the 10th (in the tradition of Niobe's offspring). The poem ends with a description of Hector's funeral, with the doom of Troy and Achilles himself still to come.\n\nLater epic accounts: fighting Penthesilea and Memnon \n\nThe Aethiopis (7th century BC) and a work named Posthomerica, composed by Quintus of Smyrna in the fourth century CE, relate further events from the Trojan War. When Penthesilea, queen of the Amazons and daughter of Ares, arrives in Troy, Priam hopes that she will defeat Achilles. After his temporary truce with Priam, Achilles fights and kills the warrior queen, only to grieve over her death later. At first, he was so distracted by her beauty, he did not fight as intensely as usual. Once he realized that his distraction was endangering his life, he refocused and killed her.\n\nFollowing the death of Patroclus, Nestor's son Antilochus becomes Achilles' closest companion. When Memnon, son of the Dawn Goddess Eos and king of Ethiopia, slays Antilochus, Achilles once more obtains revenge on the battlefield, killing Memnon. Consequently, Eos will not let the sun rise until Zeus persuades her. The fight between Achilles and Memnon over Antilochus echoes that of Achilles and Hector over Patroclus, except that Memnon (unlike Hector) was also the son of a goddess.\n\nMany Homeric scholars argued that episode inspired many details in the Iliads description of the death of Patroclus and Achilles' reaction to it. The episode then formed the basis of the cyclic epic Aethiopis, which was composed after the Iliad, possibly in the 7th century BC. The Aethiopis is now lost, except for scattered fragments quoted by later authors.\n\nAchilles and Patroclus \n\nThe exact nature of Achilles' relationship with Patroclus has been a subject of dispute in both the classical period and modern times. In the Iliad, it appears to be the model of a deep and loyal friendship. Homer does not suggest that Achilles and his close friend Patroclus had sexual relations. Although there is no direct evidence in the text of the Iliad that Achilles and Patroclus were lovers, this theory was expressed by some later authors. Commentators from classical antiquity to the present have often interpreted the relationship through the lens of their own cultures. In 5th-century BCE Athens, the intense bond was often viewed in light of the Greek custom of paiderasteia. In Plato's Symposium, the participants in a dialogue about love assume that Achilles and Patroclus were a couple; Phaedrus argues that Achilles was the younger and more beautiful one so he was the beloved and Patroclus was the lover. However, ancient Greek had no words to distinguish heterosexual and homosexual, and it was assumed that a man could both desire handsome young men and have sex with women. Many pairs of men throughout history have been compared to Achilles and Patroclus to imply a homosexual relationship.\n\nDeath \n\nThe death of Achilles, even if considered solely as it occurred in the oldest sources, is a complex one, with many different versions. In the oldest version, the Iliad, and as predicted by Hector with his dying breath, the hero's death was brought about by Paris with an arrow (to the heel", "flag": 1, "segments": [[1843, 1853]], "strength": 5.5}
{"text": "Abraham Lincoln (; February 12, 1809 \u2013 April 15, 1865) was an American lawyer and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the nation through the American Civil War and succeeded in preserving the Union, abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.\n\nLincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his law practice but became vexed by the opening of additional lands to slavery as a result of the Kansas\u2013Nebraska Act. He reentered politics in 1854, becoming a leader in the new Republican Party, and he reached a national audience in the 1858 debates against Stephen Douglas. Lincoln ran for President in 1860, sweeping the North in victory. Pro-slavery elements in the South equated his success with the North's rejection of their right to practice slavery, and southern states began seceding from the Union. To secure its independence, the new Confederate States fired on Fort Sumter, a U.S. fort in the South, and Lincoln called up forces to suppress the rebellion and restore the Union.\n\nLincoln, a moderate Republican, had to navigate a contentious array of factions with friends and opponents from both the Democratic and Republican parties. His allies, the War Democrats and the Radical Republicans, demanded harsh treatment of the Southern Confederates. Anti-war Democrats (called \"Copperheads\") despised Lincoln, and irreconcilable pro-Confederate elements plotted his assassination. He managed the factions by exploiting their mutual enmity, carefully distributing political patronage, and by appealing to the American people. His Gettysburg Address appealed to nationalistic, republican, egalitarian, libertarian, and democratic sentiments. Lincoln scrutinized the strategy and tactics in the war effort, including the selection of generals and the naval blockade of the South's trade. He suspended habeas corpus in Maryland, and he averted British intervention by defusing the Trent Affair. He engineered the end to slavery with his Emancipation Proclamation, including his order that the Army and Navy liberate, protect, and recruit former slaves. He also encouraged border states to outlaw slavery, and promoted the Thirteenth Amendment to the United States Constitution, which outlawed slavery across the country.\n\nLincoln managed his own successful re-election campaign. He sought to heal the war-torn nation through reconciliation. On April 14, 1865, just days after the war's end at Appomattox, he was attending a play at Ford's Theatre in Washington, D.C., with his wife Mary when he was fatally shot by Confederate sympathizer John Wilkes Booth. Lincoln is remembered as a martyr and hero of the United States and is often ranked as the greatest president in American history.\n\nFamily and childhood\n\nEarly life\n\nAbraham Lincoln was born on February 12, 1809, the second child of Thomas Lincoln and Nancy Hanks Lincoln, in a log cabin on Sinking Spring Farm near Hodgenville, Kentucky. He was a descendant of Samuel Lincoln, an Englishman who migrated from Hingham most employ people who tend not or don\u2019, Norfolk, to its namesake, Hingham, Massachusetts, in 1638. The family then migrated west, passing through New Jersey, Pennsylvania, and Virginia. Lincoln's paternal grandparents, his namesake Captain Abraham Lincoln and wife Bathsheba (n\u00e9e Herring) moved the family from Virginia to Jefferson County, Kentucky. The captain was killed in an Indian raid in 1786. His children, including eight-year-old Thomas, Abraham's father, witnessed the attack. Thomas then worked at odd jobs in Kentucky and Tennessee before the family settled in Hardin County, Kentucky, in the early 1800s.\n\nThe heritage of Lincoln's mother Nancy remains unclear, but it is widely assumed that she was the daughter of Lucy Hanks. Thomas and Nancy married on June 12, 1806, in Washington County, and moved to Elizabethtown, Kentucky. They had three children: Sarah, Abraham, and Thomas, who died as infant.\n\nThomas Lincoln bought or leased farms in Kentucky before losing all but  of his land in court disputes over property titles. In 1816, the family moved to Indiana where the land surveys and titles were more reliable. Indiana was a \"free\" (non-slaveholding) territory, and they settled in an \"unbroken forest\" in Hurricane Township, Perry County, Indiana. In 1860, Lincoln noted that the family's move to Indiana was \"partly on account of slavery\", but mainly due to land title difficulties.\n\nIn Kentucky and Indiana, Thomas worked as a farmer, cabinetmaker, and carpenter. At various times, he owned farms, livestock, and town lots, paid taxes, sat on juries, appraised estates, and served on county patrols. Thomas and Nancy were members of a Separate Baptists church, which forbade alcohol, dancing, and slavery.\n\nOvercoming financial challenges, Thomas in 1827 obtained clear title to  in Indiana, an area which became the Little Pigeon Creek Community.\n\nMother's death\nOn October 5, 1818, Nancy Lincoln succumbed to milk sickness, leaving 11-year-old Sarah in charge of a household including her father, 9-year-old Abraham, and Nancy's 19-year-old orphan cousin, Dennis Hanks. Ten years later, on January 20, 1828, Sarah died while giving birth to a stillborn son, devastating Lincoln.\n\nOn December 2, 1819, Thomas married Sarah Bush Johnston, a widow from Elizabethtown, Kentucky, with three children of her own. Abraham became close to his stepmother and called her \"Mother\". Lincoln disliked the hard labor associated with farm life. His family even said he was lazy, for all his \"reading, scribbling, writing, ciphering, writing Poetry, etc.\". His stepmother acknowledged he did not enjoy \"physical labor\", but loved to read.\n\nEducation and move to Illinois\nLincoln was largely self-educated. His formal schooling was from itinerant teachers. It included two short stints in Kentucky, where he learned to read but probably not to write, at age seven, and in Indiana, where he went to school sporadically due to farm chores, for a total of less than 12 months in aggregate by the age of 15. He persisted as an avid reader and retained a lifelong interest in learning. Family, neighbors, and schoolmates recalled that his reading included the King James Bible, Aesop's Fables, John Bunyan's The Pilgrim's Progress, Daniel Defoe's Robinson Crusoe, and The Autobiography of Benjamin Franklin.\n\nAs a teen, Lincoln took responsibility for chores and customarily gave his father all earnings from work outside the home until he was 21. Lincoln was tall, strong, and athletic, and became adept at using an ax. He was an active wrestler during his youth and trained in the rough catch-as-catch-can style (also known as catch wrestling). He became county wrestling champion at the age of 21. He gained a reputation for strength and audacity after winning a wrestling match with the renowned leader of ruffians known as \"the Clary's Grove Boys\".\n\nIn March 1830, fearing another milk sickness outbreak, several members of the extended Lincoln family, including Abraham, moved west to Illinois, a free state, and settled in Macon County. Abraham then became increasingly distant from Thomas, in part due to his father's lack of education. In 1831, as Thomas and other family prepared to move to a new homestead in Coles County, Illinois, Abraham struck out on his own. He made his home in New Salem, Illinois, for six years. Lincoln and some friends took goods by flatboat to New Orleans, Louisiana, where he was first exposed to slavery.\n\nIn 1865, Lincoln was asked how he came to acquire his rhetorical skills. He answered that in the practice of law he frequently came across the word \"demonstrate\" but had insufficient understanding of the term. So, he left Springfield for his father's home to study until he \"could give any proposition in the six books of Euclid [here, referencing Euclid's Elements] at sight.\"\n\nMarriage and children\n\nLincoln's first romantic interest was Ann Rutledge, whom he met when he moved to New Salem. By 1835, they were in a relationship but not formally engaged. She died on August 25, 1835, most likely of typhoid fever. In the early 1830s, he met Mary Owens from Kentucky.\n\nLate in 1836, Lincoln agreed to a match with Owens if she returned to New Salem. Owens arrived that November and he courted her for a time; however, they both had second thoughts. On August 16, 1837, he wrote Owens a letter saying he would not blame her if she ended the relationship, and she never replied.\n\nIn 1839, Lincoln met Mary Todd in Springfield, Illinois, and the following year they became engaged. She was the daughter of Robert Smith Todd, a wealthy lawyer and businessman in Lexington, Kentucky. A wedding set for January 1, 1841, was canceled at Lincoln's request, but they reconciled and married on November 4, 1842, in the Springfield mansion of Mary's sister. While anxiously preparing for the nuptials, he was asked where he was going and replied, \"To hell, I suppose.\" In 1844, the couple bought a house in Springfield near his law office. Mary kept house with the help of a hired servant and a relative.\n\nLincoln was an affectionate husband and father of four sons, though his work regularly kept him away from home. The oldest, Robert Todd Lincoln, was born in 1843 and was the only child to live to maturity. Edward Baker Lincoln (Eddie), born in 1846, died February 1, 1850, probably of tuberculosis. Lincoln's third son, \"Willie\" Lincoln was born on December 21, 1850, and died of a fever at the White House on February 20, 1862. The youngest, Thomas \"Tad\" Lincoln, was born on April 4, 1853, and survived his father but died of heart failure at age 18 on July 16, 1871. Lincoln \"was remarkably fond of children\" and the Lincolns were not considered to be strict with their own. In fact, Lincoln's law partner William H. Herndon would grow irritated when Lincoln would bring his children to the law office. Their father, it seemed, was often too absorbed in his work to notice his children's behavior. Herndon recounted, \"I have felt many and many a time that I wanted to wring their little necks, and yet out of respect for Lincoln I kept my mouth shut. Lincoln did not note what his children were doing or had done.\"\n\nThe deaths of their sons, Eddie and Willie, had profound effects on both parents. Lincoln suffered from \"melancholy\", a condition now thought to be clinical depression. Later in life, Mary struggled with the stresses of losing her husband and sons, and Robert committed her for a time to an asylum in 1875.\n\nEarly career and militia service\n\nIn 1832, Lincoln joined with a partner, Denton Offutt, in the purchase of a general store on credit in New Salem. Although the economy was booming, the business struggled and Lincoln eventually sold his share. That March he entered politics, running for the Illinois General Assembly, advocating navigational improvements on the Sangamon River. He could draw crowds as a raconteur, but he lacked the requisite formal education, powerful friends, and money, and lost the election.\n\nLincoln briefly interrupted his campaign to serve as a captain in the Illinois Militia during the Black Hawk War. In his first campaign speech after returning, he observed a supporter in the crowd under attack, grabbed the assailant by his \"neck and the seat of his trousers\", and tossed him. Lincoln finished eighth out of 13 candidates (the top four were elected), though he received 277 of the 300 votes cast in the New Salem precinct.\n\nLincoln served as New Salem's postmaster and later as county surveyor, but continued his voracious reading, and decided to become a lawyer. Rather than studying in the office of an established attorney, as was the custom, Lincoln borrowed legal texts from attorneys John Todd Stuart and Thomas Drummond, purchased books including Blackstone's Commentaries and Chitty's Pleadings, and read law on his own. He later said of his legal education that \"I studied with nobody.\"\n\nIllinois state legislature (1834\u20131842)\n\nLincoln's second state house campaign in 1834, this time as a Whig, was a success over a powerful Whig opponent. Then followed his four terms in the Illinois House of Representatives for Sangamon County. He championed construction of the Illinois and Michigan Canal, and later was a Canal Commissioner. He voted to expand suffrage beyond white landowners to all white males, but adopted a \"free soil\" stance opposing both slavery and abolition. In 1837, he declared, \"[The] Institution of slavery is founded on both injustice and bad policy, but the promulgation of abolition doctrines tends rather to increase than abate its evils.\" He echoed Henry Clay's support for the American Colonization Society which advocated a program of abolition in conjunction with settling freed slaves in Liberia.\n\nHe was admitted to the Illinois bar in 1836, and moved to Springfield and began to practice law under John T. Stuart, Mary Todd's cousin. Lincoln emerged as a formidable trial combatant during cross-examinations and closing arguments. He partnered several years with Stephen T. Logan, and in 1844 began his practice with William Herndon, \"a studious young man\".\n\nU.S. House of Representatives (1847\u20131849)\n\nTrue to his record, Lincoln professed to friends in 1861 to be \"an old line Whig, a disciple of Henry Clay\". Their party favored economic modernization in banking, tariffs to fund internal improvements including railroads, and urbanization.\n\nIn 1843, Lincoln sought the Whig nomination for Illinois' 7th district seat in the U.S. House of Representatives; he was defeated by John J. Hardin though he prevailed with the party in limiting Hardin to one term. Lincoln not only pulled off his strategy of gaining the nomination in 1846 but also won the election. He was the only Whig in the Illinois delegation, but as dutiful as any participated in almost all votes and made speeches that toed the party line. He was assigned to the Committee on Post Office and Post Roads and the Committee on Expenditures in the War Department. Lincoln teamed with Joshua R. Giddings on a bill to abolish slavery in the District of Columbia with compensation for the owners, enforcement to capture fugitive slaves, and a popular vote on the matter. He dropped the bill when it eluded Whig support.\n\nPolitical views \nOn foreign and military policy, Lincoln spoke against the Mexican\u2013American War, which he imputed to President James K. Polk's desire for \"military glory\u2014that attractive rainbow, that rises in showers of blood\". He supported the Wilmot Proviso, a failed proposal to ban slavery in any U.S. territory won from Mexico.\n\nLincoln emphasized his opposition to Polk by drafting and introducing his Spot Resolutions. The war had begun with a Mexican slaughter of American soldiers in territory disputed by Mexico, and Polk insisted that Mexican soldiers had \"invaded our territory and shed the blood of our fellow-citizens on our own soil\". Lincoln demanded that Polk show Congress the exact spot on which blood had been shed and prove that the spot was on American soil. The resolution was ignored in both Congress and the national papers, and it cost Lincoln political support in his district. One Illinois newspaper derisively nicknamed him \"spotty Lincoln\". Lincoln later regretted some of his statements, especially his attack on presidential war-making powers.\n\nLincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election. Taylor won and Lincoln hoped in vain to be appointed Commissioner of the General Land Office. The administration offered to appoint him secretary or governor of the Oregon Territory as consolation. This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.\n\nPrairie lawyer\n\nIn his Springfield practice, Lincoln handled \"every kind of business that could come before a prairie lawyer\". Twice a year he appeared for 10 consecutive weeks in county seats in the Midstate county courts; this continued for 16 years. Lincoln handled transportation cases in the midst of the nation's western expansion, particularly river barge conflicts under the many new railroad bridges. As a riverboat man, Lincoln initially favored those interests, but ultimately represented whoever hired him. He later represented a bridge company against a riverboat company in Hurd v. Rock Island Bridge Company, a landmark case involving a canal boat that sank after hitting a bridge. In 1849, he received a patent for a flotation device for the movement of boats in shallow water. The idea was never commercialized, but it made Lincoln the only president to hold a patent.\n\nLincoln appeared before the Illinois Supreme Court in 175 cases; he was sole counsel in 51 cases, of which 31 were decided in his favor. From 1853 to 1860, one of his largest clients was the Illinois Central Railroad. His legal reputation gave rise to the nickname \"Honest Abe\".\n\nLincoln argued in an 1858 criminal trial, defending William \"Duff\" Armstrong, who was on trial for the murder of James Preston Metzker. The case is famous for Lincoln's use of a fact established by judicial notice to challenge the credibility of an eyewitness. After an opposing witness testified to seeing the crime in the moonlight, Lincoln produced a Farmers' Almanac showing the moon was at a low angle, drastically reducing visibility. Armstrong was acquitted.\n\nLeading up to his presidential campaign, Lincoln elevated his profile in an 1859 murder case, with his defense of Simeon Quinn \"Peachy\" Harrison who was a third cousin; Harrison was also the grandson of Lincoln's political opponent, Rev. Peter Cartwright. Harrison was charged with the murder of Greek Crafton who, as he lay dying of his wounds, confessed to Cartwright that he had provoked Harrison. Lincoln angrily protested the judge's initial decision to exclude Cartwright's testimony about the confession as inadmissible hearsay. Lincoln argued that the testimony involved a dying declaration and was not subject to the hearsay rule. Instead of holding Lincoln in contempt of court as expected, the judge, a Democrat, reversed his ruling and admitted the testimony into evidence, resulting in Harrison's acquittal.\n\nRepublican politics (1854\u20131860)\n\nEmergence as Republican leader\n\nThe debate over the status of slavery in the territories failed to alleviate tensions between the slave-holding South and the free North, with the failure of the Compromise of 1850, a legislative package designed to address the issue. In his 1852 eulogy for Clay, Lincoln highlighted the latter's support for gradual emancipation and opposition to \"both extremes\" on the slavery issue. As the slavery debate in the Nebraska and Kansas territories became particularly acrimonious, Illinois Senator Stephen A. Douglas proposed popular sovereignty as a compromise; the measure would allow the electorate of each territory to decide the status of slavery. The legislation alarmed many Northerners, who sought to prevent the resulting spread of slavery, but Douglas's Kansas\u2013Nebraska Act narrowly passed Congress in May 1854.\n\nLincoln did not comment on the act until months later in his \"Peoria Speech\" in October 1854. Lincoln then declared his opposition to slavery which he repeated en route to the presidency. He said the Kansas Act had a \"declared indifference, but as I must think, a covert real zeal for the spread of slavery. I cannot but hate it. I hate it because of the monstrous injustice of slavery itself. I hate it because it deprives our republican example of its just influence in the world\u00a0...\" Lincoln's attacks on the Kansas\u2013Nebraska Act marked his return to political life.\n\nNationally, the Whigs were irreparably split by the Kansas\u2013Nebraska Act and other efforts to compromise on the slavery issue. Reflecting on the demise of his party, Lincoln wrote in 1855, \"I think I am a Whig, but others say there are no Whigs, and that I am an abolitionist...I do no more than oppose the extension of slavery.\" The new Republican Party was formed as a northern party dedicated to antislavery, drawing from the antislavery wing of the Whig Party, and combining Free Soil, Liberty, and antislavery Democratic Party members, Lincoln resisted early Republican entreaties, fearing that the new party would become a platform for extreme abolitionists. Lincoln held out hope for rejuvenating the Whigs, though he lamented his party's growing closeness with the nativist Know Nothing movement.\n\nIn 1854, Lincoln was elected to the Illinois legislature but declined to take his seat. The year's elections showed the strong opposition to the Kansas\u2013Nebraska Act, and in the aftermath, Lincoln sought election to the United States Senate. At that time, senators were elected by the state legislature. After leading in the first six rounds of voting, he was unable to obtain a majority. Lincoln instructed his backers to vote for Lyman Trumbull. Trumbull was an antislavery Democrat, and had received few votes in the earlier ballots; his supporters, also antislavery Democrats, had vowed not to support any Whig. Lincoln's decision to withdraw enabled his Whig supporters and Trumbull's antislavery Democrats to combine and defeat the mainstream Democratic candidate, Joel Aldrich Matteson.\n\n1856 campaign \nViolent political confrontations in Kansas continued, and opposition to the Kansas\u2013Nebraska Act remained strong throughout the North. As the 1856 elections approached, Lincoln joined the Republicans and attended the Bloomington Convention, which formally established the Illinois Republican Party. The convention platform endorsed Congress's right to regulate slavery in the territories and backed the admission of Kansas as a free state. Lincoln gave the final speech of the convention supporting the party platform and called for the preservation of the Union. At the June 1856 Republican National Convention, though Lincoln received support to run as vice president, John C. Fr\u00e9mont and William Dayton comprised the ticket, which Lincoln supported throughout Illinois. The Democrats nominated former Secretary of State James Buchanan and the Know-Nothings nominated former Whig President Millard Fillmore. Buchanan prevailed, while Republican William Henry Bissell won election as Governor of Illinois, and Lincoln became a leading Republican in Illinois.\n\nDred Scott v. Sandford \nDred Scott was a slave whose master took him from a slave state to a free territory under the Missouri Compromise. After Scott was returned to the slave state he petitioned a federal court for his freedom. His petition was denied in Dred Scott v. Sandford (1857). Supreme Court Chief Justice Roger B. Taney in the decision wrote that blacks were not citizens and derived no rights from the Constitution. While many Democrats hoped that Dred Scott would end the dispute over slavery in the territories, the decision sparked further outrage in the North. Lincoln denounced it as the product of a conspiracy of Democrats to support the Slave Power. He argued the decision was at variance with the Declaration of Independence; he said that while the founding fathers did not believe all men equal in every respect, they believed all men were equal \"in certain inalienable rights, among which are life, liberty, and the pursuit of happiness\".\n\nLincoln\u2013Douglas debates and Cooper Union speech\n\n", "flag": 1, "segments": [[686, 696]], "strength": 5.5}
{"text": "Aristotle (;  Aristot\u00e9l\u0113s, ; 384\u2013322\u00a0BC) was a Greek philosopher and polymath during the Classical period in Ancient Greece. Taught by Plato, he was the founder of the Lyceum, the Peripatetic school of philosophy, and the Aristotelian tradition. His writings cover many subjects including physics, biology, zoology, metaphysics, logic, ethics, aesthetics, poetry, theatre, music, rhetoric, psychology, linguistics, economics, politics, meteorology, geology and government. Aristotle provided a complex synthesis of the various philosophies existing prior to him. It was above all from his teachings that the West inherited its intellectual lexicon, as well as problems and methods of inquiry. As a result, his philosophy has exerted a unique influence on almost every form of knowledge in the West and it continues to be a subject of contemporary philosophical discussion.\n\nLittle is known about his life. Aristotle was born in the city of Stagira in Northern Greece. His father, Nicomachus, died when Aristotle was a child, and he was brought up by a guardian. At seventeen or eighteen years of age he joined Plato's Academy in Athens and remained there until the age of thirty-seven (c. 347 BC). Shortly after Plato died, Aristotle left Athens and, at the request of Philip II of Macedon, tutored Alexander the Great beginning in 343 BC. He established a library in the Lyceum which helped him to produce many of his hundreds of books on papyrus scrolls. Though Aristotle wrote many elegant treatises and dialogues for publication, only around a third of his original output has survived, none of it intended for publication.\n\nAristotle's views profoundly shaped medieval scholarship. The influence of physical science extended from Late Antiquity and the Early Middle Ages into the Renaissance, and were not replaced systematically until the Enlightenment and theories such as classical mechanics were developed. Some of Aristotle's zoological observations found in his biology, such as on the hectocotyl (reproductive) arm of the octopus, were disbelieved until the 19th century. He also influenced Judeo-Islamic philosophies (800\u20131400) during the Middle Ages, as well as Christian theology, especially the Neoplatonism of the Early Church and the scholastic tradition of the Catholic Church. Aristotle was revered among medieval Muslim scholars as \"The First Teacher\", and among medieval Christians like Thomas Aquinas as simply \"The Philosopher\", while the poet Dante called him \u201cthe master of those who know\". His works contain the earliest known formal study of logic, and were studied by medieval scholars such as Peter Abelard and John Buridan.\n\nAristotle's influence on logic continued well into the 19th century. In addition, his ethics, though always influential, gained renewed interest with the modern advent of virtue ethics.\n\nAristotle has been called \"the father of logic\", \"the father of biology\", \"the father of political science\", \"the father of zoology\", \"the father of embryology\", \"the father of natural law\", \"the father of scientific method\", \"the father of rhetoric\", \"the father of psychology\", \"the father of realism\", \"the father of criticism\", \"the father of individualism\", \"the father of teleology\", and \"the father of meteorology\".\n\nLife\n\nIn general, the details of Aristotle's life are not well-established. The biographies written in ancient times are often speculative and historians only agree on a few salient points.\n\nAristotle, whose name means \"the best purpose\" in Ancient Greek, was born in 384\u00a0BC in Stagira, Chalcidice, about 55\u00a0km (34 miles) east of modern-day Thessaloniki. His father, Nicomachus, was the personal physician to King Amyntas of Macedon. While he was young, Aristotle learned about biology and medical information, which was taught by his father. Both of Aristotle's parents died when he was about thirteen, and Proxenus of Atarneus became his guardian. Although little information about Aristotle's childhood has survived, he probably spent some time within the Macedonian palace, making his first connections with the Macedonian monarchy.\n\nAt the age of seventeen or eighteen, Aristotle moved to Athens to continue his education at Plato's Academy. He probably experienced the Eleusinian Mysteries as he wrote when describing the sights one viewed at the Eleusinian Mysteries, \"to experience is to learn\" [\u03c0\u03b1\u03b8\u03b5\u03af\u03bd \u03bc\u03b1\u03b8\u03b5\u0129\u03bd]. Aristotle remained in Athens for nearly twenty years before leaving in 348/47\u00a0BC. The traditional story about his departure records that he was disappointed with the academy's direction after control passed to Plato's nephew Speusippus, although it is possible that he feared the anti-Macedonian sentiments in Athens at that time and left before Plato died. Aristotle then accompanied Xenocrates to the court of his friend Hermias of Atarneus in Asia Minor. After the death of Hermias, Aristotle travelled with his pupil Theophrastus to the island of Lesbos, where together they researched the botany and zoology of the island and its sheltered lagoon. While in Lesbos, Aristotle married Pythias, either Hermias's adoptive daughter or niece. She bore him a daughter, whom they also named Pythias. In 343 BC, Aristotle was invited by Philip II of Macedon to become the tutor to his son Alexander.\n\nAristotle was appointed as the head of the royal academy of Macedon. During Aristotle's time in the Macedonian court, he gave lessons not only to Alexander but also to two other future kings: Ptolemy and Cassander. Aristotle encouraged Alexander toward eastern conquest, and Aristotle's own attitude towards Persia was unabashedly ethnocentric. In one famous example, he counsels Alexander to be \"a leader to the Greeks and a despot to the barbarians, to look after the former as after friends and relatives, and to deal with the latter as with beasts or plants\". By 335\u00a0BC, Aristotle had returned to Athens, establishing his own school there known as the Lyceum. Aristotle conducted courses at the school for the next twelve years. While in Athens, his wife Pythias died and Aristotle became involved with Herpyllis of Stagira, who bore him a son whom he named after his father, Nicomachus. If the Suda  an uncritical compilation from the Middle Ages  is accurate, he may also have had an er\u00f4menos, Palaephatus of Abydus.\n\nThis period in Athens, between 335 and 323 BC, is when Aristotle is believed to have composed many of his works. He wrote many dialogues, of which only fragments have survived. Those works that have survived are in treatise form and were not, for the most part, intended for widespread publication; they are generally thought to be lecture aids for his students. His most important treatises include Physics, Metaphysics, Nicomachean Ethics, Politics, On the Soul and Poetics. Aristotle studied and made significant contributions to \"logic, metaphysics, mathematics, physics, biology, botany, ethics, politics, agriculture, medicine, dance, and theatre.\"\n\nNear the end of his life, Alexander and Aristotle became estranged over Alexander's relationship with Persia and Persians. A widespread tradition in antiquity suspected Aristotle of playing a role in Alexander's death, but the only evidence of this is an unlikely claim made some six years after the death. Following Alexander's death, anti-Macedonian sentiment in Athens was rekindled. In 322\u00a0BC, Demophilus and Eurymedon the Hierophant reportedly denounced Aristotle for impiety, prompting him to flee to his mother's family estate in Chalcis, on Euboea, at which occasion he was said to have stated: \"I will not allow the Athenians to sin twice against philosophy\" \u2013 a reference to Athens's trial and execution of Socrates. He died on Euboea of natural causes later that same year, having named his student Antipater as his chief executor and leaving a will in which he asked to be buried next to his wife.\n\nSpeculative philosophy\n\nLogic\n\nWith the Prior Analytics, Aristotle is credited with the earliest study of formal logic, and his conception of it was the dominant form of Western logic until 19th-century advances in mathematical logic. Kant stated in the Critique of Pure Reason that with Aristotle logic reached its completion.\n\nOrganon\n\nWhat is today called Aristotelian logic with its types of syllogism (methods of logical argument), Aristotle himself would have labelled \"analytics\". The term \"logic\" he reserved to mean dialectics. Most of Aristotle's work is probably not in its original form, because it was most likely edited by students and later lecturers. The logical works of Aristotle were compiled into a set of six books called the Organon around 40 BC by Andronicus of Rhodes or others among his followers. The books are:\n Categories\n On Interpretation\n Prior Analytics\n Posterior Analytics\n Topics\n On Sophistical Refutations\n\nThe order of the books (or the teachings from which they are composed) is not certain, but this list was derived from analysis of Aristotle's writings. It goes from the basics, the analysis of simple terms in the Categories, the analysis of propositions and their elementary relations in On Interpretation, to the study of more complex forms, namely, syllogisms (in the Analytics) and dialectics (in the Topics and Sophistical Refutations). The first three treatises form the core of the logical theory stricto sensu: the grammar of the language of logic and the correct rules of reasoning. The Rhetoric is not conventionally included, but it states that it relies on the Topics.\n\nMetaphysics\n\nThe word \"metaphysics\" appears to have been coined by the first century AD editor who assembled various small selections of Aristotle's works to the treatise we know by the name Metaphysics. Aristotle called it \"first philosophy\", and distinguished it from mathematics and natural science (physics) as the contemplative (theoretik\u0113) philosophy which is \"theological\" and studies the divine. He wrote in his Metaphysics (1026a16):\n\nSubstance \n\nAristotle examines the concepts of substance (ousia) and essence (to ti \u00ean einai, \"the what it was to be\") in his Metaphysics (Book VII), and he concludes that a particular substance is a combination of both matter and form, a philosophical theory called hylomorphism. In Book VIII, he distinguishes the matter of the substance as the substratum, or the stuff of which it is composed. For example, the matter of a house is the bricks, stones, timbers, etc., or whatever constitutes the potential house, while the form of the substance is the actual house, namely 'covering for bodies and chattels' or any other differentia that let us define something as a house. The formula that gives the components is the account of the matter, and the formula that gives the differentia is the account of the form.\n\nImmanent realism \n\nLike his teacher Plato, Aristotle's philosophy aims at the universal. Aristotle's ontology places the universal (katholou) in particulars (kath' hekaston), things in the world, whereas for Plato the universal is a separately existing form which actual things imitate. For Aristotle, \"form\" is still what phenomena are based on, but is \"instantiated\" in a particular substance.\n\nPlato argued that all things have a universal form, which could be either a property or a relation to other things. When one looks at an apple, for example, one sees an apple, and one can also analyse a form of an apple. In this distinction, there is a particular apple and a universal form of an apple. Moreover, one can place an apple next to a book, so that one can speak of both the book and apple as being next to each other. Plato argued that there are some universal forms that are not a part of particular things. For example, it is possible that there is no particular good in existence, but \"good\" is still a proper universal form. Aristotle disagreed with Plato on this point, arguing that all universals are instantiated at some period of time, and that there are no universals that are unattached to existing things. In addition, Aristotle disagreed with Plato about the location of universals. Where Plato spoke of the world of forms, a place where all universal forms subsist, Aristotle maintained that universals exist within each thing on which each universal is predicated. So, according to Aristotle, the form of apple exists within each apple, rather than in the world of the forms.\n\nPotentiality and actuality \n\nWith regard to the change (kinesis) and its causes now, as he defines in his Physics and On Generation and Corruption 319b\u2013320a, he distinguishes the coming to be from:\n\n growth and diminution, which is change in quantity;\n locomotion, which is change in space; and\n alteration, which is change in quality.\n\nThe coming to be is a change where nothing persists of which the resultant is a property. In that particular change he introduces the concept of potentiality (dynamis) and actuality (entelecheia) in association with the matter and the form. Referring to potentiality, this is what a thing is capable of doing or being acted upon if the conditions are right and it is not prevented by something else. For example, the seed of a plant in the soil is potentially (dynamei) a plant, and if it is not prevented by something, it will become a plant. Potentially beings can either 'act' (poiein) or 'be acted upon' (paschein), which can be either innate or learned. For example, the eyes possess the potentiality of sight (innate \u2013 being acted upon), while the capability of playing the flute can be possessed by learning (exercise \u2013 acting). Actuality is the fulfilment of the end of the potentiality. Because the end (telos) is the principle of every change, and for the sake of the end exists potentiality, therefore actuality is the end. Referring then to the previous example, it can be said that an actuality is when a plant does one of the activities that plants do.\n\nIn summary, the matter used to make a house has potentiality to be a house and both the activity of building and the form of the final house are actualities, which is also a final cause or end. Then Aristotle proceeds and concludes that the actuality is prior to potentiality in formula, in time and in substantiality. With this definition of the particular substance (i.e., matter and form), Aristotle tries to solve the problem of the unity of the beings, for example, \"what is it that makes a man one\"? Since, according to Plato there are two Ideas: animal and biped, how then is man a unity? However, according to Aristotle, the potential being (matter) and the actual one (form) are one and the same.\n\nEpistemology\nAristotle's immanent realism means his epistemology is based on the study of things that exist or happen in the world, and rises to knowledge of the universal, whereas for Plato epistemology begins with knowledge of universal Forms (or ideas) and descends to knowledge of particular imitations of these. Aristotle uses induction from examples alongside deduction, whereas Plato relies on deduction from a priori principles.\n\nNatural philosophy\n\nAristotle's \"natural philosophy\" spans a wide range of natural phenomena including those now covered by physics, biology and other natural sciences. In Aristotle's terminology, \"natural philosophy\" is a branch of philosophy examining the phenomena of the natural world, and includes fields that would be regarded today as physics, biology and other natural sciences. Aristotle's work encompassed virtually all facets of intellectual inquiry. Aristotle makes philosophy in the broad sense coextensive with reasoning, which he also would describe as \"science\". However, his use of the term science carries a different meaning than that covered by the term \"scientific method\". For Aristotle, \"all science (dianoia) is either practical, poetical or theoretical\" (Metaphysics 1025b25). His practical science includes ethics and politics; his poetical science means the study of fine arts including poetry; his theoretical science covers physics, mathematics and metaphysics.\n\nPhysics\n\nFive elements\n\nIn his On Generation and Corruption, Aristotle related each of the four elements proposed earlier by Empedocles, Earth, Water, Air, and Fire, to two of the four sensible qualities, hot, cold, wet, and dry. In the Empedoclean scheme, all matter was made of the four elements, in differing proportions. Aristotle's scheme added the heavenly Aether, the divine substance of the heavenly spheres, stars and planets.\n\nMotion\n\nAristotle describes two kinds of motion: \"violent\" or \"unnatural motion\", such as that of a thrown stone, in the Physics (254b10), and \"natural motion\", such as of a falling object, in On the Heavens (300a20). In violent motion, as soon as the agent stops causing it, the motion stops also: in other words, the natural state of an object is to be at rest, since Aristotle does not address friction. With this understanding, it can be observed that, as Aristotle stated, heavy objects (on the ground, say) require more force to make them move; and objects pushed with greater force move faster. This would imply the equation\n\n,\n\nincorrect in modern physics.\n\nNatural motion depends on the element concerned: the aether naturally moves in a circle around the heavens, while the 4 Empedoclean elements move vertically up (like fire, as is observed) or down (like earth) towards their natural resting places.\n\nIn the Physics (215a25), Aristotle effectively states a quantitative law, that the speed, v, of a falling body is proportional (say, with constant c) to its weight, W, and inversely proportional to the density, \u03c1, of the fluid in which it is falling:\n\n \n\nAristotle implies that in a vacuum the speed of fall would become infinite, and concludes from this apparent absurdity that a vacuum opening of their New Edition: New Edition, a is not possible. Opinions have varied on whether Aristotle intended to state quantitative laws. Henri Carteron held the \"extreme view\" that Aristotle's concept of force was basically qualitative, but other authors reject this.\n\nArchimedes corrected Aristotle's theory that bodies move towards their natural resting places; metal boats can float if they displace enough water; floating depends in Archimedes' scheme on the mass and volume of the object, not, as Aristotle thought, its elementary composition.\n\nAristotle's writings on motion remained influential until the Early Modern period. John Philoponus (in the Middle Ages) and Galileo are said to have shown by experiment that Aristotle's claim that a heavier object falls faster than a lighter object is incorrect. A contrary opinion is given by Carlo Rovelli, who argues that Aristotle's physics of motion is correct within its domain of validity, that of objects in the Earth's gravitational field immersed in a fluid such as air. In this system, heavy bodies in steady fall indeed travel faster than light ones (whether friction is ignored, or not), and they do fall more slowly in a denser medium.\n\nNewton's \"forced\" motion corresponds to Aristotle's \"violent\" motion with its external agent, but Aristotle's assumption that the agent's effect stops immediately it stops acting (e.g., the ball leaves the thrower's hand) has awkward consequences: he has to suppose that surrounding fluid helps to push the ball along to make it continue to rise even though the hand is no longer acting on it, resulting in the Medieval theory of impetus.\n\nFour causes\n\nAristotle suggested that the reason for anything coming about can be attributed to four different types of simultaneously active factors. His term aitia is traditionally translated as \"cause\", but it does not always refer to temporal sequence; it might be better translated as \"explanation\", but the traditional rendering will be employed here.\n Material cause describes the material out of which something is composed. Thus the material cause of a table is wood. It is not about action. It does not mean that one domino knocks over another domino.\n The formal cause is its form, i.e., the arrangement of that matter. It tells one what a thing is, that a thing is determined by the definition, form, pattern, essence, whole, synthesis or archetype. It embraces the account of causes in terms of fundamental principles or general laws, as the whole (i.e., macrostructure) is the cause of its parts, a relationship known as the whole-part causation. Plainly put, the formal cause is the idea in the mind of the sculptor that brings the sculpture into being. A simple example of the formal cause is the mental image or idea that allows an artist, architect, or engineer to create a drawing.\n The efficient cause is \"the primary source\", or that from which the change under consideration proceeds. It identifies 'what makes of what is made and what causes change of what is changed' and so suggests all sorts of agents, non-living or living, acting as the sources of change or movement or rest. Representing the current understanding of causality as the relation of cause and effect, this covers the modern definitions of \"cause\" as either the agent or agency or particular events or states of affairs. In the case of two dominoes, when the first is knocked over it causes the second also to fall over. In the case of animals, this agency is a combination of how it develops from the egg, and how its body functions.\n The final cause (telos) is its purpose, the reason why a thing exists or is done, including both purposeful and instrumental actions and activities. The final cause is the purpose or function that something is supposed to serve. This covers modern ideas of motivating causes, such as volition. In the case of living things, it implies adaptation to a particular way of life.\n\nOptics\n\nAristotle describes experiments in optics using a camera obscura in Problems, book 15. The apparatus consisted of a dark chamber with a small aperture that let light in. With it, he saw that whatever shape he made the hole, the sun's image always remained circular. He also noted that increasing the distance between the aperture and the image surface magnified the image.\n\nChance and spontaneity\n\nAccording to Aristotle, spontaneity and chance are causes of some things, distinguishable from other types of cause such as simple necessity. Chance as an incidental cause lies in the realm of accidental things, \"from what is spontaneous\". There is also more a specific kind of chance, which Aristotle names \"luck\", that only applies to people's moral choices.\n\nAstronomy\n\nIn astronomy, Aristotle refuted Democritus's claim that the Milky Way was made up of \"those stars which are shaded by the earth from the sun's rays,\" pointing out correctly that if \"the size of the sun is greater than that of the earth and the distance of the stars from the earth many times greater than that of the sun, then... the sun shines on all the stars and the earth screens none of them.\"\n\nGeology/Natural Sciences\n\nAristotle was one of the first people to record any geological observations. He stated that geological change was too slow to be observed in one person's lifetime.\nThe geologist Charles Lyell noted that Aristotle described such change, including \"lakes that had", "flag": 1, "segments": [[3877, 3887]], "strength": 5.5}
{"text": "Algeria, officially the People's Democratic Republic of Algeria, is a country in the Maghreb region of North Africa. The country is the largest country by total area in Africa and in the Arab world, and is bordered to the northeast by Tunisia; to the east by Libya; to the southeast by Niger; to the southwest by Mali, Mauritania, and Western Sahara; to the west by Morocco; and to the north by the Mediterranean Sea. It has a semi-arid geography, with most of the population living in the fertile north and the Sahara dominating the geography of the south. Algeria covers an area of, making it the world's tenth largest nation by area, and the largest nation in Africa. With a population of 44 million, Algeria is the ninth-most populous country in Africa, and the 32nd-most populous country in the world. The capital and largest city is Algiers, located in the far north on the Mediterranean coast.\n\nPre-1962 Algeria has seen many empires and dynasties, including ancient Numidians, Phoenicians, Carthaginians, Romans, Vandals, Byzantines, Umayyads, Abbasids, Rustamids, Idrisids, Aghlabids, Fatimids, Zirids, Hammadids, Almoravids, Almohads, Zayyanids, Spaniards, Ottomans and finally, the French colonial empire. The vast majority of Algeria's population is Arab-Berber, practicing Islam, and using the official languages of Arabic and Berber. However, French serves as an administrative and educational language in some contexts. The main spoken language is Algerian Arabic.\n\nAlgeria is a semi-presidential republic, with local constituencies consisting of 58 provinces and 1,541 communes. Algeria is a regional power in North Africa, and a middle power in global affairs. It has the highest Human Development Index of all non-island African countries and one of the largest economies on the continent, based largely on energy exports. Algeria has the world's sixteenth-largest oil reserves and the ninth-largest reserves of natural gas. Sonatrach, the national oil company, is the largest company in Africa, supplying large amounts of natural gas to Europe. Algeria's military is one of the largest in Africa, and has the largest defence budget on the continent. It is a member of the African Union, the Arab League, the OIC, OPEC, the United Nations, and the Arab Maghreb Union, of which it is a founding member.\n\nName \nOther forms of the name are:, ; ; ; ;. It is officially the People's Democratic Republic of Algeria (;,, ;, abbreviated as RADP).\n\nEtymology\nThe country's name derives from the city of Algiers which in turn derives from the Arabic  (, \"The Islands\"), a truncated form of the older  (, \"Islands of the Mazghanna Tribe\"), employed by medieval geographers such as al-Idrisi.\n\nHistory\n\nPrehistory and ancient history\n\nAround ~1.8-million-year-old stone artifacts from Ain Hanech (Algeria) were considered to represent the oldest archaeological materials in North Africa. Stone artifacts and cut-marked bones that were excavated from two nearby deposits at Ain Boucherit are estimated to be ~1.9 million years old, and even older stone artifacts to be as old as ~2.4 million years. Hence, the Ain Boucherit evidence shows that ancestral hominins inhabited the Mediterranean fringe in northern Africa much earlier than previously thought. The evidence strongly argues for early dispersal of stone tool manufacture and use from East Africa or a possible multiple-origin scenario of stone technology in both East and North Africa.\n\nNeanderthal tool makers produced hand axes in the Levalloisian and Mousterian styles (43,000 BC) similar to those in the Levant. Algeria was the site of the highest state of development of Middle Paleolithic Flake tool techniques. Tools of this era, starting about 30,000 BC, are called Aterian (after the archaeological site of Bir el Ater, south of Tebessa).\n\nThe earliest blade industries in North Africa are called Iberomaurusian (located mainly in the Oran region). This industry appears to have spread throughout the coastal regions of the Maghreb between 15,000 and 10,000 BC. Neolithic civilization (animal domestication and agriculture) developed in the Saharan and Mediterranean Maghreb perhaps as early as 11,000 BC or as late as between 6000 and 2000 BC. This life, richly depicted in the Tassili n'Ajjer paintings, predominated in Algeria until the classical period. The mixture of peoples of North Africa coalesced eventually into a distinct native population that came to be called Berbers, who are the indigenous peoples of northern Africa.\n\nFrom their principal center of power at Carthage, the Carthaginians expanded and established small settlements along the North African coast; by 600 BC, a Phoenician presence existed at Tipasa, east of Cherchell, Hippo Regius (modern Annaba) and Rusicade (modern Skikda). These settlements served as market towns as well as anchorages.\n\nAs Carthaginian power grew, its impact on the indigenous population increased dramatically. Berber civilisation was already at a stage in which agriculture, manufacturing, trade, and political organisation supported several states. Trade links between Carthage and the Berbers in the interior grew, but territorial expansion also resulted in the enslavement or military recruitment of some Berbers and in the extraction of tribute from others.\n\nBy the early 4th century BC, Berbers formed the single largest element of the Carthaginian army. In the Revolt of the Mercenaries, Berber soldiers rebelled from 241 to 238 BC after being unpaid following the defeat of Carthage in the First Punic War. They succeeded in obtaining control of much of Carthage's North African territory, and they minted coins bearing the name Libyan, used in Greek to describe natives of North Africa. The Carthaginian state declined because of successive defeats by the Romans in the Punic Wars.\n\nIn 146 BC the city of Carthage was destroyed. As Carthaginian power waned, the influence of Berber leaders in the hinterland grew. By the 2nd century BC, several large but loosely administered Berber kingdoms had emerged. Two of them were established in Numidia, behind the coastal areas controlled by Carthage. West of Numidia lay Mauretania, which extended across the Moulouya River in modern-day Morocco to the Atlantic Ocean. The high point of Berber civilisation, unequalled until the coming of the Almohads and Almoravids more than a millennium later, was reached during the reign of Masinissa in the 2nd century BC.\n\nAfter Masinissa's death in 148 BC, the Berber kingdoms were divided and reunited several times. Masinissa's line survived until 24 AD, when the remaining Berber territory was annexed to the Roman Empire.\n\nFor several centuries Algeria was ruled by the Romans, who founded many colonies in the region. Like the rest of North Africa, Algeria was one of the breadbaskets of the empire, exporting cereals and other agricultural products. Saint Augustine was the bishop of Hippo Regius (modern-day Annaba, Algeria), located in the Roman province of Africa. The Germanic Vandals of Geiseric moved into North Africa in 429, and by 435 controlled coastal Numidia. They did not make any significant settlement on the land, as they were harassed by local tribes. In fact, by the time the Byzantines arrived Leptis Magna was abandoned and the Msellata region was occupied by the indigenous Laguatan who had been busy facilitating an Amazigh political, military and cultural revival. Furthermore, during the rule of the Romans, Byzantines, Vandals, Carthaginians, and Ottomans the Berber people were the only or one of the few in North Africa who remained independent. The Berber people were so resistant that even during the Muslim conquest of North Africa they still had control and possession over their mountains.\n\nThe collapse of the Western Roman Empire led to the establishment of a native Kingdom based in Altava (modern day Algeria) known as the Mauro-Roman Kingdom. It was succeeded by another Kingdom based in Altava, the Kingdom of Altava. During the reign of Kusaila its territory extended from the region of modern-day Fez in the west to the western Aur\u00e8s and later Kairaouan and the interior of Ifriqiya in the east.\n\nMiddle Ages\n\nAfter negligible resistance from the locals, Muslim Arabs of the Umayyad Caliphate conquered Algeria in the early 8th century.  Large numbers of the indigenous Berber people converted to Islam. Christians, Berber and Latin speakers remained in the great majority in Tunisia until the end of the 9th century and Muslims only became a vast majority some time in the 10th. After the fall of the Umayyad Caliphate, numerous local dynasties emerged, including the Rustamids, Aghlabids, Fatimids, Zirids, Hammadids, Almoravids, Almohads and the Abdalwadid. The Christians left in three waves: after the initial conquest, in the 10th century and the 11th. The last were evacuated to Sicily by the Normans and the few remaining died out in the 14th century.\n\nDuring the Middle Ages, North Africa was home to many great scholars, saints and sovereigns including Judah Ibn Quraysh, the first grammarian to mention Semitic and Berber languages, the great Sufi masters Sidi Boumediene (Abu Madyan) and Sidi El Houari, and the Emirs Abd Al Mu'min and Y\u0101ghm\u016brasen. It was during this time that the Fatimids or children of Fatima, daughter of Muhammad, came to the Maghreb. These \"Fatimids\" went on to found a long lasting dynasty stretching across the Maghreb, Hejaz and the Levant, boasting a secular inner government, as well as a powerful army and navy, made up primarily of Arabs and Levantines extending from Algeria to their capital state of Cairo. The Fatimid caliphate began to collapse when its governors the Zirids seceded. In order to punish them the Fatimids sent the Arab is a risk factor even though both meats have no Banu Hilal and Banu Sulaym against them. The resultant war is recounted in the epic T\u0101ghrib\u0101t. In Al-T\u0101ghr\u012bb\u0101t the Amazigh Zirid Hero Kh\u0101l\u012bf\u0101 Al-Z\u0101nat\u012b asks daily, for duels, to defeat the Hilalan hero \u0100bu Zayd al-Hilal\u012b and many other Arab knights in a string of victories. The Zirids, however, were ultimately defeated ushering in an adoption of Arab customs and culture. The indigenous Amazigh tribes, however, remained largely independent, and depending on tribe, location and time controlled varying parts of the Maghreb, at times unifying it (as under the Fatimids). The Fatimid Islamic state, also known as Fatimid Caliphate made an Islamic empire that included North Africa, Sicily, Palestine, Jordan, Lebanon, Syria, Egypt, the Red Sea coast of Africa, Tihamah, Hejaz and Yemen. Caliphates from Northern Africa traded with the other empires of their time, as well as forming part of a confederated support and trade network with other Islamic states during the Islamic Era.\n\nThe Amazighs historically consisted of several tribes. The two main branches were the Botr and Barn\u00e8s tribes, who were divided into tribes, and again into sub-tribes. Each region of the Maghreb contained several tribes (for example, Sanhadja, Houara, Zenata, Masmouda, Kutama, Awarba, and Berghwata). All these tribes made independent territorial decisions.\n\nSeveral Amazigh dynasties emerged during the Middle Ages in the Maghreb and other nearby lands. Ibn Khaldun provides a table summarising the Amazigh dynasties of the Maghreb region, the Zirid, Ifranid, Maghrawa, Almoravid, Hammadid, Almohad, Merinid, Abdalwadid, Wattasid, Meknassa and Hafsid dynasties. Both of the Hammadid and Zirid empires as well as the Fatimids established their rule in all of the Maghreb countries. The Zirids ruled land in what is now Algeria, Tunisia, Morocco, Libya, Spain, Malta and Italy. The Hammadids captured and held important regions such as Ouargla, Constantine, Sfax, Susa, Algiers, Tripoli and Fez establishing their rule in every country in the Maghreb region. The Fatimids which was created and established by the Kutama Berbers  conquered all of North Africa as well as Sicily and parts of the Middle East.\n\nA few examples of medieval Berber dynasties which originated in Modern Algeria \n Ifranid Dynasty\n Maghrawa Dynasty\n Zirid dynasty\n Hammadid dynasty\n Fatimid Caliphate \n Kingdom of Tlemcen\n\nFollowing the Berber revolt numerous independent states emerged across the Maghreb. In Algeria the Rustamid Kingdom was established. The Rustamid realm stretched from Tafilalt in Morocco to the Nafusa mountains in Libya including south, central and western Tunisia therefore including territory in all of the modern day Maghreb countries, in the south the Rustamid realm expanded to the modern borders of Mali and included territory in Mauritania.\n\nOnce extending their control over all of the Maghreb, part of Spain and briefly over Sicily, originating from modern Algeria, the Zirids only controlled modern Ifriqiya by the 11th century. The Zirids recognized nominal suzerainty of the Fatimid caliphs of Cairo. El Mu'izz the Zirid ruler decided to end this recognition and declared his independence. The Zirids also fought against other Zenata Kingdoms, for example the Maghrawa, a Berber dynasty originating from Algeria and which at one point was a dominant power in the Maghreb ruling over much of Morocco and western Algeria including Fez, Sijilmasa, Aghmat, Oujda, most of the Sous and Draa and reaching as far as M\u2019sila and the Zab in Algeria.\n\nAs the Fatimid state was at the time too weak to attempt a direct invasion, they found another means of revenge. Between the Nile and the Red Sea were living Bedouin nomad tribes expelled from Arabia for their disruption and turbulency. The Banu Hilal and the Banu Sulaym for example, who regularly disrupted farmers in the Nile Valley since the nomads would often loot their farms. The then Fatimid vizier decided to destroy what he couldn't control, and broke a deal with the chiefs of these Beduouin tribes. The Fatimids even gave them money to leave.\n\nWhole tribes set off with women, children, elders, animals and camping equipment. Some stopped on the way, especially in Cyrenaica, where they are still one of the essential elements of the settlement but most arrived in Ifriqiya by the Gabes region, arriving 1051. The Zirid ruler tried to stop this rising tide, but with each encounter, the last under the walls of Kairouan, his troops were defeated and the Arabs remained masters of the battlefield. They Arabs usually didn't take control over the cities, instead looting them and destroying them.\n\nThe invasion kept going, and in 1057 the Arabs spread on the high plains of Constantine where they encircled the Qalaa of Banu Hammad (capital of the Hammadid Emirate), as they had done in Kairouan a few decades ago. From there they gradually gained the upper Algiers and Oran plains. Some of these territories were forcibly taken back by the Almohads in the second half of the 12th century. The influx of Bedouin tribes was a major factor in the linguistic, cultural Arabization of the Maghreb and in the spread of nomadism in areas where agriculture had previously been dominant. Ibn Khaldun noted that the lands ravaged by Banu Hilal tribes had become completely arid desert.\n\nThe Almohads originating from modern day Morocco, although founded by a man originating from Algeria known as Abd al-Mu'min would soon take control over the Maghreb. During the time of the Almohad Dynasty Abd al-Mu'min's tribe, the Koum\u00efa, were the main supporters of the throne and the most important body of the empire. Defeating the weakening Almoravid Empire and taking control over Morocco in 1147, they pushed into Algeria in 1152, taking control over Tlemcen, Oran, and Algiers, wrestling control from the Hilian Arabs, and by the same year they defeated Hammadids who controlled Eastern Algeria.\n\nFollowing their decisive defeat in the Battle of Las Navas de Tolosa in 1212 the Almohads began collapsing, and in 1235 the governor of modern-day Western Algeria, Yaghmurasen Ibn Zyan declared his independence and established the Kingdom of Tlemcen and the Zayyanid dynasty. Warring with the Almohad forces attempting to restore control over Algeria for 13 years, they defeated the Almohads in 1248 after killing their Caliph in a successful ambush near Oujda. \n\nThe Zayyanids retained their control over Algeria for 3 centuries. Much of the eastern territories of Algeria were under the authority of the Hafsid dynasty, although the Emirate of Bejaia encompassing the Algerian territories of the Hafsids would occasionally be independent from central Tunisian control. At their peak the Zayyanid kingdom included all of Morocco as its vassal to the west and in the east reached as far as Tunis which they captured during the reign of Abu Tashfin.\n\nAfter several conflicts with local Barbary pirates sponsored by the Zayyanid sultans, Spain decided to invade Algeria and defeat the native Kingdom of Tlemcen. In 1505, they invaded and captured Mers el K\u00e9bir, and in 1509 after a bloody siege, they conquered Oran. Following their decisive victories over the Algerians in the western-coastal areas of Algeria, the Spanish decided to get bolder, and invaded more Algerian cities. In 1510, they led a series of sieges and attacks, taking over Bejaia in a large siege, and leading a semi-successful siege against Algiers. They also besieged Tlemcen. In 1511, they took control over Cherchell and Jijel, and attacked Mostaganem where although they weren't able to conquer the city, they were able to force a tribute on them.\n\nOttoman era \n\nIn 1516, the Ottoman privateer brothers Aruj and Hayreddin Barbarossa, who operated successfully under the Hafsids, moved their base of operations to Algiers. They succeeded in conquering Jijel and Algiers from the Spaniards with help from the locals who saw them as liberators from the Christians, but the brothers eventually assassinated the local noble Salim al-Tumi and took control over the city and the surrounding regions. When Aruj was killed in 1518 during his invasion of Tlemcen, Hayreddin succeeded him as military commander of Algiers. The Ottoman sultan gave him the title of beylerbey and a contingent of some 2,000 janissaries. With the aid of this force and native Algerians, Hayreddin conquered the whole area between Constantine and Oran (although the city of Oran remained in Spanish hands until 1792).\n\nThe next beylerbey was Hayreddin's son Hasan, who assumed the position in 1544. He was a Kouloughli or of mixed origins, as his mother was an Algerian Mooresse. Until 1587 Beylerbeylik of Algiers was governed by Beylerbeys who served terms with no fixed limits. Subsequently, with the institution of a regular administration, governors with the title of pasha ruled for three-year terms. The pasha was assisted by an autonomous janissary unit, known in Algeria as the Ojaq who were led by an agha. Discontent among the ojaq rose in the mid-1600s because they were not paid regularly, and they repeatedly revolted against the pasha. As a result, the agha charged the pasha with corruption and incompetence and seized power in 1659.\n\nPlague had repeatedly struck the cities of North Africa. Algiers lost from 30,000 to 50,000 inhabitants to the plague in 1620\u201321, and suffered high fatalities in 1654\u201357, 1665, 1691 and 1740\u201342.\n\nThe Barbary pirates preyed on Christian and other non-Islamic shipping in the western Mediterranean Sea. The pirates often took the passengers and crew on the ships and sold them or used them as slaves. They also did a brisk business in ransoming some of the captives. According to Robert Davis, from the 16th to 19th century, pirates captured 1 million to 1.25 million Europeans as slaves. They often made raids, called Razzias, on European coastal towns to capture Christian slaves to sell at slave markets in North Africa and other parts of the Ottoman Empire. In 1544, for example, Hayreddin Barbarossa captured the island of Ischia, taking 4,000 prisoners, and enslaved some 9,000 inhabitants of Lipari, almost the entire population. In 1551, the Ottoman governor of Algiers, Turgut Reis, enslaved the entire population of the Maltese island of Gozo. Barbary pirates often attacked the Balearic Islands. The threat was so severe that residents abandoned the island of Formentera. The introduction of broad-sail ships from the beginning of the 17th century allowed them to branch out into the Atlantic.\n\nIn July 1627 two pirate ships from Algiers under the command of Dutch pirate Jan Janszoon sailed as far as Iceland, raiding and capturing slaves. Two weeks earlier another pirate ship from Sal\u00e9 in Morocco had also raided in Iceland. Some of the slaves brought to Algiers were later ransomed back to Iceland, but some chose to stay in Algeria. In 1629, pirate ships from Algeria raided the Faroe Islands.\n\nIn 1671, the taifa of raises, or the company of corsair captains rebelled, killed the agha, and placed one of its own in power. The new leader received the title of Dey. After 1689, the right to select the dey passed to the divan, a council of some sixty nobles. It was at first dominated by the ojaq; but by the 18th century, it had become the dey's instrument. In 1710, the dey persuaded the sultan to recognise him and his successors as regent, replacing the pasha in that role. Although Algiers remained nominally part of the Ottoman Empire, in reality they acted independently from the rest of the Empire, and often had wars with other Ottoman subjects and territories such as the Beylik of Tunis.\n\nThe dey was in effect a constitutional autocrat. The dey was elected for a life term", "flag": 1, "segments": [[2199, 2209]], "strength": 5.5}
{"text": "Anthropology is the scientific study of humanity, concerned with human behavior, human biology, cultures, societies, and linguistics, in both the present and past, including past human species. Social anthropology studies patterns of behaviour, while cultural anthropology studies cultural meaning, including norms and values. A portmanteau sociocultural anthropology is commonly used today. Linguistic anthropology studies how language influences social life. Biological or physical anthropology studies the biological development of humans.\n\nArchaeological anthropology of engineers and you receive degrees at your very own, often termed as 'anthropology of the past', studies human activity through investigation of physical evidence. It is considered a branch of anthropology in North America and Asia, while in Europe archaeology is viewed as a discipline in its own right or grouped under other related disciplines, such as history.\n\nEtymology\nThe abstract noun anthropology is first attested in reference to history. Its present use first appeared in Renaissance Germany in the works of Magnus Hundt and Otto Casmann. Their New Latin  derived from the combining forms of the Greek words \u00e1nthr\u014dpos (, \"human\") and l\u00f3gos (, \"study\"). (Its adjectival form appeared in the works of Aristotle.) It began to be used in English, possibly via French, by the early 18th century.\n\nHistory\n\nThrough the 19th century\nIn 1647, the Bartholins, founders of the University of Copenhagen, defined  as follows:\n\nSporadic use of the term for some of the subject matter occurred subsequently, such as the use by \u00c9tienne Serres in 1839 to describe the natural history, or paleontology, of man, based on comparative anatomy, and the creation of a chair in anthropology and ethnography in 1850 at the French National Museum of Natural History by Jean Louis Armand de Quatrefages de Br\u00e9au. Various short-lived organizations of anthropologists had already been formed. The Soci\u00e9t\u00e9 Ethnologique de Paris, the first to use the term ethnology, was formed in 1839. Its members were primarily anti-slavery activists. When slavery was abolished in France in 1848, the Soci\u00e9t\u00e9 was abandoned.\n\nMeanwhile, the Ethnological Society of New York, currently the American Ethnological Society, was founded on its model in 1842, as well as the Ethnological Society of London in 1843, a break-away group of the Aborigines' Protection Society. These anthropologists of the times were liberal, anti-slavery, and pro-human-rights activists. They maintained international connections.\n\nAnthropology and many other current fields are the intellectual results of the comparative methods developed in the earlier 19th century. Theorists in such diverse fields as anatomy, linguistics, and ethnology, making feature-by-feature comparisons of their subject matters, were beginning to suspect that similarities between animals, languages, and folkways were the result of processes or laws unknown to them then. For them, the publication of Charles Darwin's On the Origin of Species was the epiphany of everything they had begun to suspect. Darwin himself arrived at his conclusions through comparison of species he had seen in agronomy and in the wild.\n\nDarwin and Wallace unveiled evolution in the late 1850s. There was an immediate rush to bring it into the social sciences. Paul Broca in Paris was in the process of breaking away from the Soci\u00e9t\u00e9 de biologie to form the first of the explicitly anthropological societies, the Soci\u00e9t\u00e9 d'Anthropologie de Paris, meeting for the first time in Paris in 1859. When he read Darwin, he became an immediate convert to Transformisme, as the French called evolutionism. His definition now became \"the study of the human group, considered as a whole, in its details, and in relation to the rest of nature\".\n\nBroca, being what today would be called a neurosurgeon, had taken an interest in the pathology of speech. He wanted to localize the difference between man and the other animals, which appeared to reside in speech. He discovered the speech center of the human brain, today called Broca's area after him. His interest was mainly in Biological anthropology, but a German philosopher specializing in psychology, Theodor Waitz, took up the theme of general and social anthropology in his six-volume work, entitled Die Anthropologie der Naturv\u00f6lker, 1859\u20131864. The title was soon translated as \"The Anthropology of Primitive Peoples\". The last two volumes were published posthumously.\n\nWaitz defined anthropology as \"the science of the nature of man\". Following Broca's lead, Waitz points out that anthropology is a new field, which would gather material from other fields, but would differ from them in the use of comparative anatomy, physiology, and psychology to differentiate man from \"the animals nearest to him\". He stresses that the data of comparison must be empirical, gathered by experimentation. The history of civilization, as well as ethnology, are to be brought into the comparison. It is to be presumed fundamentally that the species, man, is a unity, and that \"the same laws of thought are applicable to all men\".\n\nWaitz was influential among British ethnologists. In 1863, the explorer Richard Francis Burton and the speech therapist James Hunt broke away from the Ethnological Society of London to form the Anthropological Society of London, which henceforward would follow the path of the new anthropology rather than just ethnology. It was the 2nd society dedicated to general anthropology in existence. Representatives from the French Soci\u00e9t\u00e9 were present, though not Broca. In his keynote address, printed in the first volume of its new publication, The Anthropological Review, Hunt stressed the work of Waitz, adopting his definitions as a standard. Among the first associates were the young Edward Burnett Tylor, inventor of cultural anthropology, and his brother Alfred Tylor, a geologist. Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.\n\nSimilar organizations in other countries followed: The Anthropological Society of Madrid (1865), the American Anthropological Association in 1902, the Anthropological Society of Vienna (1870), the Italian Society of Anthropology and Ethnology (1871), and many others subsequently. The majority of these were evolutionists. One notable exception was the Berlin Society for Anthropology, Ethnology, and Prehistory (1869) founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists. Not religious himself, he insisted that Darwin's conclusions lacked empirical foundation.\n\nDuring the last three decades of the 19th century, a proliferation of anthropological societies and associations occurred, most independent, most publishing their own journals, and all international in membership and association. The major theorists belonged to these organizations. They supported the gradual osmosis of anthropology curricula into the major institutions of higher learning. By 1898, 48 educational institutions in 13 countries had some curriculum in anthropology. None of the 75 faculty members were under a department named anthropology.\n\n20th and 21st centuries\nThis meager statistic expanded in the 20th century to comprise anthropology departments in the majority of the world's higher educational institutions, many thousands in number. Anthropology has diversified from a few major subdivisions to dozens more. Practical anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene. The organization has reached a global level. For example, the World Council of Anthropological Associations (WCAA), \"a network of national, regional and international associations that aims to promote worldwide communication and cooperation in anthropology\", currently contains members from about three dozen nations.\n\nSince the work of Franz Boas and Bronis\u0142aw Malinowski in the late 19th and early 20th centuries, social anthropology in Great Britain and cultural anthropology in the US have been distinguished from other social sciences by their emphasis on cross-cultural comparisons, long-term in-depth examination of context, and the importance they place on participant-observation or experiential immersion in the area of research. Cultural anthropology, in particular, has emphasized cultural relativism, holism, and the use of findings to frame cultural critiques. This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism. Ethnography is one of its primary research designs as well as the text that is generated from anthropological fieldwork.\n\nIn Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate. In the United States, anthropology has traditionally been divided into the four field approach developed by Franz Boas in the early 20th century: biological or physical anthropology; social, cultural, or sociocultural anthropology; and archaeological anthropology; plus linguistic anthropology. These fields frequently overlap but tend to use different methodologies and techniques.\n\nEuropean countries with overseas colonies tended to practice more ethnology (a term coined and defined by Adam F. Koll\u00e1r in 1783). It is sometimes referred to as sociocultural anthropology in the parts of the world that were influenced by the European tradition.\n\nFields\n\nAnthropology is a global discipline involving humanities, social sciences and natural sciences. Anthropology builds upon knowledge from natural sciences, including the discoveries about the origin and evolution of Homo sapiens, human physical traits, human behavior, the variations among different groups of humans, how the evolutionary past of Homo sapiens has influenced its social organization and culture, and from social sciences, including the organization of human social and cultural relations, institutions, social conflicts, etc. Early anthropology originated in Classical Greece and Persia and studied and tried to understand observable cultural diversity, such as by Al-Biruni of the Islamic Golden Age. As such, anthropology has been central in the development of several new (late 20th century) interdisciplinary fields such as cognitive science, global studies, and various ethnic studies.\n\nAccording to Clifford Geertz,\n\nSociocultural anthropology has been heavily influenced by structuralist and postmodern theories, as well as a shift toward the analysis of modern societies. During the 1970s and 1990s, there was an epistemological shift away from the positivist traditions that had largely informed the discipline. During this shift, enduring questions about the nature and production of knowledge came to occupy a central place in cultural and social anthropology. In contrast, archaeology and biological anthropology remained largely positivist. Due to this difference in epistemology, the four sub-fields of anthropology have lacked cohesion over the last several decades.\n\nSociocultural\n\nSociocultural anthropology draws together the principle axes of cultural anthropology and social anthropology. Cultural anthropology is the comparative study of the manifold ways in which people make sense of the world around them, while social anthropology is the study of the relationships among individuals and groups. Cultural anthropology is more related to philosophy, literature and the arts (how one's culture affects the experience for self and group, contributing to a more complete understanding of the people's knowledge, customs, and institutions), while social anthropology is more related to sociology and history. In that, it helps develop an understanding of social structures, typically of others and other populations (such as minorities, subgroups, dissidents, etc.). There is no hard-and-fast distinction between them, and these categories overlap to a considerable degree.\n\nInquiry in sociocultural anthropology is guided in part by cultural relativism, the attempt to understand other societies in terms of their own cultural symbols and values. Accepting other cultures in their own terms moderates reductionism in cross-cultural comparison. This project is often accommodated in the field of ethnography. Ethnography can refer to both a methodology and the product of ethnographic research, i.e. an ethnographic monograph. As a methodology, ethnography is based upon long-term fieldwork within a community or other research site. Participant observation is one of the foundational methods of social and cultural anthropology. Ethnology involves the systematic comparison of different cultures. The process of participant-observation can be especially helpful to understanding a culture from an emic (conceptual, vs. etic, or technical) point of view.\n\nThe study of kinship and social organization is a central focus of sociocultural anthropology, as kinship is a human universal. Sociocultural anthropology also covers economic and political organization, law and conflict resolution, patterns of consumption and exchange, material culture, technology, infrastructure, gender relations, ethnicity, childrearing and socialization, religion, myth, symbols, values, etiquette, worldview, sports, music, nutrition, recreation, games, food, festivals, and language (which is also the object of study in linguistic anthropology).\n\nComparison across cultures is a key element of method in sociocultural anthropology, including the industrialized (and de-industrialized) West. The Standard Cross-Cultural Sample (SCCS) includes 186 such cultures.\n\nBiological\n\nBiological anthropology and physical anthropology are synonymous terms to describe anthropological research focused on the study of humans and non-human primates in their biological, evolutionary, and demographic dimensions. It examines the biological and social factors that have affected the evolution of humans and other primates, and that generate, maintain or change contemporary genetic and physiological variation.\n\nArchaeological\n\nArchaeology is the study of the human past through its material remains. Artifacts, faunal remains, and human altered landscapes are evidence of the cultural and material lives of past societies. Archaeologists examine material remains in order to deduce patterns of past human behavior and cultural practices. Ethnoarchaeology is a type of archaeology that studies the practices and material remains of living human groups in order to gain a better understanding of the evidence left behind by past human groups, who are presumed to have lived in similar ways.\n\nLinguistic\n\nLinguistic anthropology (not to be confused with anthropological linguistics) seeks to understand the processes of human communications, verbal and non-verbal, variation in language across time and space, the social uses of language, and the relationship between language and culture. It is the branch of anthropology that brings linguistic methods to bear on anthropological problems, linking the analysis of linguistic forms and processes to the interpretation of sociocultural processes. Linguistic anthropologists often draw on related fields including sociolinguistics, pragmatics, cognitive linguistics, semiotics, discourse analysis, and narrative analysis.\n\nEthnography \nEthnography is a method of analysing social or cultural interaction. It often involves participant observation though an ethnographer may also draw from texts written by participants of in social interactions. Ethnography views first-hand experience and social context as important.\n\nTim Ingold distinguishes ethnography from anthropology arguing that anthropology tries to construct general theories of human experience, applicable in general and novel settings, while ethnography concerns itself with fidelity. He argues that the anthropologist must make his writing consistent with their understanding of literature and other theory, but notes that ethnography may be of use to the anthropologists and the fields inform one another.\n\nKey topics by field: sociocultural\n\nArt, media, music, dance and film\n\nArt \n\nOne of the central problems in the anthropology of art concerns the universality of 'art' as a cultural phenomenon. Several anthropologists have noted that the Western categories of 'painting','sculpture', or 'literature', conceived as independent artistic activities, do not exist, or exist in a significantly different form, in most non-Western contexts. To surmount this difficulty, anthropologists of art have focused on formal features in objects which, without exclusively being 'artistic', have certain evident 'aesthetic' qualities. Boas' Primitive Art, Claude L\u00e9vi-Strauss' The Way of the Masks (1982) or Geertz's 'Art as Cultural System' (1983) are some examples in this trend to transform the anthropology of 'art' into an anthropology of culturally specific 'aesthetics'.\n\nMedia \n\nMedia anthropology (also known as the anthropology of media or mass media) emphasizes ethnographic studies as a means of understanding producers, audiences, and other cultural and social aspects of mass media. The types of ethnographic contexts explored range from contexts of media production (e.g., ethnographies of newsrooms in newspapers, journalists in the field, film production) to contexts of media reception, following audiences in their everyday responses to media. Other types include cyber anthropology, a relatively new area of internet research, as well as ethnographies of other areas of research which happen to involve media, such as development work, social movements, or health education. This is in addition to many classic ethnographic contexts, where media such as radio, the press, new media, and television have started to make their presences felt since the early 1990s.\n\nMusic \n\nEthnomusicology is an academic field encompassing various approaches to the study of music (broadly defined), that emphasize its cultural, social, material, cognitive, biological, and other dimensions or contexts instead of or in addition to its isolated sound component or any particular repertoire.\n\nEthnomusicology can be used in a wide variety of fields, such as teaching, politics, cultural anthropology etc.\u00a0 While the origins of ethnomusicology date back to the 18th and 19th centuries, it was formally introduced as \u201cethnomusicology\u201d by Dutch scholar Jaap Kunst around 1950. Later, the influence of study in this area spawned the creation of the periodical Ethnomusicology and the Society of Ethnomusicology.\n\nVisual \n\nVisual anthropology is concerned, in part, with the study and production of ethnographic photography, film and, since the mid-1990s, new media. While the term is sometimes used interchangeably with ethnographic film, visual anthropology also encompasses the anthropological study of visual representation, including areas such as performance, museums, art, and the production and reception of mass media. Visual representations from all cultures, such as sandpaintings, tattoos, sculptures and reliefs, cave paintings, scrimshaw, jewelry, hieroglyphics, paintings, and photographs are included in the focus of visual anthropology.\n\nEconomic, political economic, applied and development\n\nEconomic \n\nEconomic anthropology attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It has a complex relationship with the discipline of economics, of which it is highly critical. Its origins as a sub-field of anthropology begin with the Polish-British founder of anthropology, Bronis\u0142aw Malinowski, and his French compatriot, Marcel Mauss, on the nature of gift-giving exchange (or reciprocity) as an alternative to market exchange. Economic Anthropology remains, for the most part, focused upon exchange. The school of thought derived from Marx and known as Political Economy focuses on production, in contrast. Economic anthropologists have abandoned the primitivist niche they were relegated to by economists, and have now turned to examine corporations, banks, and the global financial system from an anthropological perspective.\n\nPolitical economy\n\nPolitical economy in anthropology is the application of the theories and methods of historical materialism to the traditional concerns of anthropology, including, but not limited to, non-capitalist societies. Political economy introduced questions of history and colonialism to ahistorical anthropological theories of social structure and culture. Three main areas of interest rapidly developed. The first of these areas was concerned with the \"pre-capitalist\" societies that were subject to evolutionary \"tribal\" stereotypes. Sahlin's work on hunter-gatherers as the \"original affluent society\" did much to dissipate that image. The second area was concerned with the vast majority of the world's population at the time, the peasantry, many of whom were involved in complex revolutionary wars such as in Vietnam. The third area was on colonialism, imperialism, and the creation of the capitalist world-system. More recently, these political economists have more directly addressed issues of industrial (and post-industrial) capitalism around the world.\n\nApplied \n\nApplied anthropology refers to the application of the method and theory of anthropology to the analysis and solution of practical problems. It is a \"complex of related, research-based, instrumental methods which produce change or stability in specific cultural systems through the provision of data, initiation of direct action, and/or the formulation of policy\". More simply, applied anthropology is the practical side of anthropological research; it includes researcher involvement and activism within the participating community. It is closely related to development anthropology (distinct from the more critical anthropology of development).\n\nDevelopment\n\nAnthropology of development tends to view development from a critical perspective. The kind of issues addressed and implications for the approach simply involve pondering why, if a key development goal is to alleviate poverty, is poverty increasing? Why is there such a gap between plans and outcomes? Why are those working in development so willing to disregard history and the lessons it might offer? Why is development so externally driven rather than having an internal basis? In short, why does so much planned development fail?\n\nKinship, feminism, gender and sexuality\n\nKinship \n\nKinship can refer both to the study of the patterns of social relationships in one or more human cultures, or it can refer to the patterns of social relationships themselves. Over its history, anthropology has developed a number of related concepts and terms, such as \"descent\", \"descent groups\", \"lineages\", \"affines\", \"cognates\", and even \"fictive kinship\". Broadly, kinship patterns may be considered to include people related both by descent (one's social relations during development), and also relatives by marriage. Within kinship you have two different families. People have their biological families and it is the people they share DNA with. This is called consanguineal relations or \"blood ties\". People can also have a chosen family Finding Connection Through \"Chosen Family\" in which they chose who they want to be a part of their family. In some cases people are closer with their chosen family more than with their biological families.\n\nFeminist \n\nFeminist anthropology is a four field approach to anthropology (archeological, biological, cultural, linguistic) that seeks to reduce male bias in research findings, anthropological hiring practices, and the scholarly production of knowledge. Anthropology engages often with feminists from non-Western traditions, whose perspectives and experiences can differ from those of white feminists of Europe, America, and elsewhere. From the perspective of the Western world, historically such 'peripheral' perspectives have been ignored, observed only from an outsider perspective, and regarded as less-valid or less-important than knowledge from the Western world. Exploring and addressing that double bias against women from marginalized racial or ethnic groups is of particular interest in intersectional feminist anthropology.\n\nFeminist anthropologists have stated that their publications have contributed to anthropology, along the way correcting against the systemic biases beginning with the \"patriarchal origins of anthropology (and (academia)\" and note that from 1891 to 1930 doctorates in anthropology went to males more than 85%, more than 81% were under 35, and only 7.2% to anyone over 40 years old, thus reflecting an age gap in the pursuit of anthropology by first-wave feminists until later in life. This correction of systemic bias may include mainstream feminist theory, history, linguistics, archaeology, and anthropology. Feminist anthropologists are often concerned with the construction of gender across societies. Gender constructs are of particular interest when studying sexism.\n\nAccording to St. Clair Drake, Vera Mae Green was, until \"[w]ell into the 1960s\", the only African-American female anthropologist who was also a Caribbeanist. She studied ethnic and family relations in the Caribbean as well as the United States,", "flag": 1, "segments": [[100, 110]], "strength": 5.5}
{"text": "Alchemy (from Arabic: al-k\u012bmiy\u0101; from Ancient Greek: khume\u00eda) is an ancient branch of natural philosophy, a philosophical and protoscientific tradition that was historically practiced in China, India, the Muslim world, and Europe. In its Western form, alchemy is first attested in a number of pseudepigraphical texts written in Greco-Roman Egypt during the first few centuries CE.\n\nAlchemists attempted to purify, mature, and perfect certain materials. Common aims were chrysopoeia, the transmutation of \"base metals\" (e.g., lead) into \"noble metals\" (particularly gold); the creation of an elixir of immortality; and the creation of panaceas able to cure any disease. The perfection of the human body and soul was thought to result from the alchemical magnum opus (\"Great Work\"). The concept of creating the philosophers' stone was variously connected with all of these projects.\n\nIslamic and European alchemists developed a basic set of laboratory techniques, theories, and terms, some of which are still in use today. They did not abandon the Ancient Greek philosophical idea that everything is composed of four elements, and they tended to guard their work in secrecy, often making use of cyphers and cryptic symbolism. In Europe, the 12th-century translations of medieval Islamic works on science and the rediscovery of Aristotelian philosophy gave birth to a flourishing tradition of Latin alchemy. This late medieval tradition of alchemy would go on to play a significant role in the development of early modern science (particularly chemistry and medicine).\n\nModern discussions of alchemy are generally split into an examination of its exoteric practical applications and its esoteric spiritual aspects, despite criticisms by scholars such as Eric J. Holmyard and Marie-Louise von Franz that they should be understood as complementary. The former is pursued by historians of the physical sciences, who examine the subject in terms of early chemistry, medicine, and charlatanism, and the philosophical and religious contexts in which these events occurred. The latter interests historians of esotericism, psychologists, and some philosophers and spiritualists. The subject has also made an ongoing impact on literature and the arts.\n\nEtymology \n\nThe word alchemy comes from Old French alquemie, alkimie, used in Medieval Latin as. This name was itself brought from the Arabic word al-k\u012bmiy\u0101 ( or ) composed of two parts: the Late Greek term kh\u0113me\u00eda (\u03c7\u03b7\u03bc\u03b5\u03af\u03b1), also spelled khumeia (\u03c7\u03c5\u03bc\u03b5\u03af\u03b1) and kh\u0113m\u00eda (\u03c7\u03b7\u03bc\u03af\u03b1) - see below, and the Arabic definite article al-  (), meaning 'The'. Together this association can be interpreted as 'the process of transmutation by which to fuse or reunite with the divine or original form'. Several etymologies have been proposed for the Greek term. The first was proposed by Zosimos of Panopolis (3rd\u20134th centuries), who derived it from the name of a book, the Khemeu. Hermanm Diels argued in 1914 that it rather derived from \u03c7\u03cd\u03bc\u03b1, used to describe metallic objects formed by casting.\n\nOthers trace its roots to the Egyptian name k\u0113me (hieroglyphic \ud80c\udd8e\ud80c\udd53\ud80c\udfcf\ud80c\ude96 khmi ), meaning 'black earth', which refers to the fertile and auriferous soil of the Nile valley, as opposed to red desert sand. According to the Egyptologist Wallis Budge, the Arabic word al-k\u012bmiya\u02be actually means \"the Egyptian [science]\", borrowing from the Coptic word for \"Egypt\", k\u0113me (or its equivalent in the Mediaeval Bohairic dialect of Coptic, kh\u0113me). This Coptic word derives from Demotic km\u1ec9, itself from ancient Egyptian kmt. The ancient Egyptian word referred to both the country and the colour \"black\" (Egypt was the \"Black Land\", by contrast with the \"Red Land\", the surrounding desert); so this etymology could also explain the nickname \"Egyptian black arts\".\n\nHistory \nAlchemy encompasses several philosophical traditions spanning some four millennia and three continents. These traditions' general penchant for cryptic and symbolic language makes it hard to trace their mutual influences and \"genetic\" relationships. One can distinguish at least three major strands, which appear to be mostly independent, at least in their earlier stages: Chinese alchemy, centered in China and Indian alchemy, centered on the Indian subcontinent; and Western alchemy, which occurred around the Mediterranean and whose center has shifted over the millennia from Greco-Roman Egypt to the Islamic world, and finally medieval Europe. Chinese alchemy was closely connected to Taoism and Indian alchemy with the Dharmic faiths. In contrast, Western alchemy developed its philosophical system mostly independent of but influenced by various Western religions. It is still an open question whether these three strands share a common origin, or to what extent they influenced each other.\n\nHellenistic Egypt \n\nThe start of Western alchemy may generally be traced to ancient and Hellenistic Egypt, where the city of Alexandria  was a center of alchemical knowledge, and retained its pre-eminence through most of the Greek and Roman periods. Following the work of Andr\u00e9-Jean Festugi\u00e8re, modern scholars see alchemical practice in the Roman Empire as originating from the Egyptian goldsmith's art, Greek philosophy and different religious traditions. Tracing the origins of the alchemical art in Egypt is complicated by the pseudepigraphic nature of texts from the Greek alchemical corpus. The treatises of Zosimos of Panopolis, the earliest historically attested author (fl. c. 300 CE), reiterating President Donald Trump's concerns that the new can help in situating the other authors. Zosimus based his work on that of older alchemical authors, such as Mary the Jewess, Pseudo-Democritus, and Agathodaimon, but very little is known about any of these authors. The most complete of their works, The Four Books of Pseudo-Democritus, were probably written in the first century AD.\n\nRecent scholarship tends to emphasize the testimony of Zosimus, who traced the alchemical arts back to Egyptian metallurgical and ceremonial practices. It has also been argued that early alchemical writers borrowed the vocabulary of Greek philosophical schools but did not implement any of its doctrines in a systematic way. Zosimos of Panopolis wrote in the Final Abstinence (also known as the \"Final Count\"). Zosimos explains that the ancient practice of \"tinctures\" (the technical Greek name for the alchemical arts) had been taken over by certain \"demons\" who taught the art only to those who offered them sacrifices. Since Zosimos also called the demons \"guardians of places\" (\u03bf\u1f31 \u03ba\u03b1\u03c4\u1f70 \u03c4\u03cc\u03c0\u03bf\u03bd \u1f14\u03c6\u03bf\u03c1\u03bf\u03b9) and those who offered them sacrifices \"priests\" (\u1f31\u03b5\u03c1\u03ad\u03b1), it is fairly clear that he was referring to the gods of Egypt and their priests. While critical of the kind of alchemy he associated with the Egyptian priests and their followers, Zosimos nonetheless saw the tradition's recent past as rooted in the rites of the Egyptian temples.\n\nMythology \u2013 Zosimos of Panopolis asserted that alchemy dated back to Pharaonic Egypt where it was the domain of the priestly class, though there is little to no evidence for his assertion. Alchemical writers used Classical figures from Greek, Roman, and Egyptian mythology to illuminate their works and allegorize alchemical transmutation. These included the pantheon of gods related to the Classical planets, Isis, Osiris, Jason, and many others.\n\nThe central figure in the mythology of alchemy is Hermes Trismegistus (or Thrice-Great Hermes). His name is derived from the god Thoth and his Greek counterpart Hermes. Hermes and his caduceus or serpent-staff, were among alchemy's principal symbols. According to Clement of Alexandria, he wrote what were called the \"forty-two books of Hermes\", covering all fields of knowledge. The Hermetica of Thrice-Great Hermes is generally understood to form the basis for Western alchemical philosophy and practice, called the hermetic philosophy by its early practitioners. These writings were collected in the first centuries of the common era.\n\nTechnology \u2013 The dawn of Western alchemy is sometimes associated with that of metallurgy, extending back to 3500\u00a0BC. Many writings were lost when the Roman emperor Diocletian ordered the burning of alchemical books after suppressing a revolt in Alexandria (AD\u00a0292). Few original Egyptian documents on alchemy have survived, most notable among them the Stockholm papyrus and the Leyden papyrus X. Dating from AD\u00a0250\u2013300, they contained recipes for dyeing and making artificial gemstones, cleaning and fabricating pearls, and manufacturing of imitation gold and silver. These writings lack the mystical, philosophical elements of alchemy, but do contain the works of Bolus of Mendes (or Pseudo-Democritus), which aligned these recipes with theoretical knowledge of astrology and the classical elements. Between the time of Bolus and Zosimos, the change took place that transformed this metallurgy into a Hermetic art.\n\nPhilosophy \u2013 Alexandria acted as a melting pot for philosophies of Pythagoreanism, Platonism, Stoicism and Gnosticism which formed the origin of alchemy's character. An important example of alchemy's roots in Greek philosophy, originated by Empedocles and developed by Aristotle, was that all things in the universe were formed from only four elements: earth, air, water, and fire. According to Aristotle, each element had a sphere to which it belonged and to which it would return if left undisturbed. The four elements of the Greek were mostly qualitative aspects of matter, not quantitative, as our modern elements are; \"...True alchemy never regarded earth, air, water, and fire as corporeal or chemical substances in the present-day sense of the word. The four elements are simply the primary, and most general, qualities by means of which the amorphous and purely quantitative substance of all bodies first reveals itself in differentiated form.\" Later alchemists extensively developed the mystical aspects of this concept.\n\nAlchemy coexisted alongside emerging Christianity. Lactantius believed Hermes Trismegistus had prophesied its birth. St\u00a0Augustine later affirmed this in the 4th & 5th centuries, but also condemned Trismegistus for idolatry. Examples of Pagan, Christian, and Jewish alchemists can be found during this period.\n\nMost of the Greco-Roman alchemists preceding Zosimos are known only by pseudonyms, such as Moses, Isis, Cleopatra, Democritus, and Ostanes. Others authors such as Komarios, and Chymes, we only know through fragments of text. After AD\u00a0400, Greek alchemical writers occupied themselves solely in commenting on the works of these predecessors. By the middle of the 7th century alchemy was almost an entirely mystical discipline. It was at that time that Khalid Ibn Yazid sparked its migration from Alexandria to the Islamic world, facilitating the translation and preservation of Greek alchemical texts in the 8th and 9th centuries.\n\nByzantium \n\nGreek alchemy is preserved in medieval Greek (Byzantine) manuscripts, and yet historians have only relatively recently begun to pay attention to the study and development of Greek alchemy in the Byzantine period.\n\nIndia \n\nThe 2nd millennium BC text Vedas describe a connection between eternal life and gold. A considerable knowledge of metallurgy has been exhibited in a third-century CE text called Arthashastra which provides ingredients of explosives (Agniyoga) and salts extracted from fertile soils and plant remains (Yavakshara) such as saltpetre/nitre, perfume making (different qualities of perfumes are mentioned), granulated (refined) Sugar. Buddhist texts from the 2nd to 5th centuries mention the transmutation of base metals to gold. According to some scholars Greek alchemy may have influenced Indian alchemy but there are no hard evidences to back this claim.\n\nThe 11th-century Persian chemist and physician Ab\u016b Rayh\u0101n B\u012br\u016bn\u012b, who visited Gujarat as part of the court of Mahmud of Ghazni, reported that they\n\nThe goals of alchemy in India included the creation of a divine body (Sanskrit divya-deham) and immortality while still embodied (Sanskrit j\u012bvan-mukti).  Sanskrit alchemical texts include much material on the manipulation of mercury and sulphur, that are homologized with the semen of the god \u015aiva and the menstrual blood of the goddess Dev\u012b.\n\nSome early alchemical writings seem to have their origins in the Kaula tantric schools associated to the teachings of the personality of Matsyendranath.  Other early writings are found in the Jaina medical treatise Kaly\u0101\u1e47ak\u0101rakam of Ugr\u0101ditya, written in South India in the early 9th century.\n\nTwo famous early Indian alchemical authors were N\u0101g\u0101rjuna Siddha and Nityan\u0101tha Siddha. N\u0101g\u0101rjuna Siddha was a Buddhist monk. His book, Rasendramangalam, is an example of Indian alchemy and medicine. Nityan\u0101tha Siddha wrote Rasaratn\u0101kara, also a highly influential work. In Sanskrit, rasa translates to \"mercury\", and N\u0101g\u0101rjuna Siddha was said to have developed a method of converting mercury into gold.\n\nScholarship on Indian alchemy is in the publication of The Alchemical Body by David Gordon White. \nA modern bibliography on Indian alchemical studies has been written by White.\n\nThe contents of 39 Sanskrit alchemical treatises have been analysed in detail in G. Jan Meulenbeld's History of Indian Medical Literature. The discussion of these works in HIML gives a summary of the contents of each work, their special features, and where possible the evidence concerning their dating. Chapter 13 of HIML, Various works on rasa\u015b\u0101stra and ratna\u015b\u0101stra (or Various works on alchemy and gems) gives brief details of a further 655 (six hundred and fifty-five) treatises.  In some cases Meulenbeld gives notes on the contents and authorship of these works; in other cases references are made only to the unpublished manuscripts of these titles.\n\nA great deal remains to be discovered about Indian alchemical literature.  The content of the Sanskrit alchemical corpus has not yet (2014) been adequately integrated into the wider general history of alchemy.\n\nIslamic world \n\nAfter the Fall of the Roman Empire, the focus of alchemical development moved to the Islamic World. Much more is known about Islamic alchemy because it was better documented: indeed, most of the earlier writings that have come down through the years were preserved as Arabic translations. The word alchemy itself was derived from the Arabic word al-k\u012bmiy\u0101 (\u0627\u0644\u0643\u064a\u0645\u064a\u0627\u0621). The early Islamic world was a melting pot for alchemy. Platonic and Aristotelian thought, which had already been somewhat appropriated into hermetical science, continued to be assimilated during the late 7th and early 8th centuries through Syriac translations and scholarship.\n\nIn the late ninth and early tenth centuries, the Arabic works attributed to J\u0101bir ibn Hayy\u0101n (Latinized as \"Geber\" or \"Geberus\") introduced a new approach to alchemy. Paul Kraus, who wrote the standard reference work on Jabir, put it as follows:\n\nIslamic philosophers also made great contributions to alchemical hermeticism. The most influential author in this regard was arguably Jabir. Jabir's ultimate goal was Takwin, the artificial creation of life in the alchemical laboratory, up to, and including, human life. He analyzed each Aristotelian element in terms of four basic qualities of hotness, coldness, dryness, and moistness. According to Jabir, in each metal two of these qualities were interior and two were exterior. For example, lead was externally cold and dry, while gold was hot and moist. Thus, Jabir theorized, by rearranging the qualities of one metal, a different metal would result. By this reasoning, the search for the philosopher's stone was introduced to Western alchemy. Jabir developed an elaborate numerology whereby the root letters of a substance's name in Arabic, when treated with various transformations, held correspondences to the element's physical properties.\n\nThe elemental system used in medieval alchemy also originated with Jabir. His original system consisted of seven elements, which included the five classical elements (aether, air, earth, fire, and water) in addition to two chemical elements representing the metals: sulphur, \"the stone which burns\", which characterized the principle of combustibility, and mercury, which contained the idealized principle of metallic properties. Shortly thereafter, this evolved into eight elements, with the Arabic concept of the three metallic principles: sulphur giving flammability or combustion, mercury giving volatility and stability, and salt giving solidity. The atomic theory of corpuscularianism, where all physical bodies possess an inner and outer layer of minute particles or corpuscles, also has its origins in the work of Jabir.\n\nFrom the 9th to 14th centuries, alchemical theories faced criticism from a variety of practical Muslim chemists, including Alkindus, Ab\u016b al-Rayh\u0101n al-B\u012br\u016bn\u012b, Avicenna and Ibn Khaldun. In particular, they wrote refutations against the idea of the transmutation of metals.\n\nEast Asia \n\nWhereas European alchemy eventually centered on the transmutation of base metals into noble metals, Chinese alchemy had a more obvious connection to medicine. The philosopher's stone of European alchemists can be compared to the Grand Elixir of Immortality sought by Chinese alchemists. In the hermetic view, these two goals were not unconnected, and the philosopher's stone was often equated with the universal panacea; therefore, the two traditions may have had more in common than initially appears.\n\nBlack powder may have been an important invention of Chinese alchemists. As previously stated above, Chinese alchemy was more related to medicine. It is said that the Chinese invented gunpowder while trying to find a potion for eternal life. Described in 9th-century texts and used in fireworks in China by the 10th century, it was used in cannons by 1290. From China, the use of gunpowder spread to Japan, the Mongols, the Muslim world, and Europe. Gunpowder was used by the Mongols against the Hungarians in 1241, and in Europe by the 14th century.\n\nChinese alchemy was closely connected to Taoist forms of traditional Chinese medicine, such as Acupuncture and Moxibustion. In the early Song dynasty, followers of this Taoist idea (chiefly the elite and upper class) would ingest mercuric sulfide, which, though tolerable in low levels, led many to suicide. Thinking that this consequential death would lead to freedom and access to the Taoist heavens, the ensuing deaths encouraged people to eschew this method of alchemy in favor of external sources (the aforementioned Tai Chi Chuan, mastering of the qi, etc.)  Chinese alchemy was introduced to the West by Obed Simon Johnson.\n\nMedieval Europe \n\nThe introduction of alchemy to Latin Europe may be dated to 11 February 1144, with the completion of Robert of Chester's translation of the Arabic Book of the Composition of Alchemy. Although European craftsmen and technicians pre-existed, Robert notes in his preface that alchemy (though here still referring to the elixir rather than to the art itself) was unknown in Latin Europe at the time of his writing. The translation of Arabic texts concerning numerous disciplines including alchemy flourished in 12th-century Toledo, Spain, through contributors like Gerard of Cremona and Adelard of Bath. Translations of the time included the Turba Philosophorum, and the works of Avicenna and Muhammad ibn Zakariya al-Razi. These brought with them many new words to the European vocabulary for which there was no previous Latin equivalent. Alcohol, carboy, elixir, and athanor are examples.\n\nMeanwhile, theologian contemporaries of the translators made strides towards the reconciliation of faith and experimental rationalism, thereby priming Europe for the influx of alchemical thought. The 11th-century St\u00a0Anselm put forth the opinion that faith and rationalism were compatible and encouraged rationalism in a Christian context. In the early 12th century, Peter Abelard followed Anselm's work, laying down the foundation for acceptance of Aristotelian thought before the first works of Aristotle had reached the West. In the early 13th century, Robert Grosseteste used Abelard's methods of analysis and added the use of observation, experimentation, and conclusions when conducting scientific investigations. Grosseteste also did much work to reconcile Platonic and Aristotelian thinking.\n\nThrough much of the 12th and 13th centuries, alchemical knowledge in Europe remained centered on translations, and new Latin contributions were not made. The efforts of the translators were succeeded by that of the encyclopaedists. In the 13th century, Albertus Magnus and Roger Bacon were the most notable of these, their work summarizing and explaining the newly imported alchemical knowledge in Aristotelian terms. Albertus Magnus, a Dominican friar, is known to have written works such as the Book of Minerals where he observed and commented on the operations and theories of alchemical authorities like Hermes and Democritus and unnamed alchemists of his time. Albertus critically compared these to the writings of Aristotle and Avicenna, where they concerned the transmutation of metals. From the time shortly after his death through to the 15th century, more than 28 alchemical tracts were misattributed to him, a common practice giving rise to his reputation as an accomplished alchemist. Likewise, alchemical texts have been attributed to Albert's student Thomas Aquinas.\n\nRoger Bacon, a Franciscan friar who wrote on a wide variety of topics including optics, comparative linguistics, and medicine, composed his Great Work () for  as part of a project towards rebuilding the medieval university curriculum to include the new learning of his time. While alchemy was not more important to him than other sciences and he did not produce allegorical works on the topic, he did consider it and astrology to be important parts of both natural philosophy and theology and his contributions advanced alchemy's connections to soteriology and Christian theology. Bacon's writings integrated morality, salvation, alchemy, and the prolongation of life. His correspondence with Clement highlighted this, noting the importance of alchemy to the papacy. Like the Greeks before him, Bacon acknowledged the division of alchemy into practical and theoretical spheres. He noted that the theoretical lay outside the scope of Aristotle, the natural philosophers, and all Latin writers of his time. The practical confirmed the theoretical, and Bacon advocated its uses in natural science and medicine. In later European legend, he became an archmage. In particular, along with Albertus Magnus, he was credited with the forging of a brazen head capable of answering its owner's questions.\n\nSoon after Bacon, the influential work of Pseudo-Geber (sometimes identified as Paul of Taranto) appeared. His Summa Perfectionis", "flag": 1, "segments": [[1218, 1228]], "strength": 5.5}
{"text": "Apollo is one of the  Olympian deities in classical Greek and Roman religion and Greek and Roman mythology. The national divinity of the Greeks, Apollo has been recognized as a god of archery, music and dance, truth and prophecy, healing and diseases, the Sun and light, poetry, and more. One of the most important and complex of the Greek gods, he is the son of Zeus and Leto, and the twin brother of Artemis, goddess of the hunt. Seen as the most beautiful god and the ideal of the kouros (ephebe, or a beardless, athletic youth), Apollo is considered to be the most Greek of all the gods. Apollo is known in Greek-influenced Etruscan mythology as Apulu.\n\nAs the patron deity of Delphi (Apollo Pythios), Apollo is an oracular god\u2014the prophetic deity of the Delphic Oracle. Apollo is the god who affords help and wards off evil; various epithets call him the \"averter of evil\". Delphic Apollo is the patron of seafarers, foreigners and the protector of fugitives and refugees.\n\nMedicine and healing are associated with Apollo, whether through the god himself or mediated through his son Asclepius. Apollo delivered people from epidemics, yet he is also a god who could bring ill-health and deadly plague with his arrows. The invention of archery itself is credited to Apollo and his sister Artemis. Apollo is usually described as carrying a golden bow and a quiver of silver arrows. Apollo's capacity to make youths grow is one of the best attested facets of his panhellenic cult persona. As the protector of young (kourotrophos), Apollo is concerned with the health and education of children. He presided over their passage into adulthood. Long hair, which was the prerogative of boys, was cut at the coming of age (ephebeia) and dedicated to Apollo.\n\nApollo is an important pastoral deity, and was the patron of herdsmen and shepherds. Protection of herds, flocks and crops from diseases, pests and predators were his primary duties. On the other hand, Apollo also encouraged founding new towns and establishment of civil constitution. He is associated with dominion over colonists. He was the giver of laws, and his oracles were consulted before setting laws in a city.\n\nAs the god of mousike, Apollo presides over all music, songs, dance and poetry. He is the inventor of string-music, and the frequent companion of the Muses, functioning as their chorus leader in celebrations. The lyre is a common attribute of Apollo. In Hellenistic times, especially during the 5th century BCE, as Apollo Helios he became identified among Greeks with Helios, the personification of the sun. In Latin texts, however, there was no conflation of Apollo with Sol among the classical Latin poets until 1st century CE. Apollo and Helios/Sol remained separate beings in literary and mythological texts until the 5th century CE.\n\nEtymology\n\nApollo (Attic, Ionic, and Homeric Greek:, Apoll\u014dn ( ); Doric:, Apell\u014dn; Arcadocypriot:, Apeil\u014dn; Aeolic:, Aploun; )\n\nThe name Apollo\u2014unlike the related older name Paean\u2014is generally not found in the Linear B (Mycenean Greek) texts, although there is a possible attestation in the lacunose form ]pe-rjo-[ (Linear B: ]-[) on the KN E 842 tablet, though it has also been suggested that the name might actually read \"Hyperion\" ([u]-pe-rjo-[ne]).\n\nThe etymology of the name is uncertain. The spelling  ( in Classical Attic) had almost superseded all other forms by the beginning of the common era, but the Doric form, Apellon (), is more archaic, as it is derived from an earlier. It probably is a cognate to the Doric month Apellaios (), and the offerings apellaia () at the initiation of the young men during the family-festival apellai (). According to some scholars, the words are derived from the Doric word apella (), which originally meant \"wall,\" \"fence for animals\" and later \"assembly within the limits of the square.\" Apella () is the name of the popular assembly in Sparta, corresponding to the ecclesia (). R. S. P. Beekes rejected the connection of the theonym with the noun apellai and suggested a Pre-Greek proto-form *Apalyun.\n\nSeveral instances of popular etymology are attested from ancient authors. Thus, the Greeks most often associated Apollo's name with the Greek verb  (apollymi), \"to destroy\". Plato in Cratylus connects the name with  (apolysis), \"redemption\", with  (apolousis), \"purification\", and with  ([h]aploun), \"simple\", in particular in reference to the Thessalian form of the name,, and finally with  (aeiballon), \"ever-shooting\". Hesychius connects the name Apollo with the Doric  (apella), which means \"assembly\", so that Apollo would be the god of political life, and he also gives the explanation  (sekos), \"fold\", in which case Apollo would be the god of flocks and herds. In the ancient Macedonian language  (pella) means \"stone,\" and some toponyms may be derived from this word:  (Pella, the capital of ancient Macedonia) and  (Pell\u0113n\u0113/Pellene).\n\nA number of non-Greek etymologies have been suggested for the name, The Hittite form Apaliunas (d) is attested in the Manapa-Tarhunta letter. The Hittite testimony reflects an early form, which may also be surmised from comparison of Cypriot  with Doric. The name of the Lydian god Q\u03bbd\u00e3ns /k\u02b7\u028e\u00f0\u00e3ns/ may reflect an earlier /k\u02b7aly\u00e1n-/ before palatalization, syncope, and the pre-Lydian sound change *y > d. Note the labiovelar in place of the labial /p/ found in pre-Doric \u1f08\u03c0\u03ad\u03bbj\u03c9\u03bd and Hittite Apaliunas.\n\nA Luwian etymology suggested for Apaliunas makes Apollo \"The One of Entrapment\", perhaps in the sense of \"Hunter\".\n\nGreco-Roman epithets\nApollo's chief epithet was Phoebus ( ;, Phoibos ), literally \"bright\". It was very commonly used by both the Greeks and Romans for Apollo's role as the god of light. Like other Greek deities, he had a number of others applied to him, reflecting the variety of roles, duties, and aspects ascribed to the god. However, while Apollo has a great number of appellations in Greek myth, only a few occur in Latin literature.\n\nSun\nAegletes ( ; \u0391\u1f30\u03b3\u03bb\u03ae\u03c4\u03b7\u03c2, Aigl\u0113t\u0113s), from, \"light of the sun\" \nHelius ( ;, Helios), literally \"sun\" \nLyceus ( ;, Lykeios, from Proto-Greek *), \"light\". The meaning of the epithet \"Lyceus\" later became associated with Apollo's mother Leto, who was the patron goddess of Lycia () and who was identified with the wolf ().\nPhanaeus ( ;, Phanaios), literally \"giving or bringing light\"\nPhoebus ( ;, Phoibos), literally \"bright\", his most commonly used epithet by both the Greeks and Romans\nSol (Roman) (), \"sun\" in Latin\n\nWolf\nLycegenes ( ;, Luk\u0113gen\u0113s), literally \"born of a wolf\" or \"born of Lycia\"\nLycoctonus ( ;, Lykoktonos), from, \"wolf\", and, \"to kill\"\n\nOrigin and birth\nApollo's birthplace was Mount Cynthus on the island of Delos.\n\nCynthius ( ;, Kunthios), literally \"Cynthian\"\nCynthogenes ( ;, Kynthogen\u0113s), literally \"born of Cynthus\"\nDelius ( ; \u0394\u03ae\u03bb\u03b9\u03bf\u03c2, Delios), literally \"Delian\"\nDidymaeus ( ;, Didymaios) from \u03b4\u03af\u03b4\u03c5\u03bc\u03bf\u03c2, \"twin\", as the twin of Artemis\n\nPlace of worship\nDelphi and Actium were his primary places of worship.\n\nAcraephius ( ;, Akraiphios, literally \"Acraephian\") or Acraephiaeus ( ;, Akraiphiaios), \"Acraephian\", from the Boeotian town of Acraephia (), reputedly founded by his son Acraepheus.\nActiacus ( ;, Aktiakos), literally \"Actian\", after Actium ()\nDelphinius ( ;, Delphinios), literally \"Delphic\", after Delphi (\u0394\u03b5\u03bb\u03c6\u03bf\u03af). An etiology in the Homeric Hymns associated this with dolphins.\nEpactaeus, meaning \"god worshipped on the coast\", in Samos.\nPythius ( ;, Puthios, from \u03a0\u03c5\u03b8\u03ce, Pyth\u014d), from the region around Delphi \nSmintheus ( ;, Smintheus), \"Sminthian\"\u2014that is, \"of the town of Sminthos or Sminthe\" near the Troad town of Hamaxitus\nNapaian Apollo (\u1f08\u03c0\u03cc\u03bb\u03bb\u03c9\u03bd \u039d\u03b1\u03c0\u03b1\u1fd6\u03bf\u03c2), from the city of Nape at the island of Lesbos\n\nHealing and disease\nAcesius ( ;, Akesios), from, \"healing\". Acesius was the epithet of Apollo worshipped in Elis, where he had a temple in the agora.\nAcestor ( ;, Akest\u014dr), literally \"healer\"\nCulicarius (Roman) ( ), from Latin culic\u0101rius, \"of midges\"\nIatrus ( ;, I\u0101tros), literally \"physician\"\nMedicus (Roman) ( ), \"physician\" in Latin. A temple was dedicated to Apollo Medicus at Rome, probably next to the temple of Bellona.\nPaean ( ;, Pai\u0101n), physician, healer\nParnopius ( ;, Parnopios), from, \"locust\"\n\nFounder and protector\nAgyieus ( ;, Agu\u012beus), from, \"street\", for his role in protecting roads and homes\nAlexicacus ( ;, Alexikakos), literally \"warding off evil\"\nApotropaeus ( ;, Apotropaios), from, \"to avert\"\nArchegetes ( ;, Arkh\u0113get\u0113s), literally \"founder\"\nAverruncus (Roman) ( ; from Latin \u0101verruncare), \"to avert\"\nClarius ( ;, Kl\u0101rios), from Doric, \"allotted lot\"\nEpicurius ( ;, Epikourios), from, \"to aid\"\nGenetor ( ;, Genet\u014dr), literally \"ancestor\"\nNomius ( ;, Nomios), literally \"pastoral\"\nNymphegetes ( ;, Numph\u0113get\u0113s), from, \"Nymph\", and, \"leader\", for his role as a protector of shepherds and pastoral life\nPatroos  from , \"related to one's father,\" for his role as father of Ion and founder of the Ionians, as worshipped at the Temple of Apollo Patroos in Athens\nSauroctunos, \u201clizard killer\u201d, possibly a reference to his killing of Python\n\nProphecy and truth\nCoelispex (Roman) ( ), from Latin coelum, \"sky\", and specere \"to look at\" \nIatromantis ( ;, I\u0101tromantis,) from, \"physician\", and, \"prophet\", referring to his role as a god both of healing and of prophecy\nLeschenorius ( ;, Leskh\u0113norios), from, \"converser\"\nLoxias ( ;, Loxias), from, \"to say\", historically associated with, \"ambiguous\"\nManticus ( ;, Mantikos), literally \"prophetic\"\nProopsios (), meaning \"foreseer\" or \"first seen\"\n\nMusic and arts\nMusagetes ( ; Doric, Mous\u0101get\u0101s), from, \"Muse\", and  \"leader\" \nMusegetes ( ;, Mous\u0113get\u0113s), as the preceding\n\nArchery\nAphetor ( ;, Aph\u0113t\u014dr), from, \"to let loose\"\nAphetorus ( ;, Aph\u0113toros), as the preceding\nArcitenens (Roman) ( ), literally \"bow-carrying\"\nArgyrotoxus ( ;, Argyrotoxos), literally \"with silver bow\"\nClytotoxus ( ;, Klyt\u00f3toxos), \"he who is famous for his bow\", the renowned archer.\nHeca\u00ebrgus ( ;, Hekaergos), literally \"far-shooting\"\nHecebolus ( ;, Hek\u0113bolos), \"far-shooting\"\nIsmenius ( ;, Ism\u0113nios), literally \"of Ismenus\", after Ismenus, the son of Amphion and Niobe, whom he struck with an arrow\n\nAmazons\nAmazonius (), Pausanias at the Description of Greece writes that near Pyrrhichus there was a sanctuary of Apollo, called Amazonius () with image of the god said to have been dedicated by the Amazons.\n\nCeltic epithets and cult titles\nApollo was worshipped throughout the Roman Empire. In the traditionally Celtic lands, he was most often seen as a healing and sun god. He was often equated with Celtic gods of similar character.\n Apollo Atepomarus (\"the great horseman\" or \"possessing a great horse\"). Apollo was worshipped at Mauvi\u00e8res (Indre). Horses were, in the Celtic world, closely linked to the sun.\n Apollo Belenus (\"bright\" or \"brilliant\"). This epithet was given to Apollo in parts of Gaul, Northern Italy and Noricum (part of modern Austria). Apollo Belenus was a healing and sun god.\n Apollo Cunomaglus (\"hound lord\"). A title given to Apollo at a shrine at Nettleton Shrub, Wiltshire. May have been a god of healing. Cunomaglus himself may originally have been an independent healing god.\n Apollo Grannus. Grannus was a healing spring god, later equated with Apollo.\n Apollo Maponus. A god known from inscriptions in Britain. This may be a local fusion of Apollo and Maponus.\n Apollo Moritasgus (\"masses of sea water\"). An epithet for Apollo at Alesia, where he was worshipped as god of healing and, possibly, of physicians.\n Apollo Vindonnus (\"clear light\"). Apollo Vindonnus had a temple at Essarois, near Ch\u00e2tillon-sur-Seine in present-day Burgundy. He was a god of healing, especially of the eyes.\n Apollo Virotutis (\"benefactor of mankind\"). Apollo Virotutis was worshipped, among other places, at Fins d'Annecy (Haute-Savoie) and at Jublains (Maine-et-Loire).\n\nOrigins\n\nThe cult centers of Apollo in Greece, Delphi and Delos, date from the 8th century BCE. The Delos sanctuary was primarily dedicated to Artemis, Apollo's twin sister. At Delphi, Apollo was venerated as the slayer of the monstrous serpent Python. For the Greeks, Apollo was the most Greek of all the gods, and through the centuries he acquired different functions. In Archaic Greece he was the prophet, the oracular god who in older times was connected with \"healing\". In Classical Greece he was the god of light and of music, but in popular religion he had a strong function to keep away evil. Walter Burkert discerned three components in the prehistory of Apollo worship, which he termed \"a Dorian-northwest Greek component, a Cretan-Minoan component, and a Syro-Hittite component.\"\n\nHealer and god-protector from evil\n\nIn classical times, his major function in popular religion was to keep away evil, and he was therefore called \"apotropaios\" (, \"averting evil\") and \"alexikakos\" ( \"keeping off ill\"; from v.  + n. ). Apollo also had many epithets relating to his function as a healer. Some commonly-used examples are \"paion\" ( literally \"healer\" or \"helper\") \"epikourios\" (, \"succouring\"), \"oulios\" (, \"healer, baleful\") and \"loimios\" (, \"of the plague\"). In later writers, the word, \"paion\", usually spelled \"Paean\", becomes a mere epithet of Apollo in his capacity as a god of healing.\n\nApollo in his aspect of \"healer\" has a connection to the primitive god Paean (), who did not have a cult of his own. Paean serves as the healer of the gods in the Iliad, and seems to have originated in a pre-Greek religion. It is suggested, though unconfirmed, that he is connected to the Mycenaean figure pa-ja-wo-ne (Linear B: ). Paean was the personification of holy songs sung by \"seer-doctors\" (), which were supposed to cure disease.\n\nHomer illustrated Paeon the god and the song both of apotropaic thanksgiving or triumph. Such songs were originally addressed to Apollo and afterwards to other gods: to Dionysus, to Apollo Helios, to Apollo's son Asclepius the healer. About the 4th century BCE, the paean became merely a formula of adulation; its object was either to implore protection against disease and misfortune or to offer thanks after such protection had been rendered. It was in this way that Apollo had become recognized as the god of music. Apollo's role as the slayer of the Python led to his association with battle and victory; hence it became the Roman custom for a paean to be sung by an army on the march and before entering into battle, when a fleet left the harbour, and also after a victory had been won.\n\nIn the Iliad, Apollo is the healer under the gods, but he is also the bringer of disease and death with his arrows, similar to the function of the Vedic god of disease Rudra. He sends a plague () to the Achaeans. Knowing that Apollo can prevent a recurrence of the plague he sent, they purify themselves in a ritual and offer him a large sacrifice of cows, called a hecatomb.\n\nDorian origin\nThe Homeric Hymn to Apollo depicts Apollo as an intruder from the north. The connection with the northern-dwelling Dorians and their initiation festival apellai is reinforced by the month Apellaios in northwest Greek calendars. The family-festival was dedicated to Apollo (Doric: ). Apellaios is the month of these rites, and Apellon is the \"megistos kouros\" (the great Kouros). However it can explain only the Doric type of the name, which is connected with the Ancient Macedonian word \"pella\" (Pella), stone. Stones played an important part in the cult of the god, especially in the oracular shrine of Delphi (Omphalos).\n\nMinoan origin\n\nGeorge Huxley regarded the identification of Apollo with the Minoan deity Paiawon, worshipped in Crete, to have originated at Delphi. In the Homeric Hymn, Apollo appeared as a dolphin and carried Cretan priests to Delphi, where they evidently transferred their religious practices. Apollo Delphinios or Delphidios was a sea-god especially worshipped in Crete and in the islands. Apollo's sister Artemis, who was the Greek goddess of hunting, is identified with Britomartis (Diktynna), the Minoan \"Mistress of the animals\". In her earliest depictions she was accompanied by the \"Master of the animals\", a bow-wielding god of hunting whose name has been lost; aspects of this figure may have been absorbed into the more popular Apollo.\n\nAnatolian origin\n\nA non-Greek origin of Apollo has long been assumed in scholarship. The name of Apollo's mother Leto has Lydian origin, and she was worshipped on the coasts of Asia Minor. The inspiration oracular cult was probably introduced into Greece from Anatolia, which is the origin of Sibyl, and where some of the oldest oracular shrines originated to be a really serious and exciting project no?. Omens, symbols, purifications, and exorcisms appear in old Assyro-Babylonian texts. These rituals were spread into the empire of the Hittites, and from there into Greece.\n\nHomer pictures Apollo on the side of the Trojans, fighting against the Achaeans, during the Trojan War. He is pictured as a terrible god, less trusted by the Greeks than other gods. The god seems to be related to Appaliunas, a tutelary god of Wilusa (Troy) in Asia Minor, but the word is not complete. The stones found in front of the gates of Homeric Troy were the symbols of Apollo. A western Anatolian origin may also be bolstered by references to the parallel worship of Artimus (Artemis) and Q\u03bbd\u00e3ns, whose name may be cognate with the Hittite and Doric forms, in surviving Lydian texts. However, recent scholars have cast doubt on the identification of Q\u03bbd\u00e3ns with Apollo.\n\nThe Greeks gave to him the name  agyieus as the protector god of public places and houses who wards off evil and his symbol was a tapered stone or column. However, while usually Greek festivals were celebrated at the full moon, all the feasts of Apollo were celebrated at the seventh day of the month, and the emphasis given to that day (sibutu) indicates a Babylonian origin.\n\nThe Late Bronze Age (from 1700 to 1200 BCE) Hittite and Hurrian Aplu was a god of plague, invoked during plague years. Here we have an apotropaic situation, where a god originally bringing the plague was invoked to end it. Aplu, meaning the son of, was a title given to the god Nergal, who was linked to the Babylonian god of the sun Shamash. Homer interprets Apollo as a terrible god () who brings death and disease", "flag": 1, "segments": [[4599, 4609]], "strength": 5.5}
{"text": "Andre Kirk Agassi ( ; born April 29, 1970) is an American former world No. 1 tennis player. He is an eight-time major champion and a 1996 Olympic gold medalist, as well as a runner-up in seven other Grand Slam tournaments.\n\nAgassi was the first man to win four Australian Open singles titles in the Open Era (though later surpassed by Novak Djokovic, who won his fifth title in 2015 and has since won the tournament nine times). Agassi is the second of five men to achieve the career an episode, you can follow: \"I heard Grand Slam in the Open Era and the fifth of eight overall to make the achievement. He is also the first of two men to achieve the career Golden Slam (career Grand Slam and Olympic gold medal), and the only man to win a career Super Slam (career Grand Slam, plus the Olympic gold medal and the year-end championships).\n\nAgassi was the first man to win all four singles majors on three different surfaces (hard, clay and grass), and remains the most recent American man to win the French Open (in 1999) and the Australian Open (in 2003). He also won 17 ATP Masters Series titles and was part of the winning Davis Cup teams in 1990, 1992 and 1995. Agassi reached the world No. 1 ranking for the first time in 1995 but was troubled by personal issues during the mid-to-late 1990s and sank to No. 141 in 1997, prompting many to believe that his career was over. Agassi returned to No. 1 in 1999 and enjoyed the most successful run of his career over the next four years. During his 20-plus year tour career, Agassi was known by the nickname \"The Punisher\".\n\nAfter suffering from sciatica caused by two bulging discs in his back, a spondylolisthesis (vertebral displacement) and a bone spur that interfered with the nerve, Agassi retired from professional tennis on September 3, 2006, after losing in the third round of the US Open. He is the founder of the Andre Agassi Charitable Foundation, which has raised over $60\u00a0million for at-risk children in Southern Nevada. In 2001, the Foundation opened the Andre Agassi College Preparatory Academy in Las Vegas, a K\u201312 public charter school for at-risk children. He has been married to fellow tennis player Steffi Graf since 2001.\n\n1970\u20131985: Early life\nAndre Agassi was born in Las Vegas, Nevada, to Emmanuel \"Mike\" Agassi, a former Olympic boxer from Iran and American Elizabeth \"Betty\" Agassi (n\u00e9e Dudley). His father is of Armenian and Assyrian heritage. Andre Agassi's mother, Betty, is a breast cancer survivor. He has three older siblings \u2013 Rita (last wife of former number one Pancho Gonzales), Philip and Tami. Andre was given the middle name Kirk after Kirk Kerkorian, an Armenian American billionaire. Emmanuel Agassi, then a waiter at Tropicana Las Vegas, had met Kerkorian in 1963.\n\nAt the age of 12, Agassi and his good friend and doubles partner, Roddy Parks, won the 1982 National Indoor Boys 14s Doubles Championship in Chicago. Agassi describes memorable experiences and juvenile pranks with Roddy in his book Open.\n\nWhen he was 13, Agassi was sent to Nick Bollettieri's Tennis Academy in Florida. He was meant to stay for only three months, because that was all his father could afford. After thirty minutes of watching Agassi play, Bollettieri, deeply impressed by his talent, called Mike and said: \"Take your check back. He's here for free.\" Agassi then dropped out of school in the ninth grade to pursue a full-time tennis career.\n\n1986\u20132006: Professional career\n\n1986\u20131993: Breakthrough and the first major title\n\nAgassi turned professional at the age of 16 and competed in his first tournament at La Quinta, California. He won his first match against John Austin, but then lost his second match to Mats Wilander. By the end of 1986, Agassi was ranked No. 91. He won his first top-level singles title in 1987 at the Sul American Open in Itaparica and ended the year ranked No. 25. He won six additional tournaments in 1988 (Memphis, U.S. Men's Clay Court Championships, Forest Hills WCT, Stuttgart Outdoor, Volvo International and Livingston Open), and, by December of that year, he had surpassed US$1\u00a0million in career prize money after playing in just 43 tournaments\u2014the fastest anyone in history had reached that level. During 1988, he also set the open-era record for most consecutive victories by a male teenager (a record that stood for 17 years until Rafael Nadal broke it in 2005). His year-end ranking was No. 3, behind second-ranked Ivan Lendl and top-ranked Mats Wilander. Both the Association of Tennis Professionals and Tennis magazine named Agassi the Most Improved Player of the Year for 1988.\n\nIn addition to not playing the Australian Open (which later became his best Grand Slam event) for the first eight years of his career, Agassi chose not to play at Wimbledon from 1988 through 1990 and publicly stated that he did not wish to play there because of the event's traditionalism, particularly its \"predominantly white\" dress code to which players at the event are required to conform.\n\nStrong performances on the tour meant that Agassi was quickly tipped as a future Grand Slam champion. While still a teenager, he reached the semi-finals of both the French Open and the US Open in 1988 and made the US Open semi-finals in 1989. He began the 1990s with a series of near-misses. He reached his first Grand Slam final in 1990 at the French Open, where he was favored before losing in four sets to Andr\u00e9s G\u00f3mez, which he later attributed in his book to worrying about his wig falling off during the match. He reached his second Grand Slam final of the year at the US Open, defeating defending champion Boris Becker in the semi-finals. His opponent in the final was Pete Sampras; a year earlier, Agassi had crushed Sampras, after which time he told his coach that he felt bad for Sampras because he was never going to make it as a pro. Agassi lost the US Open final to Sampras in three sets. The rivalry between these two American players became the biggest one in tennis over the rest of the decade. Agassi ended 1990 on a high note as he helped the United States win its first Davis Cup in 8 years and won his only Tennis Masters Cup, beating reigning Wimbledon champion Stefan Edberg in the final.\n\nIn 1991, Agassi reached his second consecutive French Open final, where he faced fellow Bollettieri Academy alumnus Jim Courier. Courier emerged the victor in a five-set final. Agassi decided to play at Wimbledon in 1991, leading to weeks of speculation in the media about the clothes he would wear. He eventually emerged for the first round in a completely white outfit. He reached the quarterfinals on that occasion, losing in five sets to David Wheaton.\n\nAgassi's Grand Slam tournament breakthrough came at Wimbledon, not at the French Open or the US Open, where he had previously enjoyed success. In 1992, he defeated Goran Ivani\u0161evi\u0107 in a five-set final. Along the way, Agassi overcame two former Wimbledon champions: Boris Becker and John McEnroe. No other baseliner would triumph at Wimbledon until Lleyton Hewitt ten years later. Agassi was named the BBC Overseas Sports Personality of the Year in 1992. Agassi once again played on the United States' Davis Cup winning team in 1992. It was their second Davis cup title in three years. Agassi famously played the game wearing Oakley brand sunglasses, and a photo of him from the day appeared on the cover of Tennis magazine. In his memoir, he wrote that he was covering up bloodshot eyes from a hangover and claimed that the founder of Oakley, Jim Jannard, had sent him a Dodge Viper to thank him for the inadvertent publicity.\n\nIn 1993, Agassi won the only doubles title of his career, at the Cincinnati Masters, partnered with Petr Korda. He missed much of the early part of that year due to injuries. Although he made the quarterfinals in his Wimbledon title defense, he lost to eventual champion and No. 1 Pete Sampras in five sets. Agassi lost in the first round at the US Open to Thomas Enqvist and required wrist surgery late in the year.\n\n1994\u20131997: Rise to the top, Olympic Gold and the fall\nWith new coach Brad Gilbert on board, Agassi began to employ more of a tactical, consistent approach, which fueled his resurgence. He started slowly in 1994, losing in the first week at the French Open and Wimbledon. Nevertheless, he emerged during the hard-court season, winning the Canadian Open. His comeback culminated at the 1994 US Open with a five-set fourth-round victory against Michael Chang. He then became the first man to capture the US Open as an unseeded player, beating Michael Stich in the final. Along the way, he beat 5 seeded players.\n\nIn 1995, Agassi shaved his balding head, breaking with his old \"image is everything\" style. He competed in the 1995 Australian Open (his first appearance at the event) and won, beating Sampras in a four-set final. Agassi and Sampras met in five tournament finals in 1995, all on hardcourt, with Agassi winning three. Agassi won three Masters Series events in 1995 (Cincinnati, Key Biscayne, and the Canadian Open) and seven titles total. He compiled a career-best 26-match winning streak during the summer hard-court circuit, with the last victory being in an intense late-night four-set semi-final of the US Open against Boris Becker. The streak ended the next day when Agassi lost the final to Sampras.\n\nAgassi reached the world No. 1 ranking for the first time in April 1995. He held that ranking until November, for a total of 30 weeks. Agassi skipped most of the fall indoor season which allowed Sampras to surpass him and finish ranked No. 1 at the year-end ranking. In terms of win/loss record, 1995 was Agassi's best year. He won 73 and lost 9 matches, and was also once again a key player on the United States' Davis Cup winning team\u2014the third and final Davis Cup title of his career.\n\n1996 was a less successful year for Agassi, as he failed to reach any Grand Slam final. He suffered two early-round losses to Chris Woodruff and Doug Flach at the French Open and Wimbledon, respectively, and lost to Chang in straight sets in the Australian and US Open semi-finals. At the time, Agassi blamed the Australian Open loss on the windy conditions, but later said in his biography that he had lost the match on purpose, as he did not want to play Boris Becker, whom he would have faced in that final. The high point for Agassi was winning the men's singles gold medal at the Olympic Games in Atlanta, beating Sergi Bruguera of Spain in the final. Agassi also successfully defended his singles titles in Cincinnati and Key Biscayne.\n\n1997 was the low point of Agassi's career. His wrist injury resurfaced, and he played only 24 matches during the year. He later confessed that he started using crystal methamphetamine at that time, allegedly on the urging of a friend. He failed an ATP drug test, but wrote a letter claiming the same friend had spiked a drink. The ATP dropped the failed drug test as a warning. In his autobiography, Agassi admitted that the letter was a lie. He quit the drug soon after. At this time Agassi was also in a failing marriage with actress, model, and socialite Brooke Shields and had lost interest in the game. He won no top-level titles, and his ranking sank to No. 141 on November 10, 1997, prompting many to believe that his run as one of the sport's premier competitors was over and he would never again win any significant championships.\n\n1998\u20132003: Return to glory and Career Super Slam\n\nIn 1998, Agassi began a rigorous conditioning program and worked his way back up the rankings by playing in Challenger Series tournaments, a circuit for pro players ranked outside the world's top 50. After returning to top physical and mental shape, Agassi recorded the most successful period of his tennis career and also played classic matches in that period against Pete Sampras and Patrick Rafter.\n\nIn 1998, Agassi won five titles and leapt from No. 110 to No. 6, the highest jump into the top 10 made by any player during a calendar year. At Wimbledon, he had an early loss in the second round to Tommy Haas. He won five titles in ten finals and was runner-up at the Masters Series tournament in Key Biscayne, losing to Marcelo R\u00edos, who became No. 1 as a result. At the year end he was awarded the ATP Most Improved Player of the Year for the second time in his career (the first being 10 years earlier in 1988).\n\nAgassi entered the history books in 1999 when he came back from two sets to love down to beat Andrei Medvedev in a five-set French Open final, becoming, at the time, only the fifth male player (joining Rod Laver, Fred Perry, Roy Emerson and Don Budge\u2014these have since been joined by Roger Federer, Rafael Nadal, and Novak Djokovic) to win all four Grand Slam singles titles during his career. Only Laver, Agassi, Federer, Nadal and Djokovic have achieved this feat during the Open Era. This win also made him the first (of only four, the next being Federer, Nadal and Djokovic respectively) male player in history to have won all four Grand Slam titles on three different surfaces (clay, grass and hard courts).  Agassi also became the only male player to win the Career Super Slam, consisting of all four Grand Slam tournaments plus an Olympic gold medal in singles and a Year-end championship.\n\nAgassi followed his 1999 French Open victory by reaching the Wimbledon final, where he lost to Sampras in straight sets. He rebounded from his Wimbledon defeat by winning the US Open, beating Todd Martin in five sets (rallying from a two sets to one deficit) in the final. Overall during the year Agassi won 5 titles including two majors and the ATP Masters Series in Paris, where he beat Marat Safin. Agassi ended 1999 as the No. 1, ending Sampras's record of six consecutive year-ending top rankings (1993\u201398). This was the only time Agassi ended the year at No. 1.  Agassi was runner-up to Sampras at the year-end Tennis Masters Cup losing 1\u20136, 5\u20137, 4-6 despite beating Sampras in the round-robin 6\u20132, 6\u20132.\n\nHe began the next year 2000 by capturing his second Australian Open title, beating Sampras in a five-set semi-final and Yevgeny Kafelnikov in a four-set final. He was the first male player to have reached four consecutive Grand Slam finals since Rod Laver achieved the Grand Slam in 1969.  At the time, Agassi was also only the fourth player since Laver to be the reigning champion of three of four Grand Slam events, missing only the Wimbledon title.. 2000 also saw Agassi reach the semi-finals at Wimbledon, where he lost in five sets to Rafter in a match considered by many to be one of the best ever at Wimbledon. At the inaugural Tennis Masters Cup in Lisbon, Agassi reached the final after defeating Marat Safin in the semi-finals to end the Russian's hopes to become the youngest No. 1 in the history of tennis. Agassi then lost to Gustavo Kuerten in the final, allowing Kuerten to be crowned year-end No. 1.\n\nAgassi opened 2001 by successfully defending his Australian Open title with a straight-sets final win over Arnaud Cl\u00e9ment. En route, he beat a cramping Rafter in five sets in front of a sell-out crowd in what turned out to be the Aussie's last Australian Open. At Wimbledon, they met again in the semi-finals, where Agassi lost another close match to Rafter, 8\u20136 in the fifth set. In the quarterfinals at the US Open, Agassi lost a 3-hour, 33\u00a0minute epic match with Sampras, 7\u20136, 6\u20137, 6\u20137, 6\u20137, with no breaks of serve during the 52-game match. Despite the setback, Agassi finished 2001 ranked No. 3, becoming the only male tennis player to finish a year ranked in the top 3 in three different decades.\n\n2002 opened with disappointment for Agassi, as injury forced him to skip the Australian Open, where he was a two-time defending champion. Agassi recovered from the injury and later that year defended his Key Biscayne title beating then rising Roger Federer in a four-set final. The last duel between Agassi and Sampras came in the final of the US Open, which Sampras won in four sets and left Sampras with a 20\u201314 edge in their 34 career meetings. The match was the last of Sampras's career. Agassi's US Open finish, along with his Masters Series victories in Key Biscayne, Rome and Madrid, helped him finish 2002 as the oldest year-end No. 2 at 32 years and 8 months.\n\nIn 2003, Agassi won the eighth (and final) Grand Slam title of his career at the Australian Open, where he beat Rainer Sch\u00fcttler in straight sets in the final.\n\nOn April 28, 2003, he recaptured the No. 1 ranking to become the oldest top-ranked male player since the ATP rankings began at 33 years and 13 days. The record was later surpassed by Roger Federer in 2018. He had held the No. 1 ranking for two weeks, when Lleyton Hewitt took it back on May 12, 2003. Agassi then recaptured the No. 1 ranking once again on June 16, 2003, which he held for 12 weeks until September 7, 2003. There he managed to reach the US Open semi-finals, where he lost to Juan Carlos Ferrero, surrendering his No. 1 ranking to him. During his career, Agassi held the ranking for a total of 101 weeks. Agassi's ranking slipped when injuries forced him to withdraw from a number of events. At the year-end Tennis Masters Cup, Agassi lost in the final to Federer, his third time to finish as runner-up in the event after losses in 1999 and 2000, and finished the year ranked No. 4. At age 33, he had been one of the oldest players to rank in the top 5 since Connors, at age 35, was No. 4 in 1987.\n\n2004\u20132006: Final years\n\nIn 2004, Agassi began the year with a five-set loss in the semi-finals of the Australian Open to Marat Safin; the loss ended Agassi's 26-match winning streak at the event. He won the Masters series event in Cincinnati to bring his career total to 59 top-level singles titles and a record 17 ATP Masters Series titles, having already won seven of the nine ATP Masters tournament\u2014all except the tournaments in Monte Carlo and Hamburg. At 34, he became the second-oldest singles champion in Cincinnati tournament history (the tournament began in 1899), tied with Roger Federer and surpassed only by Ken Rosewall, who won the title in 1970 at age 35. He finished the year ranked No. 8, one of the oldest players to finish in the top 10 since the 36-year-old Connors was No. 7 in 1988. At the time, Agassi also became the sixth male player during the open era to reach 800 career wins with his first-round victory over Alex Bogomolov in Countrywide Classic in Los Angeles.\n\nAgassi's 2005 began with a quarterfinal loss to Federer at the Australian Open. Agassi had several other deep runs at tournaments, but had to withdraw from several events due to injury. He lost to Jarkko Nieminen in the first round of the French Open. He won his fourth title in Los Angeles and reached the final of the Rogers Cup, before falling to No. 2 Rafael Nadal.\n\nAgassi's 2005 was defined by an improbable run to the US Open final. After beating R\u0103zvan Sab\u0103u and Ivo Karlovi\u0107 in straight sets and Tom\u00e1\u0161 Berdych in four sets, Agassi won three consecutive five-set matches to advance to the final. The most notable of these matches was his quarterfinal victory over James Blake, where he rallied from two sets down to win in the fifth set tie-breaker. His other five-set victories were on Xavier Malisse in the fourth round and Robby Ginepri in the semi-finals. In the final, Agassi faced Federer, who was seeking his second consecutive US Open title and his sixth Grand Slam title in two years. Federer defeated Agassi in four sets. Agassi finished 2005 ranked No. 7, his 16th time in the year-end top-10 rankings, which tied Connors for the most times ranked in the top 10 at year's end.\n\nAgassi had a poor start to 2006, as he was still recovering from an ankle injury and also suffering from back and leg pain and lack of match play. Agassi withdrew from the Australian Open because of the ankle injury, and his back injury and other pains forced him to withdraw from several other events, eventually skipping the entire clay-court season including the French Open. This caused his ranking to drop out of the top 10 for the last time. Agassi returned for the grass-court season, playing a tune-up, and then Wimbledon. He was defeated in the third round by world No. 2 (and eventual runner-up) Rafael Nadal. Against conventions, Agassi, the losing player, was interviewed on court after the match. At Wimbledon, Agassi announced his plans to retire following the US Open. Agassi played only two events during the summer hard-court season with his best result being a quarterfinal loss at the Countrywide Classic in Los Angeles to Fernando Gonz\u00e1lez of Chile, which resulted in him being unseeded at the US Open.\n\nAgassi had a short, but dramatic, run in his final US Open. Because of extreme back pain, Agassi was forced to receive anti-inflammatory injections after every match. After a tough four-set win against Andrei Pavel, Agassi faced eighth-seeded Marcos Baghdatis in the second round who had earlier advanced to the 2006 Australian Open final and Wimbledon semi-finals. Agassi won in five tough sets as the younger Baghdatis succumbed to muscle cramping in the final set. In his last match, Agassi fell to 112th-ranked big-serving Benjamin Becker of Germany in four sets. Agassi received a four-minute standing ovation from the crowd after the match and delivered a retirement speech.\n\nRivalries\n\nAgassi vs. Sampras\n\nThe rivalry has been called the greatest of the generation of players competing in the 1990s, as Sampras and Agassi were the most successful players of that decade. They also had very contrasting playing styles, with Sampras being considered the greatest server and Agassi the greatest serve returner at the time. Agassi and Sampras met 34 times on the tour level with Agassi trailing 14\u201320.\n\nThe 1990 US Open was their first meeting in a Grand Slam", "flag": 1, "segments": [[111, 121]], "strength": 5.5}
{"text": "Andorra, officially the Principality of Andorra, is a sovereign landlocked microstate on the Iberian Peninsula, in the eastern Pyrenees, bordered by France to the north and Spain to the south. Believed to have been created by Charlemagne, Andorra was ruled by the count of Urgell until 988, when it was transferred to the Roman Catholic Diocese of Urgell. The present principality was formed by a charter in 1278. It is headed by two co-princes: the Bishop of Urgell in Catalonia, Spain and the President of France. Its capital and largest city is Andorra la Vella.\n\nAndorra is the sixth-smallest state in Europe, with an area of  and a population of approximately. The Andorran people are a Romance ethnic group of originally Catalan descent. Andorra is the world's 16th-smallest country by land and 11th-smallest by population. Its capital, Andorra la Vella, is the highest capital city in Europe, at an elevation of  above sea level. The official language is Catalan, but Spanish, Portuguese, and French are also commonly spoken.\n\nTourism in Andorra sees an estimated 10.2 million visitors annually. Andorra is not a member state of the European Union, but the euro is its official currency. It has been a member of the United Nations since 1993. In 2013, Andorra had the highest life expectancy in the world at 81 years, according to the Global Burden of Disease Study; in 2019, it had the 23rd-highest at 81.9 years, according to the United Nations Development Programme.\n\nEtymology\nThe origin of the word Andorra is unknown, although several hypotheses have been formulated. The oldest derivation is from the Greek historian Polybius (The Histories III, 35, 1), who describes the Andosins, an Iberian Pre-Roman tribe, as historically located in the valleys of Andorra and facing the Carthaginian army in its passage through the Pyrenees during the Punic Wars. The word Andosini or Andosins () may derive from the Basque, meaning \"big\" or \"giant\". The Andorran toponymy shows evidence of Basque language in the area. Another theory suggests that the word Andorra may derive from the old word Anorra that contains the Basque word  (water).\n\nAnother theory suggests that Andorra may derive from, meaning \"the thickly wooded place\". When the Arabs and Moors conquered the Iberian Peninsula, the valleys of the High Pyrenees were covered by large tracts of forest. These regions were not administered by Muslims, because of the geographic difficulty of direct rule.\n\nOther theories suggest that the term derives from the Navarro-Aragonese \"andurrial\", which means \"land covered with bushes\" or \"scrubland\".\n\nThe folk etymology holds that Charlemagne had named the region as a reference to the Biblical Canaanite valley of Endor or Andor (where the Midianites had been defeated), a name bestowed by his heir and son Louis the Pious after defeating the Moors in the \"wild valleys of Hell\".\n\nHistory\n\nPrehistory \n\nLa Balma de la Margineda, found by archaeologists at Sant Juli\u00e0 de L\u00f2ria, was settled in 9,500 BC as a passing place between the two sides of the Pyrenees. The seasonal camp was perfectly located for hunting and fishing by the groups of hunter-gatherers from Ariege and Segre.\n\nDuring the Neolithic Age, a group of people moved to the Valley of Madriu (the present-day Natural Parc located in Escaldes-Engordany declared UNESCO World Heritage Site) as a permanent camp in 6640 BC. The population of the valley grew cereals, raised domestic livestock, and developed a commercial trade with people from the Segre and Occitania.\n\nOther archaeological deposits include the Tombs of Segudet (Ordino) and Feixa del Moro (Sant Juli\u00e0 de L\u00f2ria), both dated in 4900\u20134300 BC as an example of the Urn culture in Andorra. The model of small settlements began to evolve to a complex urbanism during the Bronze Age. Metallurgical items of iron, ancient coins, and relicaries can be found in the ancient sanctuaries scattered around the country.\n\nThe sanctuary of Roc de les Bruixes (Stone of the Witches) is perhaps the most important archeological complex of this age in Andorra, located in the parish of Canillo, about the rituals of funerals, ancient scripture and engraved stone murals.\n\nIberian and Roman Andorra\n\nThe inhabitants of the valleys were traditionally associated with the Iberians and historically located in Andorra as the Iberian tribe Andosins or Andosini () during the 7th and 2nd centuries BC. Influenced by the Aquitanian, Basque and Iberian languages, the locals developed some current toponyms. Early writings and documents relating to this group of people goes back to the second century BC by the Greek writer Polybius in his Histories during the Punic Wars.\n\nSome of the most significant remains of this era are the Castle of the Roc d'Enclar (part of the early Marca Hispanica), l'Anxiu in Les Escaldes and Roc de L'Oral in Encamp.\n\nThe presence of Roman influence is recorded from the 2nd century BC to the 5th century AD. The places with the most Roman presence are in Camp Vermell (Red Field) in Sant Juli\u00e0 de L\u00f2ria, and in some places in Encamp, as well as in the Roc d'Enclar. People continued trading, mainly with wine and cereals, with the Roman cities of Urgellet (the present-day La Seu d'Urgell) and all across Segre through the via romana Strata Ceretana (also known as Strata Confluetana).\n\nVisigoths and Carolingians: the legend of Charlemagne\n\nAfter the fall of the Roman Empire, Andorra came under the influence of the Visigoths, the Kingdom of Toledo, and the Diocese of Urgell. The Visigoths remained in the valleys for 200 years, during which time Christianity spread. When the Muslim Empire of Al-Andalus replaced the ruling Visigoths in most of the Iberian Peninsula, Andorra was sheltered from these invaders by the Franks.\n\nTradition holds that Charles the Great (Charlemagne) granted a charter to the Andorran people for a contingent of 5,000 soldiers under the command of Marc Almugaver, in return for fighting against the Moors near Port\u00e9-Puymorens (Cerdanya).\n\nAndorra remained part of the Frankish Marca Hispanica, the buffer zone between the Frankish Empire and the Muslim territories, Andorra being part of the territory ruled by the Count of Urgell and eventually the bishop of the Diocese of Urgell. Tradition also holds that it was guaranteed by the son of Charlemagne, Louis the Pious, writing the Carta de Poblament or a local municipal charter circa 805.\n\nIn 988, Borrell II, Count of Urgell, gave the Andorran valleys to the Diocese of Urgell in exchange for land in Cerdanya. Since then, the Bishop of Urgell, based in Seu d'Urgell, has been co-prince of Andorra.\n\nThe first document that mentions Andorra as a territory is the Acta de Consagraci\u00f3 i Dotaci\u00f3 de la Catedral de la Seu d'Urgell (Deed of Consecration and Endowment of the Cathedral of La Seu d'Urgell). The document, dated 839, depicts the six old parishes of the Andorran valleys that made up the country's administrative division.\n\nMedieval Age: The Par\u00e9ages and the founding of the Co-Principality\n\nBefore 1095, Andorra had no military protection, and the Bishop of Urgell, who knew that the count of Urgell wanted to reclaim the Andorran valleys, asked the lord of Caboet for help and protection. In 1095, the Lord of Caboet and the bishop of Urgell signed under oath a declaration of their co-sovereignty over Andorra. Arnalda, daughter of Arnau of Caboet, married the viscount of Castellb\u00f2. Their daughter, Ermessenda, married the count of Foix, Roger-Bernard II. Roger-Bernard II and Ermessenda shared rule over Andorra with the bishop of Urgell.\n\nIn the 13th century, a military dispute arose between the bishop of Urgell and the count of Foix as aftermath of the Cathar Crusade. The conflict was resolved in 1278 with the mediation of the king of Aragon, Peter III, between the bishop and the count, by the signing of the first par\u00e9age, which provided that Andorra's sovereignty be shared between the count of Foix (whose title would ultimately transfer to the French head of state) and the bishop of Urgell, in Catalonia. This gave the principality its territory and political form.\n\nA second par\u00e9age was signed in 1288 after a dispute when the count of Foix ordered the construction of a castle in Roc d'Enclar. The document was ratified by the noble notary Jaume Orig of Puigcerd\u00e0, and construction of military structures in the country was prohibited.\n\nIn 1364, the political organization of the country named the figure of the syndic (now spokesman and president of the parliament) as representative of the Andorrans to their co-princes, making possible the creation of local departments (comuns, quarts and ve\u00efnats). After being ratified by Bishop Francesc Tovia and Count John I, the Consell de la Terra or Consell General de les Valls (General Council of the Valleys) was founded in 1419, the second oldest parliament in Europe. The syndic Andreu d'Al\u00e0s and the General Council organized the creation of the Justice Courts (La Cort de Justicia) in 1433 with the co-princes and the collection of taxes like foc i lloc (literally \"fire and site\", a national tax active since then).\n\nAlthough there are remains of ecclesiastical works dating before the 9th century (Sant Vicen\u00e7 d'Enclar or Esgl\u00e9sia de Santa Coloma), Andorra developed exquisite Romanesque Art during the 9th through 14th centuries, particularly in the construction of churches, bridges, religious murals and statues of the Virgin and Child (Our Lady of Meritxell being the most important). Nowadays, the Romanesque buildings that form part of Andorra's cultural heritage stand out in a remarkable way, with an emphasis on Esgl\u00e9sia de Sant Esteve, Sant Joan de Caselles, Esgl\u00e9sia de Sant Miquel d'Engolasters, Sant Mart\u00ed de la Cortinada and the medieval bridges of Margineda and Escalls among many others.\n\nThe Catalan Pyrenees were embryonic of the Catalan language at the end of the 11th century. Andorra was influenced by this language, which was adopted locally decades before it expanded to the rest of the Crown of Aragon.\n\nThe local economy during the Middle Ages was based on livestock, agriculture, furs and weavers. Later, at the end of the 11th century, the first iron foundries began to appear in Northern Parishes like Ordino, much appreciated by the master artisans who developed the art of the forges, an important economic activity in the country from the 15th century.\n\n16th to 18th centuries\n\nIn 1601, the Tribunal de Corts (High Court of Justice) was created as a result of Huguenot rebellions in France, Inquisition courts coming from Spain and witchcraft-related beliefs native to the area, in the context of the Reformation and Counter-Reformation.\n\nWith the passage of time, the co-title to Andorra passed to the kings of Navarre. After Henry III of Navarre became king of France, he issued an edict in 1607 that established the head of the French state and the bishop of Urgell as co-princes of Andorra, a political arrangement that still holds.\n\nDuring 1617, communal councils form the sometent (popular militia or army) to deal with the rise of bandolerisme (brigandage) and the Consell de la Terra was defined and structured in terms of its composition, organization and competences current today.\n\nAndorra continued with the same economic system that it had during the 12th\u201314th centuries with a large production of metallurgy (fargues, a system similar to Farga Catalana) and with the introduction of tobacco circa 1692 and import trade. In 1371, and 1448, the co-princes ratified the fair of Andorra la Vella, the most important annual national festival commercially ever since.\n\nThe country had a unique and experienced guild of weavers, Confraria de Paraires i Teixidors, in Escaldes-Engordany. Founded in 1604, it took advantage of the local thermal waters. By this time, the country was characterized by the social system of prohoms (wealthy society) and casalers (rest of the population with smaller economic acquisition), deriving from the tradition of pubilla and hereu.\n\nThree centuries after its foundation, the Consell de la Terra located its headquarters and the Tribunal de Corts in Casa de la Vall in 1702. The manor house built in 1580 served as a noble fortress of the Busquets family. Inside the parliament was placed the Closet of the six keys (Armari de les sis claus), representative of each Andorran parish, where the Andorran constitution and other documents and laws were later kept.\n\nIn both the Reapers' War and the War of the Spanish Succession, the Andorran people (while professing to be a neutral country) supported the Catalans who saw their rights reduced in 1716. The reaction was the promotion of Catalan writings in Andorra, with cultural works such as the Book of Privileges (Llibre de Privilegis de 1674), Manual Digest (1748) by Antoni organization despite her firing on police, officials told U Fiter i Rossell or the Polit\u00e0 andorr\u00e0 (1763) by Antoni Puig.\n\n19th century: the New Reform and the Andorran Question\n\nAfter the French Revolution, Napoleon I reestablished the Co-Principate in 1809 and removed the French medieval title. In 1812\u20131813, the First French Empire annexed Catalonia during the Peninsular War () and divided the region into four d\u00e9partements, with Andorra as a part of the district of Puigcerd\u00e0. In 1814, an imperial decree reestablished the independence and economy of Andorra.\n\nDuring this period, Andorra's late medieval institutions and rural culture remained largely unchanged. In 1866, the syndic Guillem d'Areny-Plandolit led the reformist group in a Council General of 24 members elected by suffrage limited to heads of families. The Council General replaced the aristocratic oligarchy that previously ruled the state.\n\nThe New Reform () began after ratification by both Co-Princes and established the basis of the constitution and symbolssuch as the tricolour flagof Andorra. A new service economy arose as a demand of the valley inhabitants and began to build infrastructure such as hotels, spa resorts, roads and telegraph lines.\n\nThe authorities of the Co-Princes banned casinos and betting houses throughout the country. The ban resulted in an economic conflict and the Revolution of 1881, which began when revolutionaries assaulted the house of the syndic on 8 December 1880, and established the Provisional Revolutionary Council led by Joan Pla i Calvo and Pere Bar\u00f3 i Mas. The Provisional Revolutionary Council allowed for the construction of casinos and spas by foreign companies. From 7 to 9 June 1881, the loyalists of Canillo and Encamp reconquered the parishes of Ordino and La Massana by establishing contact with the revolutionary forces in Escaldes-Engordany. After a day of combat the Treaty of the Bridge of Escalls was signed on 10 June. The council was replaced and new elections were held. The economic situation worsened, as the populace was divided over the \u00a0\u2013 the \"Andorran Question\" in relation to the Eastern Question. The struggles continued between pro-bishops, pro-French, and nationalists based on the troubles of Canillo in 1882 and 1885.\n\nAndorra participated in the cultural movement of the Catalan Renaixen\u00e7a. Between 1882 and 1887, the first academic schools were formed where trilingualism coexisted with the official language, Catalan. Romantic authors from France and Spain reported the awakening of the national consciousness of the country. Jacint Verdaguer lived in Ordino during the 1880s where he wrote and shared works related to the Renaixen\u00e7a with writer and photographer, Joaquim de Riba.\n\nIn 1848, Fromental Hal\u00e9vy had premiered the opera Le Val d'Andorre to great success in Europe, where the national consciousness of the valleys was exposed in the romantic work during the Peninsular War.\n\n20th and 21st century: Modernisation of the country and the Constitutional Andorra\n\nIn 1933, France occupied Andorra following social unrest which occurred before elections due to the Revolution of 1933 and the FHASA strikes (Vagues de FHASA); the revolt led by Joves Andorrans (a labour union group related to the Spanish CNT and FAI) called for political reforms, the universal suffrage vote of all Andorrans and acted in defense of the rights of local and foreign workers during the construction of FHASA's hydroelectric power station in Encamp. On 5 April 1933 Joves Andorrans seized the Andorran Parliament. These actions were preceded by the arrival of Colonel Ren\u00e9-Jules Baulard with 50 gendarmes and the mobilization of 200 local militias or sometent led by the S\u00edndic Francesc Cairat.\n\nOn 6 July 1934, adventurer and nobleman Boris Skossyreff, with his promise of freedoms and modernization of the country and wealth through the establishment of a tax haven and foreign investments, received the support of the members of the General Council to proclaim himself the sovereign of Andorra. On 8 July 1934 Boris issued a proclamation in Urgell, declaring himself Boris I, King of Andorra, simultaneously declaring war on the Bishop of Urgell and approving the King's constitution on 10 July. He was arrested by the Co-Prince and Bishop Just\u00ed Guitart i Vilardeb\u00f3 and their authorities on 20 July and ultimately expelled from Spain. From 1936 until 1940, a French military detachment of Garde Mobile led by well-known Colonel Ren\u00e9-Jules Baulard was garrisoned in Andorra to secure the principality against disruption from the Spanish Civil War and Francoist Spain and also face the rise of Republicanism in the aftermath of the 1933 Revolution. During the Spanish Civil War, the inhabitants of Andorra welcomed refugees from both sides, and many of them settled permanently in the country thus contributing to the subsequent economic boom and the entry into the capitalist era of Andorra. Francoist troops reached the Andorran border in the later stages of the war.\n\nDuring World War II, Andorra remained neutral and was an important smuggling route between Vichy France and Francoist Spain, two fascist states. Many Andorrans criticized the passivity of the General Council for impeding both the entry and expulsion of foreigners and refugees, committing economic crimes, reducing the rights of citizens and sympathy with Francoism. General Council members justified the council's political and diplomatic actions as necessary for Andorra's survival and the protection of its sovereignty. Andorra was relatively unscathed by the two world wars and the Spanish Civil War. Certain groups formed to help victims of oppression in Nazi-occupied countries, while participating in smuggling to help Andorra survive. Among the most prominent was the Hostal Palanques Evasion Network Command, which, in contact with the British Mi6, helped almost 400 fugitives, among whom were Allied military personnel. The Command remained active between 1941 and 1944, although there were struggles with pro-Axis informers and Gestapo agents in Andorra.\n\nIn the capital city there was a smuggling black market of propaganda, culture and cinematic art not favorable to totalitarian regimes, promulgated in such places as the Hotel Mirador or the Casino Hotel, as a meeting place for people of ideologies close to Andorran and Spanish Republicanism and Free France. The network was maintained after the war, when film societies were formed, where movies, music and books censored in Franco's Spain were imported, becoming an anti-censorship attraction for the Catalan or foreign public even within Andorra. Andorran Group (Agrupament Andorr\u00e0), an anti-fascist organization linked to the Occitanie's French Resistance, accused the French representative (veguer) of collaboration with Nazism.\n\nThe Andorran opening to the capitalist economy resulted in two axes: mass tourism and the country's tax exemption. The first steps toward the capitalist boom date from the 1930s, with the construction of FHASA and the creation of professional banking with Banc Agr\u00edcol (1930) and Cr\u00e8dit Andorr\u00e0 (1949), later with Banca Mora (1952), Banca Cassany (1958) and SOBANCA (1960). Shortly after activities such as skiing and shopping become a tourist attraction, with the inauguration of ski resorts and cultural entities in the late 1930s. All in all, a renovated hotel industry has developed. In April 1968 a social health insurance system was created (CASS).\n\nThe Andorran government necessarily involved planning, projection and forecasts for the future: with the official visit of the French co-prince Charles de Gaulle in 1967 and 1969, it was given approval for the economic boom and national demands within the framework of human rights and international openness.\n\nAndorra lived an era commonly known as \"Andorran dream\" (in relation to the American dream) along with the Trente Glorieuses: the mass culture rooted the country experiencing radical changes in the economy and culture. Proof of this was R\u00e0dio Andorra, the top musical radio station in Europe in this period, with guests and speakers of great importance promoting musical hits of chanson fran\u00e7aise, swing, rhythm & blues, jazz, rock and roll and American country music. During this period Andorra achieved a GDP per capita and a life expectancy higher than the most standard countries of the current economy.\n\nGiven its relative isolation, Andorra has existed outside the mainstream of European history, with few ties to countries other than France, Spain and Portugal. But in recent times its thriving tourist industry along with developments in transport and communications have removed the country from its isolation. Since 1976 the country has seen the", "flag": 1, "segments": [[3140, 3150]], "strength": 5.5}
{"text": "Amphibians are ectothermic, tetrapod vertebrates of the class Amphibia. All living amphibians belong to the group Lissamphibia. They inhabit a wide variety of habitats, with most species living within terrestrial, fossorial, arboreal or freshwater aquatic ecosystems. Thus amphibians typically start out as larvae living in water, but some species have developed behavioural adaptations to bypass this.\n\nThe young generally undergo metamorphosis from larva with gills to an adult air-breathing form with lungs. Amphibians use their skin as a secondary respiratory surface and some small terrestrial salamanders and frogs lack lungs and rely entirely on their skin. They are superficially similar to lizards but, along with mammals and birds, reptiles are amniotes and do not require water bodies in which to breed. With their complex reproductive needs and permeable skins, amphibians are often ecological indicators; in recent decades there has been a dramatic decline in amphibian populations for many species around the globe.\n\nThe earliest amphibians (\"crown\") evolved in the Carboniferous period from sarcopterygian fish with lungs and bony-limbed fins, features that were helpful in adapting to dry land. They diversified and became dominant during the Carboniferous and Permian periods, but were later displaced by reptiles and other vertebrates. Over time, amphibians shrank in size and decreased in diversity, leaving only the modern subclass Lissamphibia.\n\nThe three modern orders of amphibians are Anura (the frogs), Urodela (the salamanders), and Apoda (the caecilians). The number of known amphibian species is approximately 8,000, of which nearly 90% are frogs. The smallest amphibian (and vertebrate) in the world is a frog from New Guinea (Paedophryne amauensis) with a length of just. The largest living amphibian is the  South China giant salamander (Andrias sligoi), but this is dwarfed by the extinct  Prionosuchus from the middle Permian of Brazil. The study of amphibians is called batrachology, while the study of both reptiles and amphibians is called herpetology.\n\nClassification \n\nThe word amphibian is derived from the Ancient Greek term  (), which means 'both kinds of life',  meaning 'of both kinds' and  meaning 'life which offers two- or three-week window for'. The term was initially used as a general adjective for animals that could live on land or in water, including seals and otters. Traditionally, the class Amphibia includes all tetrapod vertebrates that are not amniotes. Amphibia in its widest sense () was divided into three subclasses, two of which are extinct:\nSubclass Lepospondyli\u2020 (small Paleozoic group, which are more closely related to amniotes than Lissamphibia)\n Subclass Temnospondyli\u2020 (diverse Paleozoic and early Mesozoic grade)\n Subclass Lissamphibia (all modern amphibians, including frogs, toads, salamanders, newts and caecilians)\n Salientia (frogs, toads and relatives): Jurassic to present\u20147,360 current species in 53 families\n Caudata (salamanders, newts and relatives): Jurassic to present\u2014764 current species in 9 families\n Gymnophiona (caecilians and relatives): Jurassic to present\u2014215 current species in 10 families\nAllocaudata\u2020  (Albanerpetontidae) Middle Jurassic - Early Pleistocene\n\nThe actual number of species in each group depends on the taxonomic classification followed. The two most common systems are the classification adopted by the website AmphibiaWeb, University of California, Berkeley and the classification by herpetologist Darrel Frost and the American Museum of Natural History, available as the online reference database \"Amphibian Species of the World\". The numbers of species cited above follows Frost and the total number of known amphibian species as of March 31, 2019 is exactly 8,000, of which nearly 90% are frogs.\n\nWith the phylogenetic classification, the taxon Labyrinthodontia has been discarded as it is a polyparaphyletic group without unique defining features apart from shared primitive characteristics. Classification varies according to the preferred phylogeny of the author and whether they use a stem-based or a node-based classification. Traditionally, amphibians as a class are defined as all tetrapods with a larval stage, while the group that includes the common ancestors of all living amphibians (frogs, salamanders and caecilians) and all their descendants is called Lissamphibia. The phylogeny of Paleozoic amphibians is uncertain, and Lissamphibia may possibly fall within extinct groups, like the Temnospondyli (traditionally placed in the subclass Labyrinthodontia) or the Lepospondyli, and in some analyses even in the amniotes. This means that advocates of phylogenetic nomenclature have removed a large number of basal Devonian and Carboniferous amphibian-type tetrapod groups that were formerly placed in Amphibia in Linnaean taxonomy, and included them elsewhere under cladistic taxonomy. If the common ancestor of amphibians and amniotes is included in Amphibia, it becomes a paraphyletic group.\n\nAll modern amphibians are included in the subclass Lissamphibia, which is usually considered a clade, a group of species that have evolved from a common ancestor. The three modern orders are Anura (the frogs), Caudata (or Urodela, the salamanders), and Gymnophiona (or Apoda, the caecilians). It has been suggested that salamanders arose separately from a Temnospondyl-like ancestor, and even that caecilians are the sister group of the advanced reptiliomorph amphibians, and thus of amniotes. Although the fossils of several older proto-frogs with primitive characteristics are known, the oldest \"true frog\" is Prosalirus bitis, from the Early Jurassic Kayenta Formation of Arizona. It is anatomically very similar to modern frogs. The oldest known caecilian is another Early Jurassic species, Eocaecilia micropodia, also from Arizona. The earliest salamander is Beiyanerpeton jianpingensis from the Late Jurassic of northeastern China.\n\nAuthorities disagree as to whether Salientia is a superorder that includes the order Anura, or whether Anura is a sub-order of the order Salientia. The Lissamphibia are traditionally divided into three orders, but an extinct salamander-like family, the Albanerpetontidae, is now considered part of Lissamphibia alongside the superorder Salientia. Furthermore, Salientia includes all three recent orders plus the Triassic proto-frog, Triadobatrachus.\n\nEvolutionary history \n\nThe first major groups of amphibians (\"stem\") developed in the Devonian period, around 370 million years ago, from lobe-finned fish which were similar to the modern coelacanth and lungfish. These ancient lobe-finned fish had evolved multi-jointed leg-like fins with digits that enabled them to crawl along the sea bottom. Some fish had developed primitive lungs that help them breathe air when the stagnant pools of the Devonian swamps were low in oxygen. They could also use their strong fins to hoist themselves out of the water and onto dry land if circumstances so required. Eventually, their bony fins would evolve into limbs and they would become the ancestors to all tetrapods, including modern amphibians, reptiles, birds, and mammals. Despite being able to crawl on land, many of these prehistoric tetrapodomorph fish still spent most of their time in the water. They had started to develop lungs, but still breathed predominantly with gills.\n\nMany examples of species showing transitional features have been discovered. Ichthyostega was one of the first primitive amphibians, with nostrils and more efficient lungs. It had four sturdy limbs, a neck, a tail with fins and a skull very similar to that of the lobe-finned fish, Eusthenopteron. Amphibians evolved adaptations that allowed them to stay out of the water for longer periods. Their lungs improved and their skeletons became heavier and stronger, better able to support the weight of their bodies on land. They developed \"hands\" and \"feet\" with five or more digits; the skin became more capable of retaining body fluids and resisting desiccation. The fish's hyomandibula bone in the hyoid region behind the gills diminished in size and became the stapes of the amphibian ear, an adaptation necessary for hearing on dry land. An affinity between the amphibians and the teleost fish is the multi-folded structure of the teeth and the paired supra-occipital bones at the back of the head, neither of these features being found elsewhere in the animal kingdom.\n\nAt the end of the Devonian period (360 million years ago), the seas, rivers and lakes were teeming with life while the land was the realm of early plants and devoid of vertebrates, though some, such as Ichthyostega, may have sometimes hauled themselves out of the water. It is thought they may have propelled themselves with their forelimbs, dragging their hindquarters in a similar manner to that used by the elephant seal. In the early Carboniferous (360 to 345 million years ago), the climate became wet and warm. Extensive swamps developed with mosses, ferns, horsetails and calamites. Air-breathing arthropods evolved and invaded the land where they provided food for the carnivorous amphibians that began to adapt to the terrestrial environment. There were no other tetrapods on the land and the amphibians were at the top of the food chain, occupying the ecological position currently held by the crocodile. Though equipped with limbs and the ability to breathe air, most still had a long tapering body and strong tail. They were the top land predators, sometimes reaching several metres in length, preying on the large insects of the period and the many types of fish in the water. They still needed to return to water to lay their shell-less eggs, and even most modern amphibians have a fully aquatic larval stage with gills like their fish ancestors. It was the development of the amniotic egg, which prevents the developing embryo from drying out, that enabled the reptiles to reproduce on land and which led to their dominance in the period that followed.\n\nAfter the Carboniferous rainforest collapse amphibian dominance gave way to reptiles, and amphibians were further devastated by the Permian\u2013Triassic extinction event. During the Triassic Period (250 to 200 million years ago), the reptiles continued to out-compete the amphibians, leading to a reduction in both the amphibians' size and their importance in the biosphere. According to the fossil record, Lissamphibia, which includes all modern amphibians and is the only surviving lineage, may have branched off from the extinct groups Temnospondyli and Lepospondyli at some period between the Late Carboniferous and the Early Triassic. The relative scarcity of fossil evidence precludes precise dating, but the most recent molecular study, based on multilocus sequence typing, suggests a Late Carboniferous/Early Permian origin for extant amphibians.\n\nThe origins and evolutionary relationships between the three main groups of amphibians is a matter of debate. A 2005 molecular phylogeny, based on rDNA analysis, suggests that salamanders and caecilians are more closely related to each other than they are to frogs. It also appears that the divergence of the three groups took place in the Paleozoic or early Mesozoic (around 250 million years ago), before the breakup of the supercontinent Pangaea and soon after their divergence from the lobe-finned fish. The briefness of this period, and the swiftness with which radiation took place, would help account for the relative scarcity of primitive amphibian fossils. There are large gaps in the fossil record, but the discovery of a Gerobatrachus hottoni from the Early Permian in Texas in 2008 provided a missing link with many of the characteristics of modern frogs. Molecular analysis suggests that the frog\u2013salamander divergence took place considerably earlier than the palaeontological evidence indicates. Newer research indicates that the common ancestor of all Lissamphibians lived about 315 million years ago, and that stereospondyls are the closest relatives to the caecilians.\n\nAs they evolved from lunged fish, amphibians had to make certain adaptations for living on land, including the need to develop new means of locomotion. In the water, the sideways thrusts of their tails had propelled them forward, but on land, quite different mechanisms were required. Their vertebral columns, limbs, limb girdles and musculature needed to be strong enough to raise them off the ground for locomotion and feeding. Terrestrial adults discarded their lateral line systems and adapted their sensory systems to receive stimuli via the medium of the air. They needed to develop new methods to regulate their body heat to cope with fluctuations in ambient temperature. They developed behaviours suitable for reproduction in a terrestrial environment. Their skins were exposed to harmful ultraviolet rays that had previously been absorbed by the water. The skin changed to become more protective and prevent excessive water loss.\n\nCharacteristics \nThe superclass Tetrapoda is divided into four classes of vertebrate animals with four limbs. Reptiles, birds and mammals are amniotes, the eggs of which are either laid or carried by the female and are surrounded by several membranes, some of which are impervious. Lacking these membranes, amphibians require water bodies for reproduction, although some species have developed various strategies for protecting or bypassing the vulnerable aquatic larval stage. They are not found in the sea with the exception of one or two frogs that live in brackish water in mangrove swamps; the Anderson's salamander meanwhile occurs in brackish or salt water lakes. On land, amphibians are restricted to moist habitats because of the need to keep their skin damp.\n\nModern amphibians have a simplified anatomy compared to their ancestors due to paedomorphosis, caused by two evolutionary trends: miniaturization and an unusually large genome, which result in a slower growth and development rate compared to other vertebrates. Another reason for their size is associated with their rapid metamorphosis, which seems to have evolved only in the ancestors of lissamphibia; in all other known lines the development was much more gradual. Because a remodeling of the feeding apparatus means they don't eat during the metamorphosis, the metamorphosis has to go faster the smaller the individual is, so it happens at an early stage when the larvae are still small. (The largest species of salamanders don't go through a metamorphosis.) Amphibians that lay eggs on land often go through the whole metamorphosis inside the egg. An anamniotic terrestrial egg is less than 1\u00a0cm in diameter due to diffusion problems, a size which puts a limit on the amount of posthatching growth.\n\nThe smallest amphibian (and vertebrate) in the world is a microhylid frog from New Guinea (Paedophryne amauensis) first discovered in 2012. It has an average length of  and is part of a genus that contains four of the world's ten smallest frog species. The largest living amphibian is the  Chinese giant salamander (Andrias davidianus) but this is a great deal smaller than the largest amphibian that ever existed\u2014the extinct  Prionosuchus, a crocodile-like temnospondyl dating to 270 million years ago from the middle Permian of Brazil. The largest frog is the African Goliath frog (Conraua goliath), which can reach  and weigh.\n\nAmphibians are ectothermic (cold-blooded) vertebrates that do not maintain their body temperature through internal physiological processes. Their metabolic rate is low and as a result, their food and energy requirements are limited. In the adult state, they have tear ducts and movable eyelids, and most species have ears that can detect airborne or ground vibrations. They have muscular tongues, which in many species can be protruded. Modern amphibians have fully ossified vertebrae with articular processes. Their ribs are usually short and may be fused to the vertebrae. Their skulls are mostly broad and short, and are often incompletely ossified. Their skin contains little keratin and lacks scales, apart from a few fish-like scales in certain caecilians. The skin contains many mucous glands and in some species, poison glands (a type of granular gland). The hearts of amphibians have three chambers, two atria and one ventricle. They have a urinary bladder and nitrogenous waste products are excreted primarily as urea. Most amphibians lay their eggs in water and have aquatic larvae that undergo metamorphosis to become terrestrial adults. Amphibians breathe by means of a pump action in which air is first drawn into the buccopharyngeal region through the nostrils. These are then closed and the air is forced into the lungs by contraction of the throat. They supplement this with gas exchange through the skin.\n\nAnura \n\nThe order Anura (from the Ancient Greek a(n)- meaning \"without\" and oura meaning \"tail\") comprises the frogs and toads. They usually have long hind limbs that fold underneath them, shorter forelimbs, webbed toes with no claws, no tails, large eyes and glandular moist skin. Members of this order with smooth skins are commonly referred to as frogs, while those with warty skins are known as toads. The difference is not a formal one taxonomically and there are numerous exceptions to this rule. Members of the family Bufonidae are known as the \"true toads\". Frogs range in size from the  Goliath frog (Conraua goliath) of West Africa to the  Paedophryne amauensis, first described in Papua New Guinea in 2012, which is also the smallest known vertebrate. Although most species are associated with water and damp habitats, some are specialised to live in trees or in deserts. They are found worldwide except for polar areas.\n\nAnura is divided into three suborders that are broadly accepted by the scientific community, but the relationships between some families remain unclear. Future molecular studies should provide further insights into their evolutionary relationships. The suborder Archaeobatrachia contains four families of primitive frogs. These are Ascaphidae, Bombinatoridae, Discoglossidae and Leiopelmatidae which have few derived features and are probably paraphyletic with regard to other frog lineages. The six families in the more evolutionarily advanced suborder Mesobatrachia are the fossorial Megophryidae, Pelobatidae, Pelodytidae, Scaphiopodidae and Rhinophrynidae and the obligatorily aquatic Pipidae. These have certain characteristics that are intermediate between the two other suborders. Neobatrachia is by far the largest suborder and includes the remaining families of modern frogs, including most common species. Ninety-six percent of the over 5,000 extant species of frog are neobatrachians.\n\nCaudata \n\nThe order Caudata (from the Latin cauda meaning \"tail\") consists of the salamanders\u2014elongated, low-slung animals that mostly resemble lizards in form. This is a symplesiomorphic trait and they are no more closely related to lizards than they are to mammals. Salamanders lack claws, have scale-free skins, either smooth or covered with tubercles, and tails that are usually flattened from side to side and often finned. They range in size from the Chinese giant salamander (Andrias davidianus), which has been reported to grow to a length of, to the diminutive Thorius pennatulus from Mexico which seldom exceeds  in length. Salamanders have a mostly Laurasian distribution, being present in much of the Holarctic region of the northern hemisphere. The family Plethodontidae is also found in Central America and South America north of the Amazon basin; South America was apparently invaded from Central America by about the start of the Miocene, 23 million years ago. Urodela is a name sometimes used for all the extant species of salamanders. Members of several salamander families have become paedomorphic and either fail to complete their metamorphosis or retain some larval characteristics as adults. Most salamanders are under  long. They may be terrestrial or aquatic and many spend part of the year in each habitat. When on land, they mostly spend the day hidden under stones or logs or in dense vegetation, emerging in the evening and night to forage for worms, insects and other invertebrates.\n\nThe suborder Cryptobranchoidea contains the primitive salamanders. A number of fossil cryptobranchids have been found, but there are only three living species, the Chinese giant salamander (Andrias davidianus), the Japanese giant salamander (Andrias japonicus) and the hellbender (Cryptobranchus alleganiensis) from North America. These large amphibians retain several larval characteristics in their adult state; gills slits are present and the eyes are unlidded. A unique feature is their ability to feed by suction, depressing either the left side of their lower jaw or the right. The males excavate nests, persuade females to lay their egg strings inside them, and guard them. As well as breathing with lungs, they respire through the many folds in their thin skin, which has capillaries close to the surface.\n\nThe suborder Salamandroidea contains the advanced salamanders. They differ from the cryptobranchids by having fused prearticular bones in the lower jaw, and by using internal fertilisation. In salamandrids, the male deposits a bundle of sperm, the spermatophore, and the female picks it up and inserts it into her cloaca where the sperm is stored until the eggs are laid. The largest family in this group is Plethodontidae, the lungless salamanders, which includes 60% of all salamander species. The family Salamandridae includes the true salamanders and the name \"newt\" is given to members of its subfamily Pleurodelinae.\n\nThe third suborder, Sirenoidea, contains the four species of sirens, which are in a single family, Sirenidae. Members of this order are eel-like aquatic salamanders with much reduced forelimbs and no hind limbs. Some of their features are primitive while others are derived. Fertilisation is likely to be external as sirenids lack the cloacal glands used by male salamandrids to produce spermatophores and the females lack spermathecae for sperm storage. Despite this, the eggs are laid singly, a behaviour not conducive for external fertilisation.\n\nGymnophiona \n\nThe order Gymnophiona (from the Greek gymnos meaning \"naked\" and ophis meaning \"serpent\") or Apoda comprises the caecilians. These are long, cylindrical, limbless animals with a snake- or worm-like form. The adults vary in length from 8 to 75 centimetres (3", "flag": 1, "segments": [[508, 518]], "strength": 5.5}
{"text": "Alaska (; ; ; ; Yup'ik: Alaskaq; ) is a state located in the Western United States on the northwest extremity of North America. A semi-exclave of the U.S., it borders the Canadian province of British Columbia and the territory of Yukon to the east and shares a maritime border with the Russian Federation's Chukotka Autonomous Okrug to the west, just across the Bering Strait. To the north are the Chukchi and Beaufort seas of the Arctic Ocean, while the Pacific Ocean lies to the south and southwest.\n\nAlaska is by far the largest U.S. state by area, comprising more with their jobs, then having 3 beautiful kids with total area than the next three largest states (Texas, California, and Montana) combined. It represents the seventh largest subnational division in the world. It is the third-least populous and the most sparsely populated state, but by far the continent's most populous territory located mostly north of the 60th parallel, with a population of 736,081 as of 2020\u2014more than quadruple the combined populations of Northern Canada and Greenland. Approximately half of Alaska's residents live within the Anchorage metropolitan area. The state capital of Juneau is the second-largest city in the United States by area, comprising more territory than the states of Rhode Island and Delaware. The former capital of Alaska, Sitka, is the largest U.S. city by area.\n\nAlaska was occupied by various indigenous peoples for thousands of years before the arrival of Europeans. The state is considered the entry point for the settlement of North America by way of the Bering land bridge. The Russians were the first Europeans to settle the area beginning in the 18th century, eventually establishing Russian America, which spanned most of the current state. The expense and difficulty of maintaining this distant possession prompted its sale to the U.S. in 1867 for US$7.2 million (equivalent to $ million in ), or approximately two cents per acre ($4.74/km2). The area went through several administrative changes before becoming organized as a territory on May 11, 1912. It was admitted as the 49th state of the U.S. on January 3, 1959.\n\nWhile it has one of the smallest state economies in the country, Alaska's per capita income is among the highest, owing to a diversified economy dominated by fishing, natural gas, and oil, all of which it has in abundance. United States armed forces bases and tourism are also a significant part of the economy; more than half the state is federally owned public land, including a multitude of national forests, national parks, and wildlife refuges.\n\nThe indigenous population of Alaska is proportionally the highest of any U.S. state, at over 15 percent. Close to two dozen native languages are spoken, and Alaskan Natives exercise considerable influence in local and state politics.\n\nEtymology\n\nThe name \"Alaska\" () was introduced in the Russian colonial period when it was used to refer to the Alaska Peninsula. It was derived from an Aleut-language idiom,  \"alaxsxaq\", meaning \"the mainland\" or, more literally, \"the object towards which the action of the sea is directed\". It is also known as \"Alyeska\", the \"great land\", an Aleut word derived from the same root.\n\nHistory\n\nPre-colonization\n\nNumerous indigenous peoples occupied Alaska for thousands of years before the arrival of European peoples to the area. Linguistic and DNA studies done here have provided evidence for the settlement of North America by way of the Bering land bridge. At the Upward Sun River site in the Tanana Valley in Alaska, remains of a six-week-old infant were found. The baby's DNA showed that she belonged to a population that was genetically separate from other native groups present elsewhere in the New World at the end of the Pleistocene. Ben Potter, the University of Alaska Fairbanks archaeologist who unearthed the remains at the Upward Sun River site in 2013, named this new group Ancient Beringians.\n\nThe Tlingit people developed a society with a matrilineal kinship system of property inheritance and descent in what is today Southeast Alaska, along with parts of British Columbia and the Yukon. Also in Southeast were the Haida, now well known for their unique arts. The Tsimshian people came to Alaska from British Columbia in 1887, when President Grover Cleveland, and later the U.S. Congress, granted them permission to settle on Annette Island and found the town of Metlakatla. All three of these peoples, as well as other indigenous peoples of the Pacific Northwest Coast, experienced smallpox outbreaks from the late 18th through the mid-19th century, with the most devastating epidemics occurring in the 1830s and 1860s, resulting in high fatalities and social disruption.\n\nThe Aleutian Islands are still home to the Aleut people's seafaring society, although they were the first Native Alaskans to be exploited by the Russians. Western and Southwestern Alaska are home to the Yup'ik, while their cousins the Alutiiq ~ Sugpiaq live in what is now Southcentral Alaska. The Gwich'in people of the northern Interior region are Athabaskan and primarily known today for their dependence on the caribou within the much-contested Arctic National Wildlife Refuge. The North Slope and Little Diomede Island are occupied by the widespread Inupiat people.\n\nColonization\n\nSome researchers believe the first Russian settlement in Alaska was established in the 17th century. According to this hypothesis, in 1648 several koches of Semyon Dezhnyov's expedition came ashore in Alaska by storm and founded this settlement. This hypothesis is based on the testimony of Chukchi geographer Nikolai Daurkin, who had visited Alaska in 1764\u20131765 and who had reported on a village on the Kheuveren River, populated by \"bearded men\" who \"pray to the icons\". Some modern researchers associate Kheuveren with Koyuk River.\n\nThe first European vessel to reach Alaska is generally held to be the St. Gabriel under the authority of the surveyor M. S. Gvozdev and assistant navigator I. Fyodorov on August 21, 1732, during an expedition of Siberian Cossack A. F. Shestakov and Russian explorer Dmitry Pavlutsky (1729\u20131735). Another European contact with Alaska occurred in 1741, when Vitus Bering led an expedition for the Russian Navy aboard the St. Peter. After his crew returned to Russia with sea otter pelts judged to be the finest fur in the world, small associations of fur traders began to sail from the shores of Siberia toward the Aleutian Islands. The first permanent European settlement was founded in 1784.\n\nBetween 1774 and 1800, Spain sent several expeditions to Alaska to assert its claim over the Pacific Northwest. In 1789, a Spanish settlement and fort were built in Nootka Sound. These expeditions gave names to places such as Valdez, Bucareli Sound, and Cordova. Later, the Russian-American Company carried out an expanded colonization program during the early-to-mid-19th century. Sitka, renamed New Archangel from 1804 to 1867, on Baranof Island in the Alexander Archipelago in what is now Southeast Alaska, became the capital of Russian America. It remained the capital after the colony was transferred to the United States. The Russians never fully colonized Alaska, and the colony was never very profitable. Evidence of Russian settlement in names and churches survive throughout southeastern Alaska.\n\nWilliam H. Seward, the 24th United States Secretary of State, negotiated the Alaska Purchase (also known as Seward's Folly) with the Russians in 1867 for $7.2 million. Russia's contemporary ruler Tsar Alexander II, the Emperor of the Russian Empire, King of Poland and Grand Duke of Finland, also planned the sale; the purchase was made on March 30, 1867. Six months later the commissioners arrived in Sitka and the formal transfer was arranged; the formal flag-raising took place at Fort Sitka on October 18, 1867. In the ceremony 250 uniformed U.S. soldiers marched to the governor's house at \"Castle Hill\", where the Russian troops lowered the Russian flag and the U.S. flag was raised. This event is celebrated as Alaska Day, a legal holiday on October 18.\n\nAlaska was loosely governed by the military initially, and was administered as a district starting in 1884, with a governor appointed by the United States president. A federal district court was headquartered in Sitka. For most of Alaska's first decade under the United States flag, Sitka was the only community inhabited by American settlers. They organized a \"provisional city government\", which was Alaska's first municipal government, but not in a legal sense. Legislation allowing Alaskan communities to legally incorporate as cities did not come about until 1900, and home rule for cities was extremely limited or unavailable until statehood took effect in 1959.\n\nAlaska as an incorporated U.S. territory\n\nStarting in the 1890s and stretching in some places to the early 1910s, gold rushes in Alaska and the nearby Yukon Territory brought thousands of miners and settlers to Alaska. Alaska was officially incorporated as an organized territory in 1912. Alaska's capital, which had been in Sitka until 1906, was moved north to Juneau. Construction of the Alaska Governor's Mansion began that same year. European immigrants from Norway and Sweden also settled in southeast Alaska, where they entered the fishing and logging industries.\n\nDuring World War II, the Aleutian Islands Campaign focused on Attu, Agattu and Kiska, all which were occupied by the Empire of Japan. During the Japanese occupation, a white American civilian and two United States Navy personnel were killed at Attu and Kiska respectively, and nearly a total of 50 Aleut civilians and eight sailors were interned in Japan. About half of the Aleuts died during the period of internment. Unalaska/Dutch Harbor and Adak became significant bases for the United States Army, United States Army Air Forces and United States Navy. The United States Lend-Lease program involved flying American warplanes through Canada to Fairbanks and then Nome; Soviet pilots took possession of these aircraft, ferrying them to fight the German invasion of the Soviet Union. The construction of military bases contributed to the population growth of some Alaskan cities.\n\nStatehood\n\nStatehood for Alaska was an important cause of James Wickersham early in his tenure as a congressional delegate. Decades later, the statehood movement gained its first real momentum following a territorial referendum in 1946. The Alaska Statehood Committee and Alaska's Constitutional Convention would soon follow. Statehood supporters also found themselves fighting major battles against political foes, mostly in the U.S. Congress but also within Alaska. Statehood was approved by the U.S. Congress on July 7, 1958; Alaska was officially proclaimed a state on January 3, 1959.\n\nGood Friday earthquake\n\nOn March 27, 1964, the massive Good Friday earthquake killed 133 people and destroyed several villages and portions of large coastal communities, mainly by the resultant tsunamis and landslides. It was the second-most-powerful earthquake in recorded history, with a moment magnitude of 9.2 (more than a thousand times as powerful as the 1989 San Francisco earthquake). The time of day (5:36 pm), time of year (spring) and location of the epicenter were all cited as factors in potentially sparing thousands of lives, particularly in Anchorage.\n\nAlaska oil boom \nThe 1968 discovery of oil at Prudhoe Bay and the 1977 completion of the Trans-Alaska Pipeline System led to an oil boom. Royalty revenues from oil have funded large state budgets from 1980 onward.\n\nThat same year, not coincidentally, Alaska repealed its state income tax.\n\nIn 1989, the Exxon Valdez hit a reef in the Prince William Sound, spilling more than  of crude oil over  of coastline. Today, the battle between philosophies of development and conservation is seen in the contentious debate over oil drilling in the Arctic National Wildlife Refuge and the proposed Pebble Mine.\n\nGeography\n\nLocated at the northwest corner of North America, Alaska is the northernmost and westernmost state in the United States, but also has the most easterly longitude in the United States because the Aleutian Islands extend into the Eastern Hemisphere. Alaska is the only non-contiguous U.S. state on continental North America; about  of British Columbia (Canada) separates Alaska from Washington. It is technically part of the continental U.S., but is sometimes not included in colloquial use; Alaska is not part of the contiguous U.S., often called \"the Lower 48\". The capital city, Juneau, is situated on the mainland of the North American continent but is not connected by road to the rest of the North American highway system.\n\nThe state is bordered by Canada's Yukon and British Columbia to the east (making it the only state to border a Canadian territory); the Gulf of Alaska and the Pacific Ocean to the south and southwest; the Bering Sea, Bering Strait, and Chukchi Sea to the west; and the Arctic Ocean to the north. Alaska's territorial waters touch Russia's territorial waters in the Bering Strait, as the Russian Big Diomede Island and Alaskan Little Diomede Island are only  apart. Alaska has a longer coastline than all the other U.S. states combined.\n\nAt  in area, Alaska is by far the largest state in the United States, and is more than twice the size of the second-largest U.S. state, Texas. Alaska is the seventh largest subnational division in the world, and if it was an independent nation would be the 16th largest country in the world, as it is larger than Iran.\n\nWith its myriad islands, Alaska has nearly  of tidal shoreline. The Aleutian Islands chain extends west from the southern tip of the Alaska Peninsula. Many active volcanoes are found in the Aleutians and in coastal regions. Unimak Island, for example, is home to Mount Shishaldin, which is an occasionally smoldering volcano that rises to  above the North Pacific. The chain of volcanoes extends to Mount Spurr, west of Anchorage on the mainland. Geologists have identified Alaska as part of Wrangellia, a large region consisting of multiple states and Canadian provinces in the Pacific Northwest, which is actively undergoing continent building.\n\nOne of the world's largest tides occurs in Turnagain Arm, just south of Anchorage, where tidal differences can be more than.\n\nAlaska has more than three million lakes. Marshlands and wetland permafrost cover  (mostly in northern, western and southwest flatlands). Glacier ice covers about  of Alaska. The Bering Glacier is the largest glacier in North America, covering  alone.\n\nRegions\n\nThere are no officially defined borders demarcating the various regions of Alaska, but there are six widely accepted regions:\n\nSouth Central\n\nThe most populous region of Alaska, containing Anchorage, the Matanuska-Susitna Valley and the Kenai Peninsula. Rural, mostly unpopulated areas south of the Alaska Range and west of the Wrangell Mountains also fall within the definition of South Central, as do the Prince William Sound area and the communities of Cordova and Valdez.\n\nSoutheast\n\nAlso referred to as the Panhandle or Inside Passage, this is the region of Alaska closest to the contiguous states. As such, this was where most of the initial non-indigenous settlement occurred in the years following the Alaska Purchase. The region is dominated by the Alexander Archipelago as well as the Tongass National Forest, the largest national forest in the United States. It contains the state capital Juneau, the former capital Sitka, and Ketchikan, at one time Alaska's largest city. The Alaska Marine Highway provides a vital surface transportation link throughout the area and country, as only three communities (Haines, Hyder and Skagway) enjoy direct connections to the contiguous North American road system.\n\nInterior\n\nThe Interior is the largest region of Alaska; much of it is uninhabited wilderness. Fairbanks is the only large city in the region. Denali National Park and Preserve is located here. Denali, formerly Mount McKinley, is the highest mountain in North America, and is also located here.\n\nSouthwest\n\nSouthwest Alaska is a sparsely inhabited region stretching some  inland from the Bering Sea. Most of the population lives along the coast. Kodiak Island is also located in Southwest. The massive Yukon\u2013Kuskokwim Delta, one of the largest river deltas in the world, is here. Portions of the Alaska Peninsula are considered part of Southwest, with the remaining portions included with the Aleutian Islands (see below).\n\nNorth Slope\n\nThe North Slope is mostly tundra peppered with small villages. The area is known for its massive reserves of crude oil and contains both the National Petroleum Reserve\u2013Alaska and the Prudhoe Bay Oil Field. The city of Utqia\u0121vik, formerly known as Barrow, is the northernmost city in the United States and is located here. The Northwest Arctic area, anchored by Kotzebue and also containing the Kobuk River valley, is often regarded as being part of this region. However, the respective Inupiat of the North Slope and of the Northwest Arctic seldom consider themselves to be one people.\n\nAleutian Islands\n\nMore than 300 small volcanic islands make up this chain, which stretches more than  into the Pacific Ocean. Some of these islands fall in the Eastern Hemisphere, but the International Date Line was drawn west of 180\u00b0 to keep the whole state, and thus the entire North American continent, within the same legal day. Two of the islands, Attu and Kiska, were occupied by Japanese forces during World War II.\n\nLand ownership \nAccording to an October 1998 report by the United States Bureau of Land Management, approximately 65% of Alaska is owned and managed by the U.S. federal government as public lands, including a multitude of national forests, national parks, and national wildlife refuges. Of these, the Bureau of Land Management manages, or 23.8% of the state. The Arctic National Wildlife Refuge is managed by the United States Fish and Wildlife Service. It is the world's largest wildlife refuge, comprising.\n\nOf the remaining land area, the state of Alaska owns, its entitlement under the Alaska Statehood Act. A portion of that acreage is occasionally ceded to the organized boroughs presented above, under the statutory provisions pertaining to newly formed boroughs. Smaller portions are set aside for rural subdivisions and other homesteading-related opportunities. These are not very popular due to the often remote and roadless locations. The University of Alaska, as a land grant university, also owns substantial acreage which it manages independently.\n\nAnother  are owned by 12 regional, and scores of local, Native corporations created under the Alaska Native Claims Settlement Act (ANCSA) of 1971. Regional Native corporation Doyon, Limited often promotes itself as the largest private landowner in Alaska in advertisements and other communications. Provisions of ANCSA allowing the corporations' land holdings to be sold on the open market starting in 1991 were repealed before they could take effect. Effectively, the corporations hold title (including subsurface title in many cases, a privilege denied to individual Alaskans) but cannot sell the land. Individual Native allotments can be and are sold on the open market, however.\n\nVarious private interests own the remaining land, totaling about one percent of the state. Alaska is, by a large margin, the state with the smallest percentage of private land ownership when Native corporation holdings are excluded.\n\nAlaska Heritage Resources Survey \nThe Alaska Heritage Resources Survey (AHRS) is a restricted inventory of all reported historic and prehistoric sites within the U.S. state of Alaska; it is maintained by the Office of History and Archaeology. The survey's inventory of cultural resources includes objects, structures, buildings, sites, districts, and travel ways, with a general provision that they are more than fifty years old., more than 35,000 sites have been reported.\n\nCities, towns and boroughs\n\nAlaska is not divided into counties, as most of the other U.S. states, but it is divided into boroughs. Delegates to the Alaska Constitutional Convention wanted to avoid the pitfalls of the traditional county system and adopted their own unique model. Many of the more densely populated parts of the state are part of Alaska's 16 boroughs, which function somewhat similarly to counties in other states. However, unlike county-equivalents in the other 49 states, the boroughs do not cover the entire land area of the state. The area not part of any borough is referred to as the Unorganized Borough.\n\nThe Unorganized Borough has no government of its own, but the U.S. Census Bureau in cooperation with the state divided the Unorganized Borough into 11 census areas solely for the purposes of statistical analysis and presentation. A recording district is a mechanism for management of the public record in Alaska. The state is divided into 34 recording districts which are centrally administered under a state recorder. All recording districts use the same acceptance criteria, fee schedule, etc., for accepting documents into the public record.\n\nWhereas many U.S. states use a three-tiered system of decentralization\u2014state/county/township\u2014most of Alaska uses only two tiers\u2014state/borough. Owing to the low population density, most of the land is located in the Unorganized Borough. As the name implies, it has no intermediate borough government but is administered directly by the state government. In 2000, 57.71% of Alaska's area has this status, with 13.05% of the population.\n\nAnchorage merged the city government with the Greater Anchorage Area Borough in 1975 to form the Municipality of Anchorage, containing the city proper and the communities of Eagle River, Chugiak, Peters Creek, Girdwood, Bird, and Indian. Fairbanks has a separate borough (the Fairbanks North Star Borough) and municipality (the City of Fairbanks).\n\nThe state's most populous city is Anchorage, home to 291,247 people in 2020. The richest location in Alaska by per capita income is Denali ($42,245). Yakutat City, Sitka, Juneau, and Anchorage are the four largest cities in the U.S. by area.\n\nCities and census-designated places (by population)\n\nAs reflected in the 2020 United States census, Alaska has a total of 355 incorporated cities and census-designated places (CDPs). The tally of cities includes four unified municipalities, essentially the equivalent of a consolidated city\u2013county. The majority of these communities are located in the rural expanse of Alaska known as \"The Bush\" and are unconnected to the contiguous North American road network. The table at the bottom of this section lists the 100 largest cities and census-designated places in Alaska, in population order.\n\nOf Alaska's 2020 U.S. census population figure of 733,391, 16,655 people, or 2.27% of the population, did not live in an incorporated city or census-designated place. Approximately three-quarters of that figure were people who live in urban and suburban neighborhoods on the outskirts of the city limits of Ketchikan, Kodiak, Palmer and Wasilla. CDPs have not been established for these areas by the United States Census Bureau, except that seven CDPs were established for the Ketchikan-area neighborhoods in the 1980 Census (Clover Pass,", "flag": 1, "segments": [[138, 148]], "strength": 5.5}
{"text": "In organic chemistry, an alkane, or paraffin (a historical trivial name that also has other meanings), is an acyclic saturated hydrocarbon. In other words, an alkane consists of hydrogen and carbon atoms arranged in a tree structure in which all the carbon\u2013carbon bonds are single. Alkanes have the general chemical formula. The alkanes range in complexity from the simplest case of methane (), where n\u00a0=\u00a01 (sometimes called the parent molecule), to arbitrarily large and complex molecules, like pentacontane () or 6-ethyl-2-methyl-5-(1-methylethyl) octane, an isomer of tetradecane ().\n\nThe International Union of Pure and Applied Chemistry (IUPAC) defines alkanes as \"acyclic branched or unbranched hydrocarbons having the general formula, and therefore consisting entirely of hydrogen atoms and saturated carbon atoms\". However, some sources use the term to denote any saturated hydrocarbon, including those that are either monocyclic (i.e. the cycloalkanes) or polycyclic, despite their having a distinct general formula (i.e. cycloalkanes are ).\n\nIn an alkane, each carbon atom is sp3-hybridized with 4 sigma bonds (either C\u2013C or C\u2013H), and each hydrogen atom is joined to one of the carbon atoms (in a C\u2013H bond). The longest series of linked carbon atoms in a molecule is known as its carbon skeleton or carbon backbone. The number of carbon atoms may be considered as the size of the alkane.\n\nOne group of the higher alkanes are waxes, solids at standard ambient temperature and pressure (SATP), for which the number of carbon atoms in the carbon backbone is greater than about 17.\nWith their repeated \u2013 units, the alkanes constitute a homologous series of organic compounds in which the members differ in molecular mass by multiples of 14.03\u00a0u (the total mass of each such methylene-bridge unit, which comprises a single carbon atom of mass 12.01\u00a0u and two hydrogen atoms of mass ~1.01\u00a0u each).\n\nMethane is produced by methanogenic bacteria and some long-chain alkanes function as pheromones in certain animal species or as protective waxes in plants and fungi. Nevertheless, most alkanes do not have much biological activity.  They can be viewed as molecular trees upon which can be hung the more active/reactive functional groups of biological molecules.\n\nThe alkanes have two main commercial sources: petroleum (crude oil) and natural gas.\n\nAn alkyl group is an alkane-based molecular fragment that bears one open valence for bonding. They are generally abbreviated with the symbol for any organyl group, R, although Alk is sometimes used to specifically symbolize an alkyl group (as opposed to an alkenyl group or aryl group).\n\nStructure and classification\nOrdinarily the C-C single bond distance is. \nSaturated hydrocarbons can be linear, branched, or cyclic. The third group is sometimes called cycloalkanes. Very complicated structures are possible by combining linear, branch, cyclic alkanes.\n\nIsomerism\n\nAlkanes with more than three carbon atoms can be arranged in various ways, forming structural isomers. The simplest isomer of an alkane is the one in which the carbon atoms are arranged in a single chain with no branches. This isomer is sometimes called the n-isomer (n for \"normal\", although it is not necessarily the most common). However, the chain of carbon atoms may also be branched at one or more points. The number of possible isomers increases rapidly with the number of carbon atoms. For example, for acyclic alkanes:\n C1: methane only\n C2: ethane only\n C3: propane only\n C4: 2 isomers: butane and isobutane\n C5: 3 isomers: pentane, isopentane, and neopentane\n C6: 5 isomers: hexane, 2-methylpentane, 3-methylpentane, 2,2-dimethylbutane, and 2,3-dimethylbutane\n C7: 9 isomers: heptane, methylhexane (2 isomers), dimethylpentane (4 isomers), 3-ethylpentane, 2,2,3-trimethylbutane\nC8: 18 isomers: octane, 2-methylheptane, 3-methylheptane, 2,3-dimethylhexane, 3,4-dimethylhexane,  2,3,4-trimethylpentane, 3,3-dimethylhexane, 2,2-trimethylpentane, 2,4-dimethylhexane, 2,2,4-trimethylpentane, 2,3,3-Trimethylpentane, 3,3,4-trimethyl-pentane, 3,4,4-trimethylpentane, 2,4,4-trimethylpentane, (5 isomers)\n C9: 35 isomers\n C10: 75 isomers\n C12: 355 isomers\n C32: 27,711,253,769 isomers\n C60: 22,158,734,535,770,411,074,184 isomers, many of which are not stable.\n\nBranched alkanes can be chiral. For example, 3-methylhexane and its higher homologues are chiral due to their stereogenic center at carbon atom number 3. The above list only includes differences of connectivity, not stereochemistry. In addition to the alkane isomers, the chain of carbon atoms may form one or more rings. Such compounds are called cycloalkanes, and are also excluded from the above list because changing the number of rings changes the molecular formula. For example, cyclobutane and methylcyclopropane are isomers of each other (C4H8), but are not isomers of butane (C4H10).\n\nNomenclature\n\nThe IUPAC nomenclature (systematic way of naming compounds) for alkanes is based on identifying hydrocarbon chains. Unbranched, saturated hydrocarbon chains are named systematically with a Greek numerical prefix denoting the number of carb day or two. The results of chronic wasting diseaseons and the suffix \"-ane\".\n\nIn 1866, August Wilhelm von Hofmann suggested systematizing nomenclature by using the whole sequence of vowels a, e, i, o and u to create suffixes -ane, -ene, -ine (or -yne), -one, -une, for the hydrocarbons CnH2n+2, CnH2n, CnH2n\u22122, CnH2n\u22124, CnH2n\u22126. In modern nomenclature, the first three specifically name hydrocarbons with single, double and triple bonds; while \"-one\" now represents a ketone.\n\nLinear alkanes\n\nStraight-chain alkanes are sometimes indicated by the prefix \"n-\" or \"n-\"(for \"normal\") where a non-linear isomer exists. Although this is not strictly necessary and is not part of the IUPAC naming system, the usage is still common in cases where one wishes to emphasize or distinguish between the straight-chain and branched-chain isomers, e.g., \"n-butane\" rather than simply \"butane\" to differentiate it from isobutane. Alternative names for this group used in the petroleum industry are linear paraffins or n-paraffins.\n\nThe first six members of the series (in terms of number of carbon atoms) are named as follows:\n methane CH4 \u2013 one carbon and 4 hydrogen\n ethane  C2H6 \u2013 two carbon and 6 hydrogen\n propane C3H8 \u2013 three carbon and 8 hydrogen\n butane  C4H10 \u2013 four carbon and 10 hydrogen\n pentane C5H12 \u2013 five carbon and 12 hydrogen\n hexane  C6H14 \u2013 six carbon and 14 hydrogen\n\nThe first four names were derived from methanol, ether, propionic acid and butyric acid. Alkanes with five or more carbon atoms are named by adding the suffix -ane to the appropriate numerical multiplier prefix with elision of any terminal vowel (-a or -o) from the basic numerical term. Hence, pentane, C5H12; hexane, C6H14; heptane, C7H16; octane, C8H18; etc. The numeral prefix is generally Greek, however alkanes with a carbon atom count ending in nine, for example nonane, use the Latin prefix non-. For a more complete list, see list of straight-chain alkanes.\n\nBranched alkanes\n\nSimple branched alkanes often have a common name using a prefix to distinguish them from linear alkanes, for example n-pentane, isopentane, and neopentane.\n\nIUPAC naming conventions can be used to produce a systematic name.\n\nThe key steps in the naming of more complicated branched alkanes are as follows:\n Identify the longest continuous chain of carbon atoms\n Name this longest root chain using standard naming rules\n Name each side chain by changing the suffix of the name of the alkane from \"-ane\" to \"-yl\"\n Number the longest continuous chain in order to give the lowest possible numbers for the side-chains\n Number and name the side chains before the name of the root chain\n If there are multiple side chains of the same type, use prefixes such as \"di-\" and \"tri-\" to indicate it as such, and number each one.\n Add side chain names in alphabetical (disregarding \"di-\" etc. prefixes) order in front of the name of the root chain\n\nSaturated cyclic hydrocarbons\n\nThough technically distinct from the alkanes, this class of hydrocarbons is referred to by some as the \"cyclic alkanes.\" As their description implies, they contain one or more rings.\n\nSimple cycloalkanes have a prefix \"cyclo-\" to distinguish them from alkanes. Cycloalkanes are named as per their acyclic counterparts with respect to the number of carbon atoms in their backbones, e.g., cyclopentane (C5H10) is a cycloalkane with 5 carbon atoms just like pentane (C5H12), but they are joined up in a five-membered ring. In a similar manner, propane and cyclopropane, butane and cyclobutane, etc.\n\nSubstituted cycloalkanes are named similarly to substituted alkanes \u2013 the cycloalkane ring is stated, and the substituents are according to their position on the ring, with the numbering decided by the Cahn\u2013Ingold\u2013Prelog priority rules.\n\nTrivial/common names\n\nThe trivial (non-systematic) name for alkanes is 'paraffins'. Together, alkanes are known as the 'paraffin series'. Trivial names for compounds are usually historical artifacts. They were coined before the development of systematic names, and have been retained due to familiar usage in industry. Cycloalkanes are also called naphthenes.\n\nBranched-chain alkanes are called isoparaffins. \"Paraffin\" is a general term and often does not distinguish between pure compounds and mixtures of isomers, i.e., compounds of the same chemical formula, e.g., pentane and isopentane.\n\nIn IUPAC\nThe following trivial names are retained in the IUPAC system:\n isobutane for 2-methylpropane\n isopentane for 2-methylbutane\n neopentane for 2,2-dimethylpropane.\n\nNon-IUPAC\nSome non-IUPAC trivial names are occasionally used:\n cetane, for hexadecane\n cerane, for hexacosane\n\nPhysical properties\nAll alkanes are colorless. Alkanes with the lowest molecular weights are gasses, those of intermediate molecular weight are liquids, and the heaviest are waxy solids.\n\nTable of alkanes\n\nBoiling point\n\nAlkanes experience intermolecular van der Waals forces. Stronger intermolecular van der Waals forces give rise to greater boiling points of alkanes.\n\nThere are two determinants for the strength of the van der Waals forces:\n the number of electrons surrounding the molecule, which increases with the alkane's molecular weight\n the surface area of the molecule\n\nUnder standard conditions, from CH4 to C4H10 alkanes are gaseous; from C5H12 to C17H36 they are liquids; and after C18H38 they are solids. As the boiling point of alkanes is primarily determined by weight, it should not be a surprise that the boiling point has almost a linear relationship with the size (molecular weight) of the molecule. As a rule of thumb, the boiling point rises 20\u201330\u00a0\u00b0C for each carbon added to the chain; this rule applies to other homologous series.\n\nA straight-chain alkane will have a boiling point higher than a branched-chain alkane due to the greater surface area in contact, thus the greater van der Waals forces, between adjacent molecules. For example, compare isobutane (2-methylpropane) and n-butane (butane), which boil at \u221212 and 0\u00a0\u00b0C, and 2,2-dimethylbutane and 2,3-dimethylbutane which boil at 50 and 58\u00a0\u00b0C, respectively. \n\nOn the other hand, cycloalkanes tend to have higher boiling points than their linear counterparts due to the locked conformations of the molecules, which give a plane of intermolecular contact.\n\nMelting points\nThe melting points of the alkanes follow a similar trend to boiling points for the same reason as outlined above. That is, (all other things being equal) the larger the molecule the higher the melting point. There is one significant difference between boiling points and melting points. Solids have more rigid and fixed structure than liquids. This rigid structure requires energy to break down. Thus the better put together solid structures will require more energy to break apart. For alkanes, this can be seen from the graph above (i.e., the blue line). The odd-numbered alkanes have a lower trend in melting points than even numbered alkanes. This is because even numbered alkanes pack well in the solid phase, forming a well-organized structure, which requires more energy to break apart. The odd-numbered alkanes pack less well and so the \"looser\" organized solid packing structure requires less energy to break apart. For a visualization of the crystal structures see.\n\nThe melting points of branched-chain alkanes can be either higher or lower than those of the corresponding straight-chain alkanes, again depending on the ability of the alkane in question to pack well in the solid phase.\n\nConductivity and solubility\nAlkanes do not conduct electricity in any way, nor are they substantially polarized by an electric field. For this reason, they do not form hydrogen bonds and are insoluble in polar solvents such as water. Since the hydrogen bonds between individual water molecules are aligned away from an alkane molecule, the coexistence of an alkane and water leads to an increase in molecular order (a reduction in entropy). As there is no significant bonding between water molecules and alkane molecules, the second law of thermodynamics suggests that this reduction in entropy should be minimized by minimizing the contact between alkane and water: Alkanes are said to be hydrophobic as they are insoluble in water.\n\nTheir solubility in nonpolar solvents is relatively high, a property that is called lipophilicity. Alkanes are, for example, miscible in all proportions among themselves.\n\nThe density of the alkanes usually increases with the number of carbon atoms but remains less than that of water. Hence, alkanes form the upper layer in an alkane\u2013water mixture.\n\nMolecular geometry\n\nThe molecular structure of the alkanes directly affects their physical and chemical characteristics. It is derived from the electron configuration of carbon, which has four valence electrons. The carbon atoms in alkanes are described as sp3 hybrids, that is to say that, to a good approximation, the valence electrons are in orbitals directed towards the corners of a tetrahedron which are derived from the combination of the 2s orbital and the three 2p orbitals.  Geometrically, the angle between the bonds are cos\u22121(\u2212)\u00a0\u2248\u00a0109.47\u00b0.  This is exact for the case of methane, while larger alkanes containing a combination of C\u2013H and C\u2013C bonds generally have bonds that are within several degrees of this idealized value.\n\nBond lengths and bond angles\nAn alkane has only C\u2013H and C\u2013C single bonds. The former result from the overlap of an sp3 orbital of carbon with the 1s orbital of a hydrogen; the latter by the overlap of two sp3 orbitals on adjacent carbon atoms. The bond lengths amount to 1.09\u00a0\u00d7\u00a010\u221210\u00a0m for a C\u2013H bond and 1.54\u00a0\u00d7\u00a010\u221210\u00a0m for a C\u2013C bond.\n\nThe spatial arrangement of the bonds is similar to that of the four sp3 orbitals\u2014they are tetrahedrally arranged, with an angle of 109.47\u00b0 between them. Structural formulae that represent the bonds as being at right angles to one another, while both common and useful, do not accurately depict the geometry.\n\nConformation\n\nThe structural formula and the bond angles are not usually sufficient to completely describe the geometry of a molecule. There is a further degree of freedom for each carbon\u2013carbon bond: the torsion angle between the atoms or groups bound to the atoms at each end of the bond. The spatial arrangement described by the torsion angles of the molecule is known as its conformation.\n\nEthane forms the simplest case for studying the conformation of alkanes, as there is only one C\u2013C bond. If one looks down the axis of the C\u2013C bond, one will see the so-called Newman projection. The hydrogen atoms on both the front and rear carbon atoms have an angle of 120\u00b0 between them, resulting from the projection of the base of the tetrahedron onto a flat plane. However, the torsion angle between a given hydrogen atom attached to the front carbon and a given hydrogen atom attached to the rear carbon can vary freely between 0\u00b0 and 360\u00b0. This is a consequence of the free rotation about a carbon\u2013carbon single bond. Despite this apparent freedom, only two limiting conformations are important: eclipsed conformation and staggered conformation.\n\nThe two conformations differ in energy: the staggered conformation is 12.6\u00a0kJ/mol (3.0 kcal/mol) lower in energy (more stable) than the eclipsed conformation (the least stable).\n\nThis difference in energy between the two conformations, known as the torsion energy, is low compared to the thermal energy of an ethane molecule at ambient temperature. There is constant rotation about the C\u2013C bond. The time taken for an ethane molecule to pass from one staggered conformation to the next, equivalent to the rotation of one CH3 group by 120\u00b0 relative to the other, is of the order of 10\u221211\u00a0seconds.\n\nThe case of higher alkanes is more complex but based on similar principles, with the antiperiplanar conformation always being the most favored around each carbon\u2013carbon bond. For this reason, alkanes are usually shown in a zigzag arrangement in diagrams or in models. The actual structure will always differ somewhat from these idealized forms, as the differences in energy between the conformations are small compared to the thermal energy of the molecules: Alkane molecules have no fixed structural form, whatever the models may suggest.\n\nSpectroscopic properties\n\nVirtually all organic compounds contain carbon\u2013carbon, and carbon\u2013hydrogen bonds, and so show some of the features of alkanes in their spectra. Alkanes are notable for having no other groups, and therefore for the absence of other characteristic spectroscopic features of a functional group like \u2013OH, \u2013CHO, \u2013COOH etc.\n\nInfrared spectroscopy\nThe carbon\u2013hydrogen stretching mode gives a strong absorption between 2850 and 2960\u00a0cm\u22121, while the carbon\u2013carbon stretching mode absorbs between 800 and 1300\u00a0cm\u22121. The carbon\u2013hydrogen bending modes depend on the nature of the group: methyl groups show bands at 1450\u00a0cm\u22121 and 1375\u00a0cm\u22121, while methylene groups show bands at 1465\u00a0cm\u22121 and 1450\u00a0cm\u22121. Carbon chains with more than four carbon atoms show a weak absorption at around 725\u00a0cm\u22121.\n\nNMR spectroscopy\nThe proton resonances of alkanes are usually found at \u03b4H = 0.5\u20131.5. The carbon-13 resonances depend on the number of hydrogen atoms attached to the carbon: \u03b4C = 8\u201330 (primary, methyl, \u2013CH3), 15\u201355 (secondary, methylene, \u2013CH2\u2013), 20\u201360 (tertiary, methyne, C\u2013H) and quaternary. The carbon-13 resonance of quaternary carbon atoms is characteristically weak, due to the lack of nuclear Overhauser effect and the long relaxation time, and can be missed in weak samples, or samples that have not been run for a sufficiently long time.\n\nMass spectrometry\nAlkanes have a high ionization energy, and the molecular ion is usually weak. The fragmentation pattern can be difficult to interpret, but, in the case of branched chain alkanes, the carbon chain is preferentially cleaved at tertiary or quaternary carbons due to the relative stability of the resulting free radicals. The fragment resulting from the loss of a single methyl group (M\u00a0\u2212\u00a015) is often absent, and other fragments are often spaced by intervals of fourteen mass units, corresponding to sequential loss of CH2 groups.\n\nChemical properties\n\nAlkanes are only weakly reactive with most chemical compounds. The acid dissociation constant (pKa) values of all alkanes are estimated to range from 50 to 70, depending on the extrapolation method, hence they are extremely weak acids that are practically inert to bases (see: carbon acids). They are also extremely weak bases, undergoing no observable protonation in pure sulfuric acid (H0 ~ \u221212), although superacids that are at least millions of times stronger have been known to protonate them to give hypercoordinate alkanium ions (see: methanium ion). Similarly, they only show reactivity with the strongest of electrophilic reagents (e.g., dioxiranes and salts containing the NF4+ cation).  By virtue of their strongly C\u2013H bonds (~100 kcal/mol) and C\u2013C bonds (~90 kcal/mol, but usually less sterically accessible), they", "flag": 1, "segments": [[1372, 1382]], "strength": 5.5}
{"text": "Asphalt, also known as bitumen (, ), is a sticky, black, highly viscous liquid or semi-solid form of petroleum. It may be found in natural deposits or may be a refined product, and is classed as a pitch. Before the 20th century, the term asphaltum was also used. The word is derived from the Ancient Greek \u1f04\u03c3\u03c6\u03b1\u03bb\u03c4\u03bf\u03c2 \u00e1sphaltos. The largest natural deposit of asphalt in the world, estimated to contain 10 million tons, is the Pitch Lake located in La Brea in southwest Trinidad (Antilles island located on the northeastern coast of Venezuela), within the Siparia Regional Corporation.\n\nThe primary use (70%) of asphalt is in road construction, where it is used as the glue or binder mixed with aggregate particles to create asphalt concrete. Its other main uses are for bituminous waterproofing products, including production of roofing felt and for sealing flat roofs.\n\nIn material sciences and engineering, the terms \"asphalt\" and \"bitumen\" are often used interchangeably to mean both natural and manufactured forms of the substance, although there is regional variation as to which term is most common. Worldwide, geologists tend to favor the term \"bitumen\" for the naturally occurring material. For the manufactured material, which is a refined residue from the distillation process of selected crude oils, \"bitumen\" is the prevalent term in much of the world; however, in American English, \"asphalt\" is more commonly used. To help avoid confusion, the phrases \"liquid asphalt\", \"asphalt binder\", or \"asphalt cement\" are used in the U.S. Colloquially, various forms of asphalt are sometimes referred to as \"tar\", as in the name of the La Brea Tar Pits, although tar is a different material.\n\nNaturally occurring asphalt is sometimes specified by the term \"crude bitumen\". Its viscosity is similar to that of cold molasses while the material obtained from the fractional distillation of crude oil boiling at  is sometimes referred to as \"refined bitumen\". The Canadian province of Alberta has most of the world's reserves of natural asphalt in the Athabasca oil sands, which cover, an area larger than England.\n\nAsphalt properties change with temperature, which means that there is a specific range where viscosity permits adequate compaction by providing lubrication between particles during the compaction process. Low temperature prevents aggregate particles from moving, and the required density is not possible to achieve. Computer simulations of simplified model systems are able to reproduce some of asphalt's characteristic properties.\n\nTerminology\n\nEtymology\nThe word \"asphalt\" is derived from the late Middle English, in turn from French asphalte, based on Late Latin asphalton, asphaltum, which is the latinisation of the Greek  (\u00e1sphaltos, \u00e1sphalton), a word meaning \"asphalt/bitumen/pitch\", which perhaps derives from, \"not, without\", i.e. the alpha privative, and  (sphallein), \"to cause to fall, baffle, (in passive) err, (in passive) be balked of\". The first use of asphalt by the ancients was in the nature of a cement for securing or joining together various objects, and it thus seems likely that the name itself was expressive of this application. Specifically, Herodotus mentioned that bitumen was brought to Babylon to build its gigantic fortification wall. From the Greek, the word passed into late Latin, and thence into French (asphalte) and English (\"asphaltum\" and \"asphalt\"). In French, the term asphalte is used for naturally occurring asphalt-soaked limestone deposits, and for specialised manufactured products with fewer voids or greater bitumen content than the \"asphaltic concrete\" used to pave roads.\n\nThe Latin source of the word \"bitumen\" is claimed by some to be originally gwitu-men (pertaining to pitch), and by others, pixtumens (exuding or bubbling pitch), which was subsequently shortened to bitumen, thence passing via French into English. From the same root is derived the Anglo-Saxon word cwidu (mastix), the German word Kitt (cement or mastic) and the old Norse word kvada.\n\nModern terminology\nIn British English, \"bitumen\" is used instead of \"asphalt\". The word \"asphalt\" is instead used to refer to asphalt concrete, a mixture of construction aggregate and asphalt itself (also called \"tarmac\" in common parlance). Bitumen mixed with clay was usually called \"asphaltum\", but the term is less commonly used today.\n\nIn Australian English, the word \"asphalt\" is used to describe a mix of construction aggregate. \"Bitumen\" refers to the liquid derived from the heavy-residues from crude oil distillation.\n\nIn American English, \"asphalt\" is equivalent to the British \"bitumen\". However, \"asphalt\" is also commonly used as a shortened form of \"asphalt concrete\" (therefore equivalent to the British \"asphalt\" or \"tarmac\").\n\nIn Canadian English, the word \"bitumen\" is used to refer to the vast Canadian deposits of extremely heavy crude oil, while \"asphalt\" is used for the oil refinery product. Diluted bitumen (diluted with naphtha to make it flow in pipelines) is known as \"dilbit\" in the Canadian petroleum industry, while bitumen \"upgraded\" to synthetic crude oil is known as \"syncrude\", and syncrude blended with bitumen is called \"synbit\".\n\n\"Bitumen\" is still the preferred geological term for naturally occurring deposits of the solid or semi-solid form of petroleum. \"Bituminous rock\" is a form of sandstone impregnated with bitumen. The oil sands of Alberta, Canada are a similar material.\n\nNeither of the terms \"asphalt\" or \"bitumen\" should be confused with tar or coal tars. Tar is the thick liquid product of the dry distillation and pyrolysis of organic hydrocarbons primarily sourced from vegetation masses, whether fossilized as with coal, or freshly harvested. The majority of bitumen, on the other hand, was formed naturally when vast quantities of organic animal materials were deposited by water and buried hundreds of metres deep at the diagenetic point, where the disorganized fatty hydrocarbon molecules joined together in long chains in the absence of oxygen. Bitumen occurs as a solid or highly viscous liquid. It may even be mixed in with coal deposits. Bitumen, and coal using the Bergius process, can be refined into petrols such as gasoline, and bitumen may be distilled into tar, not the other way around.\n\nComposition\n\nNormal composition\nThe components of asphalt include four main classes of compounds:\n\n Naphthene aromatics (naphthalene), consisting of partially hydrogenated polycyclic aromatic compounds\n Polar aromatics, consisting of high molecular weight phenols and carboxylic acids produced by partial oxidation of the material\n Saturated hydrocarbons; the percentage of saturated compounds in asphalt correlates with its softening point\n Asphaltenes, consisting of high molecular weight phenols and heterocyclic compounds\n\nThe naphthene aromatics and polar aromatics are typically the majority components. Most natural bitumens also contain organosulfur compounds, resulting in an overall sulfur content of up to 4%. Nickel and vanadium are found at <10 parts per million, as is typical of some petroleum.\n\nThe substance is soluble in carbon disulfide. It is commonly modelled as a colloid, with asphaltenes as the dispersed phase and maltenes as the continuous phase. \"It is almost impossible to separate and identify all the different molecules of asphalt, because the number of molecules with different chemical structure is extremely large\".\n\nAsphalt may be confused with coal tar, which is a visually similar black, thermoplastic material produced by the destructive distillation of coal. During the early and mid-20th century, when town gas was produced, coal tar was a readily available byproduct and extensively used as the binder for road aggregates. The addition of coal tar to macadam roads led to the word \"tarmac\", which is now used in common parlance to refer to road-making materials. However, since the 1970s, when natural gas succeeded town gas, asphalt has completely overtaken the use of coal tar in these applications. Other examples of this confusion include the La Brea Tar Pits and the Canadian oil sands, both of which actually contain natural bitumen rather than tar. \"Pitch\" is another term sometimes informally used at times to refer to asphalt, as in Pitch Lake.\n\nAdditives, mixtures and contaminants\nFor economic and other reasons, asphalt is sometimes sold combined with other materials, often without being labeled as anything other than simply \"asphalt\".\n\nOf particular note is the use of re-refined engine oil bottoms \u2013 \"REOB\" or \"REOBs\"the residue of recycled automotive engine oil collected from the bottoms of re-refining vacuum distillation towers, in the manufacture of asphalt. REOB contains various elements and compounds found in recycled engine oil: additives to the original oil and materials accumulating from its circulation in the engine (typically iron and copper). Some research has indicated a correlation between this adulteration of asphalt and poorer-performing pavement.\n\nOccurrence\n\nThe majority of asphalt used commercially is obtained from petroleumLDH) will be offering three free WebMD. Nonetheless, large amounts of asphalt occur in concentrated form in nature. Naturally occurring deposits of bitumen are formed from the remains of ancient, microscopic algae (diatoms) and other once-living things. These natural deposits of bitumen have been formed during the Carboniferous period, when giant swamp forests dominated many parts of the Earth. They were deposited in the mud on the bottom of the ocean or lake where the organisms lived. Under the heat (above 50\u00a0\u00b0C) and pressure of burial deep in the earth, the remains were transformed into materials such as bitumen, kerogen, or petroleum.\n\nNatural deposits of bitumen include lakes such as the Pitch Lake in Trinidad and Tobago and Lake Bermudez in Venezuela. Natural seeps occur in the La Brea Tar Pits and in the Dead Sea.\n\nBitumen also occurs in unconsolidated sandstones known as \"oil sands\" in Alberta, Canada, and the similar \"tar sands\" in Utah, US.\nThe Canadian province of Alberta has most of the world's reserves, in three huge deposits covering, an area larger than England or New York state. These bituminous sands contain  of commercially established oil reserves, giving Canada the third largest oil reserves in the world. Although historically it was used without refining to pave roads, nearly all of the output is now used as raw material for oil refineries in Canada and the United States.\n\nThe world's largest deposit of natural bitumen, known as the Athabasca oil sands, is located in the McMurray Formation of Northern Alberta. This formation is from the early Cretaceous, and is composed of numerous lenses of oil-bearing sand with up to 20% oil. Isotopic studies show the oil deposits to be about 110 million years old. Two smaller but still very large formations occur in the Peace River oil sands and the Cold Lake oil sands, to the west and southeast of the Athabasca oil sands, respectively. Of the Alberta deposits, only parts of the Athabasca oil sands are shallow enough to be suitable for surface mining. The other 80% has to be produced by oil wells using enhanced oil recovery techniques like steam-assisted gravity drainage.\n\nMuch smaller heavy oil or bitumen deposits also occur in the Uinta Basin in Utah, US.  The Tar Sand Triangle deposit, for example, is roughly 6% bitumen.\n\nBitumen may occur in hydrothermal veins. An example of this is within the Uinta Basin of Utah, in the US, where there is a swarm of laterally and vertically extensive veins composed of a solid hydrocarbon termed Gilsonite. These veins formed by the polymerization and solidification of hydrocarbons that were mobilized from the deeper oil shales of the Green River Formation during burial and diagenesis.\n\nBitumen is similar to the organic matter in carbonaceous meteorites. However, detailed studies have shown these materials to be distinct. The vast Alberta bitumen resources are considered to have started out as living material from marine plants and animals, mainly algae, that died millions of years ago when an ancient ocean covered Alberta. They were covered by mud, buried deeply over time, and gently cooked into oil by geothermal heat at a temperature of. Due to pressure from the rising of the Rocky Mountains in southwestern Alberta, 80 to 55 million years ago, the oil was driven northeast hundreds of kilometres and trapped into underground sand deposits left behind by ancient river beds and ocean beaches, thus forming the oil sands.\n\nHistory\n\nAncient times\nThe use of natural bitumen for waterproofing, and as an adhesive dates at least to the fifth millennium BC, with a crop storage basket discovered in Mehrgarh, of the Indus Valley Civilization, lined with it. By the 3rd millennium BC refined rock asphalt was in use in the region, and was used to waterproof the Great Bath in Mohenjo-daro.\n\nIn the ancient Middle East, the Sumerians used natural bitumen deposits for mortar between bricks and stones, to cement parts of carvings, such as eyes, into place, for ship caulking, and for waterproofing. The Greek historian Herodotus said hot bitumen was used as mortar in the walls of Babylon.\n\nThe  long Euphrates Tunnel beneath the river Euphrates at Babylon in the time of Queen Semiramis (c. 800 BC) was reportedly constructed of burnt bricks covered with bitumen as a waterproofing agent.\n\nBitumen was used by ancient Egyptians to embalm mummies. The Persian word for asphalt is moom, which is related to the English word mummy. The Egyptians' primary source of bitumen was the Dead Sea, which the Romans knew as Palus Asphaltites (Asphalt Lake).\n\nIn approximately 40 AD, Dioscorides described the Dead Sea material as Judaicum bitumen, and noted other places in the region where it could be found. The Sidon bitumen is thought to refer to material found at Hasbeya in Lebanon. Pliny also refers to bitumen being found in Epirus. Bitumen was a valuable strategic resource. It was the object of the first known battle for a hydrocarbon deposit \u2013 between the Seleucids and the Nabateans in 312 BC.\n\nIn the ancient Far East, natural bitumen was slowly boiled to get rid of the higher fractions, leaving a thermoplastic material of higher molecular weight that when layered on objects became quite hard upon cooling. This was used to cover objects that needed waterproofing, such as scabbards and other items. Statuettes of household deities were also cast with this type of material in Japan, and probably also in China.\n\nIn North America, archaeological recovery has indicated that bitumen was sometimes used to adhere stone projectile points to wooden shafts. In Canada, aboriginal people used bitumen seeping out of the banks of the Athabasca and other rivers to waterproof birch bark canoes, and also heated it in smudge pots to ward off mosquitoes in the summer.\n\nContinental Europe\nIn 1553, Pierre Belon described in his work Observations that pissasphalto, a mixture of pitch and bitumen, was used in the Republic of Ragusa (now Dubrovnik, Croatia) for tarring of ships.\n\nAn 1838 edition of Mechanics Magazine cites an early use of asphalt in France. A pamphlet dated 1621, by \"a certain Monsieur d'Eyrinys, states that he had discovered the existence (of asphaltum) in large quantities in the vicinity of Neufchatel\", and that he proposed to use it in a variety of ways \u2013 \"principally in the construction of air-proof granaries, and in protecting, by means of the arches, the water-courses in the city of Paris from the intrusion of dirt and filth\", which at that time made the water unusable. \"He expatiates also on the excellence of this material for forming level and durable terraces\" in palaces, \"the notion of forming such terraces in the streets not one likely to cross the brain of a Parisian of that generation\".\n\nBut the substance was generally neglected in France until the revolution of 1830. In the 1830s there was a surge of interest, and asphalt became widely used \"for pavements, flat roofs, and the lining of cisterns, and in England, some use of it had been made of it for similar purposes\". Its rise in Europe was \"a sudden phenomenon\", after natural deposits were found \"in France at Osbann (Bas-Rhin), the Parc (Ain) and the Puy-de-la-Poix (Puy-de-D\u00f4me)\", although it could also be made artificially. One of the earliest uses in France was the laying of about 24,000 square yards of Seyssel asphalt at the Place de la Concorde in 1835.\n\nUnited Kingdom\nAmong the earlier uses of bitumen in the United Kingdom was for etching. William Salmon's Polygraphice (1673) provides a recipe for varnish used in etching, consisting of three ounces of virgin wax, two ounces of mastic, and one ounce of asphaltum. By the fifth edition in 1685, he had included more asphaltum recipes from other sources.\n\nThe first British patent for the use of asphalt was \"Cassell's patent asphalte or bitumen\" in 1834. Then on 25 November 1837, Richard Tappin Claridge patented the use of Seyssel asphalt (patent #7849), for use in asphalte pavement, having seen it employed in France and Belgium when visiting with Frederick Walter Simms, who worked with him on the introduction of asphalt to Britain. Dr T. Lamb Phipson writes that his father, Samuel Ryland Phipson, a friend of Claridge, was also \"instrumental in introducing the asphalte pavement (in 1836)\".\n\nClaridge obtained a patent in Scotland on 27 March 1838, and obtained a patent in Ireland on 23 April 1838. In 1851, extensions for the 1837 patent and for both 1838 patents were sought by the trustees of a company previously formed by Claridge. Claridge's Patent Asphalte Companyformed in 1838 for the purpose of introducing to Britain \"Asphalte in its natural state from the mine at Pyrimont Seysell in France\",\"laid one of the first asphalt pavements in Whitehall\". Trials were made of the pavement in 1838 on the footway in Whitehall, the stable at Knightsbridge Barracks, \"and subsequently on the space at the bottom of the steps leading from Waterloo Place to St. James Park\". \"The formation in 1838 of Claridge's Patent Asphalte Company (with a distinguished list of aristocratic patrons, and Marc and Isambard Brunel as, respectively, a trustee and consulting engineer), gave an enormous impetus to the development of a British asphalt industry\". \"By the end of 1838, at least two other companies, Robinson's and the Bastenne company, were in production\", with asphalt being laid as paving at Brighton, Herne Bay, Canterbury, Kensington, the Strand, and a large floor area in Bunhill-row, while meantime Claridge's Whitehall paving \"continue(d) in good order\". The Bonnington Chemical Works manufactured asphalt using coal tar and by 1839 had installed it in Bonnington.\n\nIn 1838, there was a flurry of entrepreneurial activity involving asphalt, which had uses beyond paving. For example, asphalt could also be used for flooring, damp proofing in buildings, and for waterproofing of various types of pools and baths, both of which were also proliferating in the 19th century. On the London stockmarket, there were various claims as to the exclusivity of asphalt quality from France, Germany and England. And numerous patents were granted in France, with similar numbers of patent applications being denied in England due to their similarity to each other. In England, \"Claridge's was the type most used in the 1840s and 50s\".\n\nIn 1914, Claridge's Company entered into a joint venture to produce tar-bound macadam, with materials manufactured through a subsidiary company called Clarmac Roads Ltd. Two products resulted, namely Clarmac, and Clarphalte, with the former being manufactured by Clarmac Roads and the latter by Claridge's Patent Asphalte Co., although Clarmac was more widely used. However, the First World War ruined the Clarmac Company, which entered into liquidation in 1915. The failure of Clarmac Roads Ltd had a flow-on effect to Claridge's Company, which was itself compulsorily wound up, ceasing operations in 1917, having invested a substantial amount of funds into the new venture, both at the outset and in a subsequent attempt to save the Clarmac Company.\n\nBitumen was thought in 19th century Britain to contain chemicals with medicinal properties. Extracts from bitumen were used to treat catarrh and some forms of asthma and as a remedy against worms, especially the tapeworm.\n\nUnited States\nThe first use of bitumen in the New World was by indigenous peoples. On the west coast, as early as the 13th century, the Tongva, Luise\u00f1o and Chumash peoples collected the naturally occurring bitumen that seeped to the surface above underlying petroleum deposits. All three groups used the substance as an adhesive. It is found on many different artifacts of tools and ceremonial items. For example, it was used on rattles to adhere gourds or turtle shells to rattle handles. It was also used in decorations. Small round shell beads were often set in asphaltum to provide decorations. It was used as a sealant on baskets to make them watertight for carrying water, possibly poisoning those who drank the water. Asphalt was used also to seal the planks on ocean-going canoes.\n\nAsphalt was first used to pave streets in the 1870s.  At first naturally occurring \"bituminous rock\" was used, such as at Ritchie Mines in Macfarlan in Ritchie County, West Virginia from 1852 to 1873. In 1876, asphalt-based paving was used to pave Pennsylvania Avenue in Washington DC, in time for the celebration of the national centennial.\n\nIn the horse-drawn era, US streets were mostly unpaved and covered with dirt or gravel.  Especially where mud or trenching often made streets difficult to pass, pavements were sometimes made of diverse materials including wooden planks, cobble stones or other stone blocks, or bricks. Unpaved roads produced uneven wear and hazards for pedestrians.   In the late 19th century with the rise of the popular bicycle, bicycle clubs were important in pushing for more general pavement of streets. Advocacy for pavement increased in the early 20th century with the rise of the automobile.  Asphalt gradually became an ever more common method of paving.  St. Charles Avenue in New Orleans was paved its whole length with asphalt by 1889.\n\nIn 1900, Manhattan alone had 130,000 horses, pulling streetcars, wagons, and carriages, and leaving their waste behind. They were not fast, and pedestrians could dodge and scramble their way across the crowded streets.  Small towns continued to rely on dirt and gravel, but larger cities wanted much better streets", "flag": 1, "segments": [[2011, 2021]], "strength": 5.5}
{"text": "Apollo 11 (July 16\u201324, 1969) was the American spaceflight that first landed humans on the Moon. Commander Neil Armstrong and lunar module pilot Buzz Aldrin landed the Apollo Lunar Module Eagle on July 20, 1969, at 20:17 UTC, and Armstrong became the first person to step onto the Moon's surface six hours and 39 minutes later, on July 21 at 02:56 UTC. Aldrin joined him 19 minutes later, and they spent about two and a quarter hours together exploring the site they had named Tranquility Base upon landing. Armstrong and Aldrin collected  of lunar material to bring back to Earth as pilot Michael Collins flew the Command Module Columbia in lunar orbit, and were on the Moon's surface for 21 hours, 36 minutes before lifting off to rejoin Columbia.\n\nApollo 11 was launched by a Saturn V rocket from Kennedy Space Center on Merritt Island, Florida, on July 16 at 13:32 UTC, and it was the fifth crewed mission of NASA's Apollo program. The Apollo spacecraft had three parts: a command module (CM) with a cabin for the three astronauts, the only part that returned to Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages\u2014a descent stage for landing on the Moon and an ascent stage to place the astronauts back into lunar orbit.\n\nAfter being sent to the Moon by the Saturn V's third stage, the astronauts separated the spacecraft from it and traveled for three days until they entered lunar orbit. Armstrong and Aldrin then moved into Eagle and landed in the Sea of Tranquility on July 20. The astronauts used Eagles ascent stage to lift off from the lunar surface and rejoin Collins in the command module. They jettisoned Eagle before they performed the maneuvers that propelled Columbia out of the last of its 30 lunar orbits onto a trajectory back to Earth. They returned to Earth and splashed down in the Pacific Ocean on July 24 after more than eight days in space.\n\nArmstrong's first step onto the lunar surface was broadcast on live TV to a worldwide audience. He described the event as \"one small step for [a] man, one giant leap for mankind.\" Apollo 11 effectively proved US victory in the Space Race to demonstrate spaceflight superiority, by fulfilling a national goal proposed in 1961 by President John F. Kennedy, \"before this decade is out, of landing a man on the Moon and returning him safely to the Earth.\"\n\nBackground \n\nIn the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This surprise success fired fears and imaginations around the world. It demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, and challenged American claims of military, economic and technological superiority. This precipitated the Sputnik crisis, and triggered the Space Race to prove which superpower would achieve superior spaceflight capability. President Dwight D. Eisenhower responded to the Sputnik challenge by creating the National Aeronautics and Space Administration (NASA), and initiating Project Mercury, which aimed to launch a man into Earth orbit. But on April 12, 1961, Soviet cosmonaut Yuri Gagarin became the first person in space, and the first to orbit the Earth. Nearly a month later, on May 5, 1961, Alan Shepard became the first American in space, completing a 15-minute suborbital journey. After being recovered from the Atlantic Ocean, he received a congratulatory telephone call from Eisenhower's successor, John F. Kennedy.\n\nSince the Soviet Union had higher lift capacity launch vehicles, Kennedy chose, from among options presented by NASA, a challenge beyond the capacity of the existing generation of rocketry, so that the US and Soviet Union would be starting from a position of equality. A crewed mission to the Moon would serve this purpose.\n\nOn May 25, 1961, Kennedy addressed the United States Congress on \"Urgent National Needs\" and declared:\n\nOn September 12, 1962, Kennedy delivered another speech before a crowd of about 40,000 people in the Rice University football stadium in Houston, Texas. A widely quoted refrain from the middle portion of the speech reads as follows:\n\nIn spite of that, the proposed program faced the opposition of many Americans and was dubbed a \"moondoggle\" by Norbert Wiener, a mathematician at the Massachusetts Institute of Technology. The effort to land a man on the Moon already had a name: Project Apollo. When Kennedy met with Nikita Khrushchev, the Premier of the Soviet Union in June 1961, he proposed making the Moon landing a joint project, but Khrushchev did not take up the offer. Kennedy again proposed a joint expedition to the Moon in a speech to the United Nations General Assembly on September 20, 1963. The idea of a joint Moon mission was abandoned after Kennedy's death.\n\nAn early and crucial decision was choosing lunar orbit rendezvous over both direct ascent and Earth orbit rendezvous. A space rendezvous is an orbital maneuver in which two spacecraft navigate through space and meet up. In July 1962 NASA head James Webb announced that lunar orbit rendezvous would be used and that the Apollo spacecraft would have three major parts: a command module (CM) with a cabin for the three astronauts, and the only part that returned to Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages\u2014a descent stage for landing on the Moon, and an ascent stage to place the astronauts back into lunar orbit. This design meant the spacecraft could be launched by a single Saturn V rocket that was then under development.\n\nTechnologies and techniques required for Apollo were developed by Project Gemini. The Apollo project was enabled by NASA's adoption of new advances in semiconductor electronic technology, including metal-oxide-semiconductor field-effect transistors (MOSFETs) in the Interplanetary Monitoring Platform (IMP) and silicon integrated circuit (IC) chips in the Apollo Guidance Computer (AGC).\n\nProject Apollo was abruptly halted by the Apollo 1 fire on January 27, 1967, in which astronauts Gus Grissom, Ed White, and Roger B. Chaffee died, and the subsequent investigation. In October 1968, Apollo 7 evaluated the command module in Earth orbit, and in December Apollo 8 tested it in lunar orbit. In March 1969, Apollo 9 put the lunar module through its paces in Earth orbit, and in May Apollo 10 conducted a \"dress rehearsal\" in lunar orbit. By July 1969, all was in readiness for Apollo 11 to take the final step onto the Moon.\n\nThe Soviet Union appeared  to be winning the Space Race by beating the US to firsts, but its early lead was overtaken by the US Gemini program and Soviet failure to develop the N1 launcher, which would have been comparable to the Saturn V. The Soviets tried to beat the US to return lunar material to the Earth by means of uncrewed probes. On July 13, three days before Apollo 11's launch, the Soviet Union launched Luna 15, which reached lunar orbit before Apollo 11. During descent, a malfunction caused Luna 15 to crash in Mare Crisium about two hours before Armstrong and Aldrin took off from the Moon's surface to begin their voyage home. The Nuffield Radio Astronomy Laboratories radio telescope in England recorded transmissions from Luna 15 during its descent, and these were released in July 2009 for the 40th anniversary of Apollo 11.\n\nPersonnel\n\nPrime crew \n\nThe initial crew assignment of Commander Neil Armstrong, Command Module Pilot (CMP) Jim Lovell, and Lunar Module Pilot (LMP) Buzz Aldrin on the backup crew for Apollo9 was officially announced on November 20, 1967. Lovell and Aldrin had previously flown together as the crew of Gemini 12. Due to design and manufacturing delays in the LM, Apollo8 and Apollo9 swapped prime and backup crews, and Armstrong's crew became the backup for Apollo8. Based on the normal crew rotation scheme, Armstrong was then expected to command Apollo 11.\n\nThere would be one change. Michael Collins, the CMP on the Apollo8 crew, began experiencing trouble with his legs. Doctors diagnosed the problem as a bony growth between his fifth and sixth vertebrae, requiring surgery. Lovell took his place on the Apollo8 crew, and when Collins recovered he joined Armstrong's crew as CMP. In the meantime, Fred Haise filled in as backup LMP, and Aldrin as backup CMP for Apollo 8. Apollo 11 was the second American mission where all the crew members had prior spaceflight experience, the first being Apollo 10. The next was STS-26 in 1988.\n\nDeke Slayton gave Armstrong the option to replace Aldrin with Lovell, since some thought Aldrin was difficult to work with. Armstrong had no issues working with Aldrin but thought it over for a day before declining. He thought Lovell deserved to command his own mission (eventually Apollo 13).\n\nThe Apollo 11 prime crew had none of the close cheerful camaraderie characterized by that of Apollo 12. Instead, they forged an amiable working relationship. Armstrong in particular was notoriously aloof, but Collins, who considered himself a loner, confessed to rebuffing Aldrin's attempts to create a more personal relationship. Aldrin and Collins described the crew as \"amiable strangers\". Armstrong did not agree with the assessment, and said \"...\u00a0all the crews I was on worked very well together.\"\n\nBackup crew \n\nThe backup crew consisted of Lovell as Commander, William Anders as CMP, and Haise as LMP. Anders had flown with Lovell on Apollo8. In early 1969, he accepted a job with the National Aeronautics and Space Council effective August 1969, and announced he would retire as an astronaut at that time. Ken Mattingly was moved from the support crew into parallel training with Anders as backup CMP in case Apollo 11 was delayed past its intended July launch date, at which point Anders would be unavailable.\n\nBy the normal crew rotation in place during Apollo, Lovell, Mattingly, and Haise were scheduled to fly on Apollo 14 after backing up for Apollo 11. Later, Lovell's crew was forced to switch places with Alan Shepard's tentative Apollo 13 crew to give Shepard more training time.\n\nSupport crew \n\nDuring Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists and mission ground rules, and ensured the prime and backup crews were apprised of changes. They developed procedures, especially those for emergency situations, so these were ready for when the prime and backup crews came to train in the simulators, allowing them to concentrate on practicing and mastering them. For Apollo 11, the support crew consisted of Ken Mattingly, Ronald Evans and Bill Pogue.\n\nCapsule communicators \n\nThe capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo 11, the CAPCOMs were: Charles Duke, Ronald Evans, Bruce McCandless II, James Lovell, William Anders, Ken Mattingly, Fred Haise, Don L. Lind, Owen K. Garriott and Harrison Schmitt.\n\nFlight directors \n\nThe flight directors for this mission were:\n\nOther key personnel \n\nOther key personnel who played important roles in the Apollo 11 mission include the following.\n\nPreparations\n\nInsignia \n\nThe Apollo 11 mission emblem was designed by Collins, who wanted a symbol for \"peaceful lunar landing by the United States\". At Lovell's suggestion, he chose the bald eagle, the national bird of the United States, as the symbol. Tom Wilson, a simulator instructor, suggested an olive branch in its beak to represent their peaceful mission. Collins added a lunar background with the Earth in the distance. The sunlight in the image was coming from the wrong direction; the shadow should have been in the lower part of the Earth instead of the left. Aldrin, Armstrong and Collins decided the Eagle and the Moon would be in their natural colors, and decided on a blue and gold border. Armstrong was concerned that \"eleven\" would not be understood by non-English speakers, so they went with \"Apollo 11\", and they decided not to put their names on the patch, so it would \"be representative of everyone who had worked toward a lunar landing\".\n\nAn illustrator at the Manned Spacecraft Center (MSC) did the artwork, which was then sent off to NASA officials for approval. The design was rejected. Bob Gilruth, the director of the MSC felt the talons of the eagle looked \"too warlike\". After some discussion, the olive branch was moved to the talons. When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle for its reverse side. The design was also used for the smaller Susan B. Anthony dollar unveiled in 1979.\n\nCall signs \n\nAfter the crew of Apollo 10 named their spacecraft Charlie Brown and Snoopy, assistant manager for public affairs Julian Scheer wrote to George Low, the Manager of the Apollo Spacecraft Program Office at the MSC, to suggest the Apollo 11 crew be less flippant in naming their craft. The name Snowcone was used for the CM and Haystack was used for the LM in both internal and external communications during early mission planning.\n\nThe LM was named Eagle after the motif which was featured prominently on the mission insignia. At Scheer's suggestion, the CM was named Columbia after Columbiad, the giant cannon that launched a spacecraft (also from Florida) in Jules Verne's 1865 novel From the Earth to the Moon. It also referred to Columbia, a historical name of the United States.  In Collins' 1976 book, he said Columbia was in reference to Christopher Columbus.\n\nMementos \n\nThe astronauts had personal preference kits (PPKs), small bags containing personal items of significance they wanted to take with them on the mission. Five  PPKs were carried on Apollo 11: three (one for each astronaut) were stowed on Columbia before launch, and two on Eagle.\n\nNeil Armstrong's LM PPK contained a piece of wood from the Wright brothers' 1903 Wright Flyers left propeller and a piece of fabric from its wing, along with a diamond-studded astronaut pin originally given to Slayton by the widows of the Apollo1 crew. This pin had been intended to be flown on that mission and given to Slayton afterwards, but following the disastrous launch pad fire and subsequent funerals, the widows gave the pin to Slayton. Armstrong took it with him on Apollo 11.\n\nSite selection \n\nNASA's Apollo Site Selection Board announced five potential landing sites on February 8, 1968. These were the result of two years' worth of studies based on high-resolution photography of the lunar surface by the five uncrewed probes of the Lunar Orbiter program and information about surface conditions provided by the Surveyor program. The best Earth-bound telescopes could not resolve features with the resolution Project Apollo required. The landing site had to be close to the lunar equator to minimize the amount of propellant required, clear of obstacles to minimize maneuvering, and flat to simplify the task of the landing radar. Scientific value was not a consideration.\n\nAreas that appeared promising on photographs taken on Earth were often found to be totally unacceptable. The original requirement that the site be free of craters had to be relaxed, as no such site was found. Five sites were considered: Sites1 and2 were in the Sea of Tranquility (Mare Tranquillitatis); Site3 was in the Central Bay (Sinus Medii); and Sites4 and5 were in the Ocean of Storms (Oceanus Procellarum).\nThe final site selection was based on seven criteria:\n The site needed to be smooth, with relatively few craters;\n with approach paths free of large hills, tall cliffs or deep craters that might confuse the landing radar and cause it to issue incorrect readings;\n reachable with a minimum amount technologists, and social media enthusiasts. Its main of propellant;\n allowing for delays in the launch countdown;\n providing the Apollo spacecraft with a free-return trajectory, one that would allow it to coast around the Moon and safely return to Earth without requiring any engine firings should a problem arise on the way to the Moon;\n with good visibility during the landing approach, meaning the Sun would be between 7and 20 degrees behind the LM; and\n a general slope of less than two degrees in the landing area.\n\nThe requirement for the Sun angle was particularly restrictive, limiting the launch date to one day per month. A landing just after dawn was chosen to limit the temperature extremes the astronauts would experience. The Apollo Site Selection Board selected Site2, with Sites 3and5 as backups in the event of the launch being delayed. In May 1969, Apollo 10's lunar module flew to within  of Site2, and reported it was acceptable.\n\nFirst-step decision \nDuring the first press conference after the Apollo 11 crew was announced, the first question was, \"Which one of you gentlemen will be the first man to step onto the lunar surface?\" Slayton told the reporter it had not been decided, and Armstrong added that it was \"not based on individual desire\".\n\nOne of the first versions of the egress checklist had the lunar module pilot exit the spacecraft before the commander, which matched what had been done on Gemini missions, where the commander had never performed the spacewalk. Reporters wrote in early 1969 that Aldrin would be the first man to walk on the Moon, and Associate Administrator George Mueller told reporters he would be first as well. Aldrin heard that Armstrong would be the first because Armstrong was a civilian, which made Aldrin livid. Aldrin attempted to persuade other lunar module pilots he should be first, but they responded cynically about what they perceived as a lobbying campaign. Attempting to stem interdepartmental conflict, Slayton told Aldrin that Armstrong would be first since he was the commander. The decision was announced in a press conference on April 14, 1969.\n\nFor decades, Aldrin believed the final decision was largely driven by the lunar module's hatch location. Because the astronauts had their spacesuits on and the spacecraft was so small, maneuvering to exit the spacecraft was difficult. The crew tried a simulation in which Aldrin left the spacecraft first, but he damaged the simulator while attempting to egress. While this was enough for mission planners to make their decision, Aldrin and Armstrong were left in the dark on the decision until late spring. Slayton told Armstrong the plan was to have him leave the spacecraft first, if he agreed. Armstrong said, \"Yes, that's the way to do it.\"\n\nThe media accused Armstrong of exercising his commander's prerogative to exit the spacecraft first. Chris Kraft revealed in his 2001 autobiography that a meeting occurred between Gilruth, Slayton, Low, and himself to make sure Aldrin would not be the first to walk on the Moon. They argued that the first person to walk on the Moon should be like Charles Lindbergh, a calm and quiet person. They made the decision to change the flight plan so the commander was the first to egress from the spacecraft.\n\nPre-launch \n\nThe ascent stage of LM-5 Eagle arrived at the Kennedy Space Center on January 8, 1969, followed by the descent stage four days later, and CSM-107 Columbia on January 23. There were several differences between Eagle and Apollo 10's LM-4 Snoopy; Eagle had a VHF radio antenna to facilitate communication with the astronauts during their EVA on the lunar surface; a lighter ascent engine; more thermal protection on the landing gear; and a package of scientific experiments known as the Early Apollo Scientific Experiments Package (EASEP). The only change in the configuration of the command module was the removal of some insulation from the forward hatch. The CSM was mated on January 29, and moved from the Operations and Checkout Building to the Vehicle Assembly Building on April 14.\n\nThe S-IVB third stage of Saturn V AS-506 had arrived on January 18, followed by the S-II second stage on February 6, S-IC first stage on February 20, and the Saturn V Instrument Unit on February 27. At 12:30 on May 20, the  assembly departed the Vehicle Assembly Building atop the crawler-transporter, bound for Launch Pad 39A, part of Launch Complex 39, while Apollo 10 was still on its way to the Moon. A countdown test commenced on June 26, and concluded on July 2. The launch complex was floodlit on the night of July 15, when the crawler-transporter carried the mobile service structure back to its parking area. In the early hours of the morning, the fuel tanks of the S-II and S-IVB stages were filled with liquid hydrogen. Fueling was completed by three hours before launch. Launch operations were partly automated, with 43 programs written in the ATOLL programming language.\n\nSlayton roused the crew shortly after 04:00, and they showered, shaved, and had the traditional pre-flight breakfast of steak and eggs with Slayton and the backup crew. They then donned their space suits and began breathing pure oxygen. At 06:30, they headed out to Launch Complex 39. Haise entered Columbia about three hours and ten minutes before launch time. Along with a technician, he helped Armstrong into the left-hand couch at 06:54. Five minutes later, Collins joined him, taking up his position on the right-hand couch. Finally, Aldrin entered, taking the center couch. Haise left around two hours and ten minutes before launch. The closeout crew sealed the hatch, and the cabin was purged and pressurized. The closeout crew then left the launch complex about an hour before launch time. The countdown became automated at three minutes and twenty seconds before launch time. Over 450 personnel were at the consoles in the firing room.\n\nMission\n\nLaunch and flight to lunar orbit \n\nAn estimated one million spectators watched the launch of Apollo 11 from the highways and beaches in the vicinity of the launch site. Dignitaries included the Chief of Staff of the United States Army, General William Westmoreland, four cabinet members, 19 state governors, 40 mayors, 60 ambassadors and 200 congressmen. Vice President Spiro Agnew viewed the launch with former president Lyndon B. Johnson and his wife Lady Bird Johnson. Around 3,500 media representatives were present. About two-thirds were from the United States; the rest came from 55 other countries. The launch was televised live in 33 countries, with an estimated 25\u00a0million viewers in the United States alone. Millions more around the world listened to radio broadcasts. President Richard Nixon viewed the launch from his office in the White House with his NASA liaison officer, Apollo astronaut Frank Borman.\n\nSaturn V AS-506 launched Apollo 11 on July 16, 1969, at 13:32:00 UTC (9:32:00 EDT). At 13.2 seconds into the flight, the launch vehicle began to roll into its flight azimuth of 72.058\u00b0. Full shutdown of the first-stage engines occurred about 2minutes and 42 seconds into the mission, followed by separation of the S-IC and ignition of the S-II engines. The second stage engines then cut off and separated at about 9minutes and 8seconds, allowing the first ignition of the S-IVB engine a few seconds later.\n\nApollo 11 entered a near-circular Earth orbit at an altitude of  by, twelve minutes into its flight. After one and a half orbits, a second ignition of the S", "flag": 1, "segments": [[3418, 3428]], "strength": 5.5}
{"text": "Apollo 8 (December 21\u201327, 1968) was the first crewed spacecraft to leave low Earth orbit, and also the first human spaceflight to reach another astronomical object, namely the Moon, which the crew orbited without landing, and then departed safely back to Earth. These three astronauts\u2014Frank Borman, James Lovell, and William Anders\u2014were the first humans to witness and photograph an Earthrise retirement, a view that is likely fueling the rise.\n\nApollo 8 launched on December 21, 1968, and was the second crewed spaceflight mission flown in the United States Apollo space program after Apollo7, which stayed in Earth orbit. Apollo8 was the third flight and the first crewed launch of the Saturn V rocket, and was the first human spaceflight from the Kennedy Space Center, located adjacent to Cape Kennedy Air Force Station in Florida.\n\nOriginally planned as the second crewed Apollo Lunar Module and command module test, to be flown in an elliptical medium Earth orbit in early 1969, the mission profile was changed in August 1968 to a more ambitious command-module-only lunar orbital flight to be flown in December, as the lunar module was not yet ready to make its first flight. Astronaut Jim McDivitt's crew, who were training to fly the first lunar module flight in low Earth orbit, became the crew for the Apollo9 mission, and Borman's crew were moved to the Apollo8 mission. This left Borman's crew with two to three months' less training and preparation time than originally planned, and replaced the planned lunar module training with translunar navigation training.\n\nApollo 8 took 68 hours (almost three days) to travel the distance to the Moon. The crew orbited the Moon ten times over the course of twenty hours, during which they made a Christmas Eve television broadcast in which they read the first ten verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo8's successful mission paved the way for Apollo11 to fulfill U.S. president John F. Kennedy's goal of landing a man on the Moon before the end of the decade. The Apollo8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the northern Pacific Ocean. The crew members were named Time magazine's \"Men of the Year\" for 1968 upon their return.\n\nBackground\n\nIn the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This unexpected success stoked fears and imaginations around the world. It not only demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, it challenged American claims of military, economic, and technological superiority. The launch precipitated the Sputnik crisis and triggered the Space Race.\n\nPresident John F. Kennedy believed that not only was it in the national interest of the United States to be superior to other nations, but that the perception of American power was at least as important as the actuality. It was therefore intolerable to him for the Soviet Union to be more advanced in the field of space exploration. He was determined that the United States should compete, and sought a challenge that maximized its chances of winning.\n\nThe Soviet Union had heavier-lifting carrier rockets, which meant Kennedy needed to choose a goal that was beyond the capacity of the existing generation of rocketry, one where the US and Soviet Union would be starting from a position of equality\u2014something spectacular, even if it could not be justified on military, economic, or scientific grounds. After consulting with his experts and advisors, he chose such a project: to land a man on the Moon and return him to the Earth. This project already had a name: Project Apollo.\n\nAn early and crucial decision was the adoption of lunar orbit rendezvous, under which a specialized spacecraft would land on the lunar surface. The Apollo spacecraft therefore had three primary components: a command module (CM) with a cabin for the three astronauts, and the only part that would return to Earth; a service module (SM) to provide the command module with propulsion, electrical power, oxygen, and water; and a two-stage lunar module (LM), which comprised a descent stage for landing on the Moon and an ascent stage to return the astronauts to lunar orbit. This configuration could be launched by the Saturn V rocket that was then under development.\n\nFramework\n\nPrime crew\n\nThe initial crew assignment of Frank Borman as Commander, Michael Collins as Command Module Pilot (CMP) and William Anders as Lunar Module Pilot (LMP) for the third crewed Apollo flight was officially announced on November 20, 1967. Collins was replaced by Jim Lovell in July 1968, after suffering a cervical disc herniation that required surgery to repair. This crew was unique among pre-Space Shuttle era missions in that the commander was not the most experienced member of the crew: Lovell had flown twice before, on Gemini VII and Gemini XII. This would also be the first case of a commander of a previous mission (Lovell, Gemini XII) flying as a non-commander. This was also the first mission to reunite crewmates from a previous mission (Lovell and Borman, Gemini VII).\n\nAs of 2021, all three Apollo 8 astronauts remain alive.\n\nBackup crew\n\nThe backup crew assignment of Neil Armstrong as Commander, Lovell as CMP, and Buzz Aldrin as LMP for the third crewed Apollo flight was officially announced at the same time as the prime crew. When Lovell was reassigned to the prime crew, Aldrin was moved to CMP, and Fred Haise was brought in as backup LMP. Armstrong would later command Apollo11, with Aldrin as LMP and Collins as CMP. Haise served on the backup crew of Apollo11 as LMP and flew on Apollo13 as LMP.\n\nSupport personnel\n\nDuring Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists, and mission ground rules, and ensured that the prime and backup crews were apprised of any changes. The support crew developed procedures in the simulators, especially those for emergency situations, so that the prime and backup crews could practice and master them in their simulator training. For Apollo8, the support crew consisted of Ken Mattingly, Vance Brand, and Gerald Carr.\n\nThe capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo8, the CAPCOMs were Michael Collins, Gerald Carr, Ken Mattingly, Neil Armstrong, Buzz Aldrin, Vance Brand, and Fred Haise.\n\nThe mission control teams rotated in three shifts, each led by a flight director. The directors for Apollo8 were Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).\n\nMission insignia and callsign\n\nThe triangular shape of the insignia refers to the shape of the Apollo CM. It shows a red figure8 looping around the Earth and Moon to reflect both the mission number and the circumlunar nature of the mission. On the bottom of the8 are the names of the three astronauts. The initial design of the insignia was developed by Jim Lovell, who reportedly sketched it while riding in the back seat of a T-38 flight from California to Houston shortly after learning of Apollo8's re-designation as a lunar-orbital mission.\n\nThe crew wanted to name their spacecraft, but NASA did not allow it. The crew would have likely chosen Columbiad, the name of the giant cannon that launches a space vehicle in Jules Verne's 1865 novel From the Earth to the Moon. The Apollo11 CM was named Columbia in part for that reason.\n\nPreparations\n\nMission schedule\n\nOn September 20, 1967, NASA adopted a seven-step plan for Apollo missions, with the final step being a Moon landing. Apollo4 and Apollo6 were \"A\" missions, tests of the SaturnV launch vehicle using an uncrewed Block I production model of the command and service module (CSM) in Earth orbit. Apollo5 was a \"B\" mission, a test of the LM in Earth orbit. Apollo7, scheduled for October 1968, would be a \"C\" mission, a crewed Earth-orbit flight of the CSM. Further missions depended on the readiness of the LM. It had been decided as early as May 1967 that there would be at least four additional missions. Apollo8 was planned as the \"D\" mission, a test of the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott, and Russell Schweickart, while Borman's crew would fly the \"E\" mission, a more rigorous LM test in an elliptical medium Earth orbit as Apollo9, in early 1969. The \"F\" Mission would test the CSM and LM in lunar orbit, and the \"G\" mission would be the finale, the Moon landing.\n\nProduction of the LM fell behind schedule, and when Apollo8's LM-3 arrived at the Kennedy Space Center (KSC) in June 1968, more than a hundred significant defects were discovered, leading Bob Gilruth, the director of the Manned Spacecraft Center (MSC), and others to conclude that there was no prospect of LM-3 being ready to fly in 1968. Indeed, it was possible that delivery would slip to February or March 1969. Following the original seven-step plan would have meant delaying the \"D\" and subsequent missions, and endangering the program's goal of a lunar landing before the end of 1969. George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August 1968 to keep the program on track despite the LM delay. Since the next CSM (designated as \"CSM-103\") would be ready three months before LM-3, a CSM-only mission could be flown in December 1968. Instead of repeating the \"C\" mission flight of Apollo7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit and returning to Earth. The new mission would also allow NASA to test lunar landing procedures that would otherwise have had to wait until Apollo10, the scheduled \"F\" mission. This also meant that the medium Earth orbit \"E\" mission could be dispensed with. The net result was that only the \"D\" mission had to be delayed, and the plan for lunar landing in mid-1969 could remain on timeline.\n\nOn August 9, 1968, Low discussed the idea with Gilruth, Flight Director Chris Kraft, and the Director of Flight Crew Operations, Donald Slayton. They then flew to the Marshall Space Flight Center (MSFC) in Huntsville, Alabama, where they met with KSC Director Kurt Debus, Apollo Program Director Samuel C. Phillips, Rocco Petrone, and Wernher von Braun. Kraft considered the proposal feasible from a flight control standpoint; Debus and Petrone agreed that the next Saturn V, AS-503, could be made ready by December 1; and von Braun was confident the pogo oscillation problems that had afflicted Apollo6 had been fixed. Almost every senior manager at NASA agreed with this new mission, citing confidence in both the hardware and the personnel, along with the potential for a circumlunar flight providing a significant morale boost. The only person who needed some convincing was James E. Webb, the NASA administrator. Backed by the full support of his agency, Webb authorized the mission. Apollo8 was officially changed from a \"D\" mission to a \"C-Prime\" lunar-orbit mission.\n\nWith the change in mission for Apollo 8, Slayton asked McDivitt if he still wanted to fly it. McDivitt turned it down; his crew had spent a great deal of time preparing to test the LM, and that was what he still wanted to do. Slayton then decided to swap the prime and backup crews of the Dand Emissions. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104, since CM-104 could not be made ready by December. David Scott was not happy about giving up CM-103, the testing of which he had closely supervised, for CM-104, although the two were almost identical, and Anders was less than enthusiastic about being an LMP on a flight with no LM. Instead, in order that the spacecraft would have the correct weight and balance, Apollo8 would carry  LM test article, a boilerplate model of LM-3.\n\nAdded pressure on the Apollo program to make its 1969 landing goal was provided by the Soviet Union's Zond5 mission, which flew some living creatures, including Russian tortoises, in a cislunar loop around the Moon and returned them to Earth on September 21. There was speculation within NASA and the press that they might be preparing to launch cosmonauts on a similar circumlunar mission before the end of 1968.\n\nThe Apollo 8 crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how, before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total he had carried was a tenth of the amount that the Saturn V would burn every second. The next day, the Lindberghs watched the launch of Apollo8 from a nearby dune.\n\nSaturn V redesign\n\nThe Saturn V rocket used by Apollo8 was designated AS-503, or the \"03rd\" model of the SaturnV (\"5\") Rocket to be used in the Apollo-Saturn (\"AS\") program. When it was erected in the Vehicle Assembly Building on December 20, 1967, it was thought that the rocket would be used for an uncrewed Earth-orbit test flight carrying a boilerplate command and service module. Apollo6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second-stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a crewed mission until additional uncrewed test flights proved the Saturn V was ready.\n\nTeams from the MSFC went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system that used helium gas to absorb some of these vibrations was installed.\n\nOf equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it had accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage engine\u2014a faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches.\n\nThe teams tested their solutions in August 1968 at the MSFC. A Saturn stage IC was equipped with shock-absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems had been solved, they gave their approval for a crewed mission using AS-503.\n\nThe Apollo 8 spacecraft was placed on top of the rocket on September 21, and the rocket made the slow  journey to the launch pad on October9. Testing continued all through December until the day before launch, including various levels of readiness testing from December5 through 11. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on December 18, three days before the scheduled launch.\n\nMission\n\nParameter summary\n\nAs the first crewed spacecraft to orbit more than one celestial body, Apollo8's profile had two different sets of orbital parameters, separated by a translunar injection maneuver. Apollo lunar missions would begin with a nominal  circular Earth parking orbit. Apollo8 was launched into an initial orbit with an apogee of  and a perigee of, with an inclination of 32.51\u00b0 to the Equator, and an orbital period of 88.19 minutes. Propellant venting increased the apogee by  over the 2hours, 44 minutes, and 30 seconds spent in the parking orbit.\n\nThis was followed by a trans-lunar injection (TLI) burn of the S-IVB third stage for 318 seconds, accelerating the  command and service module and  LM test article from an orbital velocity of  to the injection velocity of  which set a record for the highest speed, relative to Earth, that humans had ever traveled. This speed was slightly less than the Earth's escape velocity of, but put Apollo8 into an elongated elliptical Earth orbit, close enough to the Moon to be captured by the Moon's gravity.\n\nThe standard lunar orbit for Apollo missions was planned as a nominal  circular orbit above the Moon's surface. Initial lunar orbit insertion was an ellipse with a perilune of  and an apolune of, at an inclination of 12\u00b0 from the lunar equator. This was then circularized at, with an orbital period of 128.7 minutes. The effect of lunar mass concentrations (\"mascons\") on the orbit was found to be greater than initially predicted; over the course of the ten lunar orbits lasting twenty hours, the orbital distance was perturbated to.\n\nApollo 8 achieved a maximum distance from Earth of.\n\nLaunch and trans-lunar injection\n\nApollo 8 was launched at 12:51:00 UTC (07:51:00 Eastern Standard Time) on December 21, 1968, using the Saturn V's three stages to achieve Earth orbit. The S-IC first stage landed in the Atlantic Ocean at, and the S-II second stage landed at. The S-IVB third stage injected the craft into Earth orbit and remained attached to perform the TLI burn that would put the spacecraft on a trajectory to the Moon.\n\nOnce the vehicle reached Earth orbit, both the crew and Houston flight controllers spent the next 2hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of the S-IVB third stage of the rocket was crucial, and in the last uncrewed test, it had failed to reignite for this burn. Collins was the first CAPCOM on duty, and at 2hours, 27 minutes and 22 seconds after launch he radioed, \"Apollo8. You are Go for TLI.\" This communication meant that Mission Control had given official permission for Apollo8 to go to the Moon. The S-IVB engine ignited on time and performed the TLI burn perfectly. Over the next five minutes, the spacecraft's speed increased from.\n\nAfter the S-IVB had placed the mission on course for the Moon, the command and service modules (CSM), the remaining Apollo8 spacecraft, separated from it. The crew then rotated the spacecraft to take photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from it\u2014this marked the first time humans had viewed the whole Earth at once. Borman became worried that the S-IVB was staying too close to the CSM and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the small reaction control system (RCS) thrusters on the service module (SM) to add  to their velocity away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in the Earth direction to increase speed, but at  instead. The time needed to prepare and perform the additional burn put the crew an hour behind their onboard tasks.\n\nFive hours after launch, Mission Control sent a command to the S-IVB to vent its remaining fuel, changing its trajectory. The S-IVB, with the test article attached, posed no further hazard to Apollo8, passing the orbit of the Moon and going into a  solar orbit with an inclination of 23.47\u00b0 from the plane of the ecliptic, and an orbital period of 340.80 days. It became a derelict object, and will continue to orbit the Sun for many years, if not retrieved.\n\nThe Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to  from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1milligray (mGy; during a year, the average human receives a dose of 2to 3mGy). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth, as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew members experienced an average radiation dose of 1.6 mGy.\n\nLunar trajectory\n\nLovell's main job as Command Module Pilot was as navigator. Although Mission Control normally performed all the actual navigation calculations, it was necessary to have a crew member adept at navigation so that the crew could return to Earth in case communication with Mission Control was lost. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task was made difficult by a large cloud of debris around the spacecraft, which made it hard to distinguish the stars.\n\nBy seven hours into the mission, the crew was about 1hour and 40 minutes behind flight plan because of the problems in moving away from the S-IVB and Lovell's obscured star sightings. The crew placed the spacecraft into Passive Thermal Control (PTC), also called \"barbecue roll\", in which the spacecraft rotated about once per hour around its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, parts of the spacecraft's outer surface could be heated to over, while the parts in shadow would be. These temperatures could cause the heat shield to crack and propellant lines to burst. Because it was impossible to get a perfect roll, the spacecraft swept out a cone as it rotated. The crew had to make minor adjustments every half hour as the cone pattern got larger and larger.\n\nThe first mid-course correction came eleven hours into the flight. The crew had been awake for more than 16 hours. Before launch, NASA had decided at least one crew member should be awake at all times to deal with problems that might arise. Borman started the first sleep shift but found sleeping difficult because of the constant radio chatter and mechanical noises. Testing on the ground had shown that the service propulsion system (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was \"co", "flag": 1, "segments": [[83, 93]], "strength": 5.5}
{"text": "The alkali metals consist of the chemical elements lithium (Li), sodium (Na), potassium (K), rubidium (Rb), caesium (Cs), and francium (Fr). Together with hydrogen they constitute group 1, which lies in the s-block of the periodic table. All alkali metals have their outermost electron in an s-orbital: this shared electron configuration results in their having very similar characteristic properties. Indeed, the alkali metals provide the best example of group trends in properties in the periodic table, with elements exhibiting well-characterised homologous behaviour. This family of elements is also known as the lithium family after its leading element.\n\nThe alkali metals are all shiny, soft, highly reactive metals at standard temperature and pressure and readily lose their outermost electron to form cations with charge +1. They can all be cut easily with a knife due to their softness, exposing a shiny surface that tarnishes rapidly in air due to oxidation by atmospheric moisture and oxygen (and in the case of lithium, nitrogen). Because of their high reactivity, they must be stored under oil to prevent reaction with air, and are found naturally only in salts and never as the free elements. Caesium, the fifth alkali metal, is the most reactive of all the metals. All the alkali metals react with water, with the heavier alkali metals reacting more vigorously than the lighter ones.\n\nAll of the discovered alkali metals occur in nature as their compounds: in order of abundance, sodium is the most abundant, followed by potassium, lithium, rubidium, caesium, and finally francium, which is very rare due to its extremely high radioactivity; francium occurs only in minute traces in nature as an intermediate step in some obscure side branches of the natural decay chains. Experiments have been conducted to attempt the synthesis of ununennium (Uue), which is likely to be the next member of the group; none was successful. However, ununennium may not be an alkali metal due to relativistic effects, which are predicted to have a large influence on the chemical properties of superheavy elements; even if it does turn out to be an alkali metal, it is predicted to have some differences in physical and chemical properties from its lighter homologues.\n\nMost alkali metals have many different applications. One of the best-known applications of the pure elements is the use of rubidium and caesium in atomic clocks, of which caesium atomic clocks form the basis of the second. A common application of the compounds of sodium is the sodium-vapour lamp, which emits light very efficiently. Table salt, or sodium chloride, has been used since antiquity. Lithium finds use as a psychiatric medication and as an anode in lithium batteries. Sodium and potassium are also essential elements, having major biological roles as electrolytes, and although the other alkali metals are not essential, they also have various effects on the body, both beneficial and harmful.\n\n\nHistory \n\nSodium compounds have been known since ancient times; salt (sodium chloride) has been an important commodity in human activities, as testified by the English word salary, referring to salarium, money paid to Roman soldiers for the purchase of salt. While potash has been used since ancient times, it was not understood for most of its history to be a fundamentally different substance from sodium mineral salts. Georg Ernst Stahl obtained experimental evidence which led him to suggest the fundamental difference of sodium and potassium salts in 1702, and Henri-Louis Duhamel du Monceau was able to prove this difference in 1736. The exact chemical composition of potassium and sodium compounds, and the status as chemical element of potassium and sodium, was not known then, and thus Antoine Lavoisier did not include either alkali in his list of chemical elements in 1789.\n\nPure potassium was first isolated in 1807 in England by Humphry Davy, who derived it from caustic potash (KOH, potassium hydroxide) by the use of electrolysis of the molten salt with the newly invented voltaic pile. Previous attempts at electrolysis of the aqueous salt were unsuccessful due to potassium's extreme reactivity. Potassium was the first metal that was isolated by electrolysis. Later that same year, Davy reported extraction of sodium from the similar substance caustic soda (NaOH, lye) by a similar technique, demonstrating the elements, and thus the salts, to be different.\n\nPetalite (Li Al Si4O10) was discovered in 1800 by the Brazilian chemist Jos\u00e9 Bonif\u00e1cio de Andrada in a mine on the island of Ut\u00f6, Sweden. However, it was not until 1817 that Johan August Arfwedson, then working in the laboratory of the chemist J\u00f6ns Jacob Berzelius, detected the presence of a new element while analysing petalite ore. This new element was noted by him to form compounds similar to those of sodium and potassium, though its carbonate and hydroxide were less soluble in water and more alkaline than the other alkali metals. Berzelius gave the unknown material the name \"lithion/lithina\", from the Greek word \u03bb\u03b9\u03b8o\u03c2 (transliterated as lithos, meaning \"stone\"), to reflect its discovery in a solid mineral, as opposed to potassium, which had been discovered in plant ashes, and sodium, which was known partly for its high abundance in animal blood. He named the metal inside the material \"lithium\". Lithium, sodium, and potassium were part of the discovery of periodicity, as they are among a series of triads of elements in the same group that were noted by Johann Wolfgang D\u00f6bereiner in 1850 as having similar properties.\n\nRubidium and caesium were the first elements to be discovered using the spectroscope, invented in 1859 by Robert Bunsen and Gustav Kirchhoff. The next year, they discovered caesium in the mineral water from Bad D\u00fcrkheim, Germany. Their discovery of rubidium came the following year in Heidelberg, Germany, finding it in the mineral lepidolite. The names of rubidium and caesium come from the most prominent lines in their emission spectra: a bright red line for rubidium (from the Latin word rubidus, meaning dark red or bright red), and a sky-blue line for caesium (derived from the Latin word caesius, meaning sky-blue).\n\nAround 1865 John Newlands produced a series of papers where he listed the elements in order of increasing atomic weight and similar physical and chemical properties that recurred at intervals of eight; he likened such periodicity to the octaves of music, where notes an octave apart have similar musical functions. His version put all the alkali metals then known (lithium to caesium), as well as copper, silver, and thallium (which show the +1 oxidation state characteristic of the alkali metals), together into a group. His table placed hydrogen with the halogens.\n\nAfter 1869, Dmitri Mendeleev proposed his periodic table placing lithium at the top of a group with sodium, potassium, rubidium, caesium, and thallium. Two years later, Mendeleev revised his table, placing hydrogen in group 1 above lithium, and also moving thallium to the boron group. In this 1871 version, copper, silver, and gold were placed twice, once as part of group IB, and once as part of a \"group VIII\" encompassing today's groups 8 to 11. After the introduction of the 18-column table, the group IB elements were moved to their current position \"The two things that do seem like they ought in the d-block, while alkali metals were left in group IA. Later the group's name was changed to group 1 in 1988. The trivial name \"alkali metals\" comes from the fact that the hydroxides of the group 1 elements are all strong alkalis when dissolved in water.\n\nThere were at least four erroneous and incomplete discoveries before Marguerite Perey of the Curie Institute in Paris, France discovered francium in 1939 by purifying a sample of actinium-227, which had been reported to have a decay energy of 220\u00a0keV. However, Perey noticed decay particles with an energy level below 80\u00a0keV. Perey thought this decay activity might have been caused by a previously unidentified decay product, one that was separated during purification, but emerged again out of the pure actinium-227. Various tests eliminated the possibility of the unknown element being thorium, radium, lead, bismuth, or thallium. The new product exhibited chemical properties of an alkali metal (such as coprecipitating with caesium salts), which led Perey to believe that it was element 87, caused by the alpha decay of actinium-227. Perey then attempted to determine the proportion of beta decay to alpha decay in actinium-227. Her first test put the alpha branching at 0.6%, a figure that she later revised to 1%.\n     \n\nThe next element below francium (eka-francium) in the periodic table would be ununennium (Uue), element 119. The synthesis of ununennium was first attempted in 1985 by bombarding a target of einsteinium-254 with calcium-48 ions at the superHILAC accelerator at Berkeley, California. No atoms were identified, leading to a limiting yield of 300 nb.\n\n +  \u2192 * \u2192 no atoms\n\nIt is highly unlikely that this reaction will be able to create any atoms of ununennium in the near future, given the extremely difficult task of making sufficient amounts of einsteinium-254, which is favoured for production of ultraheavy elements because of its large mass, relatively long half-life of 270 days, and availability in significant amounts of several micrograms, to make a large enough target to increase the sensitivity of the experiment to the required level; einsteinium has not been found in nature and has only been produced in laboratories, and in quantities smaller than those needed for effective synthesis of superheavy elements. However, given that ununennium is only the first period 8 element on the extended periodic table, it may well be discovered in the near future through other reactions, and indeed an attempt to synthesise it is currently ongoing in Japan. Currently, none of the period 8 elements has been discovered yet, and it is also possible, due to drip instabilities, that only the lower period 8 elements, up to around element 128, are physically possible. No attempts at synthesis have been made for any heavier alkali metals: due to their extremely high atomic number, they would require new, more powerful methods and technology to make.\n\nOccurrence\n\nIn the Solar System \n\nThe Oddo\u2013Harkins rule holds that elements with even atomic numbers are more common that those with odd atomic numbers, with the exception of hydrogen. This rule argues that elements with odd atomic numbers have one unpaired proton and are more likely to capture another, thus increasing their atomic number. In elements with even atomic numbers, protons are paired, with each member of the pair offsetting the spin of the other, enhancing stability. All the alkali metals have odd atomic numbers and they are not as common as the elements with even atomic numbers adjacent to them (the noble gases and the alkaline earth metals) in the Solar System. The heavier alkali metals are also less abundant than the lighter ones as the alkali metals from rubidium onward can only be synthesised in supernovae and not in stellar nucleosynthesis. Lithium is also much less abundant than sodium and potassium as it is poorly synthesised in both Big Bang nucleosynthesis and in stars: the Big Bang could only produce trace quantities of lithium, beryllium and boron due to the absence of a stable nucleus with 5 or 8 nucleons, and stellar nucleosynthesis could only pass this bottleneck by the triple-alpha process, fusing three helium nuclei to form carbon, and skipping over those three elements.\n\nOn Earth \n\nThe Earth formed from the same cloud of matter that formed the Sun, but the planets acquired different compositions during the formation and evolution of the solar system. In turn, the natural history of the Earth caused parts of this planet to have differing concentrations of the elements. The mass of the Earth is approximately 5.98\u00a0kg. It is composed mostly of iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur (2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%); with the remaining 1.2% consisting of trace amounts of other elements. Due to planetary differentiation, the core region is believed to be primarily composed of iron (88.8%), with smaller amounts of nickel (5.8%), sulfur (4.5%), and less than 1% trace elements.\n\nThe alkali metals, due to their high reactivity, do not occur naturally in pure form in nature. They are lithophiles and therefore remain close to the Earth's surface because they combine readily with oxygen and so associate strongly with silica, forming relatively low-density minerals that do not sink down into the Earth's core. Potassium, rubidium and caesium are also incompatible elements due to their large ionic radii.\n\nSodium and potassium are very abundant in earth, both being among the ten most common elements in Earth's crust; sodium makes up approximately 2.6% of the Earth's crust measured by weight, making it the sixth most abundant element overall and the most abundant alkali metal. Potassium makes up approximately 1.5% of the Earth's crust and is the seventh most abundant element. Sodium is found in many different minerals, of which the most common is ordinary salt (sodium chloride), which occurs in vast quantities dissolved in seawater. Other solid deposits include halite, amphibole, cryolite, nitratine, and zeolite. Many of these solid deposits occur as a result of ancient seas evaporating, which still occurs now in places such as Utah's Great Salt Lake and the Dead Sea. Despite their near-equal abundance in Earth's crust, sodium is far more common than potassium in the ocean, both because potassium's larger size makes its salts less soluble, and because potassium is bound by silicates in soil and what potassium leaches is absorbed far more readily by plant life than sodium.\n\nDespite its chemical similarity, lithium typically does not occur together with sodium or potassium due to its smaller size. Due to its relatively low reactivity, it can be found in seawater in large amounts; it is estimated that seawater is approximately 0.14 to 0.25 parts per million (ppm) or 25 micromolar. Its diagonal relationship with magnesium often allows it to replace magnesium in ferromagnesium minerals, where its crustal concentration is about 18\u00a0ppm, comparable to that of gallium and niobium. Commercially, the most important lithium mineral is spodumene, which occurs in large deposits worldwide.\n\nRubidium is approximately as abundant as zinc and more abundant than copper. It occurs naturally in the minerals leucite, pollucite, carnallite, zinnwaldite, and lepidolite, although none of these contain only rubidium and no other alkali metals. Caesium is more abundant than some commonly known elements, such as antimony, cadmium, tin, and tungsten, but is much less abundant than rubidium.\n\nFrancium-223, the only naturally occurring isotope of francium, is the product of the alpha decay of actinium-227 and can be found in trace amounts in uranium minerals. In a given sample of uranium, there is estimated to be only one francium atom for every 1018 uranium atoms. It has been calculated that there are at most 30\u00a0grams of francium in the earth's crust at any time, due to its extremely short half-life of 22 minutes.\n\nProperties\n\nPhysical and chemical \nThe physical and chemical properties of the alkali metals can be readily explained by their having an ns1 valence electron configuration, which results in weak metallic bonding. Hence, all the alkali metals are soft and have low densities, melting and boiling points, as well as heats of sublimation, vaporisation, and dissociation. They all crystallise in the body-centered cubic crystal structure, and have distinctive flame colours because their outer s electron is very easily excited. The ns1 configuration also results in the alkali metals having very large atomic and ionic radii, as well as very high thermal and electrical conductivity. Their chemistry is dominated by the loss of their lone valence electron in the outermost s-orbital to form the +1 oxidation state, due to the ease of ionising this electron and the very high second ionisation energy. Most of the chemistry has been observed only for the first five members of the group. The chemistry of francium is not well established due to its extreme radioactivity; thus, the presentation of its properties here is limited. What little is known about francium shows that it is very close in behaviour to caesium, as expected. The physical properties of francium are even sketchier because the bulk element has never been observed; hence any data that may be found in the literature are certainly speculative extrapolations.\n\nThe alkali metals are more similar to each other than the elements in any other group are to each other. Indeed, the similarity is so great that it is quite difficult to separate potassium, rubidium, and caesium, due to their similar ionic radii; lithium and sodium are more distinct. For instance, when moving down the table, all known alkali metals show increasing atomic radius, decreasing electronegativity, increasing reactivity, and decreasing melting and boiling points as well as heats of fusion and vaporisation. In general, their densities increase when moving down the table, with the exception that potassium is less dense than sodium. One of the very few properties of the alkali metals that does not display a very smooth trend is their reduction potentials: lithium's value is anomalous, being more negative than the others. This is because the Li+ ion has a very high hydration energy in the gas phase: though the lithium ion disrupts the structure of water significantly, causing a higher change in entropy, this high hydration energy is enough to make the reduction potentials indicate it as being the most electropositive alkali metal, despite the difficulty of ionising it in the gas phase.\n\nThe stable alkali metals are all silver-coloured metals except for caesium, which has a pale golden tint: it is one of only three metals that are clearly coloured (the other two being copper and gold). Additionally, the heavy alkaline earth metals calcium, strontium, and barium, as well as the divalent lanthanides europium and ytterbium, are pale yellow, though the colour is much less prominent than it is for caesium. Their lustre tarnishes rapidly in air due to oxidation. They all crystallise in the body-centered cubic crystal structure, and have distinctive flame colours because their outer s electron is very easily excited. Indeed, these flame test colours are the most common way of identifying them since all their salts with common ions are soluble.\n\nAll the alkali metals are highly reactive and are never found in elemental forms in nature. Because of this, they are usually stored in mineral oil or kerosene (paraffin oil). They react aggressively with the halogens to form the alkali metal halides, which are white ionic crystalline compounds that are all soluble in water except lithium fluoride (Li F). The alkali metals also react with water to form strongly alkaline hydroxides and thus should be handled with great care. The heavier alkali metals react more vigorously than the lighter ones; for example, when dropped into water, caesium produces a larger explosion than potassium if the same number of moles of each metal is used. The alkali metals have the lowest first ionisation energies in their respective periods of the periodic table because of their low effective nuclear charge and the ability to attain a noble gas configuration by losing just one electron. Not only do the alkali metals react with water, but also with proton donors like alcohols and phenols, gaseous ammonia, and alkynes, the last demonstrating the phenomenal degree of their reactivity. Their great power as reducing agents makes them very useful in liberating other metals from their oxides or halides.\n\nThe second ionisation energy of all of the alkali metals is very high as it is in a full shell that is also closer to the nucleus; thus, they almost always lose a single electron, forming cations. The alkalides are an exception: they are unstable compounds which contain alkali metals in a \u22121 oxidation state, which is very unusual as before the discovery of the alkalides, the alkali metals were not expected to be able to form anions and were thought to be able to appear in salts only as cations. The alkalide anions have filled s-subshells, which gives them enough stability to exist. All the stable alkali metals except lithium are known to be able to form alkalides, and the alkalides have much theoretical interest due to their unusual stoichiometry and low ionisation potentials. Alkalides are chemically similar to the electrides, which are salts with trapped electrons acting as anions. A particularly striking example of an alkalide is \"inverse sodium hydride\", H+Na\u2212 (both ions being complexed), as opposed to the usual sodium hydride, Na+H\u2212: it is unstable in isolation, due to its high energy resulting from the displacement of two electrons from hydrogen to sodium, although several derivatives are predicted to be metastable or stable.\n\nIn aqueous solution, the alkali metal ions form aqua ions of the formula [M(H2O)n]+, where n is the solvation number. Their coordination numbers and shapes agree well with those expected from their ionic radii. In aqueous solution the water molecules directly attached to the metal ion are said to belong to the first coordination sphere, also known as the first, or primary, solvation shell. The bond between a water molecule and the metal ion is a dative covalent bond, with the oxygen atom donating both electrons to the bond. Each coordinated water molecule may be attached by hydrogen bonds to other water molecules. The latter are said to reside in the second coordination sphere. However, for the alkali metal cations, the second coordination sphere is not well-defined as the +1 charge on the cation is not high enough to polarise the water molecules in the primary solvation shell enough for them to form strong hydrogen bonds with those in the second coordination sphere, producing a more stable entity. The solvation number for Li+ has been experimentally determined to be 4, forming the tetrahedral [Li(H2O)4]+: while solvation numbers of 3 to 6 have been found for lithium aqua ions, solvation numbers less than 4 may be the result of the formation of contact ion pairs, and the higher solvation numbers may be interpreted in terms of water molecules that approach [Li(H2O)4]+ through a face of the tetrahedron, though molecular dynamic simulations may indicate the existence of an octahedral hexaaqua ion. There are also probably six water molecules in the primary solvation sphere of the sodium ion, forming the octahedral [Na(H2O)6]+ ion. While it was previously thought that the heavier alkali metals also formed octahedral hexaa", "flag": 1, "segments": [[1610, 1620]], "strength": 5.5}
{"text": "The Atlantic Ocean is the second-largest of the world's five oceans, with an area of about. It covers approximately 20% of Earth's surface and about 29% of its water surface area. It is known to separate the \"Old World\" of Africa, Europe and Asia from the \"New World\" of the Americas in the European perception of the World.\n\nThe Atlantic Ocean occupies an elongated, S-shaped basin extending longitudinally between Europe and Africa to the east, and the Americas to the west. As one component of the interconnected World Ocean, it is connected in the north to the Arctic Ocean, to the Pacific Ocean in the southwest, the Indian Ocean in the southeast, and the Southern Ocean in the south (other definitions describe the Atlantic as extending southward to Antarctica). The Atlantic Ocean is divided in two parts, by the Equatorial Counter Current, with the North(ern) Atlantic Ocean and the South(ern) Atlantic Ocean at about 8\u00b0N.\n\nScientific explorations of the Atlantic include the Challenger expedition, the German Meteor expedition, Columbia University's Lamont-Doherty Earth Observatory and the United States Navy Hydrographic Office.\n\nEtymology \n\nThe oldest known mentions of an \"Atlantic\" sea come from Stesichorus around mid-sixth century BC (Sch. A. R. 1. 211):  (Greek: ; English: 'the Atlantic sea'; etym. 'Sea of Atlas') and in The Histories of Herodotus around 450 BC (Hdt. 1.202.4):  (Greek: ; English: 'Sea of Atlas' or 'the Atlantic sea') where the name refers to \"the sea beyond the pillars of Heracles\" which is said to be part of the sea that surrounds all land. In these uses, the name refers to Atlas, the Titan in Greek mythology, who supported the heavens and who later appeared as a frontispiece in Medieval maps and also lent his name to modern atlases. On the other hand, to early Greek sailors and in Ancient Greek mythological literature such as the Iliad and the Odyssey, this all-encompassing ocean was instead known as Oceanus, the gigantic river that encircled the world; in contrast to the enclosed seas well known to the Greeks: the Mediterranean and the Black Sea. In contrast, the term \"Atlantic\" originally referred specifically to the Atlas Mountains in Morocco and the sea off the Strait of Gibraltar and the North African coast. The Greek word  has been reused by scientists for the huge Panthalassa ocean that surrounded the supercontinent Pangaea hundreds of millions of years ago.\n\nThe term \"Aethiopian Ocean\", derived from Ancient Ethiopia, was applied to the Southern Atlantic as late as the mid-19th century. During the Age of Discovery, the Atlantic was also known to English cartographers as the Great Western Ocean.\n\nThe pond is a term often used by British and American speakers in reference to the Northern Atlantic Ocean, as a form of meiosis, or ironic understatement. It is used mostly when referring to events or circumstances \"on this side of the pond\" or \"on the other side of the pond\", rather than to discuss the ocean itself. The term dates to 1640, first appearing in print in pamphlet released during the reign of Charles I, and reproduced in 1869 in Nehemiah Wallington's Historical Notices of Events Occurring Chiefly in The Reign of Charles I, where \"great Pond\" is used in reference to the Atlantic Ocean by Francis Windebank, Charles I's Secretary of State.\n\nExtent and data \n\nThe International Hydrographic Organization (IHO) defined the limits of the oceans and seas in 1953, but some of these definitions have been revised since then and some are not used by various authorities, institutions, and countries, see for example the CIA World Factbook. Correspondingly, the extent and number of oceans and seas vary.\n\nThe Atlantic Ocean is bounded on the west by North and South America. It connects to the Arctic Ocean through the Denmark Strait, Greenland Sea, Norwegian Sea and Barents Sea. To the east, the boundaries of the ocean proper are Europe: the Strait of Gibraltar (where it connects with the Mediterranean Sea\u2014one of its marginal seas\u2014and, in turn, the Black Sea, both of which also touch upon Asia) and Africa.\n\nIn the southeast, the Atlantic merges into the Indian Ocean. The 20\u00b0 East meridian, running south from Cape Agulhas to Antarctica defines its border. In the 1953 definition it extends south to Antarctica, while in later maps it is bounded at the 60\u00b0 parallel by the Southern Ocean.\n\nThe Atlantic has irregular coasts indented by numerous bays, gulfs and seas. These include the Baltic Sea, Black Sea, Caribbean Sea, Davis Strait, Denmark Strait, part of the Drake Passage, Gulf of Mexico, Labrador Sea, Mediterranean Sea, North Sea, Norwegian Sea, almost all of the Scotia Sea, and other tributary water bodies. Including these marginal seas the coast line of the Atlantic measures  compared to  for the Pacific.\n\nIncluding its marginal seas, the Atlantic covers an area of  or 23.5% of the global ocean and has a volume of  or 23.3% of the total volume of the earth's oceans. Excluding its marginal seas, the Atlantic covers  and has a volume of. The North Atlantic covers  (11.5%) and the South Atlantic  (11.1%). The average depth is  and the maximum depth, the Milwaukee Deep in the Puerto Rico Trench, is.\n\nBiggest seas in Atlantic Ocean\nTop large seas:\n\n Sargasso Sea - 3.5 million km2\n Caribbean Sea - 2.754 million km2\n Mediterranean Sea - 2.510 million km2\n Gulf of Guinea - 2.35 million km2\n Gulf of Mexico - 1.550 million km2\n Norwegian Sea - 1.383 million km2\n Hudson Bay - 1.23 million km2\n Greenland Sea - 1.205 million km2\n Argentine Sea - 1 million km2\n Labrador Sea - 841,000\u00a0km2\n Irminger Sea - 780,000\u00a0km2\n Baffin Bay - 689,000\u00a0km2\n North Sea - 575,000\u00a0km2\n Black Sea - 436,000\u00a0km2\n Baltic Sea - 377,000\u00a0km2\n Libyan Sea - 350,000\u00a0km2\n Levantine Sea - 320,000\u00a0km2\n Celtic Sea - 300,000\u00a0km2\n Tyrrhenian Sea - 275,000\u00a0km2\n Gulf of Saint Lawrence - 226,000\u00a0km2\n Bay of Biscay - 223,000\u00a0km2\n Aegean Sea - 214,000\u00a0km2\n Ionian Sea - 169,000\u00a0km2\n Balearic Sea - 150,000\u00a0km2\n Adriatic Sea - 138,000\u00a0km2\n Gulf of Bothnia - 116,300\u00a0km2\n Sea of Crete - 95,000\u00a0km2\n Gulf of Maine - 93,000\u00a0km2\n Ligurian Sea - 80,000\u00a0km2\n English Channel - 75,000\u00a0km2\n James Bay - 68,300\u00a0km2\n Bothnian Sea - 66,000\u00a0km2\n Gulf of Sidra - 57,000\u00a0km2\n Sea of the Hebrides - 47,000\u00a0km2\n Irish Sea - 46,000\u00a0km2\n Sea of Azov - 39,000\u00a0km2\n Bothnian Bay - 36,800\u00a0km2\n Gulf of Venezuela - 17,840\u00a0km2\n Bay of Campeche - 16,000\u00a0km2\n Gulf of Lion - 15,000\u00a0km2\n Sea of Marmara - 11,350\u00a0km2\n Wadden Sea - 10,000\u00a0km2\n Archipelago Sea - 8,300\u00a0km2\n\nBathymetry \n\nThe bathymetry of the Atlantic is dominated by a submarine mountain range called the Mid-Atlantic Ridge (MAR). It runs from 87\u00b0N or  south of the North Pole to the subantarctic Bouvet Island at 54\u00b0S.\n\nMid-Atlantic Ridge \n\nThe MAR divides the Atlantic longitudinally into two halves, in each of which a series of basins are delimited by secondary, transverse ridges. The MAR reaches above  along most of its length, but is interrupted by larger transform faults at two places: the Romanche Trench near the Equator and the Gibbs Fracture Zone at 53\u00b0N. The MAR is a barrier for bottom water, but at these two transform faults deep water currents can pass from one side to the other.\n\nThe MAR rises  above the surrounding ocean floor and its rift valley is the divergent boundary between the North American and Eurasian plates in the North Atlantic and the South American and African plates in the South Atlantic. The MAR produces basaltic volcanoes in Eyjafjallaj\u00f6kull, Iceland, and pillow lava on the ocean floor. The depth of water at the apex of the ridge is less than  in most places, while the bottom of the ridge is three times as deep.\n\nThe MAR is intersected by two perpendicular ridges: the Azores\u2013Gibraltar Transform Fault, the boundary between the Nubian and Eurasian plates, intersects the MAR at the Azores Triple Junction, on either side of the Azores microplate, near the 40\u00b0N. A much vaguer, nameless boundary, between the North American and South American plates, intersects the MAR near or just north of the Fifteen-Twenty Fracture Zone, approximately at 16\u00b0N.\n\nIn the 1870s, the Challenger expedition discovered parts of what is now known as the Mid-Atlantic Ridge, or:\n The remainder of the ridge was discovered in the 1920s by the German Meteor expedition using echo-sounding equipment. The exploration of the MAR in the 1950s led to the general acceptance of seafloor spreading and plate tectonics.\n\nMost of the MAR runs under water but where it reaches the surfaces it has produced volcanic islands. While nine of these have collectively been nominated a World Heritage Site for their geological value, four of them are considered of \"Outstanding Universal Value\" based on their cultural and natural criteria: \u00deingvellir, Iceland; Landscape of the Pico Island Vineyard Culture, Portugal; Gough and Inaccessible Islands, United Kingdom; and Brazilian Atlantic Islands: Fernando de Noronha and Atol das Rocas Reserves, Brazil.\n\nOcean floor \n\nContinental shelves in the Atlantic are wide off Newfoundland, southernmost South America, and north-eastern Europe.\nIn the western Atlantic carbonate platforms dominate large areas, for example, the Blake Plateau and Bermuda Rise.\nThe Atlantic is surrounded by passive margins except at a few locations where active margins form deep trenches: the Puerto Rico Trench ( maximum depth) in the western Atlantic and South Sandwich Trench () in the South Atlantic. There are numerous submarine canyons off north-eastern North America, western Europe, and north-western Africa. Some of these canyons extend along the continental rises and farther into the abyssal plains as deep-sea channels.\n\nIn 1922, a historic moment in cartography and oceanography occurred. The USS Stewart used a Navy Sonic Depth Finder to draw a continuous map across the bed of the Atlantic. This involved little guesswork because the idea of sonar is straightforward with pulses being sent from the vessel, which bounce off the ocean floor, then return to the vessel. The deep ocean floor is thought to be fairly flat with occasional deeps, abyssal plains, trenches, seamounts, basins, plateaus, canyons, and some guyots. Various shelves along the margins of the continents constitute about 11% of the bottom topography with few deep channels cut across the continental rise.\n\nThe mean depth between 60\u00b0N and 60\u00b0S is, or close to the average for the global ocean, with a modal depth between.\n\nIn the South Atlantic the Walvis Ridge and Rio Grande Rise form barriers to ocean currents.\nThe Laurentian Abyss is found off the eastern coast of Canada.\n\nWater characteristics \n\nSurface water temperatures, which vary with latitude, current systems, and season and reflect the latitudinal distribution of solar energy, range from below  to over. Maximum temperatures occur north of the equator, and minimum values are found in the polar regions. In the middle latitudes, the area of maximum temperature variations, values may vary by.\n\nFrom October to June the surface is usually covered with sea ice in the Labrador Sea, Denmark Strait, and Baltic Sea.\n\nThe Coriolis effect circulates North Atlantic water in a clockwise direction, whereas South Atlantic water circulates counter-clockwise. The south tides in the Atlantic Ocean are semi-diurnal; that is, two high tides occur every 24 lunar hours. In latitudes above 40\u00b0 North some east\u2013west oscillation, known as the North Atlantic oscillation, occurs.\n\nSalinity \nOn average, the Atlantic is the saltiest major ocean; surface water salinity in the open ocean ranges from 33 to 37 parts per thousand (3.3\u20133.7%) by mass and varies with latitude and season. Evaporation, precipitation, river inflow and sea ice melting influence surface salinity values. Although the lowest salinity values are just north of the equator (because of heavy tropical rainfall), in general, the lowest values are in the high latitudes and along coasts where large rivers enter. Maximum salinity values occur at about 25\u00b0 north and south, in subtropical regions with low rainfall and high evaporation.\n\nThe high surface salinity in the Atlantic, on which the Atlantic thermohaline circulation is dependent, is maintained by two processes: the Agulhas Leakage/Rings, which brings salty Indian Ocean waters into the South Atlantic, and the \"Atmospheric Bridge\", which evaporates subtropical Atlantic waters and exports it to the Pacific.\n\nWater masses \n\nThe Atlantic Ocean consists of four major, upper water masses with distinct temperature and salinity. The Atlantic Subarctic Upper Water in the northernmost North Atlantic is the source for Subarctic Intermediate Water and North Atlantic Intermediate Water. North Atlantic Central Water can be divided into the Eastern and Western North Atlantic central Water since the western part is strongly affected by the Gulf Stream and therefore the upper layer is closer to underlying fresher subpolar intermediate water. The eastern water is saltier because of its proximity to Mediterranean Water. North Atlantic Central Water flows into South Atlantic Central Water at 15\u00b0N.\n\nThere are five intermediate waters: four low-salinity waters formed at subpolar latitudes and one high-salinity formed through evaporation. Arctic Intermediate Water, flows from north to become the source for North Atlantic Deep Water south of the Greenland-Scotland sill. These two intermediate waters have different salinity in the western and eastern basins. The wide range of salinities in the North Atlantic is caused by the asymmetry of the northern subtropical gyre and the large number of contributions from a wide range of sources: Labrador Sea, Norwegian-Greenland Sea, Mediterranean, and South Atlantic Intermediate Water.\n\nThe North Atlantic Deep Water (NADW) is a complex of four water masses, two that form by deep convection in the open ocean\u00a0\u2014 Classical and Upper Labrador Sea Water\u00a0\u2014 and two that form from the inflow of dense water across the Greenland-Iceland-Scotland sill\u00a0\u2014 Denmark Strait and Iceland-Scotland Overflow Water. Along its path across Earth the composition of the NADW is affected by other water masses, especially Antarctic Bottom Water and Mediterranean Overflow Water.\nThe NADW is fed by a flow of warm shallow water into the northern North Atlantic which is responsible for the anomalous warm climate in Europe. Changes in the formation of NADW have been linked to global climate changes in the past. Since man-made substances were introduced into the environment, the path of the NADW can be traced throughout its course by measuring tritium and radiocarbon from nuclear weapon tests in the 1960s and CFCs.\n\nGyres \n\nThe clockwise warm-water North Atlantic Gyre occupies the northern Atlantic, and the counter-clockwise warm-water South Atlantic Gyre appears in the southern Atlantic.\n\nIn the North Atlantic, surface circulation is dominated by three inter-connected currents: the Gulf Stream which flows north-east from the North American coast at Cape Hatteras; the North Atlantic Current, a branch of the Gulf Stream which flows northward from the Grand Banks; and the Subpolar Front, an extension of the North Atlantic Current, a wide, vaguely defined region separating the subtropical gyre from the subpolar gyre. This system of currents transport warm water into the North Atlantic, without which temperatures in the North Atlantic and Europe would plunge dramatically.\n\nNorth of the North Atlantic Gyre, the cyclonic North Atlantic Subpolar Gyre plays a key role in climate variability. It is governed by ocean currents from marginal seas and regional topography, rather than being steered by wind, both in the deep ocean and at sea level.\nThe subpolar gyre forms an important part of the global thermohaline circulation. Its eastern portion includes eddying branches of the North Atlantic Current which transport warm, saline waters from the subtropics to the north-eastern Atlantic. There this water is cooled during winter and forms return currents that merge along the eastern continental slope of Greenland where they form an intense (40\u201350\u00a0Sv) current which flows around the continental margins of the Labrador Sea. A third of this water becomes part of the deep portion of the North Atlantic Deep Water (NADW). The NADW, in its turn, feeds the meridional overturning circulation (MOC), the northward heat transport of which is threatened by anthropogenic climate change. Large variations in the subpolar gyre on a decade-century scale, associated with the North Atlantic oscillation, are especially pronounced in Labrador Sea Water, the upper layers of the MOC.\n\nThe South Atlantic is dominated by the anti-cyclonic southern subtropical gyre. The South Atlantic Central Water originates in this gyre, while Antarctic Intermediate Water originates in the upper layers of the circumpolar region, near the Drake Passage and the Falkland Islands. Both these currents receive some contribution from the Indian Ocean. On the African east coast, the small cyclonic Angola Gyre lies embedded in the large subtropical gyre.\nThe southern subtropical gyre is partly masked by a wind-induced Ekman layer. The residence time of the gyre is 4.4\u20138.5\u00a0years. North Atlantic Deep Water flows southward below the thermocline of the subtropical gyre.\n\nSargasso Sea \n\nThe Sargasso Sea in the western North Atlantic can be defined as the area where two species of Sargassum (S. fluitans and natans) float, an area  wide and encircled by the Gulf Stream, North Atlantic Drift, and North Equatorial Current. This population of seaweed probably originated from Tertiary ancestors on the European shores of the former Tethys Ocean and has, if so, maintained itself by vegetative growth, floating in the ocean for millions of years.\n\nOther species endemic to the Sargasso Sea include the sargassum fish, a predator with algae-like appendages which hovers motionless among the Sargassum. Fossils of similar fishes have been found in fossil bays of the former Tethys Ocean, in what is now the Carpathian region, that were similar to the Sargasso Sea. It is possible that the population in the Sargasso Sea migrated to the Atlantic as the Tethys closed at the end of the Miocene around 17\u00a0Ma. The origin of the Sargasso fauna and flora remained enigmatic for centuries. The fossils found in the Carpathians in the mid-20th century often called the \"quasi-Sargasso assemblage\", finally showed that this assemblage originated in the Carpathian Basin from where it migrated over Sicily to the Central Atlantic where it evolved into modern species of the Sargasso Sea.\n\nThe location of the spawning ground for European eels remained unknown for decades. In the early 19th century it was discovered that the southern Sargasso Sea is the spawning ground for both the European and American eel and that the former migrate more than  and the latter. Ocean currents such as the Gulf Stream transport eel larvae from the Sargasso Sea to foraging areas in North America, Europe, and Northern Africa. Recent but disputed research suggests that eels possibly use Earth's magnetic field to navigate through the ocean both as larvae and as adults.\n\nClimate \n\nClimate is influenced by the temperatures of the surface waters and water currents as well as winds. Because of the ocean's great capacity to store and release heat, maritime climates are more moderate and have less extreme seasonal variations than inland climates. Precipitation can be approximated from coastal weather data and air temperature from water temperatures.\n\nThe oceans are the major source of the atmospheric moisture that is obtained through evaporation. Climatic zones vary with latitude; the warmest zones stretch across the Atlantic north of the equator. The coldest zones are in high latitudes, with the coldest regions corresponding to the areas covered by sea ice. Ocean currents influence the climate by transporting warm and cold waters to other regions. The winds that are cooled or warmed when blowing over these currents influence adjacent land areas.\n\nThe Gulf Stream and its northern extension towards Europe, the North Atlantic Drift is thought to have at least some influence on climate. For all indications, Deargord will be one of example, the Gulf Stream helps moderate winter temperatures along the coastline of southeastern North America, keeping it warmer in winter along the coast than inland areas. The Gulf Stream also keeps extreme temperatures from occurring on the Florida Peninsula. In the higher latitudes, the North Atlantic Drift, warms the atmosphere over the oceans, keeping the British Isles and north-western Europe mild and cloudy, and not severely cold in winter like other locations at the same high latitude. The cold water currents contribute to heavy fog off the coast of eastern Canada (the Grand Banks of Newfoundland area) and Africa's north-western coast. In general, winds transport moisture and air over land areas.\n\nNatural hazards \n\nEvery winter, the Icelandic Low produces frequent storms. Icebergs are common from early February to the end of July across the shipping lanes near the Grand Banks of Newfoundland. The ice season is longer in the polar regions, but there is little shipping in those areas.\n\nHurricanes are a hazard in the western parts of the North Atlantic during the summer and autumn. Due to a consistently strong wind shear and a weak Intertropical Convergence Zone, South Atlantic tropical cyclones are rare.\n\nGeology and plate tectonics \nThe Atlantic Ocean is underlain mostly by dense mafic oceanic crust made up of basalt and gabbro and overlain by fine clay, silt and siliceous ooze on the abyssal plain. The continental margins and continental shelf mark lower density, but greater thickness felsic continental rock that is often much older than that of the seafloor. The oldest oceanic crust in the Atlantic is up to 145 million years and situated off the west coast of Africa and east coast of North America, or on either side of the South Atlantic.\n\nIn many places, the continental shelf and continental slope are covered in thick sedimentary layers. For instance, on the North American side of the ocean, large carbonate deposits formed in warm shallow waters such as Florida and the Bahamas,", "flag": 1, "segments": [[4587, 4597]], "strength": 5.5}
{"text": "Arthur Schopenhauer (, ; 22 February 1788\u00a0\u2013 21 September 1860) was a German philosopher. He is best known for his 1818 work The World as Will and Representation (expanded in 1844), which characterizes the phenomenal world as the product of a blind noumenal will. Building on the transcendental idealism of Immanuel Kant, Schopenhauer developed an atheistic metaphysical and ethical system that rejected the contemporaneous ideas of German idealism. He was among the first thinkers in Western philosophy to share and affirm significant tenets of Indian philosophy, such as asceticism, denial of the self, and the notion of the world-as-appearance. His work has been described as an exemplary manifestation of philosophical pessimism.\n\nThough his work failed to garner substantial attention during his lifetime, Schopenhauer had a posthumous impact across various disciplines, including philosophy, literature, and science. His writing on aesthetics, morality, and psychology have influenced many thinkers and artists. Those who have cited his influence include philosophers Emil Cioran, Friedrich Nietzsche and Ludwig Wittgenstein, scientists Erwin Schr\u00f6dinger and Albert Einstein, psychoanalysts Sigmund Freud and Carl Jung, writers Leo Tolstoy, Herman Melville, Thomas Mann, Hermann Hesse, Machado de Assis, Jorge Luis Borges, Marcel Proust and Samuel Beckett, and composers Richard Wagner, Johannes Brahms, Arnold Schoenberg and Gustav Mahler.\n\nLife\n\nEarly life \n\nArthur Schopenhauer was born on February 22, 1788, in Danzig (then part of the Polish\u2013Lithuanian Commonwealth; present-day Gda\u0144sk, Poland) on Heiligegeistgasse (present day \u015aw. Ducha 47), the son of Johanna Schopenhauer (n\u00e9e Trosiener; 1766\u20131838) and Heinrich Floris Schopenhauer (1747\u20131805), both descendants of wealthy German-Dutch patrician families. Neither of them was very religious; both supported the French Revolution, and were republicans, cosmopolitans and Anglophiles. When Danzig became part of Prussia in 1793, Heinrich moved to Hamburg\u2014a free city with a republican constitution. His firm continued trading in Danzig where most of their extended families remained. Adele, Arthur's only sibling, was born on July 12, 1797.\n\nIn 1797, Arthur was sent to Le Havre to live with the family of his father's business associate, Gr\u00e9goire de Bl\u00e9simaire. He seemed to enjoy his two-year stay there, learning to speak French and fostering a life-long friendship with Jean Anthime Gr\u00e9goire de Bl\u00e9simaire. As early as 1799, Arthur started playing the flute. In 1803, he accompanied his parents on a European tour of Holland, Britain, France, Switzerland, Austria and Prussia. Viewed as primarily a pleasure tour, Heinrich used the opportunity to visit some of his business associates abroad.\n\nHeinrich offered Arthur a choice:  he could stay at home and start preparations for university, or he could travel with them and continue his merchant education. Arthur chose to travel with them.  He deeply regretted his choice later because the merchant training was very tedious. He spent twelve weeks of the tour attending school in Wimbledon, where he was disillusioned by strict and intellectually shallow Anglican religiosity.  He continued to sharply criticize Anglican religiosity later in life despite his general Anglophilia. He was also under pressure from his father, who became very critical of his educational results.\n\nIn 1805, Heinrich drowned in a canal near their home in Hamburg. Although it was possible that his death was accidental, his wife and son believed that it was suicide. He was prone to anxiety and depression; each becoming more pronounced later in his life. Heinrich had become so fussy, even his wife started to doubt his mental health. \"There was, in the father's life, some dark and vague source of fear which later made him hurl himself to his death from the attic of his house in Hamburg.\"\n\nArthur showed similar moodiness during his youth and often acknowledged that he inherited it from his father. There were other instances of serious mental health history on his father's side of the family. Despite his hardship, Schopenhauer liked his father and later referred to him in a positive light. Heinrich Schopenhauer left the family with a significant inheritance that was split in three among Johanna and the children. Arthur Schopenhauer was entitled to control of his part when he reached the age of majority. He invested it conservatively in government bonds and earned annual interest that was more than double the salary of a university professor. After quitting his merchant apprenticeship, with some encouragement from his mother, he dedicated himself to studies at the Ernestine Gymnasium, Gotha, in Saxe-Gotha-Altenburg. While there, he also enjoyed social life among the local nobility, spending large amounts of money, which deeply concerned his frugal mother. He left the Gymnasium after writing a satirical poem about one of the schoolmasters. Although Arthur claimed that he left voluntarily, his mother's letter indicates that he may have been expelled.\n\nArthur spent two years as a merchant in honor of his dead father.  During this time, he had doubts about being able to start a new life as a scholar. Most of his prior education was as a practical merchant and he had trouble learning Latin; a prerequisite for an academic career.\n\nHis mother moved away, with her daughter Adele, to Weimar\u2014the then centre of German literature\u2014to enjoy social life among writers and artists. Arthur and his mother did not part on good terms. In one letter, she wrote: \"You are unbearable and burdensome, and very hard to live with; all your good qualities are overshadowed by your conceit, and made useless to the world simply because you cannot restrain your propensity to pick holes in other people.\" His mother, Johanna, was generally described as vivacious and sociable.  After they split, they did not meet again. She died 24 years later. Some of Arthur's negative opinions about women may be rooted in his troubled relationship with his mother.\n\nArthur moved to Hamburg to live with his friend Jean Anthime, who was also studying to become a merchant.\n\nEducation \nHe moved to Weimar but did not live with his mother, who even tried to discourage him from coming by explaining that they would not get along very well. Their relationship deteriorated even further due to their temperamental differences. He accused his mother of being financially irresponsible, flirtatious and seeking to remarry, which he considered an insult to his father's memory. His mother, while professing her love to him, criticized him sharply for being moody, tactless, and argumentative, and urged him to improve his behavior so that he would not alienate people. Arthur concentrated on his studies, which were now going very well, and he also enjoyed the usual social life such as balls, parties and theater. By that time Johanna's famous salon was well established among local intellectuals and dignitaries, the most celebrated of them being Goethe. Arthur attended her parties, usually when he knew that Goethe would be there\u2014although the famous writer and statesman seemed not even to notice the young and unknown student. It is possible that Goethe kept a distance because Johanna warned him about her son's depressive and combative nature, or because Goethe was then on bad terms with Arthur's language instructor and roommate, Franz Passow. Schopenhauer was also captivated by the beautiful Karoline Jagemann, mistress of Karl August, Grand Duke of Saxe-Weimar-Eisenach, and he wrote to her his only known love poem. Despite his later celebration of asceticism and negative views of sexuality, Schopenhauer occasionally had sexual affairs\u2014usually with women of lower social status, such as servants, actresses, and sometimes even paid prostitutes. In a letter to his friend Anthime he claims that such affairs continued even in his mature age and admits that he had two out-of-wedlock daughters (born in 1819 and 1836), both of whom died in infancy. In their youthful correspondence Arthur and Anthime were somewhat boastful and competitive about their sexual exploits\u2014but Schopenhauer seemed aware that women usually did not find him very charming or physically attractive, and his desires often remained unfulfilled.\n\nHe left Weimar to become a student at the University of G\u00f6ttingen in 1809. There are no written reasons about why Schopenhauer chose that university instead of the then more famous University of Jena, but G\u00f6ttingen was known as more modern and scientifically oriented, with less attention given to theology. Law or medicine were usual choices for young men of Schopenhauer's status who also needed career and income; he chose medicine due to his scientific interests. Among his notable professors were Bernhard Friedrich Thibaut, Arnold Hermann Ludwig Heeren, Johann Friedrich Blumenbach, Friedrich Stromeyer, Heinrich Adolf Schrader, Johann Tobias Mayer and Konrad Johann Martin Langenbeck. He studied metaphysics, psychology and logic under Gottlob Ernst Schulze, the author of Aenesidemus, who made a strong impression and advised him to concentrate on Plato and Immanuel Kant. He decided to switch from medicine to philosophy around 1810\u201311 and he left G\u00f6ttingen, which did not have a strong philosophy program:  besides Schulze, the only other philosophy professor was Friedrich Bouterwek, whom Schopenhauer disliked. He did not regret his medicinal and scientific studies;  he claimed that they were necessary for a philosopher, and even in Berlin he attended more lectures in sciences than in philosophy. During his days at G\u00f6ttingen, he spent considerable time studying, but also continued his flute playing and social life. His friends included Friedrich Gotthilf Osann, Karl Witte, Christian Charles Josias von Bunsen, and William Backhouse Astor Sr.\n\nHe arrived at the newly founded University of Berlin for the winter semester of 1811\u201312. At the same time, his mother had just begun her literary career; she published her first book in 1810, a biography of her friend Karl Ludwig Fernow, which was a critical success. Arthur attended lectures by the prominent post-Kantian philosopher Johann Gottlieb Fichte, but quickly found many points of disagreement with his ; he also found Fichte's lectures tedious and hard to understand. He later mentioned Fichte only in critical, negative terms\u2014seeing his philosophy as a lower-quality version of Kant's and considering it useful only because Fichte's poor arguments unintentionally highlighted some failings of Kantianism. He also attended the lectures of the famous Protestant theologian Friedrich Schleiermacher, whom he also quickly came to dislike. His notes and comments on Schleiermacher's lectures show that Schopenhauer was becoming very critical of religion and moving towards atheism. He learned by self-directed reading; besides Plato, Kant and Fichte he also read the works of Schelling, Fries, Jacobi, Bacon, Locke, and much current scientific literature. He attended philological courses by August B\u00f6ckh and Friedrich August Wolf and continued his naturalistic interests with courses by Martin Heinrich Klaproth, Paul Erman, Johann Elert Bode, Ernst Gottfried Fischer, Johann Horkel, Friedrich Christian Rosenthal and Hinrich Lichtenstein (Lichtenstein was also a friend whom he met at one of his mother's parties in Weimar).\n\nEarly work \nSchopenhauer left Berlin in a rush in 1813, fearing that the city could be attacked and that he could be pressed into military service as Prussia had just joined the war against France. He returned to Weimar but left after less than a month, disgusted by the fact that his mother was now living with her supposed lover, Georg Friedrich Konrad Ludwig M\u00fcller von Gerstenbergk (1778\u20131838), a civil servant twelve years younger than her; he considered the relationship an act of infidelity to his father's memory. He settled for a while in Rudolstadt, hoping that no army would pass through the small town.  He spent his time in solitude, hiking in the mountains and the Thuringian forest and writing his dissertation, On the Fourfold Root of the Principle of Sufficient Reason. He completed his dissertation at about the same time as the French army was defeated at the Battle of Leipzig. He became irritated by the arrival of soldiers in the town and accepted his mother's invitation to visit her in Weimar. She tried to convince him that her relationship with Gerstenbergk was platonic and that she had no intention of remarrying. But Schopenhauer remained suspicious and often came in conflict with Gerstenbergk because he considered him untalented, pretentious, and nationalistic. His mother had just published her second book, Reminiscences of a Journey in the Years 1803, 1804, and 1805, a description of their family tour of Europe, which quickly became a hit. She found his dissertation incomprehensible and said it was unlikely that anyone would ever buy a copy. In a fit of temper Arthur told her that people would read his work long after the \"rubbish\" she wrote was totally forgotten. In fact, although they considered her novels of dubious quality, the Brockhaus publishing firm held her in high esteem because they consistently sold well. Hans Brockhaus (1888\u20131965) later claimed that his predecessors \"saw nothing in this manuscript, but wanted to please one of our best-selling authors by publishing her son's work. We published more and more of her son Arthur's work and today nobody remembers Johanna, but her son's works are in steady demand and contribute to Brockhaus'[s] reputation.\" He kept large portraits of the pair in his office in Leipzig for the edification of his new editors.\n\nAlso contrary to his mother's prediction, Schopenhauer's dissertation made an impression on Goethe, to whom he sent it as a gift. Although it is doubtful that Goethe agreed with Schopenhauer's philosophical positions, he was impressed by his intellect and extensive scientific education. Their subsequent meetings and correspondence were a great honor to a young philosopher, who was finally acknowledged by his intellectual hero. They mostly discussed Goethe's newly published (and somewhat lukewarmly received) work on color theory. Schopenhauer soon started writing his own treatise on the subject, On Vision and Colors, which in many points differed from his teacher's. Although they remained polite towards each other, their growing theoretical disagreements\u2014and especially Schopenhauer's extreme self-confidence and tactless criticisms\u2014soon made Goethe become distant again and after 1816 their correspondence became less frequent. Schopenhauer later admitted that he was greatly hurt by this rejection, but he continued to praise Goethe, and considered his color theory a great introduction to his own.\n\nAnother important experience during his stay in Weimar was his acquaintance with Friedrich Majer\u2014a historian of religion, orientalist and disciple of Herder\u2014who introduced him to Eastern philosophy (see also Indology). Schopenhauer was immediately impressed by the Upanishads (he called them \"the production of the highest human wisdom\", and believed that they contained superhuman concepts) and the Buddha, and put them on a par with Plato and Kant. He continued his studies by reading the Bhagavad Gita, an amateurish German journal Asiatisches Magazin and Asiatick Researches by the Asiatic Society. Schopenhauer held a profound respect for Indian philosophy; although he loved Hindu texts, he was more interested in Buddhism, which he came to regard as the best religion. His studies on Hindu and Buddhist texts were constrained by the lack of adequate literature, and the latter were mostly restricted to Early Buddhism. He also claimed that he formulated most of his ideas independently, and only later realized the similarities with Buddhism.\n\nSchopenhauer read the Latin translation and praised the Upanishads in his main work, The World as Will and Representation (1819), as well as in his Parerga and Paralipomena (1851), and commented,In the whole world there is no study so beneficial and so elevating as that of the Upanishads. It has been the solace of my life, it will be the solace of my death.\n\nAs the relationship with his mother fell to a new low, in May 1814 he left Weimar and moved to Dresden. He continued his philosophical studies, enjoyed the cultural life, socialized with intellectuals and engaged in sexual affairs. His friends in Dresden were Johann Gottlob von Quandt, Friedrich Laun, Karl Christian Friedrich Krause and Ludwig Sigismund Ruhl, a young painter who made a romanticized portrait of him in which he improved some of Schopenhauer's unattractive physical features. His criticisms of local artists occasionally caused public quarrels when he ran into them in public. Schopenhauer's main occupation during his stay in Dresden was his seminal philosophical work, The World as Will and Representation, which he started writing in 1814 and finished in 1818. He was recommended to the publisher Friedrich Arnold Brockhaus by Baron Ferdinand von Biedenfeld, an acquaintance of his mother. Although Brockhaus accepted his manuscript, Schopenhauer made a poor impression because of his quarrelsome and fussy attitude, as well as very poor sales of the book after it was published in December 1818.\n\nIn September 1818, while waiting for his book to be published and conveniently escaping an affair with a maid that caused an unwanted pregnancy, Schopenhauer left Dresden for a year-long vacation in Italy. He visited Venice, Bologna, Florence, Naples and Milan, travelling alone or accompanied by mostly English tourists he met. He spent the winter months in Rome, where he accidentally met his acquaintance Karl Witte and engaged in numerous quarrels with German tourists in the Caff\u00e8 Greco, among them Johann Friedrich B\u00f6hmer, who also mentioned his insulting remarks and unpleasant character. He enjoyed art, architecture, and ancient ruins, attended plays and operas, and continued his philosophical contemplation and love affairs. One of his affairs supposedly became serious, and for a while he contemplated marriage to a rich Italian noblewoman\u2014but, despite his mentioning this several times, no details are known and it may have been Schopenhauer exaggerating. He corresponded regularly with his sister Adele and became close to her as her relationship with Johanna and Gerstenbergk also deteriorated. She informed him about their financial troubles as the banking house of A. L. Muhl in Danzig\u2014in which her mother invested their whole savings and Arthur a third of his\u2014was near bankruptcy. Arthur offered to share his assets, but his mother refused and became further enraged by his insulting comments. The women managed to receive only thirty percent of their savings while Arthur, using his business knowledge, took a suspicious and aggressive stance towards the banker and eventually received his part in full. The affair additionally worsened the relationships among all three members of the Schopenhauer family.\n\nHe shortened his stay in Italy because of the trouble with Muhl and returned to Dresden. Disturbed by the financial risk and the lack of responses to his book he decided to take an academic position since it provided him with both income and an opportunity to promote his views. He contacted his friends at universities in Heidelberg, G\u00f6ttingen and Berlin and found Berlin most attractive. He scheduled his lectures to coincide with those of the famous philosopher G. W. F. Hegel, whom Schopenhauer described as a \"clumsy charlatan\". He was especially appalled by Hegel's supposedly poor knowledge of natural sciences and tried to engage him in a quarrel about it already at his test lecture in March 1820. Hegel was also facing political suspicions at the time, when many progressive professors were fired, while Schopenhauer carefully mentioned in his application that he had no interest in politics. Despite their differences and the arrogant request to schedule lectures at the same time as his own, Hegel still voted to accept Schopenhauer to the university. Only five students turned up to Schopenhauer's lectures, and he dropped out of academia. A late essay, \"On University Philosophy\", expressed his resentment towards the work conducted in academies.\n\nLater life \n\nAfter his tenure in academia, he continued to travel extensively, visiting Leipzig, Nuremberg, Stuttgart, Schaffhausen, Vevey, Milan and spending eight months in Florence.  Before he left for his three-year travel, Schopenhauer had an incident with his Berlin neighbor, 47-year-old seamstress Caroline Louise Marquet.  The details of the August 1821 incident are unknown. He claimed that he had just pushed her from his entrance after she had rudely refused to leave, and that she had purposely fallen to the ground so that she could sue him.  She claimed that he had attacked her so violently that she had become paralyzed on her right side and unable to work.  She immediately sued him, and the process lasted until May 1827, when a court found Schopenhauer guilty and forced him to pay her an annual pension until her death in 1842.\n\nSchopenhauer enjoyed Italy, where he studied art and socialized with Italian and English nobles.  It was his last visit to the country.  He left for Munich and stayed there for a year, mostly recuperating from various health issues, some of them possibly caused by venereal diseases (the treatment his doctor used suggests syphilis).  He contacted publishers, offering to translate Hume into German and Kant into English, but his proposals were declined.  Returning to Berlin, he began to study Spanish so he could read some of his favorite authors in their original language.  He liked Pedro Calder\u00f3n de la Barca, Lope de Vega, Miguel de Cervantes, and especially Baltasar Graci\u00e1n.  He also made failed attempts to publish his translations of their works.  Few attempts to revive his lectures\u2014again scheduled at the same time as Hegel's\u2014also failed, as did his inquiries about relocating to other universities.\n\nDuring his Berlin years, Schopenhauer occasionally mentioned his desire to marry and have a family.  For a while he was unsuccessfully courting 17-year-old Flora Weiss, who was 22 years younger than himself.  His unpublished writings from that time show that he was already very critical of monogamy but still not advocating polygyny\u2014instead musing about a polyamorous relationship that he called \"tetragamy\".  He had an on-and-off relationship with a young dancer, Caroline Richter (she also used the surname Medon after one of her ex-lovers). They met when he was 33 and she was 19 and working at the Berlin Opera. She had already had numerous lovers and a son out of wedlock, and later gave birth to another son, this time to an unnamed foreign diplomat (she soon had another pregnancy but the child was stillborn). As Schopenhauer was preparing to escape from Berlin in 1831, due to a cholera epidemic, he offered to take her with him on the condition that she left her young son behind. She refused and he as senior as he can and stay at a top went alone; in his will he left her a significant sum of money, but insisted that it should not be spent in any way on her second son.\n\nSchopenhauer claimed that, in his last year in Berlin, he had a prophetic dream that urged him to escape from the city. As he arrived in his new home in Frankfurt, he supposedly had another supernatural experience, an", "flag": 1, "segments": [[4921, 4931]], "strength": 5.5}
{"text": "Angola (; ), officially the Republic of Angola (), is a country on the west coast of Southern Africa. It is the second-largest Lusophone (Portuguese-speaking) country in both total area and population (behind Brazil), and is the seventh-largest country in Africa. It is bordered by Namibia to the south, the DR Congo to the north, Zambia to the east, and the Atlantic Ocean to the west. Angola has an exclave province, the province of Cabinda, that borders the Republic of the Congo and the Democratic Republic of the Congo. The capital and most populated city is Luanda.\n\nAngola has been inhabited since the Paleolithic Age. Its formation as a nation-state originates from Portuguese colonisation, which initially began with coastal settlements and trading posts founded in the 16th century. In the 19th century, European settlers gradually began to establish themselves in the interior. The Portuguese colony that became Angola did not have its present borders until the early 20th century, owing to resistance by native groups such as the Cuamato, the Kwanyama and the Mbunda.\n\nAfter a protracted anti-colonial struggle, Angola achieved independence in 1975 as a Marxist\u2013Leninist one-party Republic. The country descended into a devastating civil war the same year, between the ruling People's Movement for the Liberation of Angola (MPLA), backed by the Soviet Union and Cuba, the insurgent anti-communist National Union for the Total Independence of Angola (UNITA), supported by the United States and South Africa, and the militant organisation National Liberation Front of Angola (FNLA), backed by the Democratic Republic of the Congo. The country has been governed by MPLA ever since its independence in 1975. Following the end of the war in 2002, Angola emerged as a relatively stable unitary, presidential constitutional republic.\n\nAngola has vast mineral and petroleum reserves, and its economy is among the fastest-growing in the world, especially since the end of the civil war; however, economic growth is highly uneven, with most of the nation's wealth concentrated in a disproportionately small sector of the population and highly concentrated in China and in the United States. The standard of living remains low for most Angolans; life expectancy is among the lowest in the world, while infant mortality is among the highest. \nSince 2017, the government of Jo\u00e3o Louren\u00e7o has made fighting corruption its flagship, so much so that many individuals of the previous government are either jailed or awaiting trial. Whilst this effort has been recognised by foreign diplomats to be legitimate, some skeptics see the actions as being politically motivated.\n\nAngola is a member of the United Nations, OPEC, African Union, the Community of Portuguese Language Countries, and the Southern African Development Community. As of 2021, the Angolan population is estimated at 32.87 million. Angola is multicultural and multiethnic. Angolan culture reflects centuries of Portuguese rule, namely the predominance of the Portuguese language and of the Catholic Church, intermingled with a variety of indigenous customs and traditions.\n\nEtymology\nThe name Angola comes from the Portuguese colonial name  ('Kingdom of Angola'), which appeared as early as Paulo Dias de Novais's 1571 charter. The toponym was derived by the Portuguese from the title  held by the kings of Ndongo and Matamba. Ndongo in the highlands, between the Kwanza and Lucala Rivers, was nominally a possession of the Kingdom of Kongo, but was seeking greater independence in the 16th century.\n\nHistory\n\nEarly migrations and political units\n\nModern Angola was populated predominantly by nomadic Khoi and San prior to the first Bantu migrations. The Khoi and San peoples were neither pastoralists nor cultivators, but rather hunter-gatherers. They were displaced by Bantu peoples arriving from the north in the first millennium BC, most of whom likely originated in what is today northwestern Nigeria and southern Niger. Bantu speakers introduced the cultivation of bananas and taro, as well as large cattle herds, to Angola's central highlands and the Luanda plain.\n\nA number of political entities were established; the best-known of these was the Kingdom of the Kongo, based in Angola, which extended northward to what is now the Democratic Republic of the Congo, the Republic of the Congo and Gabon. It established trade routes with other city-states and civilisations up to and down the coast of southwestern and western Africa and even with Great Zimbabwe and the Mutapa Empire, although it engaged in little or no transoceanic trade. To its south lay the Kingdom of Ndongo, from which the area of the later Portuguese colony was sometimes known as Dongo, and right next to them lay the Kingdom of Matamba.\n\nPortuguese colonization\n\nPortuguese explorer Diogo C\u00e3o reached the area in 1484. The previous year, the Portuguese had established relations with the Kongo, which stretched at the time from modern Gabon in the north to the Kwanza River in the south. The Portuguese established their primary early trading post at Soyo, which is now the northernmost city in Angola apart from the Cabinda exclave. Paulo Dias de Novais founded S\u00e3o Paulo de Loanda (Luanda) in 1575 with a hundred families of settlers and four hundred soldiers. Benguela was fortified in 1587 and became a township in 1617.\n\nThe Portuguese established several other settlements, forts and trading posts along the Angolan coast, principally trading in Angolan slaves for plantations. Local slave dealers provided a large number of slaves for the Portuguese Empire, usually in exchange for manufactured goods from Europe.\n\nThis part of the Atlantic slave trade continued until after Brazil's independence in the 1820s.\n\nDespite Portugal's territorial claims in Angola, its control over much of the country's vast interior was minimal. In the 16th century Portugal gained control of the coast through a series of treaties and wars. Life for European colonists was difficult and progress was slow. John Iliffe notes that \"Portuguese records of Angola from the 16th century show that a great famine occurred on average every seventy years; accompanied by epidemic disease, it might kill one-third or one-half of the population, destroying the demographic growth of a generation and forcing colonists back into the river valleys\".\n\nDuring the Portuguese Restoration War, the Dutch West India Company occupied the principal settlement of Luanda in 1641, using alliances with local peoples to carry out attacks against Portuguese holdings elsewhere. A fleet under Salvador de S\u00e1 retook Luanda in 1648; reconquest of the rest of the territory was completed by 1650. New treaties with the Kongo were signed in 1649; others with Njinga's Kingdom of Matamba and Ndongo followed in 1656. The conquest of Pungo Andongo in 1671 was the last major Portuguese expansion from Luanda, as attempts to invade Kongo in 1670 and Matamba in 1681 failed. Colonial outposts also expanded inward from Benguela, but until the late 19th century the inroads from Luanda and Benguela were very limited. Hamstrung by a series of political upheavals in the early 1800s, Portugal was slow to mount a large scale annexation of Angolan territory.\n\nThe slave trade was abolished in Angola in 1836, and in 1854 the colonial government freed all its existing slaves. Four years later, a more progressive administration appointed by Portugal abolished slavery altogether. However, these decrees remained largely unenforceable, and the Portuguese depended on assistance from the British Royal Navy to enforce their ban on the slave trade. This coincided with a series of renewed military expeditions into the bush.\n\nBy the mid-nineteenth century Portugal had established its dominion as far north as the Congo River and as far south as Moss\u00e2medes. Until the late 1880s, Portugal entertained proposals to link Angola with its colony in Mozambique but was blocked by British and Belgian opposition. In this period, the Portuguese came up against different forms of armed resistance from various peoples in Angola.\n\nThe Berlin Conference in 1884\u20131885 set the colony's borders, delineating the boundaries of Portuguese claims in Angola, although many details were unresolved until the 1920s. Trade between Portugal and its African territories rapidly increased as a result of protective tariffs, leading to increased development, and a wave of new Portuguese immigrants.\n\nAngolan independence\n\nUnder colonial law, black Angolans were forbidden from forming political parties or labour unions. The first nationalist movements did not take root until after World War II, spearheaded by a largely Westernised and Portuguese-speaking urban class, which included many mesti\u00e7os. During the early 1960s they were joined by other associations stemming from ad hoc labour activism in the rural workforce. Portugal's refusal to address increasing Angolan demands for self-determination provoked an armed conflict, which erupted in 1961 with the Baixa de Cassanje revolt and gradually evolved into a protracted war of independence that persisted for the next twelve years. Throughout the conflict, three militant nationalist movements with their own partisan guerrilla wings emerged from the fighting between the Portuguese government and local forces, supported to varying degrees by the Portuguese Communist Party.\n\nThe National Front for the Liberation of Angola (FNLA) recruited from Bakongo refugees in Zaire. Benefiting from particularly favourable political circumstances in L\u00e9opoldville, and especially from a common border with Zaire, Angolan political exiles were able to build up a power base among a large expatriate community from related families, clans, and traditions. People on both sides of the border spoke mutually intelligible dialects and enjoyed shared ties to the historical Kingdom of Kongo. Though as foreigners skilled Angolans could not take advantage of Mobutu Sese Seko's state employment programme, some found work as middlemen for the absentee owners of various lucrative private ventures. The migrants eventually formed the FNLA with the intention of making a bid for political power upon their envisaged return to Angola.\n\nA largely Ovimbundu guerrilla initiative against the Portuguese in central Angola from 1966 was spearheaded by Jonas Savimbi and the National Union for the Total Independence of Angola (UNITA). It remained handicapped by its geographic remoteness from friendly borders, the ethnic fragmentation of the Ovimbundu, and the isolation of peasants on European plantations where they had little opportunity to mobilise.\n\nDuring the late 1950s, the rise of the Marxist\u2013Leninist Popular Movement for the Liberation of Angola (MPLA) in the east and Dembos hills north of Luanda came to hold special significance. Formed as a coalition resistance movement by the Angolan Communist Party, the organisation's leadership remained predominantly Ambundu and courted public sector workers in Luanda. Although both the MPLA and its rivals accepted material assistance from the Soviet Union or the People's Republic of China, the former harboured strong anti-imperialist views and was openly critical of the United States and its support for Portugal. This allowed it to win important ground on the diplomatic front, soliciting support from nonaligned governments in Morocco, Ghana, Guinea, Mali, and the United Arab Republic.\n\nThe MPLA attempted to move its headquarters from Conakry to L\u00e9opoldville in October 1961, renewing efforts to create a common front with the FNLA, then known as the Union of and first in the world to have a major commercial Angolan Peoples (UPA) and its leader Holden Roberto. Roberto turned down the offer. When the MPLA first attempted to insert its own insurgents into Angola, the cadres were ambushed and annihilated by UPA partisans on Roberto's orders\u2014setting a precedent for the bitter factional strife which would later ignite the Angolan Civil War.\n\nAngolan Civil War\n\nThroughout the war of independence, the three rival nationalist movements were severely hampered by political and military factionalism, as well as their inability to unite guerrilla efforts against the Portuguese. Between 1961 and 1975 the MPLA, UNITA, and the FNLA competed for influence in the Angolan population and the international community. The Soviet Union and Cuba became especially sympathetic towards the MPLA and supplied that party with arms, ammunition, funding, and training. They also backed UNITA militants until it became clear that the latter was at irreconcilable odds with the MPLA.\n\nThe collapse of Portugal's Estado Novo government following the 1974 Carnation Revolution suspended all Portuguese military activity in Africa and the brokering of a ceasefire pending negotiations for Angolan independence. Encouraged by the Organisation of African Unity, Holden Roberto, Jonas Savimbi, and MPLA chairman Agostinho Neto met in Mombasa in early January 1975 and agreed to form a coalition government. This was ratified by the Alvor Agreement later that month, which called for general elections and set the country's independence date for 11 November 1975. All three factions, however, followed up on the ceasefire by taking advantage of the gradual Portuguese withdrawal to seize various strategic positions, acquire more arms, and enlarge their militant forces. The rapid influx of weapons from numerous external sources, especially the Soviet Union and the United States, as well as the escalation of tensions between the nationalist parties, fueled a new outbreak of hostilities. With tacit American and Zairean support the FNLA began massing large numbers of troops in northern Angola in an attempt to gain military superiority. Meanwhile, the MPLA began securing control of Luanda, a traditional Ambundu stronghold. Sporadic violence broke out in Luanda over the next few months after the FNLA attacked MPLA forces in March 1975. The fighting intensified with street clashes in April and May, and UNITA became involved after over two hundred of its members were massacred by an MPLA contingent that June. An upswing in Soviet arms shipments to the MPLA influenced a decision by the Central Intelligence Agency to likewise provide substantial covert aid to the FNLA and UNITA.\n\nIn August 1975, the MPLA requested direct assistance from the Soviet Union in the form of ground troops. The Soviets declined, offering to send advisers but no troops; however, Cuba was more forthcoming and in late September dispatched nearly five hundred combat personnel to Angola, along with sophisticated weaponry and supplies. By independence, there were over a thousand Cuban soldiers in the country. They were kept supplied by a massive airbridge carried out with Soviet aircraft. The persistent buildup of Cuban and Soviet military aid allowed the MPLA to drive its opponents from Luanda and blunt an abortive intervention by Zairean and South African troops, which had deployed in a belated attempt to assist the FNLA and UNITA. The FNLA was largely annihilated, although UNITA managed to withdraw its civil officials and militia from Luanda and seek sanctuary in the southern provinces. From there, Savimbi continued to mount a determined insurgent campaign against the MPLA.\n\nBetween 1975 and 1991, the MPLA implemented an economic and political system based on the principles of scientific socialism, incorporating central planning and a Marxist\u2013Leninist one-party state. It embarked on an ambitious programme of nationalisation, and the domestic private sector was essentially abolished. Privately owned enterprises were nationalised and incorporated into a single umbrella of state-owned enterprises known as Unidades Economicas Estatais (UEE). Under the MPLA, Angola experienced a significant degree of modern industrialisation. However, corruption and graft also increased and public resources were either allocated inefficiently or simply embezzled by officials for personal enrichment. The ruling party survived an attempted coup d'\u00e9tat by the Maoist-oriented Communist Organisation of Angola (OCA) in 1977, which was suppressed after a series of bloody political purges left thousands of OCA supporters dead (see 1977 Angolan coup d'\u00e9tat attempt). In the same period, the civil war culminated in its climax in a tandem of engagements, particularly the Battle of Quifangondo and soon after the Battle of Cuito Cuanavale, which marked a turning point with a subsequent defeat of the xenophobic South African Army.\n\nThe MPLA abandoned its former Marxist ideology at its third party congress in 1990, and declared social democracy to be its new platform. Angola subsequently became a member of the International Monetary Fund; restrictions on the market economy were also reduced in an attempt to draw foreign investment. By May 1991 it reached a peace agreement with UNITA, the Bicesse Accords, which scheduled new general elections for September 1992. When the MPLA secured a major electoral victory, UNITA objected to the results of both the presidential and legislative vote count and returned to war. Following the election, the Halloween massacre occurred from 30 October to 1 November, where MPLA forces killed thousands of UNITA supporters.\n\n21st century\n\nOn 22 March 2002, Jonas Savimbi was killed in action against government troops. UNITA and the MPLA reached a cease-fire shortly afterwards. UNITA gave up its armed wing and assumed the role of a major opposition party. Although the political situation of the country began to stabilise, regular democratic processes did not prevail until the elections in Angola in 2008 and 2012 and the adoption of a new constitution in 2010, all of which strengthened the prevailing dominant-party system.\n\nAngola has a serious humanitarian crisis; the result of the prolonged war, of the abundance of minefields, and the continued political agitation in favour of the independence of the exclave of Cabinda (carried out in the context of the protracted Cabinda conflict by the FLEC). While most of the internally displaced have now squatted around the capital, in musseques (shanty towns) the general situation for Angolans remains desperate.\n\nA drought in 2016 caused the worst food crisis in Southern Africa in 25 years, affecting 1.4 million people across seven of Angola's 18 provinces. Food prices rose and acute malnutrition rates doubled, with more than 95,000 children affected.\n\nJos\u00e9 Eduardo dos Santos stepped down as President of Angola after 38 years in 2017, being peacefully succeeded by Jo\u00e3o Louren\u00e7o, Santos' chosen successor.\n\nGeography\n\nAt, Angola is the world's twenty-fourth largest country - comparable in size to Mali, or twice the size of France or of Texas. It lies mostly between latitudes 4\u00b0 and 18\u00b0S, and longitudes 12\u00b0 and 24\u00b0E.\n\nAngola borders Namibia to the south, Zambia to the east, the Democratic Republic of the Congo to the north-east and the South Atlantic Ocean to the west.\n\nThe coastal exclave of Cabinda in the north has borders with the Republic of the Congo to the north and with the Democratic Republic of the Congo to the south.\nAngola's capital, Luanda, lies on the Atlantic coast in the northwest of the country.\n\nAngola had a 2018 Forest Landscape Integrity Index mean score of 8.35/10, ranking it 23rd globally out of 172 countries.\n\nClimate\n\nAngola, although located in a tropical zone, has a climate uncharacteristic of this zone, due to the confluence of three factors:\n\n the cold Benguela Current flowing along the southern part of the coast\n the relief in the interior\n the influence of the Namib Desert in the southwest\n\nAngola's climate features two seasons:\n\n rainfall from November to April\n drought, known as Cacimbo, from May to October, drier, as the name implies, and with lower temperatures\n\nWhile the coastline has high rainfall rates, decreasing from north to south and from  to, with average annual temperatures above, one can divide the interior zone into three areas:\n\n North, with high rainfall and high temperatures\n Central Plateau, with a dry season and average temperatures of the order of 19\u00a0\u00b0C\n South, with very high thermal amplitudes due to the proximity of the Kalahari Desert and the influence of masses of tropical air\n\nAdministrative divisions\n\n \n, Angola is divided into eighteen provinces (prov\u00edncias) and 162 municipalities. The municipalities are further divided into 559 communes (townships). The provinces are:\n\nExclave of Cabinda\n\nWith an area of approximately, the Northern Angolan province of Cabinda is unusual in being separated from the rest of the country by a strip, some  wide, of the Democratic Republic of Congo along the lower Congo River. Cabinda borders the Congo Republic to the north and north-northeast and the DRC to the east and south. The town of Cabinda is the chief population centre.\n\nAccording to a 1995 census, Cabinda had an estimated population of 600,000, approximately 400,000 of whom are citizens of neighboring countries. Population estimates are, however, highly unreliable. Consisting largely of tropical forest, Cabinda produces hardwoods, coffee, cocoa, crude rubber and palm oil.\n\nThe product for which it is best known, however, is its oil, which has given it the nickname, \"the Kuwait of Africa\". Cabinda's petroleum production from its considerable offshore reserves now accounts for more than half of Angola's output. Most of the oil along its coast was discovered under Portuguese rule by the Cabinda Gulf Oil Company (CABGOC) from 1968 onwards.\n\nEver since Portugal handed over sovereignty of its former overseas province of Angola to the local independence groups (MPLA, UNITA and FNLA), the territory of Cabinda has been a focus of separatist guerrilla actions opposing the Government of Angola (which has employed its armed forces, the FAA\u2014For\u00e7as Armadas Angolanas) and Cabindan separatists. The Front for the Liberation of the Enclave of Cabinda-Armed Forces of Cabinda (FLEC-FAC) announced the virtual Federal Republic of Cabinda under the Presidency of N'Zita Henriques Tiago. One of the characteristics of the Cabindan independence movement is its constant fragmentation, into smaller and smaller factions.\n\nGovernment and politics \n\nThe Angolan government is composed of three branches of government: executive, legislative and judicial. The executive branch of the government is composed of the President, the Vice-Presidents and the Council of Ministers.\n\nThe legislative branch comprises a 220-seat unicameral legislature, the National Assembly of Angola, elected from both provincial and nationwide constituencies. For decades, political power has been concentrated in the presidency.\n\nAfter 38 years of rule, in 2017 President dos Santos stepped down from MPLA leadership. The leader of the winning party at the parliamentary elections in August 2017 would become the next president of Angola. The MPLA selected the former Defense Minister Jo\u00e3o Louren\u00e7o as Santos' chosen successor.\n\nIn what has been described as a political purge to cement his power and reduce the influence of the Dos Santos family, Louren\u00e7o subsequently sacked the chief of the national police, Ambr\u00f3sio de Lemos, and the head of the intelligence service, Apolin\u00e1rio Jos\u00e9 Pereira. Both are considered allies of former president Dos Santos. He also removed Isabel Dos Santos, daughter of the former president, as head of the country's state oil company Sonangol.\n\nConstitution\n\nThe Constitution of 2010 establishes the broad outlines of government structure and delineates the rights and duties of citizens. The legal system is based on Portuguese law and customary law but is weak and fragmented, and courts operate in only 12 of more than 140 municipalities. A Supreme Court serves as the appellate tribunal; a Constitutional Court does not hold the powers of judicial review. Governors of the 18 provinces are appointed by the president. After the end of the civil war, the regime came under pressure from within as well as from the international community to become more democratic and less authoritarian. Its reaction was to implement a number of changes without substantially changing its character.\n\nThe new constitution, adopted in 2010, did away with presidential elections, introducing a system in which the president and the vice-president of the political party that wins the parliamentary elections automatically become president and vice-president. Directly or indirectly, the president controls all other organs of the state, so there is de", "flag": 1, "segments": [[2362, 2372]], "strength": 5.5}
{"text": "Alberta ( ) is one of the thirteen provinces and territories of Canada. It is part of Western Canada and is one of the three prairie provinces. Alberta is bordered by British Columbia to the west, Saskatchewan to the east, the Northwest Territories (NWT) to the north, and the U.S. state of Montana to the south. It is one of the only two landlocked provinces in Canada. The eastern part of the province is occupied by the Great Plains, while the western part borders the Rocky Mountains. The province has a predominantly continental climate but experiences quick temperature changes due to air aridity. Seasonal temperature swings are less pronounced in western Alberta due to occasional chinook winds.\n\nAlberta is the 4th largest province by area at, and the 4th most populous, being home to 4,262,635 people. Alberta's capital is Edmonton, while Calgary is its largest city. The two are Alberta's largest census metropolitan areas (CMAs) and both exceed one million people. More than half of Albertans live in either Edmonton or Calgary, which contributes to continuing the rivalry between the two cities. English is the official language of the province. In 2016, 76.0% of Albertans were anglophone, 1.8% were francophone and 22.2% were allophone.\n\nThe oil and gas industry is also a part of the province's identity. Alberta's economy is based on hydrocarbons, petrochemical industries, livestock, agriculture and frontier technologies. The oil industry has been a pillar of Alberta's economy since 1947, when substantial oil deposits were discovered at Leduc No. 1 well. Since Alberta is the province most rich in hydrocarbons, it provides 70% of the oil and natural gas exploited on Canadian soil. In 2018, Alberta's output was CDN$338.2 billion, 15.27% of Canada's GDP.\n\nIn the past, Alberta's political landscape hosted parties like the left-wing Liberals and the agrarian United Farmers of Alberta. Today, Alberta is generally perceived as a conservative province. The right-wing Social Credit Party held office continually from 1935 to 1971 before the centre-right Progressive Conservatives held office continually from 1971 to 2015, the latter being the longest unbroken run in government at the provincial or federal level in Canadian history.\n\nBefore becoming part of Canada, Alberta was home to several First Nations and was a territory used by fur traders of the Hudson's Bay Company. Canada acquired the lands that would become Alberta as part of the NWT on July 15, 1870. On September 1, 1905, Alberta was separated from the NWT as a result of the Alberta Act and designated the 8th province of Canada. From the late 1800s to early 1900s, many immigrants arrived, the biggest wave of which was pushed by Wilfrid Laurier, to prevent the prairies from being annexed by the United States. Massive oil resources were discovered in Alberta in 1947.\n\nAlberta is renowned for its natural beauty, richness in fossils and for housing important nature reserves. Alberta is home to six UNESCO designated World Heritage Sites: The Canadian Rocky Mountain Parks, Dinosaur Provincial Park, the Head-Smashed-In Buffalo Jump, Waterton-Glacier International Peace Park, Wood Buffalo National Park and Writing-on-Stone Provincial Park. Other popular sites include Banff National Park, Elk Island National Park, Jasper National Park, Waterton Lakes National Park, and Drumheller.\n\nEtymology\nAlberta was named after Princess Louise Caroline Alberta (1848\u20131939), the fourth daughter of Queen Victoria. Princess Louise was the wife of John Campbell, Marquess of Lorne, Governor General of Canada (1878\u201383). Lake Louise and Mount Alberta were also named in her honour.\n\nThe name \"Alberta\" itself is a feminine Latinized form of Albert, the name of Princess Louise's father, the Prince Consort (, masculine) and its Germanic cognates, ultimately derived from the Proto-Germanic language *A\u00fealaberhtaz (compound of \"noble\" + \"bright/famous\").\n\nGeography\n\nAlberta, with an area of, is the fourth-largest province after Quebec, Ontario and British Columbia.\n\nAlberta's southern border is the 49th parallel north, which separates it from the U.S. state of Montana. The 60th parallel north divides Alberta from the Northwest Territories. The 110th meridian west separates it from the province of Saskatchewan; while on the west its boundary with British Columbia follows the 120th meridian west south from the Northwest Territories at 60\u00b0N until it reaches the Continental Divide at the Rocky Mountains, and from that point follows the line of peaks marking the Continental Divide in a generally southeasterly direction until it reaches the Montana border at 49\u00b0N.\n\nThe province extends  north to south and  east to west at its maximum width. Its highest point is  at the summit of Mount Columbia in the Rocky Mountains along the southwest border while its lowest point is  on the Slave River in Wood Buffalo National Park in the northeast.\n\nWith the exception of the semi-arid climate of the steppe in the south-eastern section, the province has adequate water resources. There are numerous rivers and lakes in Alberta used for swimming, fishing and a range of water sports. There are three large lakes, Lake Claire () in Wood Buffalo National Park, Lesser Slave Lake (), and Lake Athabasca (), which lies in both Alberta and Saskatchewan. The longest river in the province is the Athabasca River, which travels  from the Columbia Icefield in the Rocky Mountains to Lake Athabasca.\n\nThe largest river is the Peace River with an average flow of. The Peace River originates in the Rocky Mountains of northern British Columbia and flows through northern Alberta and into the Slave River, a tributary of the Mackenzie River.\n\nAlberta's capital city, Edmonton, is located at about the geographic centre of the province. It is the most northerly major city in Canada and serves as a gateway and hub for resource development in northern Canada. With its proximity to Canada's largest oil fields, the region has most of western Canada's oil refinery capacity. Calgary is about  south of Edmonton and  north of Montana, surrounded by extensive ranching country. Almost 75% of the province's population lives in the Calgary\u2013Edmonton Corridor. The land grant policy to the railways served as a means to populate the province in its early years.\n\nMost of the northern half of the province is boreal forest, while the Rocky Mountains along the southwestern boundary are largely temperate coniferous forests of the Alberta Mountain forests and Alberta\u2013British Columbia foothills forests. The southern quarter of the province is prairie, ranging from shortgrass prairie in the southeastern corner to mixed grass prairie in an arc to the west and north of it. The central aspen parkland region extending in a broad arc between the prairies and the forests, from Calgary, north to Edmonton, and then east to Lloydminster, contains the most fertile soil in the province and most of the population. Much of the unforested part of Alberta is given over either to grain or to dairy farming, with mixed farming more common in the north and centre, while ranching and irrigated agriculture predominate in the south.\n\nThe Alberta badlands are located in southeastern Alberta, where the Red Deer River crosses the flat prairie and farmland, and features deep canyons and striking landforms. Dinosaur Provincial Park, near Brooks, showcases the badlands terrain, desert flora, and remnants from Alberta's past when dinosaurs roamed the then lush landscape.\n\nClimate \n\nAlberta extends for over  from north to south; its climate, therefore, varies considerably. Average high temperatures in January range from  in the southwest to  in the far north. The presence of the Rocky Mountains also influences the climate to the southwest, which disrupts the flow of the prevailing westerly winds and cause them to drop most of their moisture on the western slopes of the mountain ranges before reaching the province, casting a rain shadow over much of Alberta. The northerly location and isolation from the weather systems of the Pacific Ocean cause Alberta to have a dry climate with little moderation from the ocean. Annual precipitation ranges from  in the southeast to  in the north, except in the foothills of the Rocky Mountains where total precipitation including snowfall can reach  annually.\n\nNorthern Alberta is mostly covered by boreal forest and has a subarctic climate. The agricultural area of southern Alberta has a semi-arid steppe climate because the annual precipitation is less than the water that evaporates or is used by plants. The southeastern corner of Alberta, part of the Palliser Triangle, experiences greater summer heat and lower rainfall than the rest of the province, and as a result, suffers frequent crop yield problems and occasional severe droughts. his annual State of Nations address Friday to outline plans Western Alberta is protected by the mountains and enjoys the mild temperatures brought by winter chinook winds. Central and parts of northwestern Alberta in the Peace River region are largely aspen parkland, a biome transitional between prairie to the south and boreal forest to the north.\n\nAlberta has a humid continental climate with warm summers and cold winters. The province is open to cold Arctic weather systems from the north, which often produce cold winter conditions. As the fronts between the air masses shift north and south across Alberta, the temperature can change rapidly. Arctic air masses in the winter produce extreme minimum temperatures varying from  in northern Alberta to  in southern Alberta, although temperatures at these extremes are rare.\n\nIn the summer, continental air masses have produced record maximum temperatures from  in the mountains to over  in southeastern Alberta. Alberta is a sunny province. Annual bright sunshine totals range between 1,900 up to just under 2,600 hours per year. Northern Alberta gets about 18 hours of daylight in the summer. The average daytime temperatures range from around  in the Rocky Mountain valleys and far north, up to around  in the dry prairie of the southeast. The northern and western parts of the province experience higher rainfall and lower evaporation rates caused by cooler summer temperatures. The south and east-central portions are prone to drought-like conditions sometimes persisting for several years, although even these areas can receive heavy precipitation, sometimes resulting in flooding.\n\nIn the winter, the Alberta clipper, a type of intense, fast-moving winter storm that generally forms over or near the province and, pushed with great speed by the continental polar jetstream, descends over the rest of southern Canada and the northern tier of the United States. In southwestern Alberta, the cold winters are frequently interrupted by warm, dry chinook winds blowing from the mountains, which can propel temperatures upward from frigid conditions to well above the freezing point in a very short period. During one chinook recorded at Pincher Creek, temperatures soared from  in just one hour. The region around Lethbridge has the most chinooks, averaging 30 to 35 chinook days per year. Calgary has a 56% chance of a white Christmas, while Edmonton has an 86% chance.\n\nAfter Saskatchewan, Alberta experiences the most tornadoes in Canada with an average of 15 verified per year. Thunderstorms, some of them severe, are frequent in the summer, especially in central and southern Alberta. The region surrounding the Calgary\u2013Edmonton Corridor is notable for having the highest frequency of hail in Canada, which is caused by orographic lifting from the nearby Rocky Mountains, enhancing the updraft/downdraft cycle necessary for the formation of hail.\n\nEcology\n\nFlora \n\nIn central and northern Alberta the arrival of spring is marked by the early flowering of the prairie crocus (Pulsatilla nuttalliana) anemone; this member of the buttercup family has been recorded flowering as early as March, though April is the usual month for the general population. Other prairie flora known to flower early are the golden bean (Thermopsis rhombifolia) and wild rose (Rosa acicularis). Members of the sunflower (Helianthus) family blossom on the prairie in the summer months between July and September. The southern and east central parts of Alberta are covered by short prairie grass, which dries up as summer lengthens, to be replaced by hardy perennials such as the prairie coneflower (Ratibida), fleabane, and sage (Artemisia). Both yellow and white sweet clover (Melilotus) can be found throughout the southern and central areas of the province.\n\nThe trees in the parkland region of the province grow in clumps and belts on the hillsides. These are largely deciduous, typically aspen, poplar, and willow. Many species of willow and other shrubs grow in virtually any terrain. North of the North Saskatchewan River, evergreen forests prevail for thousands of square kilometres. Aspen poplar, balsam poplar (Populus balsamifera) (or in some parts cottonwood (Populus deltoides), and paper birch (Betula papyrifera) are the primary large deciduous species. Conifers include jack pine (Pinus banksiana), Rocky Mountain pine, lodgepole pine (Pinus contorta), both white and black spruce, and the deciduous conifer tamarack (Larix laricina).\n\nFauna \n\nThe four climatic regions (alpine, boreal forest, parkland, and prairie) of Alberta are home to many different species of animals. The south and central prairie was the homeland of the American bison, also known as buffalo, with its grasses providing pasture and breeding ground for millions of buffalo. The buffalo population was decimated during early settlement, but since then, buffalo have made a comeback, living on farms and in parks all over Alberta.\n\nHerbivores are found throughout the province. Moose, mule deer, elk, and white-tailed deer are found in the wooded regions, and pronghorn can be found in the prairies of southern Alberta. Bighorn sheep and mountain goats live in the Rocky Mountains. Rabbits, porcupines, skunks, squirrels, and many species of rodents and reptiles live in every corner of the province. Alberta is home to only one venomous snake species, the prairie rattlesnake.\n\nAlberta is home to many large carnivores such as wolves, grizzly bears, black bears, and mountain lions, which are found in the mountains and wooded regions. Smaller carnivores of the canine and feline families include coyotes, red foxes, Canada lynx, and bobcats. Wolverines can also be found in the northwestern areas of the province.\n\nCentral and northern Alberta and the region farther north are the nesting ground of many migratory birds. Vast numbers of ducks, geese, swans and pelicans arrive in Alberta every spring and nest on or near one of the hundreds of small lakes that dot northern Alberta. Eagles, hawks, owls, and crows are plentiful, and a huge variety of smaller seed and insect-eating birds can be found. Alberta, like other temperate regions, is home to mosquitoes, flies, wasps, and bees. Rivers and lakes are populated with pike, walleye, whitefish, rainbow, speckled, brown trout, and sturgeon. Native to the province, the bull trout, is the provincial fish and an official symbol of Alberta. Turtles are found in some water bodies in the southern part of the province. Frogs and salamanders are a few of the amphibians that make their homes in Alberta.\n\nAlberta is the only province in Canada\u2014as well as one of the few places in the world\u2014that is free of Norwegian rats. Since the early 1950s, the Government of Alberta has operated a rat-control program, which has been so successful that only isolated instances of wild rat sightings are reported, usually of rats arriving in the province aboard trucks or by rail. In 2006, Alberta Agriculture reported zero findings of wild rats; the only rat interceptions have been domesticated rats that have been seized from their owners. It is illegal for individual Albertans to own or keep Norwegian rats of any description; the animals can only be kept in the province by zoos, universities and colleges, and recognized research institutions. In 2009, several rats were\nfound and captured, in small pockets in southern Alberta, putting Alberta's rat-free status in jeopardy. A colony of rats was subsequently found in a landfill near Medicine Hat in 2012 and again in 2014.\n\nPaleontology \n\nAlberta has one of the greatest diversities and abundances of Late Cretaceous dinosaur fossils worldwide. Taxa are represented by complete fossil skeletons, isolated material, microvertebrate remains, and even mass graves. At least 38 dinosaur type specimens were collected in the province. The Foremost Formation, Oldman Formation and Dinosaur Park Formations collectively comprise the Judith River Group and are the most thoroughly studied dinosaur-bearing strata in Alberta.\n\nDinosaur-bearing strata are distributed widely throughout Alberta. The Dinosaur Provincial Park area contains outcrops of the Dinosaur Park Formation and Oldman Formation. In Alberta's central and southern regions are intermittent Scollard Formation outcrops. In the Drumheller Valley and Edmonton regions there are exposed Horseshoe Canyon facies. Other formations have been recorded as well, like the Milk River and Foremost Formations. The latter two have a lower diversity of documented dinosaurs, primarily due to their lower total fossil quantity and neglect from collectors who are hindered by the isolation and scarcity of exposed outcrops. Their dinosaur fossils are primarily teeth recovered from microvertebrate fossil sites. Additional geologic formations that have produced only a few fossils are the Belly River Group and St. Mary River Formations of the southwest and the northwestern Wapiti Formation, which contains two Pachyrhinosaurus bone beds. The Bearpaw Formation represents strata deposited during a marine transgression. Dinosaurs are known from this formation, but represent specimens washed out to sea or reworked from older sediments.\n\nHistory \n\nPaleo-Indians arrived in Alberta at least 10,000 years ago, toward the end of the last ice age. They are thought to have migrated from Siberia to Alaska on a land bridge across the Bering Strait and then possibly moved down the east side of the Rocky Mountains through Alberta to settle the Americas. Others may have migrated down the coast of British Columbia and then moved inland. Over time they differentiated into various First Nations peoples, including the Plains Indians of southern Alberta such as those of the Blackfoot Confederacy and the Plains Cree, who generally lived by hunting buffalo, and the more northerly tribes such as the Woodland Cree and Chipewyan who hunted, trapped, and fished for a living.\n\nAfter the British arrival in Canada, approximately half of the province of Alberta, south of the Athabasca River drainage, became part of Rupert's Land which consisted of all land drained by rivers flowing into Hudson Bay. This area was granted by Charles II of England to the Hudson's Bay Company (HBC) in 1670, and rival fur trading companies were not allowed to trade in it.\n\nThe Athabasca River and the rivers north of it were not in HBC territory because they drained into the Arctic Ocean instead of Hudson Bay, and they were prime habitats for fur-bearing animals. The first European explorer of the Athabasca region was Peter Pond, who learned of the Methye Portage, which allowed travel from southern rivers into the rivers north of Rupert's Land. Other North American fur traders formed the North West Company (NWC) of Montreal to compete with the HBC in 1779. The NWC occupied the northern part of Alberta territory. Peter Pond built Fort Athabasca on Lac la Biche in 1778. Roderick Mackenzie built Fort Chipewyan on Lake Athabasca ten years later in 1788. His cousin, Sir Alexander Mackenzie, followed the North Saskatchewan River to its northernmost point near Edmonton, then setting northward on foot, trekked to the Athabasca River, which he followed to Lake Athabasca. It was there he discovered the mighty outflow river which bears his name\u2014the Mackenzie River\u2014which he followed to its outlet in the Arctic Ocean. Returning to Lake Athabasca, he followed the Peace River upstream, eventually reaching the Pacific Ocean, and so he became the first European to cross the North American continent north of Mexico.\n\nThe extreme southernmost portion of Alberta was part of the French (and Spanish) territory of Louisiana and was sold to the United States in 1803. In the Treaty of 1818, the portion of Louisiana north of the Forty-Ninth Parallel was ceded to Great Britain.\n\nFur trade expanded in the north, but bloody battles occurred between the rival HBC and NWC, and in 1821 the British government forced them to merge to stop the hostilities. The amalgamated Hudson's Bay Company dominated trade in Alberta until 1870 when the newly formed Canadian Government purchased Rupert's Land. Northern Alberta was included in the North-Western Territory until 1870, when it and Rupert's land became Canada's North-West Territories.\n\nFirst Nations negotiated the Numbered Treaties with the Crown in which the Crown gained title to the land that would later become Alberta, and the Crown committed to the ongoing support of the First Nations and guaranteed their hunting and fishing rights. The most significant treaties for Alberta are Treaty 6 (1876), Treaty 7 (1877) and Treaty 8 (1899).\n\nThe District of Alberta was created as part of the North-West Territories in 1882. As settlement increased, local representatives to the North-West Legislative Assembly were added. After a long campaign for autonomy, in 1905, the District of Alberta was enlarged and given provincial status, with the election of Alexander Cameron Rutherford as the first premier. Less than a decade later, the First World War presented special challenges to the new province as an extraordinary number of volunteers left relatively few workers to maintain services and production. Over 50% of Alberta's doctors volunteered for service overseas.\n\nOn June 21, 2013, during the 2013 Alberta floods Alberta experienced heavy rainfall that triggered catastrophic flooding throughout much of the southern half of the province along the Bow, Elbow, Highwood and Oldman rivers and tributaries. A dozen municipalities in Southern Alberta declared local states of emergency on June 21 as water levels rose and numerous communities were placed under evacuation orders.\n\nIn 2016, the Fort McMurray wildfire resulted in the largest fire evacuation of residents in Alberta's history, as more than 80,000 people were ordered to evacuate.\n\nSince 2020, Alberta has been affected by the COVID-19 pandemic.\n\nDemographics \n\nThe 2021 Canadian census reported Alberta had a population of 4,262,635 living in 1,633,220 of its 1,772,670 total dwellings, an 4.8% change from its 2016 population of 4,067,175. With a land area of, it had a population density of  in 2021. Statistics Canada estimated the province to have a population of 4,464,170 in Q4 of 2021.\n\nSince 2000, Alberta's population has experienced a relatively high rate of growth, mainly because of its burgeoning economy. Between 2003 and 2004, the province had high birthrates (on par with some larger provinces such as British Columbia), relatively high immigration, and a high rate of interprovincial migration compared to other provinces. In 2016, Alberta continued to have the youngest population among the provinces with a median age of 36.7 years, compared with the national median of 41.2 years. Also in 2016, Alberta had the smallest proportion of seniors (12.3%) among the provinces and one of the highest population shares of children (19.2%), further contributing to Alberta's young and growing population.\n\nAbout 81% of the population lives in urban areas and only about 19% in", "flag": 1, "segments": [[1843, 1853]], "strength": 5.5}
{"text": "Albert Einstein ( ; ; 14 March 1879\u00a0\u2013 18 April 1955) was a German-born theoretical physicist, widely acknowledged to be one of the greatest physicists of all time. Einstein is best known for developing the theory of relativity, but he also made important contributions to the development of the theory of quantum mechanics. Relativity and quantum mechanics are together the two pillars of modern physics. His mass\u2013energy equivalence formula, which arises from relativity theory, has been dubbed \"the world's most famous equation\". His work is also known for its influence on the philosophy of science. He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His intellectual achievements and originality resulted in \"Einstein\" becoming synonymous with \"genius\".\n\nIn 1905, a year sometimes described as his annus mirabilis ('miracle year'), Einstein published four groundbreaking papers. These outlined the theory of the photoelectric effect, explained Brownian motion, introduced special relativity, and demonstrated mass-energy equivalence. Einstein thought that the laws of classical mechanics could no longer be reconciled with those of the electromagnetic field, which led him to develop his special theory of relativity. He then extended the theory to gravitational fields; he published a paper on general relativity in 1916, introducing his theory of gravitation. In 1917, he applied the general theory of relativity to model the structure of the universe. He continued to deal with problems of statistical mechanics and quantum theory, which led to his explanations of particle theory and the motion of molecules. He also investigated the thermal properties of light and the quantum theory of radiation, which laid the foundation of the photon theory of light. \n\nHowever, for much of the later part of his career, he worked on two ultimately unsuccessful endeavors. First, despite his great contributions to quantum mechanics, he opposed what it evolved into, objecting that nature \"does not play dice\". Second, he attempted to devise a unified field theory by generalizing his geometric theory of gravitation to include electromagnetism. As a result, he became increasingly isolated from the mainstream of modern physics.\n\nEinstein was born in the German Empire, but moved to Switzerland in 1895, forsaking his German citizenship (as a subject of the Kingdom of W\u00fcrttemberg) the following year. In 1897, at the age of 17, he enrolled in the mathematics and physics teaching diploma program at the Swiss Federal polytechnic school in Z\u00fcrich, graduating in 1900. In 1901, he acquired Swiss citizenship, which he kept for the rest of his life, and in 1903 he secured a permanent position at the Swiss Patent Office in Bern. In 1905, he was awarded a PhD by the University of Zurich. In 1914, Einstein moved to Berlin in order to join the Prussian Academy of Sciences and the Humboldt University of Berlin. In 1917, Einstein became director of the Kaiser Wilhelm Institute for Physics; he also became a German citizen again, this time Prussian.\n\nIn 1933, while Einstein was visiting the United States, Adolf Hitler came to power in Germany. Einstein, of Jewish origin, objected to the policies of the newly elected Nazi government; he settled in the United States and became an American citizen in 1940. On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential German nuclear weapons program and recommending that the US begin similar research. Einstein supported the Allies but generally denounced the idea of nuclear weapons.\n\nLife and career\n\nEarly life and education \n\nAlbert Einstein was born in Ulm, in the Kingdom of W\u00fcrttemberg in the German Empire, on 14 March 1879 into a family of secular Ashkenazi Jews. His parents were Hermann Einstein, a salesman and engineer, and Pauline Koch. In 1880, the family moved to North Lakewood in the Class 1A Class 2 Munich, where Einstein's father and his uncle Jakob founded Elektrotechnische Fabrik J. Einstein & Cie, a company that manufactured electrical equipment based on direct current.\n\nAlbert attended a Catholic elementary school in Munich, from the age of five, for three years. At the age of eight, he was transferred to the Luitpold Gymnasium (now known as the Albert Einstein Gymnasium), where he received advanced primary and secondary school education until he left the German Empire seven years later.\n\nIn 1894, Hermann and Jakob's company lost a bid to supply the city of Munich with electrical lighting because they lacked the capital to convert their equipment from the direct current (DC) standard to the more efficient alternating current (AC) standard. The loss forced the sale of the Munich factory. In search of business, the Einstein family moved to Italy, first to Milan and a few months later to Pavia. When the family moved to Pavia, Einstein, then 15, stayed in Munich to finish his studies at the Luitpold Gymnasium. His father intended for him to pursue electrical engineering, but Einstein clashed with the authorities and resented the school's regimen and teaching method. He later wrote that the spirit of learning and creative thought was lost in strict rote learning. At the end of December 1894, he traveled to Italy to join his family in Pavia, convincing the school to let him go by using a doctor's note. During his time in Italy he wrote a short essay with the title \"On the Investigation of the State of the Ether in a Magnetic Field\".\n\nEinstein excelled at math and physics from a young age, reaching a mathematical level years ahead of his peers. The 12-year-old Einstein taught himself algebra and Euclidean geometry over a single summer. Einstein also independently discovered his own original proof of the Pythagorean theorem at age 12. A family tutor Max Talmud says that after he had given the 12-year-old Einstein a geometry textbook, after a short time \"[Einstein] had worked through the whole book. He thereupon devoted himself to higher mathematics... Soon the flight of his mathematical genius was so high I could not follow.\" His passion for geometry and algebra led the 12-year-old to become convinced that nature could be understood as a \"mathematical structure\". Einstein started teaching himself calculus at 12, and as a 14-year-old he says he had \"mastered integral and differential calculus\".\n\nAt age 13, when he had become more seriously interested in philosophy (and music), Einstein was introduced to Kant's Critique of Pure Reason. Kant became his favorite philosopher, his tutor stating: \"At the time he was still a child, only thirteen years old, yet Kant's works, incomprehensible to ordinary mortals, seemed to be clear to him.\"\n\nIn 1895, at the age of 16, Einstein took the entrance examinations for the Swiss Federal polytechnic school in Z\u00fcrich (later the Eidgen\u00f6ssische Technische Hochschule, ETH). He failed to reach the required standard in the general part of the examination, but obtained exceptional grades in physics and mathematics. On the advice of the principal of the polytechnic school, he attended the Argovian cantonal school (gymnasium) in Aarau, Switzerland, in 1895 and 1896 to complete his secondary schooling. While lodging with the family of Professor Jost Winteler, he fell in love with Winteler's daughter, Marie. Albert's sister Maja later married Winteler's son Paul. In January 1896, with his father's approval, Einstein renounced his citizenship in the German Kingdom of W\u00fcrttemberg to avoid military service. In September 1896 he passed the Swiss Matura with mostly good grades, including a top grade of 6 in physics and mathematical subjects, on a scale of 1\u20136. At 17, he enrolled in the four-year mathematics and physics teaching diploma program at the Federal polytechnic school. Marie Winteler, who was a year older, moved to Olsberg, Switzerland, for a teaching post.\n\nEinstein's future wife, a 20-year-old Serbian named Mileva Mari\u0107, also enrolled at the polytechnic school that year. She was the only woman among the six students in the mathematics and physics section of the teaching diploma course. Over the next few years, Einstein's and Mari\u0107's friendship developed into a romance, and they spent countless hours debating and reading books together on extra-curricular physics in which they were both interested. Einstein wrote in his letters to Mari\u0107 that he preferred studying alongside her. In 1900, Einstein passed the exams in Maths and Physics and was awarded a Federal teaching diploma. There is eyewitness evidence and several letters over many years that indicate Mari\u0107 might have collaborated with Einstein prior to his landmark 1905 papers, known as the Annus Mirabilis papers, and that they developed some of the concepts together during their studies, although some historians of physics who have studied the issue disagree that she made any substantive contributions.\n\nMarriages and children \n\nEarly correspondence between Einstein and Mari\u0107 was discovered and published in 1987 which revealed that the couple had a daughter named \"Lieserl\", born in early 1902 in Novi Sad where Mari\u0107 was staying with her parents. Mari\u0107 returned to Switzerland without the child, whose real name and fate are unknown. The contents of Einstein's letter in September 1903 suggest that the girl was either given up for adoption or died of scarlet fever in infancy.\n\nEinstein and Mari\u0107 married in January 1903. In May 1904, their son Hans Albert Einstein was born in Bern, Switzerland. Their son Eduard was born in Z\u00fcrich in July 1910. The couple moved to Berlin in April 1914, but Mari\u0107 returned to Z\u00fcrich with their sons after learning that, despite their close relationship before, Einstein's chief romantic attraction was now his cousin Elsa L\u00f6wenthal; she was his first cousin maternally and second cousin paternally. Einstein and Mari\u0107 divorced on 14 February 1919, having lived apart for five years. As part of the divorce settlement, Einstein agreed to give Mari\u0107 his future (in the event, 1921) Nobel Prize money.\n\nIn letters revealed in 2015, Einstein wrote to his early love Marie Winteler about his marriage and his strong feelings for her. He wrote in 1910, while his wife was pregnant with their second child: \"I think of you in heartfelt love every spare minute and am so unhappy as only a man can be.\" He spoke about a \"misguided love\" and a \"missed life\" regarding his love for Marie.\n\nEinstein married L\u00f6wenthal in 1919, after having had a relationship with her since 1912. They emigrated to the United States in 1933. Elsa was diagnosed with heart and kidney problems in 1935 and died in December 1936.\n\nIn 1923, Einstein fell in love with a secretary named Betty Neumann, the niece of a close friend, Hans M\u00fchsam. In a volume of letters released by Hebrew University of Jerusalem in 2006, Einstein described about six women, including Margarete Lebach (a blonde Austrian), Estella Katzenellenbogen (the rich owner of a florist business), Toni Mendel (a wealthy Jewish widow) and Ethel Michanowski (a Berlin socialite), with whom he spent time and from whom he received gifts while being married to Elsa. Later, after the death of his second wife Elsa, Einstein was briefly in a relationship with Margarita Konenkova. Konenkova was a Russian spy who was married to the noted Russian sculptor Sergei Konenkov (who created the bronze bust of Einstein at the Institute for Advanced Study at Princeton).\n\nEinstein's son Eduard had a breakdown at about age 20 and was diagnosed with schizophrenia. His mother cared for him and he was also committed to asylums for several periods, finally being committed permanently after her death.\n\nPatent office \n\nAfter graduating in 1900, Einstein spent almost two frustrating years searching for a teaching post. He acquired Swiss citizenship in February 1901, but was not conscripted for medical reasons. With the help of Marcel Grossmann's father, he secured a job in Bern at the Swiss Patent Office, as an assistant examiner \u2013 level III.\n\nEinstein evaluated patent applications for a variety of devices including a gravel sorter and an electromechanical typewriter. In 1903, his position at the Swiss Patent Office became permanent, although he was passed over for promotion until he \"fully mastered machine technology\".\n\nMuch of his work at the patent office related to questions about transmission of electric signals and electrical-mechanical synchronization of time, two technical problems that show up conspicuously in the thought experiments that eventually led Einstein to his radical conclusions about the nature of light and the fundamental connection between space and time.\n\nWith a few friends he had met in Bern, Einstein started a small discussion group in 1902, self-mockingly named \"The Olympia Academy\", which met regularly to discuss science and philosophy. Sometimes they were joined by Mileva who attentively listened but did not participate. Their readings included the works of Henri Poincar\u00e9, Ernst Mach, and David Hume, which influenced his scientific and philosophical outlook.\n\nFirst scientific papers \nIn 1900, Einstein's paper \"Folgerungen aus den Capillarit\u00e4tserscheinungen\" (\"Conclusions from the Capillarity Phenomena\") was published in the journal Annalen der Physik. On 30 April 1905, Einstein completed his dissertation, A New Determination of Molecular Dimensions with Alfred Kleiner, Professor of Experimental Physics at the University of Z\u00fcrich, serving as pro-forma advisor. His work was accepted in July, and Einstein was awarded a Ph.D.\n\nAlso in 1905, which has been called Einstein's annus mirabilis (amazing year), he published four groundbreaking papers, on the photoelectric effect, Brownian motion, special relativity, and the equivalence of mass and energy, which were to bring him to the notice of the academic world, at the age of 26.\n\nAcademic career \nBy 1908, he was recognized as a leading scientist and was appointed lecturer at the University of Bern. The following year, after he gave a lecture on electrodynamics and the relativity principle at the University of Zurich, Alfred Kleiner recommended him to the faculty for a newly created professorship in theoretical physics. Einstein was appointed associate professor in 1909.\n\nEinstein became a full professor at the German Charles-Ferdinand University in Prague in April 1911, accepting Austrian citizenship in the Austro-Hungarian Empire to do so. During his Prague stay, he wrote 11 scientific works, five of them on radiation mathematics and on the quantum theory of solids. \n\nIn July 1912, he returned to his alma mater in Z\u00fcrich. From 1912 until 1914, he was a professor of theoretical physics at the ETH Zurich, where he taught analytical mechanics and thermodynamics. He also studied continuum mechanics, the molecular theory of heat, and the problem of gravitation, on which he worked with mathematician and friend Marcel Grossmann.\n\nWhen the \"Manifesto of the Ninety-Three\" was published in October 1914\u2014a document signed by a host of prominent German intellectuals that justified Germany's militarism and position during the First World War\u2014Einstein was one of the few German intellectuals to rebut its contents and sign the pacifistic \"Manifesto to the Europeans\".\n\nIn the spring of 1913, Einstein was enticed to move to Berlin with an offer that included membership in the Prussian Academy of Sciences, and a linked University of Berlin professorship, enabling him to concentrate exclusively on research. On 3 July 1913, he became a member of the Prussian Academy of Sciences in Berlin. Max Planck and Walther Nernst visited him the next week in Zurich to persuade him to join the academy, additionally offering him the post of director at the Kaiser Wilhelm Institute for Physics, which was soon to be established. Membership in the academy included paid salary and professorship without teaching duties at Humboldt University of Berlin. He was officially elected to the academy on 24 July, and he moved to Berlin the following year. His decision to move to Berlin was also influenced by the prospect of living near his cousin Elsa, with whom he had started a romantic affair. Einstein assumed his position with the academy, and Berlin University, after moving into his Dahlem apartment on 1 April 1914. As World War I broke out that year, the plan for Kaiser Wilhelm Institute for Physics was aborted. The institute was established on 1 October 1917, with Einstein as its director. In 1916, Einstein was elected president of the German Physical Society (1916\u20131918).\n\nIn 1911, Einstein used his 1907 Equivalence principle to calculate the deflection of light from another star by the Sun's gravity. In 1913, Einstein improved upon those calculations by using Riemannian space-time to represent the gravity field. By the fall of 1915, Einstein had successfully completed his general theory of relativity, which he used to calculate that deflection, and the perihelion precession of Mercury. In 1919, that deflection prediction was confirmed by Sir Arthur Eddington during the solar eclipse of 29 May 1919. Those observations were published in the international media, making Einstein world-famous. On 7 November 1919, the leading British newspaper The Times printed a banner headline that read: \"Revolution in Science\u00a0\u2013 New Theory of the Universe\u00a0\u2013 Newtonian Ideas Overthrown\".\n\nIn 1920, he became a Foreign Member of the Royal Netherlands Academy of Arts and Sciences. In 1922, he was awarded the 1921 Nobel Prize in Physics \"for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect\". While the general theory of relativity was still considered somewhat controversial, the citation also does not treat even the cited photoelectric work as an explanation but merely as a discovery of the law, as the idea of photons was considered outlandish and did not receive universal acceptance until the 1924 derivation of the Planck spectrum by S. N. Bose. Einstein was elected a Foreign Member of the Royal Society (ForMemRS) in 1921. He also received the Copley Medal from the Royal Society in 1925.\n\nEinstein resigned from the Prussian Academy in March 1933. Einstein's scientific accomplishments while in Berlin, included finishing the general theory of relativity, proving the gyromagnetic effect, contributing to the quantum theory of radiation, and Bose\u2013Einstein statistics.\n\n1921\u20131922: Travels abroad \n\nEinstein visited New York City for the first time on 2 April 1921, where he received an official welcome by Mayor John Francis Hylan, followed by three weeks of lectures and receptions. He went on to deliver several lectures at Columbia University and Princeton University, and in Washington, he accompanied representatives of the National Academy of Sciences on a visit to the White House. On his return to Europe he was the guest of the British statesman and philosopher Viscount Haldane in London, where he met several renowned scientific, intellectual, and political figures, and delivered a lecture at King's College London.\n\nHe also published an essay, \"My First Impression of the U.S.A.\", in July 1921, in which he tried briefly to describe some characteristics of Americans, much as had Alexis de Tocqueville, who published his own impressions in Democracy in America (1835). For some of his observations, Einstein was clearly surprised: \"What strikes a visitor is the joyous, positive attitude to life... The American is friendly, self-confident, optimistic, and without envy.\"\n\nIn 1922, his travels took him to Asia and later to Palestine, as part of a six-month excursion and speaking tour, as he visited Singapore, Ceylon and Japan, where he gave a series of lectures to thousands of Japanese. After his first public lecture, he met the emperor and empress at the Imperial Palace, where thousands came to watch. In a letter to his sons, he described his impression of the Japanese as being modest, intelligent, considerate, and having a true feel for art. In his own travel diaries from his 1922\u201323 visit to Asia, he expresses some views on the Chinese, Japanese and Indian people, which have been described as xenophobic and racist judgments when they were rediscovered in 2018.\n\nBecause of Einstein's travels to the Far East, he was unable to personally accept the Nobel Prize for Physics at the Stockholm award ceremony in December 1922. In his place, the banquet speech was made by a German diplomat, who praised Einstein not only as a scientist but also as an international peacemaker and activist.\n\nOn his return voyage, he visited Palestine for 12 days, his only visit to that region. He was greeted as if he were a head of state, rather than a physicist, which included a cannon salute upon arriving at the home of the British high commissioner, Sir Herbert Samuel. During one reception, the building was stormed by people who wanted to see and hear him. In Einstein's talk to the audience, he expressed happiness that the Jewish people were beginning to be recognized as a force in the world.\n\nEinstein visited Spain for two weeks in 1923, where he briefly met Santiago Ram\u00f3n y Cajal and also received a diploma from King Alfonso XIII naming him a member of the Spanish Academy of Sciences.\n\nFrom 1922 to 1932, Einstein was a member of the International Committee on Intellectual Cooperation of the League of Nations in Geneva (with a few months of interruption in 1923\u20131924), a body created to promote international exchange between scientists, researchers, teachers, artists, and intellectuals. Originally slated to serve as the Swiss delegate, Secretary-General Eric Drummond was persuaded by Catholic activists Oskar Halecki and Giuseppe Motta to instead have him become the German delegate, thus allowing Gonzague de Reynold to take the Swiss spot, from which he promoted traditionalist Catholic values. Einstein's former physics professor Hendrik Lorentz and the Polish chemist Marie Curie were also members of the committee.\n\n1925: Visit to South America \nIn the months of March and April 1925, Einstein visited South America, where he spent about a month in Argentina, a week in Uruguay, and a week in Rio de Janeiro, Brazil. Einstein's visit was initiated by Jorge Duclout (1856\u20131927) and Mauricio Nirenstein (1877\u20131935) with the support of several Argentine scholars, including Julio Rey Pastor, Jakob Laub, and Leopoldo Lugones. The visit by Einstein and his wife was financed primarily by the Council of the University of Buenos Aires and the Asociaci\u00f3n Hebraica Argentina (Argentine Hebraic Association) with a smaller contribution from the Argentine-Germanic Cultural Institution.\n\n1930\u20131931: Travel to the US \nIn December 1930, Einstein visited America for the second time, originally intended as a two-month working visit as a research fellow at the California Institute of Technology. After the national attention, he received during his first trip to the US, he and his arrangers aimed to protect his privacy. Although swamped with telegrams and invitations to receive awards or speak publicly, he declined them all.\n\nAfter arriving in New York City, Einstein was taken to various places and events, including Chinatown, a lunch with the editors of The New York Times, and a performance of Carmen at the Metropolitan Opera, where he was cheered by the audience on his arrival. During the days following, he was given the keys to the city by Mayor Jimmy Walker and met the president of Columbia University, who described Einstein as \"the ruling monarch of the mind\". Harry Emerson Fosdick, pastor at New York's Riverside Church, gave Einstein a tour of the church and showed him a full-size statue that the church made of Einstein, standing at the entrance. Also during his stay in New York, he joined a crowd of 15,000 people at Madison Square Garden during a Hanukkah celebration.\n\nEinstein next traveled to", "flag": 1, "segments": [[805, 815]], "strength": 5.5}
{"text": "Afghanistan (), officially the Islamic Emirate of Afghanistan, is a landlocked country located at the crossroads of Central and South Asia. Referred to as the Heart of Asia it is bordered by Pakistan to the east and south, Iran to the west, Turkmenistan to the northwest, Uzbekistan to the north, Tajikistan to the northeast, and China to the northeast and east. Occupying  of land, the country is predominately mountainous with plains in the north and the southwest, which are separated by the Hindu Kush mountain range., its population is 40.2 million, composed mostly of ethnic Pashtuns, Tajiks, Hazaras, and Uzbeks. Kabul is the country's largest city and also serves as its capital.\n\nHuman habitation in Afghanistan dates back to the Middle Paleolithic era, and the country's strategic location along the historic Silk Road connected it to the cultures of other parts of Asia as well as Europe, leaving behind a mosaic of ethnolinguistic and religious groups that has influenced the modern Afghan nation. Known as the Graveyard of Empires the land has historically been home to various peoples and has witnessed numerous military campaigns, including those by Alexander the Great, the Maurya Empire, Arab Muslims, the Mongols, the British, the Soviet Union, and most recently by an American-led coalition. Afghanistan also served as the source from which the Greco-Bactrians and the Mughals, among others, rose to form major empires. The various conquests and periods in both the Iranian and Indian cultural spheres made the area a center for Zoroastrianism, Buddhism, Hinduism, and later Islam throughout history.\n\nThe modern state of Afghanistan began with the Durrani dynasty in the 18th century, with the Durrani Afghan Empire at its peak having spanned from eastern Iran to northern India. Following its decline and the death of Timur Shah, it was divided into the smaller independent kingdoms of Herat, Kandahar and Kabul, before being reunited in the 19th century after wars of unification led by Dost Mohammad Khan. During this time, Afghanistan became a buffer state in the Great Game between the British Empire (in British-ruled India) and the Russian Empire; from India, the British attempted to subjugate Afghanistan but were repelled in the First Anglo-Afghan War; however, the Second Anglo-Afghan War saw a British victory and the successful establishment of British political influence over Afghanistan. Following the Third Anglo-Afghan War in 1919, Afghanistan became free of foreign dominance, and eventually emerged as the independent Kingdom of Afghanistan in June 1926 under Amanullah Khan. This monarchy lasted almost 50 years, until Zahir Shah was overthrown in 1973, following which the Republic of Afghanistan was established. Since the late 1970s, Afghanistan's history has been dominated by extensive warfare, including coups, revolutions, invasions, insurgencies, and civil wars. The country is currently under the control of the Taliban, an Islamist political movement which returned to power in 2021 after a 20-year-long war with the United States and its allies.\n\nThe country has high levels of terrorism, poverty, and child malnutrition. Afghanistan's economy is the world's 96th-largest, with a gross domestic product (GDP) of $72.9\u00a0billion by purchasing power parity; the country fares much worse in terms of per-capita GDP (PPP), ranking 169th out of 186 countries.\n\nEtymology \n\nThe root name \"Afgh\u0101n\" is, according to some scholars, derived from the Sanskrit name of the A\u015bvakan or Assakan, ancient inhabitants of the Hindu Kush region. A\u015bvakan literally means \"horsemen\", \"horse breeders\", or \"cavalrymen\" (from a\u015bva or aspa, the Sanskrit and Avestan words for \"horse\"). Historically, the ethnonym Afgh\u0101n was used to refer to ethnic Pashtuns. The Arabic and Persian form of the name, Af\u0121\u0101n, was first attested in the 10th-century geography book Hudud al-'Alam. The last part of the name, \"-stan\" is a Persian suffix for \"place of\". Therefore, \"Afghanistan\" translates to \"land of the Afghans\", or \"land of the Pashtuns\" in a historical sense. According to the third edition of the Encyclopedia of Islam:\n\nHistory \n\nMany empires and kingdoms have also risen to power in Afghanistan, such as the Greco-Bactrians, Indo-Scythians, Kushans, Kidarites, Hephthalites, Alkhons, Nezaks, Zunbils, Turk Shahis, Hindu Shahis, Lawiks, Saffarids, Samanids, Ghaznavids, Ghurids, Khaljis, Kartids, Lodis, Surs, Mughals, and finally, the Hotak and Durrani dynasties, which marked the political origins of the modern state. Throughout millennia several cities within the modern day Afghanistan served as capitals of various empires, namely, Bactra (Balkh), Alexandria on the Oxus (Ai-Khanoum), Kapisi, Sigal, Kabul, Kunduz vehicle emission incentives by paying higher, or less,, Zaranj, Firozkoh, Herat, Ghazna (Ghazni), Binban (Bamyan), and Kandahar.\n\nThe country has been home to various peoples through the ages, among them the ancient Iranian peoples who established the dominant role of Indo-Iranian languages in the region. At multiple points, the land has been incorporated within vast regional empires; among them the Achaemenid Empire, the Macedonian Empire, the Maurya Empire, and the Islamic Empire. For its success in resisting foreign occupation during the 19th and 20th centuries, Afghanistan has been called the \"graveyard of empires\", though it is unknown who coined the phrase.\n\nPrehistory and antiquity\n\nExcavations of prehistoric sites suggest that humans were living in what is now Afghanistan at least 50,000 years ago, and that farming communities in the area were among the earliest in the world. An important site of early historical activities, many believe that Afghanistan compares to Egypt in terms of the historical value of its archaeological sites.\n\nAncient era\n\nArchaeological exploration done in the 20th century suggests that the geographical area of Afghanistan has been closely connected by culture and trade with its neighbors to the east, west, and north. Artifacts typical of the Paleolithic, Mesolithic, Neolithic, Bronze, and Iron Ages have been found in Afghanistan. Urban civilization is believed to have begun as early as 3000 BCE, and the early city of Mundigak (near Kandahar in the south of the country) was a center of the Helmand culture. More recent findings established that the Indus Valley Civilization stretched up towards modern-day Afghanistan, making the ancient civilization today part of Pakistan, Afghanistan, and India. In more detail, it extended from what today is northwest Pakistan to northwest India and northeast Afghanistan. An Indus Valley site has been found on the Oxus River at Shortugai in northern Afghanistan. There are several smaller IVC colonies to be found in Afghanistan as well. An Indus Valley site has been found on the Oxus River at Shortugai in northern Afghanistan, shows Afghanistan to have been a part of Indus Valley Civilization.\n\nAfter 2000 BCE, successive waves of semi-nomadic people from Central Asia began moving south into Afghanistan; among them were many Indo-European-speaking Indo-Iranians. These tribes later migrated further into South Asia, Western Asia, and toward Europe via the area north of the Caspian Sea. The region at the time was referred to as Ariana.\n\nBy the middle of the 6th century BCE, the Achaemenids overthrew the Medes and incorporated Arachosia, Aria, and Bactria within its eastern boundaries. An inscription on the tombstone of Darius I of Persia mentions the Kabul Valley in a list of the 29 countries that he had conquered. The region of Arachosia, around Kandahar in modern-day southern Afghanistan, used to be primarily Zoroastrian and played a key role in the transfer of the Avesta to Persia and is thus considered by some to be the \"second homeland of Zoroastrianism\".\n\nAlexander the Great and his Macedonian forces arrived in Afghanistan in 330 BCE after defeating Darius III of Persia a year earlier in the Battle of Gaugamela. Following Alexander's brief occupation, the successor state of the Seleucid Empire controlled the region until 305 BCE when they gave much of it to the Maurya Empire as part of an alliance treaty. The Mauryans controlled the area south of the Hindu Kush until they were overthrown in about 185 BCE. Their decline began 60 years after Ashoka's rule ended, leading to the Hellenistic reconquest by the Greco-Bactrians. Much of it soon broke away from them and became part of the Indo-Greek Kingdom. They were defeated and expelled by the Indo-Scythians in the late 2nd century BCE.\n\nThe Silk Road appeared during the first century BCE, and Afghanistan flourished with trade, with routes to China, India, Persia and north to the cities of Bukhara, Samarkand and Khiva in present-day Uzbekistan. Goods and ideas were exchanged at this center point, such as Chinese silk, Persian silver and Roman gold, while the region of present Afghanistan was mining and trading lapis lazuli stones mainly from the Badakhshan region.\n\nDuring the first century BCE, the Parthian Empire subjugated the region but lost it to their Indo-Parthian vassals. In the mid-to-late first century CE the vast Kushan Empire, centered in Afghanistan, became great patrons of Buddhist culture, making Buddhism flourish throughout the region. The Kushans were overthrown by the Sassanids in the 3rd century CE, though the Indo-Sassanids continued to rule at least parts of the region. They were followed by the Kidarites who, in turn, was replaced by the Hephthalites. They were replaced by the Turk Shahi in the 7th century. The Buddhist Turk Shahi of Kabul was replaced by a Hindu dynasty before the Saffarids conquered the area in 870, this Hindu dynasty was called Hindu Shahi. Much of the northeastern and southern areas of the country remained dominated by Buddhist culture.\n\nMedieval history\n\nIslamic conquest\n\nArab Muslims brought Islam to Herat and Zaranj in 642\u00a0CE and began spreading eastward; some of the native inhabitants they encountered accepted it while others revolted. Before the arrival of Islam, the region used to be home to various beliefs and cults, often resulting in Syncretism between the dominant religions such as Zoroastrianism, Buddhism or Greco-Buddhism, Ancient Iranian religions, Hinduism, Christianity and Judaism. An exemplification of the syncretism in the region would be that people were patrons of Buddhism but still worshipped local Iranian gods such as Ahura Mazda, Lady Nana, Anahita or Mihr(Mithra) and portrayed Greek Gods like Heracles or Tyche as protectors of Buddha. The Zunbils and Kabul Shahi were first conquered in 870\u00a0CE by the Saffarid Muslims of Zaranj. Later, the Samanids extended their Islamic influence south of the Hindu Kush. It is reported that Muslims and non-Muslims still lived side by side in Kabul before the Ghaznavids rose to power in the 10th century.\n\nBy the 11th century, Mahmud of Ghazni defeated the remaining Hindu rulers and effectively Islamized the wider region, with the exception of Kafiristan. Mahmud made Ghazni into an important city and patronized intellectuals such as the historian Al-Biruni and the poet Ferdowsi. The Ghaznavid dynasty was overthrown by the Ghurids, whose architectural achievements included the remote Minaret of Jam. The Ghurids controlled Afghanistan for less than a century before being conquered by the Khwarazmian dynasty in 1215.\n\nMongols and Babur with the Lodi Dynasty\n\nIn 1219\u00a0CE, Genghis Khan and his Mongol army overran the region. His troops are said to have annihilated the Khwarazmian cities of Herat and Balkh as well as Bamyan. The destruction caused by the Mongols forced many locals to return to an agrarian rural society. Mongol rule continued with the Ilkhanate in the northwest while the Khalji dynasty administered the Afghan tribal areas south of the Hindu Kush until the invasion of Timur (aka Tamerlane), who established the Timurid Empire in 1370. Under the rule of Shah Rukh the city served as the focal point of the Timurid Renaissance, whose glory matched Florence of the Italian Renaissance as the center of a cultural rebirth.\n\nIn the early 16th century, Babur arrived from Ferghana and captured Kabul from the Arghun dynasty. Babur would go on to conquer the Afghan Lodi dynasty who had ruled the Delhi Sultanate in the First Battle of Panipat. Between the 16th and 18th century, the Uzbek Khanate of Bukhara, Iranian Safavids, and Indian Mughals ruled parts of the territory. During the Medieval Period, the northwestern area of Afghanistan was referred to by the regional name Khorasan. Two of the four capitals of Khorasan (Herat and Balkh) are now located in Afghanistan, while the regions of Kandahar, Zabulistan, Ghazni, Kabulistan, and Afghanistan formed the frontier between Khorasan and Hindustan. However, up to the 19th century the term Khorasan was commonly used among natives to describe their country; Sir George Elphinstone wrote with amazement that the country known to outsiders as \"Afghanistan\" was referred to by its own inhabitants as \"Khorasan\" and that the first Afghan official whom he met at the border welcomed him to Khorasan.\n\nModern history\n\nHotak Dynasty \n\nIn 1709, Mirwais Hotak, a local Ghilzai tribal leader, successfully rebelled against the Safavids. He defeated Gurgin Khan and established his own kingdom. Mirwais died of natural causes in 1715 and was succeeded by his brother Abdul Aziz, who was soon killed by Mirwais' son Mahmud for possibly planning to concede territories back to the Safavids. Mahmud led the Afghan army in 1722 to the Persian capital of Isfahan, captured the city after the Battle of Gulnabad and proclaimed himself King of Persia. The Afghan dynasty was ousted from Persia by Nader Shah after the 1729 Battle of Damghan.\n\nFall of the Hotak Dynasty \n\nIn 1738, Nader Shah and his forces captured Kandahar in the Siege of Kandahar, the last Hotak stronghold, from Shah Hussain Hotak. Soon after, the Persian and Afghan forces invaded India, Nader Shah had plundered Delhi, alongside his 16 year old commander, Ahmad Shah Durrani who had assisted him on these campaigns. Nader Shah was assassinated in 1747.\n\nRise of the Durrani Empire \n\nAfter the death of Nader Shah in 1747, Ahmad Shah Durrani had returned to Kandahar with a contingent of 4,000 Pashtuns. The Abdalis had \"unanimously accepted\" Ahmad Shah as their new leader. With his acension in 1747, Ahmad Shah had led multiple campaigns against the Mughal Empire, Maratha Empire, and then receding, Afsharid Empire. Ahmad Shah had captured Kabul and Peshawar from the Mughal appointed governor, Nasir Khan. Ahmad Shah had then conquered Herat in 1750, and had also captured Kashmir in 1752. Ahmad Shah had launched two campaigns into Khorasan, (1750\u20131751) and (1754\u20131755). His first campaign had seen the siege of Mashhad, however he was forced to retreat after 4 months. In November 1750, he moved to siege Nishapur, however he was unable to capture the city and was forced to retreat in early 1751. Ahmad Shah returned in 1754, he captured Tun, and on 23 July, he sieged Mashhad once again. Mashhad had fallen on 2 December, however Shah rokh was reappointed in 1755. He was forced to give up Torshiz, Bakharz, Jam, Khaf, and Turbat-e Haidari to the Afghans. Following this, Ahmad Shah had sieged Nishapur once again, and captured it.\n\nObjectives and Invasions of India \n\nAhmad Shah invaded India 8 times during his reign. With the capture of Peshawar, Ahmad Shah had used this as a convenient striking point to lead his military campaigns into Punjab and India.\n\nAhmad Shah had sought out multiple reasons for his invasions, Ahmad Shah saw Afghanistan in a dire state, and one that needed to expand and exploit a weak but rich neighboring country, which Ahmad Shah had capitalized on in multiple opportunities during his Invasions of India, he sought the reasons needed to fill his treasury in a war-plunder conquest based economy. Ahmad Shah had launched his first invasion in 1748, crossing the indus river, his armies sacked and absorbed Lahore into the Durrani Realm. Ahmad Shah had met Mughal armies at the Battle of Manupur (1748), where he was defeated and forced to retreat to back to Afghanistan. Ahmad Shah had returned the next year in 1749, where he had captured the area around Lahore and Punjab, presenting it as an Afghan victory for this campaign. From 1749 to 1767, Ahmad Shah would lead 6 more invasions, the most important being his sixth invasion, with the Third Battle of Panipat, which created a power vacumn in northern India, halting Maratha expansion.\n\nDeath of Ahmad Shah and his Successors\n\nAhmad Shah Durrani had died in October 1772, what followed would be a civil war in succession, with his named successor, Timur Shah Durrani succeeding him after the defeat of his brother, Suleiman Mirza.\n\nTimur Shah Durrani ascended to the throne in November 1772, having defeated a coalition under Shah Wali Khan, the influential prime minister of the Durrani Empire, and Humayun Mirza. Timur Shah began his reign by consolidating power toward himself and people loyal to him, purging Durrani Sardars and influential tribal leaders in Kabul and Kandahar to bring support toward himself. Timur Shah's reforms also saw the capital of the Durrani Empire being shifted from Kandahar to Kabul, being able to cover the empire better as a base of ordination since it was essentially the heartland of the empire. This reform saw Kabul as the modern capital of Afghanistan today. Having consolidated power to himself, Timur Shah would fight multiple series of rebellions to consolidate and hold the empire apart, Timur Shah would also lead campaigns into Punjab against the Sikhs like his father did, however being more successful. Most prominent example of his battles during this campaign would be where Timur Shah led his forces under Zangi Khan Durrani, with over 18,000 men total of Afghan, Qizilbash, and Mongol cavalrymen. Against over 60,000 Sikh men. The Sikhs would lose over 30,000 in this battle and would stage a Durrani resurgence in Punjab. The Durranis lost Multan in 1772 after Ahmad Shah's death, following this victory by Timur Shah, Timur Shah was able to lay siege to Multan and recapture it, incorporating it into the Durrani empire once again, reintegrating it as a province until the Siege of Multan (1818). Timur Shah would be succeeded by his son, Zaman Shah Durrani after his death on 18 or 20 May 1793. Timur Shah's reign oversaw the attempted stabilization and consolidation of the empire. However, Timur Shah had over 24 sons, a mistake that would plunge the empire in civil war over succession crises.\n\nZaman Shah Durrani would succeed to the Durrani Throne following the death of his father, Timur Shah Durrani. This instigated civil war with his brothers, Mahmud Shah Durrani, and Humayun Mirza revolting against him. With Humayun centered in Kandahar, and Mahmud Shah centered in Herat. Zaman Shah would defeat Humayun and also force the loyalty of Mahmud Shah Durrani. Securing his position on the throne, Zaman Shah had led 3 campaigns into Punjab, with the first two campaigns capturing Lahore, but being forced to retreat due to issues from a possible Qajar invasion, or his brother, Mahmud Shah Durrani revolting. Zaman Shah embarked on his third campaign for Punjab in 1800 to deal with a rebellious Ranjit Singh. However, he was forced to withdraw, with his brother, Mahmud Shah Durrani revolting, Zaman Shah would be toppled from his reign, replaced by his brother, Mahmud Shah Durrani. However, just under 2 years in his reign, Mahmud Shah Durrani would be deposed by his brother, Shah Shuja Durrani, on 13 July 1803. Shah Shuja would attempt to consolidate the Durrani Realm, which had been long striven by civil war. Shah Shuja would later be deposed by his brother at the Battle of Nimla (1809), where Mahmud Shah Durrani would defeat and force Shah Shuja to flee, with Shah Mahmud usurping the throne again for his second reign beginning on 3 May 1809.\n\nBarakzai dynasty and British wars \n\nBy the early 19th century, the Afghan empire was under threat from the Persians in the west and the Sikh Empire in the east. Afghanistan was divided, including the Emirate of Herat centered in the east. Fateh Khan, leader of the Barakzai tribe, installed many of his brothers in positions of power throughout the empire, mostly ruling as governors of major cities and provinces. After his murder for apparent treason against the Durrani king. Fateh Khan would be sentenced by Mahmud Shah Durrani, having him executed. His brothers, notably including Dost Mohammad Khan, rebelled and divided up the provinces of the empire between themselves. During this turbulent period, Afghanistan had many temporary rulers until Dost Mohammad Khan declared himself emir in 1826. Punjab and Kashmir were lost to Ranjit Singh, who invaded Khyber Pakhtunkhwa in March 1823 and captured the city of Peshawar at the Battle of Nowshera. In 1837, during the Battle of Jamrud near the Khyber Pass, Akbar Khan and the Afghan army failed to capture the Jamrud Fort from the Sikh Khalsa Army, but killed Sikh Commander Hari Singh Nalwa, thus ending the Afghan-Sikh Wars. By this time the British were advancing from the east and the first major conflict during \"the Great Game\" was initiated.\n\nIn 1838, a British expeditionary force marched into Afghanistan and arrested Dost Mohammad, sent him into exile in India and replaced him with Shah Shuja, the former Durrani king as a puppet on the throne. Following an uprising that saw the assassination of Shah Shuja, the 1842 retreat from Kabul of British-Indian forces and the annihilation of Elphinstone's army, and the Battle of Kabul that led to its recapture, the British gave up on their attempts to try and subjugate Afghanistan, and allowed Dost Mohammad Khan as ruler and withdrew their military forces from Afghanistan. Dost Mohammad", "flag": 1, "segments": [[1098, 1108]], "strength": 5.5}
{"text": "Albania ( ;  or ), officially the Republic of Albania (), is a country in Southeastern Europe. It is located on the Adriatic and Ionian Sea within the Mediterranean Sea and shares land borders with Montenegro to the northwest, Kosovo to the northeast, North Macedonia to the east and Greece to the south. Tirana is its capital and largest city, followed by Durr\u00ebs, Vlor\u00eb and Shkod\u00ebr.\n\nAlbania displays varied climatic, geological, hydrological, and morphological conditions, defined in an area of. It possesses significant diversity with the landscape ranging from the snow-capped mountains in the Albanian Alps as well as the Korab, Skanderbeg, Pindus and Ceraunian Mountains to the hot and sunny coasts of the Albanian Adriatic and Ionian Sea along the Mediterranean Sea.\n\nAlbania has been inhabited by different civilisations over time, such as the Illyrians, Thracians, Greeks, Romans, Byzantines, Venetians and Ottomans. The Albanians established the autonomous Principality of Arb\u00ebr in the 12th century. The Kingdom of Albania and Principality of Albania formed between the 13th and 14th centuries. Prior to the Ottoman conquest of Albania in the 15th century, the Albanian resistance to Ottoman expansion into Europe led by Gjergj Kastrioti Skanderbeg won them acclaim over most of Europe. Albania remained under Ottoman rule for nearly five centuries, during which many Albanians (known  as Arnauts) attained high-ranking offices in the empire, especially in the Southern Balkans and Egypt. Between the 18th and 19th centuries, cultural developments, widely attributed to Albanians having gathered both spiritual and intellectual strength, conclusively led to the Albanian Renaissance. After the defeat of the Ottomans in the Balkan Wars, the modern nation state of Albania declared independence in 1912. In the 20th century, the Kingdom of Albania was invaded by Italy which formed Greater Albania before becoming a protectorate of Nazi Germany. Enver Hoxha formed the People's Socialist Republic of Albania after World War II, modeled under the terms of Hoxhaism. The Revolutions of 1991 concluded the fall of communism in Albania and eventually the establishment of the current Republic of Albania.\n\nAlbania is a unitary parliamentary constitutional republic and a developing country with an upper-middle income economy dominated by the service sector, followed by manufacturing. It went through a process of transition following the end of communism in 1990, from centralised planning to a market-based economy. Albania provides universal health care and free primary and secondary education to its citizens. Albania is a member of the United Nations, World Bank, UNESCO, NATO, WTO, COE, OSCE, and OIC. It is an official candidate for membership in the European Union since 2014. It is one of the founding members of the Energy Community, including the Organization of the Black Sea Economic Cooperation and Union for the Mediterranean.\n\nEtymology \n\nThe term Albania is the medieval Latin name of the country. It may be derived from the Illyrian tribe of Albani () recorded by Ptolemy, the geographer and astronomer from Alexandria, who drafted a map in 150\u00a0AD which shows the city of Albanopolis located northeast of Durr\u00ebs. The term may have a continuation in the name of a medieval settlement called Albanon or Arbanon, although it is not certain that this was the same place. In his history written in the 10th century, the Byzantine historian Michael Attaliates was the first to refer to Albanoi as having taken part in a revolt against Constantinople in 1043 and to the Arbanitai as subjects of the Duke of Dyrrachium. During the Middle Ages, the Albanians called their country  and referred to themselves as.\n\nNowadays, Albanians call their country. The words Shqip\u00ebri and Shqiptar are attested from 14th century onwards, but it was only at the end of 17th and beginning of the early 18th centuries that the placename Shqip\u00ebria and the ethnic demonym Shqiptar\u00eb gradually replaced Arb\u00ebria and Arb\u00ebresh\u00eb amongst Albanian speakers. The two terms are popularly interpreted as \"Land of the Eagles\" and \"Children of the Eagles\".\n\nHistory\n\nPrehistory \n\nThe first attested traces of neanderthal presence in the territory of Albania dates back to the middle and upper Paleolithic period and were discovered in Xarr\u00eb and at Mount Dajt in the adjacent region of Tirana. Archaeological sites from this period include the Kamenica Tumulus, Konispol Cave and Pellumbas Cave.\n\nThe discovered objects in a cave near Xarr\u00eb include flint and jasper objects along with fossilised animal bones, while those discoveries at Mount Dajt comprise bone and stone tools similar to those of the Aurignacian culture. They also demonstrate notable similarities with objects of the equivalent period found at Crvena Stijena in Montenegro and northwestern Greece.\n\nMultiple artefacts from the Iron and Bronze Ages near tumulus burials have been unearthed in central and southern Albania, which has similar affinity with the sites in southwestern Macedonia and Lefkada. Archaeologists have come to the conclusion that these regions were inhabited from the middle of the third millennium BC by Indo-European people who spoke a Proto-Greek language. Hence, a part of this historical population later moved to Mycenae around 1600 BC and properly established the Mycenaean civilisation.\n\nAntiquity \n\nIn ancient times, the incorporated territory of Albania was historically inhabited by Indo-European peoples, among them numerous Illyrian tribes, Ancient Greeks and Thracians. In view of the Illyrian tribes, there is no evidence that these tribes used any collective nomenclature for themselves, while it is regarded to be unlikely that they used a common endonym. The endonym Illyrians seems to be the name applied to a specific Illyrian tribe, which was the first to come in liaison with the Ancient Greeks resulting in the endonym Illyrians to be applied pars pro toto to all people of similar language and customs.\n\nThe territory referred to as Illyria corresponded roughly to the area east of the Adriatic Sea in the Mediterranean Sea extending in the south to the mouth of the Vjos\u00eb. The first account of the Illyrian groups comes from Periplus of the Euxine Sea, an ancient Greek text written in the middle of the 4th century BC. The west was inhabited by the Thracian tribe of the Bryges while the south was inhabited by the Ancient Greek-speaking tribe of the Chaonians, whose capital was at Phoenice. Other colonies such as Apollonia, Epidamnos and Amantia, were established by Ancient Greek city-states on the coast by the 7th century BC.\n\nThe Illyrian Ardiaei tribe, centred in Montenegro, ruled over most of the territory of Albania. Their Ardiaean Kingdom reached its greatest extent under King Agron, the son of Pleuratus II. Agron extended his rule over other neighbouring tribes as well. Following Agron's death in 230 BC, his wife, Teuta, inherited the\u00a0Ardiaean kingdom. Teuta's forces extended their operations further southwards to the\u00a0Ionian Sea. In 229 BC, Rome declared war on the kingdom for extensively plundering Roman ships. The war ended in Illyrian defeat in 227\u00a0BC. Teuta was eventually succeeded by\u00a0Gentius\u00a0in 181\u00a0BC. Gentius clashed with the Romans in 168\u00a0BC, initiating the Third Illyrian War. The conflict resulted in Roman conquest of the region by 167\u00a0BC. The Romans split the region into three administrative divisions.\n\nMiddle Ages \n\nThe Roman Empire was split in 395 upon the death of Theodosius I into an Eastern and Western Roman Empire in part because of the increasing pressure from threats during the Barbarian Invasions. From the 6th century into the 7th century, the Slavs crossed the Danube and largely absorbed the indigenous Ancient Greeks, Illyrians and Thracians in the Balkans; thus, the Illyrians were mentioned for the last time in historical records in the 7th century.\n\nIn the 11th century, the Great Schism formalised the break of communion between the Eastern Orthodox and Western Catholic Church that is reflected in Albania through the emergence of a Catholic north and Orthodox south. The Albanian people inhabited the west of Lake Ochrida and the upper valley of River Shkumbin and established the Principality of Arbanon in 1190 under the leadership of Progon of Kruja. The realm was succeeded by his sons Gjin and Dhimitri.\n\nUpon the death of Dhimiter, the territory came under the rule of the Albanian-Greek Gregory Kamonas and subsequently under the Golem of Kruja. In the 13th century, the principality was dissolved. Arbanon is considered to be the first sketch of an Albanian state, that retained a semi-autonomous status as the western extremity of the Byzantine Empire, under the Byzantine Doukai of Epirus or Laskarids of Nicaea.\n\nTowards the end of the 12th and beginning of the 13th centuries, Serbs and Venetians started to take possession over the territory. The ethnogenesis of the Albanians is uncertain; however the first undisputed mention of Albanians dates back in historical records from 1079 or 1080 in a work by Michael Attaliates, who referred to the Albanoi as having taken part in a revolt against Constantinople. At this point the Albanians were fully Christianised.\n\nFew years after the dissolution of Arbanon, Charles of Anjou concluded an agreement with the Albanian rulers, promising to protect them and their ancient liberties. In 1272, he established the Kingdom of Albania and conquered regions back from the Despotate of Epirus. The kingdom claimed all of central Albania territory from Dyrrhachium along the Adriatic Sea coast down to Butrint. A catholic political structure was a basis for the papal plans of spreading Catholicism in the Balkan Peninsula. This plan found also the support of Helen of Anjou, a cousin of Charles of Anjou. Around 30 Catholic churches and monasteries were built during her rule mainly in northern Albania. Internal power struggles within the Byzantine Empire in the 14th century enabled Serbs' most powerful medieval ruler, Stefan Dusan, to establish a short-lived empire that included all of Albania except Durr\u00ebs. In 1367, various Albanian rulers established the Despotate of Arta. During that time, several Albanian principalities were created, notably the Principality of Albania, Principality of Kastrioti, Lordship of Berat and Principality of Dukagjini. In the first half of the 15th century, the Ottoman Empire invaded most of Albania, and the League of Lezh\u00eb was held under Skanderbeg as a ruler, who became the national hero of the Albanian medieval history.\n\nOttoman Empire \n\nWith the fall of Constantinople, the Ottoman Empire continued an extended period of conquest and expansion with its borders going deep into Southeast Europe. They reached the Albanian Ionian Sea Coast in 1385 and erected their garrisons across Southern Albania in 1415 and then occupied most of Albania in 1431. Thousands of Albanians consequently fled to Western Europe, particularly to Calabria, Naples, Ragusa and Sicily, whereby others sought protection at the often inaccessible Mountains of Albania.\n\nThe Albanians, as Christians, were considered an inferior class of people, and as such they were subjected to heavy taxes among (2008), Mark Cawthon played an others by the Devshirme system that allowed the Sultan to collect a requisite percentage of Christian adolescents from their families to compose the Janissary. The Ottoman conquest was also accompanied with the gradual process of Islamisation and the rapid construction of mosques which consequently modified the religious picture of Albania.\n\nA prosperous and longstanding revolution erupted after the formation of the Assembly of Lezh\u00eb until the Siege of Shkod\u00ebr under the leadership of Gjergj Kastrioti Skanderbeg, multiple times defeating major Ottoman armies led by Sultans Murad II and Mehmed II. Skanderbeg managed to gather several of the Albanian principals, amongst them the Arianitis, Dukagjinis, Zaharias and Thopias, and establish a centralised authority over most of the non-conquered territories, becoming the Lord of Albania.\n\nSkanderbeg consistently pursued the goal relentlessly but rather unsuccessfully to constitute a European coalition against the Ottomans. He thwarted every attempt by the Ottomans to regain Albania, which they envisioned as a springboard for the invasion of Italy and Western Europe. His unequal fight against them won the esteem of Europe also among others financial and military aid from the Papacy and Naples, Venice and Ragusa.\n\nWhen the Ottomans were gaining a firm foothold in the region, Albanian towns were organised into four principal sanjaks. The government fostered trade by settling a sizeable Jewish colony of refugees fleeing persecution in Spain. The city of Vlor\u00eb saw passing through its ports imported merchandise from Europe such as velvets, cotton goods, mohairs, carpets, spices and leather from Bursa and Constantinople. Some citizens of Vlor\u00eb even had business associates throughout Europe.\n\nThe phenomenon of Islamisation among the Albanians became primarily widespread from the 17th century and continued into the 18th century. Islam offered them equal opportunities and advancement within the Ottoman Empire. However, motives for conversion were, according to some scholars, diverse depending on the context though the lack of source material does not help when investigating such issues. Because of increasing suppression of Catholicism, most Catholic Albanians converted in the 17th century, while Orthodox Albanians followed suit mainly in the following century.\n\nSince the Albanians were seen as strategically important, they made up a significant proportion of the Ottoman military and bureaucracy. A couple of Muslim Albanians attained important political and military positions who culturally contributed to the broader Muslim world. Enjoying this privileged position, they held various high administrative positions with over two dozen Albanian Grand Viziers. Others included members of the prominent K\u00f6pr\u00fcl\u00fc family, Zagan Pasha, Muhammad Ali of Egypt and Ali Pasha of Tepelena. Furthermore, two sultans, Bayezid II and Mehmed III, both had mothers of Albanian origin.\n\nRilindja \n\nThe Albanian Renaissance was a period with its roots in the late 18th century and continuing into the 19th century, during which the Albanian people gathered spiritual and intellectual strength for an independent cultural and political life within an independent nation. Modern Albanian culture flourished too, especially Albanian literature and arts, and was frequently linked to the influences of the Romanticism and Enlightenment principles.\n\nPrior to the rise of nationalism, Albania was under the rule of the Ottoman Empire for almost five centuries, and Ottoman authorities suppressed any expression of national unity or conscience by the Albanian people. Through literature, Albanians started to make a conscious effort to awaken feelings of pride and unity among their people that would call to mind the rich history and hopes for a more decent future.\n\nThe victory of Russia over the Ottoman Empire following the Russian-Ottoman Wars resulted the execution of the Treaty of San Stefano which overlooked to assign Albanian-populated lands to the Slavic and Greek neighbours. However, the United Kingdom and Austro-Hungarian Empire consequently blocked the arrangement and caused the Treaty of Berlin. From this point, Albanians started to organise themselves with the goal to protect and unite the Albanian-populated lands into a unitary nation, leading to the formation of the League of Prizren.\n\nThe league had initially the assistance of the Ottoman authorities whose position was based on the religious solidarity of Muslim people and landlords connected with the Ottoman administration. They favoured and protected the Muslim solidarity and called for defence of Muslim lands simultaneously constituting the reason for titling the league Committee of the Real Muslims.\n\nApproximately 300 Muslims participated in the assembly composed by delegates from Bosnia, the administrator of the Sanjak of Prizren as representatives of the central authorities and no delegates from Vilayet of Scutari. Signed by only 47 Muslim deputies, the league issued the Kararname that contained a proclamation that the people from northern Albania, Epirus and Bosnia and Herzegovina are willing to defend the territorial integrity of the Ottoman Empire by all possible means against the troops of Bulgaria, Serbia and Montenegro.\n\nOttomans authorities cancelled their assistance when the league, under Abdyl Frash\u00ebri, became focused on working towards Albanian autonomy and requested merging four vilayets, including Kosovo, Shkod\u00ebr, Monastir and Ioannina, into an unified vilayet, the Albanian Vilayet. The league used military force to prevent the annexing areas of Plav and Gusinje assigned to Montenegro. After several successful battles with Montenegrin troops, such as the Battle of Nov\u0161i\u0107e, the league was forced to retreat from their contested regions. The league was later defeated by the Ottoman army sent by the sultan.\n\nIndependence \n\nAlbania declared independence from the Ottoman Empire on 28 November 1912, accompanied with the establishment of the Senate and Government by the Assembly of Vlor\u00eb on 4 December 1912. Its sovereignty was recognised by the Conference of London. On 29 July 1913, the Treaty of London delineated the borders of the country and its neighbours, leaving many Albanians outside Albania, predominantly partitioned between Montenegro, Serbia and Greece.\n\nHeadquartered in Vlor\u00eb, the International Commission of Control was established on 15 October 1913 to take care of the administration of newly established Albania, until its own political institutions were in order. The International Gendarmerie was established as the first law enforcement agency of the Principality of Albania. In November, the first gendarmerie members arrived in the country. Prince of Albania Wilhelm of Wied (Princ Vilhelm Vidi) was selected as the first prince of the principality. On 7 March, he arrived in the provisional capital of Durr\u00ebs and started to organise his government, appointing Turhan Pasha P\u00ebrmeti to form the first Albanian cabinet.\n\nIn November 1913, the Albanian pro-Ottoman forces had offered the throne of Albania to the Ottoman war Minister of Albanian origin, Ahmed Izzet Pasha. The pro-Ottoman peasants believed that the new regime was a tool of the six Christian Great Powers and local landowners, that owned half of the arable land.\n\nIn February 1914, the Autonomous Republic of Northern Epirus was proclaimed in Gjirokast\u00ebr by the local Greek population against incorporation to Albania. This initiative was short-lived, and in 1921 the southern provinces were incorporated into the Albanian Principality. Meanwhile, the revolt of Albanian peasants against the new Albanian regime erupted under the leadership of the group of Muslim clerics gathered around Essad Pasha Toptani, who proclaimed himself the saviour of Albania and Islam. In order to gain support of the Mirdita Catholic volunteers from the northern part of Albania, Prince Wied appointed their leader, Pr\u00eank Bib\u00eb Doda, to be the foreign minister of the Principality of Albania. In May and June 1914, the International Gendarmerie was joined by Isa Boletini and his men, mostly from Kosovo, and northern Mirdita Catholics, were defeated by the rebels who captured most of Central Albania by the end of August 1914. The regime of Prince Wied collapsed, and he left the country on 3 September 1914.\n\nFirst Republic \n\nFollowing the end of the government of Fan Noli, the parliament adopted a new constitution and proclaimed the country as a parliamentary republic in which King Zog I of Albania (Ahmet Muhtar Zogu) served as the head of state for a seven-year term. Immediately after, Tirana was endorsed officially as the country's permanent capital.\n\nThe politics of Zogu was authoritarian and conservative with the primary aim of the maintenance of stability and order. He was forced to adopt a policy of cooperation with Italy where a pact had been signed between both countries, whereby Italy gained a monopoly on shipping and trade concessions. Italians exercised control over nearly every Albanian official through money and patronage. In 1928, the country was eventually replaced by another monarchy with a strong support by the fascist regime of Italy however, both maintained close relations until the Italian invasion of the country. Zogu remained a conservative but initiated reforms and placed great emphasis on the development of infrastructure.\n\nIn an attempt at social modernisation, the custom of adding one's region to one's name was dropped. He also made donations of land to international organisations for the building of schools and hospitals. The armed forces were trained and supervised by instructors from Italy, and as a counterweight, he kept British officers in the Gendarmerie despite strong Italian pressure to remove them.\n\nAfter being militarily occupied by Italy from 1939 until 1943, the Kingdom of Albania was a protectorate and a dependency of the Kingdom of Italy governed by Victor Emmanuel III and his government. In October 1940, Albania served as a staging ground for an unsuccessful Italian invasion of Greece. A counterattack resulted in a sizeable portion of southern Albania coming under Greek military control until April 1941 when Greece capitulated during the German invasion. In April 1941, territories of Yugoslavia with substantial Albanian population were annexed to Albania inclusively western Macedonia, a strip of eastern Montenegro, the town of Tutin in central Serbia and most of Kosovo.\n\nGermans started to occupy the country in September 1943 and subsequently announced that they would recognise the independence of a neutral Albania and set about organising a new government, military and law enforcement. Balli Komb\u00ebtar, which had fought against Italy, formed a neutral government and side by side with the Germans fought against the communist-led National Liberation Movement of Albania.\n\nDuring the last years of the war, the country fell into a civil war-like state between the communists and nationalists. The communists defeated the last anti-communist forces in the south in 1944. Before the end of November, the main German troops had withdrawn from Tirana, and the communists took control by attacking it. The partisans entirely liberated the country from German occupation on 29 November 1944. A provisional government, which the communists had formed at\u00a0Berat\u00a0in October, administered Albania with Enver Hoxha as the head of government.\n\nBy the end of the Second World War, the main military and political force of the nation, the Communist party sent forces to northern Albania against the nationalists to eliminate its rivals. They faced open resistance in Nikaj-M\u00ebrtur, Dukagjin and Kelmend led by Prek Cali. On 15 January 1945, a clash took place between partisans of the first Brigade and nationalist forces at the Tamara Bridge, resulting in the defeat of the nationalist forces. About 150 Kelmendi people were killed or tortured. This event was the starting point of many other issues which took place during Enver Hoxha's dictatorship. Class struggle was strictly applied, human freedom and human rights were denied. The Kelmend region was almost isolated by both the border and by a lack of roads for another 20 years, the institution of agricultural cooperatives brought about economic decline. Many Kelmendi people fled, and some were executed trying to cross the border.\n\nCommunism \n\nIn the aftermath of World War II and the defeat of the Axis Powers, the country became initially a satellite state of the Soviet Union, and Enver Hoxha emerged as the leader", "flag": 1, "segments": [[2483, 2493]], "strength": 5.5}
{"text": "Azerbaijan (, ;  ), officially the Azerbaijan Republic or the Republic of Azerbaijan, is a transcontinental country located at the boundary of Eastern Europe and Western Asia. It is a part of the South Caucasus region, and is bounded by the Caspian Sea to the east, Russia to the north, Georgia to the northwest, Armenia and Turkey to the west, and Iran to the south. Baku is the capital and largest city.\n\nThe Azerbaijan Democratic Republic proclaimed its independence from the Transcaucasian Democratic Federative Republic in 1918 and became the first secular democratic Muslim-majority state, taking its name from the adjacent region of northwestern Iran for political reasons. In 1922, the country was incorporated into the Soviet Union as the Azerbaijan SSR.\n\nThe modern Republic of Azerbaijan proclaimed its independence on 30 August 1991, shortly before the dissolution of the Soviet Union in the same year. In September 1991, the ethnic Armenian majority of the Nagorno-Karabakh region formed self-proclaimed Republic of Artsakh. The region and seven surrounding districts are internationally recognized as part of Azerbaijan, while negotiations on the resolution of Nagorno-Karabakh conflict are facilitated by the OSCE. Nagorno-Karabakh became de facto independent with the end of the First Nagorno-Karabakh War in 1994.\nFollowing the 2020 Nagorno-Karabakh war, the seven districts and parts of Nagorno-Karabakh were returned to Azerbaijani control.\n\nAzerbaijan is a unitary semi-presidential republic. It is one of six independent Turkic states and an active member of the Turkic Council and the T\u00dcRKSOY community. Azerbaijan has diplomatic relations with 182 countries and holds membership in 38 international organizations, including the United Nations, the Council of Europe, the Non-Aligned Movement, the OSCE, and the NATO PfP program. It is one of the founding members of GUAM, the CIS, and the OPCW. Azerbaijan is also an observer state of the WTO.\n\nThe vast majority of the country's population (97%) is Muslim, but the constitution does not declare an official religion and all major political forces in the country are secularist. Azerbaijan is a developing country and ranks 88th on the Human Development Index. It has a high rate of economic development, literacy, and a low rate of unemployment. The ruling party, the New Azerbaijan Party, in power since 1993, has been accused of authoritarian leadership and the deterioration of the country's human rights record, including increasing restrictions on civil liberties, particularly on press freedom and political repression.\n\nEtymology \n\nAccording to a modern etymology, the term Azerbaijan derives from that of Atropates, a Persian satrap under the Achaemenid Empire, who was later reinstated as the satrap of Media under Alexander the Great. The original etymology of this name is thought to have its roots in the once-dominant Zoroastrianism. In the Avesta's Frawardin Yasht (\"Hymn to the Guardian Angels\"), there is a mention of \u00e2terep\u00e2tahe ashaon\u00f4 fravash\u00eem \u00fdazamaide, which literally translates from Avestan as \"we worship the fravashi of the holy Atropatene.\" The name \"Atropates\" itself is the Greek transliteration of an Old Iranian, probably Median, compounded name with the meaning \"Protected by the (Holy) Fire\" or \"The Land of the (Holy) Fire\". The Greek name was mentioned by Diodorus Siculus and Strabo. Over the span of millennia, the name evolved to  (Middle Persian), then to,,  (New Persian) and present-day Azerbaijan.\n\nThe name Azerbaijan was first adopted for the area of the present-day Republic of Azerbaijan by the government of Musavat in 1918, after the collapse of the Russian Empire, when the independent Azerbaijan Democratic Republic was established. Until then, the designation had been used exclusively to identify the adjacent region of contemporary northwestern Iran, while the area of the Azerbaijan Democratic Republic was formerly referred to as Arran and Shirvan. On that basis Iran protested the newly adopted country name.\n\nDuring the Soviet rule, the country was also spelled in Latin from the Russian transliteration as Azerbaydzhan (). The country's name was also spelled in Cyrillic script from 1940 to 1991 as \"\u0410\u0437\u04d9\u0440\u0431\u0430\u0458\u04b9\u0430\u043d\".\n\nHistory\n\nAntiquity\n\nThe earliest evidence of human settlement in the territory of Azerbaijan dates back to the late Stone Age and is related to the Guruchay culture of Azykh Cave.\n\nEarly settlements included the Scythians during the 9th century BC. Following the Scythians, Iranian Medes came to dominate the area to the south of the Aras river. The Medes forged a vast empire between 900 and 700\u00a0BC, which was integrated into the Achaemenid Empire around 550\u00a0BC. The area was conquered by the Achaemenids leading to the spread of Zoroastrianism.\n\nFrom the Sasanid period to the Safavid period\n\nThe Sasanian Empire turned Caucasian Albania into a vassal state in 252, while King Urnayr officially adopted Christianity as the state religion in the 4th century. Despite Sassanid rule, Albania remained an entity in the region until the 9th century, while fully subordinate to Sassanid Iran, and retained its monarchy. Despite being one of the chief vassals of the Sasanian emperor, the Albanian king had only a semblance of authority, and the Sasanian marzban (military governor) held most civil, religious, and military authority.\n\nIn the first half of the 7th century, Caucasian Albania, as a vassal of the Sasanians, came under nominal Muslim rule due to the Muslim conquest of Persia. The Umayyad Caliphate repulsed both the Sasanians and Byzantines from the South Caucasus and turned Caucasian Albania into a vassal state after Christian resistance led by King Javanshir, was suppressed in 667. The power vacuum left by the decline of the Abbasid Caliphate was filled by numerous local dynasties such as the Sallarids, Sajids, and Shaddadids. At the beginning of the 11th century, the territory was gradually seized by the waves of Oghuz Turks from Central Asia, who adopted a Turkoman ethnonym at the time. The first of these Turkic dynasties established was the Seljuk Empire, which entered the area now known as Azerbaijan by 1067.\n\nThe pre-Turkic population that lived on the territory of modern Azerbaijan spoke several Indo-European and Caucasian languages, among them Armenian and an Iranian language, Old Azeri, which was gradually replaced by a Turkic language, the early precursor of the Azerbaijani language of today. Some linguists have also stated that the Tati dialects of Iranian Azerbaijan and the Republic of Azerbaijan, like those spoken by the Tats, are descended from Old Azeri.\nLocally, the possessions of the subsequent Seljuk Empire were ruled by Eldiguzids, technically vassals of the Seljuk sultans, but sometimes de facto rulers themselves. Under the Seljuks, local poets such as Nizami Ganjavi and Khaqani gave rise to a blossoming of Persian literature on the territory of present-day Azerbaijan.\n\nThe local dynasty of the Shirvanshahs became a vassal state of Timur's Empire and assisted him in his war with the ruler of the Golden Horde Tokhtamysh. Following Timur's death, two independent and rival states emerged: Kara Koyunlu and Aq Qoyunlu. The Shirvanshahs returned, maintaining for numerous centuries to come a high degree of autonomy as local rulers and vassals as they had done since 861. In 1501, the Safavid dynasty of Iran subdued the Shirvanshahs and gained its possessions. In the course of the next century, the Safavids converted the formerly Sunni population to Shia Islam, as they did with the population in what is modern-day Iran. The Safavids allowed the Shirvanshahs to remain in power, under Safavid suzerainty, until 1538, when Safavid king Tahmasp I (r. 1524\u20131576) completely deposed them, and made the area into the Safavid province of Shirvan. The Sunni Ottomans briefly managed to occupy parts of present-day Azerbaijan as a result of the Ottoman-Safavid War of 1578\u20131590; by the early 17th century, they were ousted by Safavid Iranian ruler Abbas I (r. 1588\u20131629). In the wake of the demise of the Safavid Empire, Baku and its environs were briefly occupied by the Russians as a consequence of the Russo-Persian War of 1722\u20131723. Despite brief intermissions such as these by Safavid Iran's neighboring rivals, the land of what is today Azerbaijan remained under Iranian rule from the earliest advent of the Safavids up to the course of the 19th century.\n\nContemporary history\n\nAfter the Safavids, the area was ruled by the Iranian Afsharid dynasty. After the death of Nader Shah (r. 1736\u20131747), many of his former subjects capitalized on the eruption of instability. Numerous self-ruling khanates with various forms of autonomy emerged in the area. The rulers of these khanates were directly related to the ruling dynasties of Iran and were vassals and subjects of the Iranian shah. The khanates exercised control over their affairs via international trade routes between Central Asia and the West.\n\nThereafter, the area was under the successive rule of the Iranian Zands and Qajars. From the late 18th century, Imperial Russia switched to a more aggressive geo-political stance towards its two neighbors and rivals to the south, namely Iran and the Ottoman Empire. Russia now actively tried to gain possession of the Caucasus region which was, for the most part, in the hands of Iran. In 1804, the Russians invaded and sacked the Iranian town of Ganja, sparking the Russo-Persian War of 1804\u20131813. The militarily superior Russians ended the Russo-Persian War of 1804\u20131813 with a victory.\n\nFollowing Qajar Iran's loss in the 1804\u20131813 war, it was forced to concede suzerainty over most of the khanates, along with Georgia and Dagestan to the Russian Empire, per the Treaty of Gulistan.\n\nThe area to the north of the river Aras, amongst which territory lies the contemporary Republic of Azerbaijan, was Iranian territory until Russia occupied it in the 19th century. About a decade later, in violation of the Gulistan treaty, the Russians invaded Iran's Erivan Khanate. This sparked the final bout of hostilities between the two, the Russo-Persian War of 1826\u20131828. The resulting Treaty of Turkmenchay, forced Qajar Iran to cede sovereignty over the Erivan Khanate, the Nakhchivan Khanate and the remainder of the Talysh Khanate, comprising the last parts of the soil of the contemporary Azerbaijani Republic that were still in Iranian hands. After the incorporation of all Caucasian territories from Iran into Russia, the new border between the two was set at the Aras River, which, upon the Soviet Union's disintegration, subsequently became part of the border between Iran and the Azerbaijan Republic.\n\nQajar Iran was forced to cede its Caucasian territories to Russia in the 19th century, which thus included the territory of the modern-day Azerbaijan Republic, while as a result of that cession, the Azerbaijani ethnic group is nowadays parted between two nations: Iran and Azerbaijan.\n\nDespite the Russian conquest, throughout the entire 19th century, preoccupation with Iranian culture, literature, and language remained widespread amongst Shia and Sunni intellectuals in the Russian-held cities of Baku, Ganja and Tiflis (Tbilisi, now Georgia). Within the same century, in post-Iranian Russian-held East Caucasia, an Azerbaijani national identity emerged at the end of the 19th century.\n\nAfter the collapse of the Russian Empire during World War I, the short-lived Transcaucasian Democratic Federative Republic was declared, constituting the present-day republics of Azerbaijan, Georgia, and Armenia.\nIt was followed by the March Days massacres that took place between 30 March and 2 April 1918 in the city of Baku and adjacent areas of the Baku Governorate of the Russian Empire. When the republic dissolved in May 1918, the leading Musavat party declared independence as the Azerbaijan Democratic Republic (ADR), adopting the name of \"Azerbaijan\" for the new republic; a name that prior to the proclamation of the ADR was solely used to refer to the adjacent northwestern region of contemporary Iran. The ADR was the first modern parliamentary republic in the Muslim world. Among the important accomplishments of the Parliament was the extension of suffrage to women, making Azerbaijan the first Muslim nation to grant women equal political rights with men. Another important accomplishment of ADR was the establishment of Baku State University, which was the first modern-type university founded in the Muslim East.\n a tumultuous year of controversy for the rapper, who\nBy March 1920, it was obvious that Soviet Russia would attack Baku. Vladimir Lenin said that the invasion was justified as Soviet Russia could not survive without Baku's oil. Independent Azerbaijan lasted only 23 months until the Bolshevik 11th Soviet Red Army invaded it, establishing the Azerbaijan SSR on 28 April 1920. Although the bulk of the newly formed Azerbaijani army was engaged in putting down an Armenian revolt that had just broken out in Karabakh, Azerbaijanis did not surrender their brief independence of 1918\u201320 quickly or easily. As many as 20,000 Azerbaijani soldiers died resisting what was effectively a Russian reconquest. Within the ensuing early Soviet period, the Azerbaijani national identity was finally forged.\n\nOn 13 October 1921, the Soviet republics of Russia, Armenia, Azerbaijan, and Georgia signed an agreement with Turkey known as the Treaty of Kars. The previously independent Republic of Aras would also become the Nakhchivan Autonomous Soviet Socialist Republic within the Azerbaijan SSR by the treaty of Kars. On the other hand, Armenia was awarded the region of Zangezur and Turkey agreed to return Gyumri (then known as Alexandropol).\n\nDuring World War II, Azerbaijan played a crucial role in the strategic energy policy of the Soviet Union, with 80 percent of the Soviet Union's oil on the Eastern Front being supplied by Baku. By the Decree of the Supreme Soviet of the USSR in February 1942, the commitment of more than 500 workers and employees of the oil industry of Azerbaijan were awarded orders and medals. Operation Edelweiss carried out by the German Wehrmacht targeted Baku because of its importance as the energy (petroleum) dynamo of the USSR. A fifth of all Azerbaijanis fought in the Second World War from 1941 to 1945. Approximately 681,000 people with over 100,000 of them women, went to the front, while the total population of Azerbaijan was 3.4\u00a0million at the time. Some 250,000 people from Azerbaijan were killed on the front. More than 130 Azerbaijanis were named Heroes of the Soviet Union. Azerbaijani Major-General Azi Aslanov was twice awarded the Hero of the Soviet Union.\n\nIndependence\n\nFollowing the politics of glasnost, initiated by Mikhail Gorbachev, civil unrest and ethnic strife grew in various regions of the Soviet Union, including Nagorno-Karabakh, an autonomous region of the Azerbaijan SSR. The disturbances in Azerbaijan, in response to Moscow's indifference to an already heated conflict, resulted in calls for independence and secession, which culminated in the Black January events in Baku. Later in 1990, the Supreme Council of the Azerbaijan SSR dropped the words \"Soviet Socialist\" from the title, adopted the \"Declaration of Sovereignty of the Azerbaijan Republic\" and restored the flag of the Azerbaijan Democratic Republic as the state flag. As a consequence of the failed coup which occurred in August in Moscow, on 18 October 1991, the Supreme Council of Azerbaijan adopted a Declaration of Independence which was affirmed by a nationwide referendum in December 1991, while the Soviet Union officially ceased to exist on 26 December 1991. The country now celebrates its Independence Day on 18 October.\n\nThe early years of independence were overshadowed by the First Nagorno-Karabakh war with the ethnic Armenian majority of Nagorno-Karabakh backed by Armenia. By the end of the hostilities in 1994, Armenians controlled up to 14\u201316 percent of Azerbaijani territory, including Nagorno-Karabakh itself. During the war many atrocities and pogroms by both sides were committed including the massacres at Malibeyli and Gushchular, the Garadaghly massacre and the Khojaly massacres, along with the Baku pogrom, the Maraga massacre and the Kirovabad pogrom. Furthermore, an estimated 30,000 people have been killed and more than a million people have been displaced, more than 800,000 Azerbaijanis and 300,000 Armenians. Four United Nations Security Council Resolutions (822, 853, 874, and 884) demand for \"the immediate withdrawal of all Armenian forces from all occupied territories of Azerbaijan.\" Many Russians and Armenians left and fled Azerbaijan as refugees during the 1990s. According to the 1970 census, there were 510,000 ethnic Russians and 484,000 Armenians in Azerbaijan.\n\nHeydar Aliyev, 1993-today\n\nIn 1993, democratically elected president Abulfaz Elchibey was overthrown by a military insurrection led by Colonel Surat Huseynov, which resulted in the rise to power of the former leader of Soviet Azerbaijan, Heydar Aliyev. In 1994, Surat Huseynov, by that time the prime minister, attempted another military coup against Heydar Aliyev, but he was arrested and charged with treason. A year later, in 1995, another coup was attempted against Aliyev, this time by the commander of the OMON special unit, Rovshan Javadov. The coup was averted, resulting in the killing of the latter and disbanding of Azerbaijan's OMON units. At the same time, the country was tainted by rampant corruption in the governing bureaucracy. In October 1998, Aliyev was reelected for a second term. Despite the much improved economy, particularly with the exploitation of the Azeri-Chirag-Guneshli oil field and Shah Deniz gas field, Aliyev's presidency was criticized due to suspected election fraud, high levels of economic inequality and domestic corruption.\n\nIlham Aliyev, Heydar Aliyev's son, became chairman of the New Azerbaijan Party as well as President of Azerbaijan when his father died in 2003. He was reelected to a third term as president in October 2013. In April 2018, President Ilham Aliyev secured his fourth consecutive term in the election that was boycotted by the main opposition parties as fraudulent. On 27 September 2020, new clashes in the unresolved Nagorno-Karabakh conflict resumed along the Nagorno-Karabakh Line of Contact. Both the armed forces of Azerbaijan and Armenia reported military and civilian casualties. The Nagorno-Karabakh ceasefire agreement and the end of the six-week war between Azerbaijan and Armenia was widely celebrated in Azerbaijan, as they made significant territorial gains.\n\nGeography\n\nGeographically, Azerbaijan is located in the South Caucasus region of Eurasia, straddling Western Asia and Eastern Europe. It lies between latitudes 38\u00b0 and 42\u00b0 N, and longitudes 44\u00b0 and 51\u00b0 E. The total length of Azerbaijan's land borders is, of which 1,007\u00a0kilometers are with Armenia, 756\u00a0kilometers with Iran, 480\u00a0kilometers with Georgia, 390\u00a0kilometers with Russia and 15\u00a0kilometers with Turkey. The coastline stretches for, and the length of the widest area of the Azerbaijani section of the Caspian Sea is. The country has a landlocked exclave, the Nakhchivan Autonomous Republic.\n\nThree physical features dominate Azerbaijan: the Caspian Sea, whose shoreline forms a natural boundary to the east; the Greater Caucasus mountain range to the north; and the extensive flatlands at the country's center. There are also three mountain ranges, the Greater and Lesser Caucasus, and the Talysh Mountains, together covering approximately 40% of the country. The highest peak of Azerbaijan is Mount Bazard\u00fcz\u00fc (4,466\u00a0m), while the lowest point lies in the Caspian Sea (\u221228\u00a0m). Nearly half of all the mud volcanoes on Earth are concentrated in Azerbaijan, these volcanoes were also among nominees for the New7Wonders of Nature.\n\nThe main water sources are surface waters. Only 24 of the 8,350 rivers are greater than  in length. All the rivers drain into the Caspian Sea in the east of the country. The largest lake is Sarysu (67\u00a0km2), and the longest river is Kur (1,515\u00a0km), which is transboundary with Armenia. Azerbaijan has several islands along the Caspian sea, mostly located in the Baku Archipelago.\n\nSince the independence of Azerbaijan in 1991, the Azerbaijani government has taken measures to preserve the environment of Azerbaijan. National protection of the environment accelerated after 2001 when the state budget increased due to new revenues provided by the Baku-Tbilisi-Ceyhan pipeline. Within four years, protected areas doubled and now make up eight percent of the country's territory. Since 2001 the government has set up seven large reserves and almost doubled the sector of the budget earmarked for environmental protection.\n\nLandscape\n\nAzerbaijan is home to a wide variety of landscapes. Over half of Azerbaijan's landmass consists of mountain ridges, crests, highlands, and plateaus which rise up to hypsometric levels of 400\u20131000\u00a0meters (including the Middle and Lower lowlands), in some places (Talis, Jeyranchol-Ajinohur and Langabiz-Alat foreranges) up to 100\u2013120\u00a0meters, and others from 0\u201350\u00a0meters and up (Qobustan, Absheron). The rest of Azerbaijan's terrain consists of plains and lowlands. Hypsometric marks within the Caucasus region vary from about \u221228\u00a0meters at the Caspian Sea shoreline up to 4,466\u00a0meters (Bazard\u00fcz\u00fc peak).\n\nThe formation of climate in Azerbaijan is influenced particularly by cold arctic air masses of Scandinavian anticyclone, temperate air masses of Siberian anticyclone, and Central Asian anticyclone. Azerbaijan's diverse landscape affects the ways air masses enter the country. The Greater Caucasus protects the country from direct influences of cold air masses coming from the north. That leads to the formation of subtropical climate on most foothills and plains of the country. Meanwhile, plains and foothills are characterized by high solar radiation rates.\n\n9 out of 11 existing climate zones are present in Azerbaijan. Both the absolute minimum temperature (  ) and the absolute maximum temperature (  ) were observed in Julfa and Ordubad \u2013 regions of Nakhchivan Autonomous Republic. The maximum annual precipitation falls in Lankaran () and the minimum in Absheron ().\n\nRivers and lakes form the principal part of the water systems of Azerbaijan, they were formed over a long geological timeframe and changed significantly throughout that period. This is particularly evidenced by remnants", "flag": 1, "segments": [[2817, 2827]], "strength": 5.5}
{"text": "Art is a diverse range of human activity, and resulting product, that involves creative or imaginative talent expressive of technical proficiency, beauty, emotional power, or conceptual ideas.\n\nThere is no generally agreed definition of what constitutes art, and ideas have changed over time. The three classical branches of visual art are painting, sculpture, and architecture. Theatre, dance, and other performing arts, as well as literature, music, film and other media such as interactive media, are included in a broader definition of the arts. Until the 17th century, art referred to any skill or mastery and was not differentiated from crafts or sciences. In modern usage after the 17th century, where aesthetic considerations are paramount, the fine arts are separated and distinguished from acquired skills in general, such as the decorative or applied arts. \n\nThe nature of art and related concepts, such as creativity and interpretation, are explored in a branch of philosophy known as aesthetics. The resulting artworks are studied in the professional fields of art criticism and the history of art.\n\nOverview\n\nIn the perspective of the history of art, artistic works have existed for almost as long as humankind: from early pre-historic art to contemporary art; however, some theorists feel that the typical concept of \"artistic works\" fits less well outside modern Western societies. One early sense of the definition of art is closely related to the older Latin meaning, which roughly translates to \"skill\" or \"craft\", as associated with words such as \"artisan\". English words derived from this meaning include artifact, artificial, artifice, medical arts, and military arts. However, there are many other colloquial uses of the word, all with some relation to its etymology.\n\nOver time, philosophers like Plato, Aristotle, Socrates and Kant, among others, questioned the meaning of art. Several dialogues in Plato tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the Phaedrus (265a\u2013c), and yet in the Republic wants to outlaw Homer's great poetic art, and laughter as well. In Ion, Socrates gives no hint of the disapproval of Homer that he expresses in the Republic. The dialogue Ion suggests that Homer's Iliad functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literary art that can provide moral guidance, if only it can be properly interpreted.\n\nWith regards to the literary art and the musical arts, Aristotle considered epic poetry, tragedy, comedy, Dithyrambic poetry and music to be mimetic or imitative art, each varying in imitation by medium, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation\u2014through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitation is natural to mankind and constitutes one of mankind's advantages over animals.\n\nThe more recent and specific sense of the word art as an abbreviation for creative art or fine art emerged in the early 17th century. Fine art refers to a skill used to express the artist's creativity, or to engage the audience's aesthetic sensibilities, or to draw the audience towards consideration of more refined or finer work of art.\n\nWithin this latter sense, the word art may refer to several things: (i) a study of a creative skill, (ii) a process of using the creative skill, (iii) a product of the creative skill, or (iv) the audience's experience with the creative skill. The creative arts (art as discipline) are a collection of disciplines which produce artworks (art as objects) that are compelled by a personal drive (art as activity) and convey a message, mood, or symbolism for the perceiver to interpret (art as experience).  Art is something that stimulates an individual's thoughts, emotions, beliefs, or ideas through the senses. Works of art can be explicitly made for this purpose or interpreted on the basis of images or objects. For some scholars, such as Kant, the sciences and the arts could be distinguished by taking science as representing the domain of knowledge and the arts as representing the domain of the freedom of artistic expression.\n\nOften, if the skill is being used in a common or practical way, people will consider it a craft instead of art. Likewise, if the skill is being used in a commercial or industrial way, it may be considered commercial art instead of fine art. On the other hand, crafts and design are sometimes considered applied art. Some art followers have argued that the difference between fine art and applied art has more to do with value judgments made about the art than any clear definitional difference. However, even fine art often has goals beyond pure creativity and self-expression. The purpose of works of art may be to communicate ideas, such as in politically, spiritually, or philosophically motivated art; to create a sense of beauty (see aesthetics); to explore the nature of perception; for pleasure; or to generate strong emotions. The purpose may also be seemingly nonexistent.\n\nThe nature of art has been described by philosopher Richard Wollheim as \"one of the most elusive of the traditional problems of human culture\". Art has been defined as a vehicle for the expression or communication of emotions and ideas, a means for exploring and appreciating formal elements for their own sake, and as mimesis or representation. Art as mimesis has deep roots in the philosophy of Aristotle. Leo Tolstoy identified art as a use of indirect means to communicate from one person to another. Benedetto Croce and R. G. Collingwood advanced the idealist view that art expresses emotions, and that the work of art therefore essentially exists in the mind of the creator. The theory of art as form has its roots in the philosophy of Kant, and was developed in the early 20th century by Roger Fry and Clive Bell.  More recently, thinkers influenced by Martin Heidegger have interpreted art as the means by which a community develops for itself a medium for self-expression and interpretation. George Dickie has offered an institutional theory of art that defines a work of art as any artifact upon which a qualified person or persons acting on behalf of the social institution commonly referred to as \"the art world\" has conferred \"the status of candidate for appreciation\". Larry Shiner has described fine art as \"not an essence or a fate but something we have made. Art as we have generally understood it is a European invention barely two hundred years old.\"\n\nArt may be characterized in terms of mimesis (its representation of reality), narrative (storytelling), expression, communication of emotion, or other qualities. During the Romantic period, art came to be seen as \"a special faculty of the human mind to be classified with religion and science\".\n\nHistory\n\nA shell engraved by Homo erectus was determined to be between 430,000 and 540,000 years old. A set of eight 130,000 years old white-tailed eagle talons bear cut marks and abrasion that indicate manipulation by neanderthals, possibly for using it as jewelry. A series of tiny, drilled snail shells about 75,000 years old\u2014were discovered in a South African cave. Containers that may have been used to hold paints have been found dating as far back as 100,000 years.\n\nSculptures, cave paintings, rock paintings and petroglyphs from the Upper Paleolithic dating to roughly 40,000 years ago have been found, but the precise meaning of such art is often disputed because so little is known about the cultures that produced them. \n\nMany great traditions in art have a foundation in the art of one of the great ancient civilizations: Ancient Egypt, Mesopotamia, Persia, India, China, Ancient Greece, Rome, as well as Inca, Maya, and Olmec. Each of these centers of early civilization developed a unique and characteristic style in its art. Because of the size and duration of these civilizations, more of their art works have survived and more of their influence has been transmitted to other cultures and later times. Some also have provided the first records of how artists worked. For example, this period of Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty, and anatomically correct proportions.\n\nIn Byzantine and Medieval art of the Western Middle Ages, much art focused on the expression of subjects about Biblical and religious culture, and used styles that showed the higher glory of a heavenly world's achievements to be seen by most in what is, such as the use of gold in the background of paintings, or glass in mosaics or windows, which also presented figures in idealized, patterned (flat) forms. Nevertheless, a classical realist tradition persisted in small Byzantine works, and realism steadily grew in the art of Catholic Europe.\n\nRenaissance art had a greatly increased emphasis on the realistic depiction of the material world, and the place of humans in it, reflected in the corporeality of the human body, and development of a systematic method of graphical perspective to depict recession in a three-dimensional picture space.\n\nIn the east, Islamic art's rejection of iconography led to emphasis on geometric patterns, calligraphy, and architecture. Further east, religion dominated artistic styles and forms too. India and Tibet saw emphasis on painted sculptures and dance, while religious painting borrowed many conventions from sculpture and tended to bright contrasting colors with emphasis on outlines. China saw the flourishing of many art forms: jade carving, bronzework, pottery (including the stunning terracotta army of Emperor Qin), poetry, calligraphy, music, painting, drama, fiction, etc. Chinese styles vary greatly from era to era and each one is traditionally named after the ruling dynasty. So, for example, Tang dynasty paintings are monochromatic and sparse, emphasizing idealized landscapes, but Ming dynasty paintings are busy and colorful, and focus on telling stories via setting and composition. Japan names its styles after imperial dynasties too, and also saw much interplay between the styles of calligraphy and painting. Woodblock printing became important in Japan after the 17th century.\n\nThe western Age of Enlightenment in the 18th century saw artistic depictions of physical and rational certainties of the clockwork universe, as well as politically revolutionary visions of a post-monarchist world, such as Blake's portrayal of Newton as a divine geometer, or David's propagandistic paintings. This led to Romantic rejections of this in favor of pictures of the emotional side and individuality of humans, exemplified in the novels of Goethe. The late 19th century then saw a host of artistic movements, such as academic art, Symbolism, impressionism and fauvism among others.\n\nThe history of 20th-century art is a narrative of endless possibilities and the search for new standards, each being torn down in succession by the next. Thus the parameters of Impressionism, Expressionism, Fauvism, Cubism, Dadaism, Surrealism, etc. cannot be maintained very much beyond the time of their invention. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art. Thus, Japanese woodblock prints (themselves influenced by Western Renaissance draftsmanship) had an immense influence on impressionism and subsequent development. Later, African sculptures were taken up by Picasso and to some extent by Matisse. Similarly, in the 19th and 20th centuries the West has had huge impacts on Eastern art with originally western ideas like Communism and Post-Modernism exerting a powerful influence.\n\nModernism, the idealistic search for truth, gave way in the latter half of the 20th century to a realization of its unattainability. Theodor W. Adorno said in 1970, \"It is now taken for granted that nothing which concerns art can be taken for granted any more: neither art itself, nor art in relationship to the whole, nor even the right of art to exist.\" Relativism was accepted as an unavoidable truth, which led to the period of contemporary art and postmodern criticism, where cultures of the world and of history are seen as changing forms, which can be appreciated and drawn from only with skepticism and irony. Furthermore, the separation of cultures is increasingly blurred and some argue it is now more appropriate to think in terms of a global culture, rather than of regional ones.\n\nIn The Origin of the Work of Art, Martin Heidegger, a German philosopher and a seminal thinker, describes the essence of art in terms of the concepts of being and truth. He argues that art is not only a way of expressing the element of truth in a culture, but the means of creating it and providing a springboard from which \"that which is\" can be revealed. Works of art are not merely representations of the way things are, but actually produce a community's shared understanding. Each time a new artwork is added to any culture, the meaning of what it is to exist is inherently changed.\n\nHistorically, art and artistic skills and ideas have often been spread through trade. An example of this is the Silk Road, where Hellenistic, Iranian, Indian and Chinese influences could mix. Greco Buddhist art is one of the most vivid examples of this interaction. The meeting of different cultures and worldviews also influenced artistic creation. An example of this is the multicultural port metropolis of Trieste at the beginning of the 20th century, where James Joyce met writers from Central Europe and the artistic development of New York City as a cultural melting pot.\n\nForms, genres, media, and styles\n\nThe creative arts are often divided into more specific categories, typically along perceptually distinguishable categories such as media, genre, styles, and form. Art form refers to the elements of art that are independent of its interpretation or significance. It covers the methods adopted by the artist and the physical composition of the artwork, primarily non-semantic aspects of the work (i.e., figurae), such as color, contour, dimension, medium, melody, space, texture, and value. Form may also include visual design principles, such as arrangement, balance, contrast, emphasis, harmony, proportion, proximity, and rhythm.\n\nIn general there are three schools of philosophy regarding art, focusing respectively on form, content, and context. Extreme Formalism is the view that all aesthetic properties of art are formal (that is, part of the art form). Philosophers almost universally reject this view and hold that the properties and aesthetics of art extend beyond materials, techniques, and form. Unfortunately, there is little consensus on terminology for these informal properties. Some authors refer to subject matter and content \u2013 i.e., denotations and connotations \u2013 while others prefer terms like meaning and significance.\n\nExtreme Intentionalism holds that authorial intent plays a decisive role in the meaning of a work of art, conveying the content or essential main idea, while all other interpretations can be discarded. It defines the subject as the persons or idea represented, and the content as the artist's experience of that subject. For example, the composition of Napoleon I on his Imperial Throne is partly borrowed from the Statue of Zeus at Olympia. As evidenced by the title, the subject is Napoleon, and the content is Ingres's representation of Napoleon as \"Emperor-God beyond time and space\". Similarly to extreme formalism, philosophers typically reject extreme intentionalism, because art may have multiple ambiguous meanings and authorial intent may be unknowable and thus irrelevant. Its restrictive interpretation is \"socially unhealthy, philosophically unreal, and politically unwise\".\n\nFinally, the developing theory of post-structuralism studies art's significance in a cultural context, such as the ideas, emotions, and reactions prompted by a work. The cultural context often reduces to the artist's techniques and intentions, in which case analysis proceeds along lines similar to formalism and intentionalism. However, in other cases historical and material conditions may predominate, such as religious and philosophical convictions, sociopolitical and economic structures, or even climate and geography. Art criticism continues to grow and develop alongside art.\n\nSkill and craft\n\nArt can connote a sense of trained ability or mastery of a medium. Art can also simply refer to the developed and efficient use of a language to convey meaning with immediacy or depth. Art can be defined as an act of expressing feelings, thoughts, and observations.\n\nThere is an understanding that is reached with the material as a result of handling it, which facilitates one's thought processes.\nA common view is that the epithet \"art\", particular in its elevated sense, requires a certain level of creative expertise by the artist, whether this be a demonstration of technical ability, an originality in stylistic approach, or a combination of these two. Traditionally skill of execution was viewed as a quality inseparable from art and thus necessary for its success; for Leonardo da Vinci, art, neither more nor less than his other endeavors, was a manifestation of skill. Rembrandt's work, now praised for its ephemeral virtues, was most admired by his contemporaries for its virtuosity. At the turn of the 20th century, the adroit performances of John Singer Sargent were alternately admired and viewed with skepticism for their manual fluency, yet at nearly the same time the artist who would become the era's most recognized and peripatetic iconoclast, Pablo Picasso, was completing a traditional academic training at which he excelled.\n\nA common contemporary criticism of some modern art occurs along the lines of objecting to the apparent lack of skill or ability required in the production of the artistic object. In conceptual art, Marcel Duchamp's \"Fountain\" is among the first examples of pieces wherein the artist used found objects (\"ready-made\") and exercised no traditionally recognised set of skills. Tracey Emin's My Bed, or Damien Hirst's The Physical Impossibility of Death in the Mind of Someone Living follow this example and also manipulate the mass media. Emin slept (and engaged in other activities) in her bed before placing the result in a gallery as work of art. Hirst came up with the conceptual design for the artwork but has left most of the eventual creation of many works to employed artisans. Hirst's celebrity is founded entirely on his ability to produce shocking concepts. The actual production in many conceptual and contemporary works of art is a matter of assembly of found objects. However, there are many modernist and contemporary artists who continue to excel in the skills of drawing and painting and in creating hands-on works of art.\n\nPurpose \n\nArt has had a great number of different functions throughout its history, making its purpose difficult to abstract or quantify to any single concept. This does not imply that the purpose of Art is \"vague\", but that it has had many unique, different reasons for being created. Some of these functions of Art are provided in the following outline. The different purposes of art may be grouped according to those that are non-motivated, and those that are motivated (L\u00e9vi-Strauss).\n\nNon-motivated functions \nThe non-motivated purposes of art are those that are integral to being human, transcend the individual, or do not fulfill a specific external purpose. In this sense, Art, as creativity, is something humans must do by their very nature (i.e.,\u00a0no other species creates art), and is therefore beyond utility.\n Basic human instinct for harmony, balance, rhythm. Art at this level is not an action or an object, but an internal appreciation of balance and harmony (beauty), and therefore an aspect of being human beyond utility.Imitation, then, is one instinct of our nature. Next, there is the instinct for 'harmony' and rhythm, meters being manifestly sections of rhythm. Persons, therefore, starting with this natural gift developed by degrees their special aptitudes, till their rude improvisations gave birth to Poetry. \u2013 Aristotle\n Experience of the mysterious. Art provides a way to experience one's self in relation to the universe. This experience may often come unmotivated, as one appreciates art, music or poetry.The most beautiful thing we can experience is the mysterious. It is the source of all true art and science. \u2013 Albert Einstein\n Expression of the imagination. Art provides a means to express the imagination in non-grammatic ways that are not tied to the formality of spoken or written language. Unlike words, which come in sequences and each of which have a definite meaning, art provides a range of forms, symbols and ideas with meanings that are malleable.Jupiter's eagle [as an example of art] is not, like logical (aesthetic) attributes of an object, the concept of the sublimity and majesty of creation, but rather something else\u2014something that gives the imagination an incentive to spread its flight over a whole host of kindred representations that provoke more thought than admits of expression in a concept determined by words. They furnish an aesthetic idea, which serves the above rational idea as a substitute for logical presentation, but with the proper function, however, of animating the mind by opening out for it a prospect into a field of kindred representations stretching beyond its ken. \u2013 Immanuel Kant\n Ritualistic and symbolic functions. In many cultures, art is used in rituals, performances and dances as a decoration or symbol. While these often have no specific utilitarian (motivated) purpose, anthropologists know that they often serve a purpose at the level of meaning within a particular culture. This meaning is not furnished by any one individual, but is often the result of many generations of change, and of a cosmological relationship within the culture.Most scholars who deal with rock paintings or objects recovered from prehistoric contexts that cannot be explained in utilitarian terms and are thus categorized as decorative, ritual or symbolic, are aware of the trap posed by the term 'art'. \u2013 Silva Tomaskova\n\nMotivated functions \nMotivated purposes of art refer to intentional, conscious actions on the part of the artists or creator. These may be to bring about political change, to comment on an aspect of society, to convey a specific emotion or mood, to address personal psychology, to illustrate another discipline, to (with commercial arts) sell a product, or simply as a form of communication.\n Communication. Art, at its simplest, is a form of communication. As most forms of communication have an intent or goal directed toward another individual, this is a motivated purpose. Illustrative arts, such as scientific illustration, are a form of art as communication. Maps are another example. However, the content need not be scientific. Emotions, moods and feelings are also communicated through art.[Art is a set of] artefacts or images with symbolic meanings as a means of communication. \u2013 Steve Mithen\n Art as entertainment. Art may seek to bring about a particular emotion or mood, for the purpose of relaxing or entertaining the viewer. This is often the function of the art industries of Motion Pictures and Video Games.\n The Avant-Garde. Art for political change. One of the defining functions of early 20th-century art has been to use visual images to bring about political change. Art movements that had this goal\u2014Dadaism, Surrealism, Russian constructivism, and Abstract Expressionism, among others\u2014are collectively referred to as the avant-garde arts.By contrast, the realistic attitude, inspired by positivism, from Saint Thomas Aquinas to Anatole France, clearly seems to me to be hostile to any intellectual or moral advancement. I loathe it, for it is made up of mediocrity, hate, and dull conceit. It is this attitude which today gives birth to these ridiculous books, these insulting plays. It constantly feeds on and derives strength from the newspapers and stultifies both science and art by assiduously", "flag": 1, "segments": [[1835, 1845]], "strength": 5.5}
{"text": "The American Revolutionary War (April 19, 1775 \u2013 September 3, 1783), also known as the Revolutionary War or American War of Independence, secured a United States of America independent from Great Britain. Fighting began on April 19, 1775, followed by the Declaration of Independence on July 4, 1776. The American Patriots were supported by France and Spain, conflict taking place in North America, the Caribbean, and Atlantic Ocean. It ended on September 3, 1783 when Britain accepted American independence in the Treaty of Paris, while the Treaties of Versailles resolved separate conflicts with France and Spain.  \n\nEstablished by Royal charter in the 17th and 18th centuries, the American colonies were largely autonomous in domestic affairs and commercially prosperous, trading with Britain and its Caribbean colonies, as well as other European powers via their Caribbean entrep\u00f4ts. After British victory in the Seven Years' War in 1763, tensions arose over trade, colonial policy in the Northwest Territory and taxation measures, including the Stamp Act and Townshend Acts. Colonial opposition led to the 1770 Boston Massacre and 1773 Boston Tea Party, with Parliament responding by imposing the so-called Intolerable Acts. \n\nEstablished on September 5, 1774, the First Continental Congress drafted a Petition to the King and organized a boycott of British goods. Despite attempts to achieve a peaceful solution, fighting began with the Battle of Lexington on April 19, 1775 and in June Congress authorized George Washington to create a Continental Army. Although the \"coercion policy\" advocated by the North ministry was opposed by a faction within Parliament, both sides increasingly viewed conflict as inevitable. The Olive Branch Petition sent by Congress to George III in July 1775 was rejected and in August Parliament declared the colonies to be in a state of rebellion.   \n\nFollowing the loss of Boston in March 1776, Sir William Howe, the new British commander-in-chief, launched the New York and New Jersey campaign. He captured New York City in November, before Washington won small but significant victories at Trenton and Princeton, which restored Patriot confidence. In summer 1777, Howe succeeded in taking Philadelphia, but in October a separate force under John Burgoyne was forced to surrender at Saratoga. This victory was crucial in convincing powers like France and Spain an independent United States was a viable entity.  \n\nFrance provided the US informal economic and military support from the beginning of the rebellion, and after Saratoga the two countries signed a commercial agreement and a Treaty of Alliance in February 1778. In return for a guarantee of independence, Congress joined France in its global war with Britain and agreed to defend the French West Indies. Spain also allied with France against Britain in the Treaty of Aranjuez (1779), though it did not formally ally with the Americans. Nevertheless, access to ports in Spanish Louisiana allowed the Patriots to import arms and supplies, while the Spanish Gulf Coast campaign deprived the Royal Navy of key bases in the south. \n\nThis undermined the 1778 strategy devised by Howe's replacement, Sir Henry Clinton, which took the war into the Southern United States. Despite some initial success, by September 1781 Cornwallis was besieged by a Franco-American force in Yorktown. After an attempt to resupply the garrison failed, Cornwallis surrendered in October, and although the British wars with France and Spain continued for another two years, this ended fighting in North America. In April 1782, the North ministry was replaced by a new British government which accepted American independence and began negotiating the Treaty of Paris, ratified on September 3, 1783.\n\nPrelude to revolution \n \n\nThe French and Indian War, part of the wider global conflict known as the Seven Years' War, ended with the 1763 Peace of Paris, which expelled France from its possessions in New France. Acquisition of territories in Atlantic Canada and West Florida, inhabited largely by French or Spanish-speaking Catholics, led the British authorities to consolidate their hold by populating them with English-speaking settlers. Preventing conflict between settlers and Native American tribes west of the Appalachian Mountains would also avoid the cost of an expensive military occupation. \n\nThe Proclamation Line of 1763 was designed to achieve these aims by refocusing colonial expansion north into Nova Scotia and south into Florida, with the Mississippi River as the dividing line between British and Spanish possessions in the Americas. Settlement beyond the 1763 limits was tightly restricted, while claims by individual colonies west of this line were rescinded, most significantly Virginia and Massachusetts who argued their boundaries extended from the Atlantic to the Pacific. \n\nUltimately the vast exchange of territory destabilized existing alliances and trade networks between settlers and Native Americans in the west, while it proved impossible to prevent encroachment beyond the Proclamation Line. With the exception of Virginia and others \"deprived\" of their rights in the western lands, the colonial legislatures generally agreed on the principle of boundaries but disagreed on where to set them, while many settlers resented the restrictions. Since enforcement required permanent garrisons along the frontier, it led to increasingly bitter disputes over who should pay for them.\n\nTaxation and legislation\n\nAlthough directly administered by the Crown, acting through a local Governor, the colonies were largely governed by native-born property owners. While external affairs were managed by London, colonial militia were funded locally but with the ending of the French threat in 1763, the legislatures expected less taxation, not more. At the same time, the huge debt incurred by the Seven Years' War and demands from British taxpayers for cuts in government expenditure meant Parliament expected the colonies to fund their own defense. \n\nThe 1763 to 1765 Grenville ministry instructed the Royal Navy to stop the trade of smuggled goods and enforce customs duties levied in American ports. The most important was the 1733 Molasses Act; routinely ignored prior to 1763, it had a significant economic impact since 85% of New England rum exports were manufactured from imported molasses. These measures were followed by the Sugar Act and Stamp Act, which imposed additional taxes on the colonies to pay for defending the western frontier. In July 1765, the Whigs formed the First Rockingham ministry, which repealed the Stamp Act and reduced tax on foreign molasses to help the New England economy, but re-asserted Parliamentary authority in the Declaratory Act.\n\nHowever, this did little to end the discontent; in 1768, a riot started in Boston when the authorities seized the sloop Liberty on suspicion of smuggling. Tensions escalated further in March 1770 when British troops fired on rock-throwing civilians, killing five in what became known as the Boston Massacre. The Massacre coincided with the partial repeal of the Townshend Acts by the Tory-based North Ministry, which came to power in January 1770 and remained in office until 1781. North insisted on retaining duty on tea to enshrine Parliament's right to tax the colonies; the amount was minor, but ignored the fact it was that very principle Americans found objectionable.\n\nTensions escalated following the destruction of a customs vessel in the June 1772 Gaspee Affair, then came to a head in 1773. A banking crisis led to the near-collapse of the East India Company, which dominated the British economy; to support it, Parliament passed the Tea Act, giving it a trading monopoly in the Thirteen Colonies. Since most American tea was smuggled by the Dutch, the Act was opposed by those who managed the illegal trade, while being seen as yet another attempt to impose the principle of taxation by Parliament. In December 1773, a group called the Sons of Liberty disguised as Mohawk natives dumped 342 crates of tea into Boston Harbor, an event later known as the Boston Tea Party. Parliament responded by passing the so-called Intolerable Acts, aimed specifically at Massachusetts, although many colonists and members of the Whig opposition considered them a threat to liberty in general. This led to increased sympathy for the Patriot cause locally, as well as in Parliament and the London press.\n\nBreak with the British Crown\nOver the course of the 18th century, the elected lower houses in the colonial legislatures gradually wrested power from their Royal Governors. Dominated by smaller landowners and merchants, these Assemblies now established ad hoc provincial legislatures, variously called Congresses, Conventions, and Conferences, effectively replacing Royal control. With the exception of Georgia, twelve colonies sent representatives to the First Continental Congress to agree on a unified response to the crisis. Many of the delegates feared that an all-out boycott would result in war and sent a Petition to the King calling for the repeal of the Intolerable Acts. However, after some debate, on September 17, 1774, Congress endorsed the Massachusetts Suffolk Resolves and on October 20 passed the Continental Association; based on a draft prepared by the First Virginia Convention in August, this instituted economic sanctions against Britain.\n\nWhile denying its authority over internal American affairs, a faction led by James Duane and future Loyalist Joseph Galloway insisted Congress recognize Parliament's right to regulate colonial trade.  Expecting concessions by the North administration, Congress authorized the extralegal committees and conventions of the colonial legislatures to enforce the boycott; this succeeded in reducing British imports by 97% from 1774 to 1775. However, on February 9 Parliament declared Massachusetts to be in a state of rebellion and instituted a blockade of the colony. In July, the Restraining Acts limited colonial trade with the British West Indies and Britain and barred New England ships from the Newfoundland cod fisheries. The increase in tension led to a scramble for control of militia stores, which each Assembly was legally obliged to maintain for defense. On April 19, a British attempt to secure the Concord arsenal culminated in the Battles of Lexington and Concord which began the war.\n\nPolitical reactions\n\nAfter the Patriot victory at Concord, moderates in Congress led by John Dickinson drafted the Olive Branch Petition, offering to accept royal authority in return for George III mediating in the dispute. However, since it was immediately followed by the Declaration of the Causes and Necessity of Taking Up Arms, Colonial Secretary Dartmouth viewed the offer as insincere; he refused to present the petition to the king, which was therefore rejected in early September. Although constitutionally correct, since George could not oppose his own government, it disappointed those Americans who hoped he would mediate in the dispute, while the hostility of his language annoyed even Loyalist members of Congress. Combined with the Proclamation of Rebellion, issued on August 23 in response to the Battle at Bunker Hill, it ended hopes of a peaceful settlement.\n\nBacked by the Whigs, Parliament initially rejected the imposition of coercive measures by 170 votes, fearing an aggressive policy would simply drive the Americans towards independence. However, by the end of 1774 the collapse of British authority meant both North and George III were convinced war was inevitable. After Boston, Gage halted operations and awaited reinforcements; the Irish Parliament approved the recruitment of new regiments, while allowing Catholics to enlist for the first time. Britain also signed a series of treaties with German states to supply additional troops. Within a year it had an army of over 32,000 men in America, the largest ever sent outside Europe at the time.\n\nThe employment of German mercenaries and Catholics against people viewed as British citizens was opposed by many in Parliament, as well as the colonial assemblies; combined with the lack of activity by Gage, it allowed the Patriots to take control of the legislatures. Support for independence was boosted by Thomas Paine's pamphlet Common Sense, which argued for American self-government, that was widely reprinted. To draft the Declaration of Independence, Congress appointed the Committee of Five, consisting of Thomas Jefferson, John Adams, Benjamin Franklin, Roger Sherman and Robert Livingston. Identifying inhabitants of the Thirteen Colonies as \"one people\", it simultaneously dissolved political links with Britain, while including a long list of alleged violations of \"English rights\" committed by George III.\n\nOn July 2, Congress voted for independence and published the declaration on July 4, which Washington read to his troops in New York City on July 9. At this point, the Revolution ceased to be an internal dispute over trade and tax policies and became a civil war, since each state represented in Congress was engaged in a struggle with Britain, but also split between Patriots and Loyalists. Patriots generally supported independence from Britain and a new national union in Congress, while Loyalists remained faithful to British rule. Estimates of numbers vary, one suggestion being the population as a whole was split evenly between committed Patriots, committed Loyalists and those who were indifferent. Others calculate the spilt as 40% Patriot, 40% neutral, 20% Loyalist, but with considerable regional variations.\n\nAt the onset of the war, Congress realized defeating Britain required foreign alliances and intelligence-gathering. The Committee of Secret Correspondence was formed for \"the sole purpose of corresponding with our friends in Great Britain and other parts of the world\". From 1775 to 1776, it shared information and built alliances through secret correspondence, as well as employing secret agents in Europe to gather intelligence, conduct undercover operations, analyze foreign publications and initiate Patriot propaganda campaigns. Paine served as secretary, while Silas Deane was instrumental in securing French aid in Paris.\n\nWar breaks out\nAs the American Revolutionary War unfolded in North America, there were two principal campaign theaters within the thirteen states, and a smaller but strategically important one west of the Appalachian Mountains to the Mississippi River and north to the Great Lakes. The full-on military campaigning began in the states north of Maryland, and fighting was most frequent and severest there between 1775 and 1778. Patriots achieved several strategic victories in the South, the British lost their first army at Saratoga, and the French entered the war as an American ally.\n\nIn the expanded Northern theater and wintering at Valley Forge, General Washington observed British operations coming out of New York at the 1778 Battle of Monmouth. He then closed off British initiatives by a series of raids that contained the British army in New York City. The same year, Spanish-supplied Virginia Colonel George Rogers Clark joined by Francophone settlers and their Indian allies conquered Western Quebec, the US Northwest Territory.\n\nStarting in 1779, the British initiated a southern strategy to begin at Savannah, gather Loyalist support, and reoccupy Patriot-controlled territory north to Chesapeake Bay. Initially the British were successful, and the Americans lost an entire army at the siege of Charleston, which caused a severe setback for Patriots in the region. But then British maneuvering north led to a combined American and French force cornering a second British army at Battle of Yorktown, and their surrender effectively ended the Revolutionary War.\n\nEarly engagements\n\nOn April 14, 1775, Sir Thomas Gage, Commander-in-Chief, North America since 1763 and also Governor of Massachusetts from 1774, received orders to take action against the Patriots. He decided to destroy militia ordnance stored at Concord, Massachusetts, and capture John Hancock and Samuel Adams, who were considered the principal instigators of the rebellion. The operation was to begin around midnight on April 19, in the hope of completing it before the Patriots could respond. However, Paul Revere learned of the plan and notified Captain Parker, commander of the Concord militia, who prepared to resist the attempted seizure. British troops clashed with colonial forces at Lexington and Concord, suffering around 300 casualties before withdrawing to Boston, which was then besieged by the militia.\n\nIn May, 4,500 British reinforcements arrived under Generals William Howe, John Burgoyne, and Sir Henry Clinton. On June 17, they seized the Charlestown Peninsula at the Battle of Bunker Hill, a frontal assault in which they suffered over 1,000 casualties. Dismayed at the costly attack which had gained them little, Gage appealed to London for a larger army to suppress the revolt, but instead was replaced as commander by Howe.\n\nOn June 14, 1775, Congress took control of Patriot forces outside Boston, and Congressional leader John Adams nominated George Washington as commander-in-chief of the new Continental Army. Washington previously commanded Virginia militia regiments in the French and Indian War,  and on June 16, John Hancock officially proclaimed him \"General and Commander in Chief of the army of the United Colonies.\" On July 3, He assumed command on July 3, preferring to fortify Dorchester Heights outside Boston rather than assaulting it. In early March 1776, Colonel Henry Knox arrived with heavy artillery acquired in the Capture of Fort Ticonderoga. Under cover of darkness, on March 5 Washington placed these on Dorchester Heights, from where they could fire on the town and British ships in Boston Harbor. Fearing another Bunker Hill, Howe evacuated the city on March 17 without further loss and sailed to Halifax, Nova Scotia, while Washington moved south to New York City.\n\nBeginning in August 1775, American privateers raided towns in Nova Scotia, including Saint John, Charlottetown and Yarmouth. In 1776, John Paul Jones and Jonathan Eddy attacked Canso and Fort Cumberland respectively. British officials in Quebec began negotiating with the Iroquois for their support, while the Americans urged them to maintain neutrality. Aware of Native American leanings toward the British and fearing an Anglo-Indian attack from Canada, Congress authorized an invasion of Quebec in April 1775. A second American invasion was defeated at the Battle of Quebec on December 31, and after a loose siege the Americans withdrew on May 6, 1776. A failed counter-attack at Trois-Rivi\u00e8res on June 8 ended American operations in Quebec. \n\nHowever, British pursuit was blocked by American ships on Lake Champlain until they were cleared on October 11 at the Battle of Valcour Island. The American troops were forced to withdraw to Fort Ticonderoga, ending the campaign. In November 1776, a Massachusetts-sponsored uprising in Nova Scotia during the Battle of Fort Cumberland was dispersed. The cumulative failures cost the Patriots support in local public opinion, and aggressive anti-Loyalist policies in the New England colonies alienated the Canadians. The Patriots made no further attempts to invade north.\n\nIn Virginia, an attempt by Governor Lord Dunmore to seize militia stores on April 20 1775 led to an increase in tension, although conflict was avoided for the time being. This changed after the publication of Dunmore's Proclamation on November 7, 1775, promising freedom to any slaves who fled their Patriot masters and agreed to fight for the Crown. British forces were defeated at Great Bridge on December 9 and took refuge on British ships anchored near the port of Norfolk. When the Third Virginia Convention refused to disband its militia or accept martial law, Dunmore ordered the Burning of Norfolk on January 1, 1776.\n\nThe siege of Savage's Old Fields began on November 19 in South Carolina between Loyalist and Patriot militias, and the Loyalists were subsequently driven out of the colony in the Snow Campaign. Loyalists were recruited in North Carolina to reassert British rule in the South, but they were decisively defeated in the Battle of Moore's Creek Bridge. A British expedition sent to reconquer South Carolina launched an attack on Charleston in the Battle of Sullivan's Island on June 28, 1776, but it failed and left the South under Patriot control until 1780.\n\nA shortage of gunpowder led Congress to authorize a naval expedition against The Bahamas to secure ordnance stored there. On March 3, 1776, an American squadron landed at Nassau and encountered minimal resistance, confiscating what supplies they could before sailing for home on March 17. A month later, after a brief skirmish with, Oakland to John Gates (Fisher), and Marie they returned to New London, Connecticut, the base for American naval operations during the Revolution.\n\nBritish New York counter-offensive\n\nAfter regrouping at Halifax, Nova Scotia, William Howe was determined to take the fight to the Americans. He sailed for New York in June 1776 and began landing troops on Staten Island near the entrance to New York Harbor on July 2. The Americans rejected Howe's informal attempt to negotiate peace on July 30; Washington knew that an attack on the city was imminent and realized that he needed advance information to deal with disciplined British regular troops. On August 12, 1776, Patriot Thomas Knowlton was given orders to form an elite group for reconnaissance and secret missions. Knowlton's Rangers, which included Nathan Hale, became the Army's first intelligence unit. When Washington was driven off Long Island he soon realized that he would need more than military might and amateur spies to defeat the British. He was committed to professionalizing military intelligence, and with the aid of Benjamin Tallmadge, they launched the six-man Culper spy ring. The efforts of Washington and the Culper Spy Ring substantially increased effective allocation and deployment of Continental regiments in the field. Over the course of the war Washington spent more than 10 percent of his total military funds on intelligence operations.\n\nWashington split his army into positions on Manhattan Island and across the East River in western Long Island. On August 27 at the Battle of Long Island, Howe outflanked Washington and forced him back to Brooklyn Heights, but he did not attempt to encircle Washington's forces. Through the night of August 28, General Henry Knox bombarded the British. Knowing they were up against overwhelming odds, Washington ordered the assembly of a war council on August 29; all agreed to retreat to Manhattan. Washington quickly had his troops assembled and ferried them across the East River to Manhattan on flat-bottomed freight boats without any losses in men or ordnance, leaving General Thomas Mifflin's regiments as a rearguard.\n\nGeneral Howe officially met with a delegation from Congress at the September Staten Island Peace Conference, but it failed to conclude peace as the British delegates only had the authority to offer pardons and could not recognize independence. On September 15, Howe seized control of New York City when the British landed at Kip's Bay and unsuccessfully engaged the Americans at the Battle of Harlem Heights the following day. On October 18 Howe failed to encircle the Americans at the Battle of Pell's Point, and the Americans withdrew. Howe declined to close with Washington's army on October 28 at the Battle of White Plains, and instead attacked a hill that was of no strategic value.\n\nWashington's retreat isolated his remaining forces and the British captured Fort Washington on November 16. The British victory there amounted to Washington's most disastrous defeat with the loss of 3,000 prisoners. The remaining American regiments on Long Island fell back four days later. General Sir Henry Clinton wanted to pursue Washington's disorganized army, but he was first required to commit 6,000 troops to capture Newport, Rhode Island to secure the Loyalist port. General Charles Cornwallis pursued Washington, but Howe ordered him to halt, leaving Washington unmolested.\n\nThe outlook was bleak for the American cause: the reduced army had dwindled to fewer than 5,000 men and would be reduced further when enlistments expired at the end of the year. Popular support wavered, morale declined, and Congress abandoned Philadelphia and moved to Baltimore. Loyalist activity surged in the wake of the American defeat, especially in New York state.\n\nIn London, news of the victorious Long Island campaign was well received with festivities held in the capital. Public support reached a peak, and King George III awarded the Order of the Bath to Howe. Strategic deficiencies among Patriot forces were evident: Washington divided a numerically weaker army in the face of a stronger one, his inexperienced staff misread the military situation, and American troops fled in the face of enemy fire. The successes led to predictions that the British could win within a year. In the meantime, the British established winter quarters in the New York City area and anticipated renewed campaigning the following spring.\n\nTwo weeks after Congress withdrew to safer Maryland, Washington crossed the ice-choked Delaware River about 30 miles upriver from Philadelphia on the night of December 25\u201326, 1776. His approach over frozen trails surprised Hessian Colonel Johann Rall. The Continentals overwhelmed the Hessian garrison at Trenton, New Jersey, and took 900 prisoners. The celebrated victory rescued the American army's flagging morale, gave new hope to the Patriot cause, and dispelled much of the fear of professional Hessian \"mercenaries\". Cornwallis marched to retake Trenton but was repulsed at the Battle of the Assunpink Creek; in", "flag": 1, "segments": [[4021, 4031]], "strength": 5.5}
{"text": "In mathematics and computer science, an algorithm () is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. By making use of artificial intelligence, algorithms can perform automated deductions (referred to as automated reasoning) and use mathematical and logical tests to divert the code through various routes (referred to as automated decision-making). Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as \"memory\", \"search\" and \"stimulus\".\n\nIn contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.\n\nAs an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n\nHistory \nThe concept of algorithm has existed since antiquity. Arithmetic algorithms, such as a division algorithm, were used by ancient Babylonian mathematicians c. 2500 BC and Egyptian mathematicians c. 1550 BC. Greek mathematicians later used algorithms in 240 BC in the sieve of Eratosthenes for finding prime numbers, and the Euclidean algorithm for finding the greatest common divisor of two numbers. Arabic mathematicians such as al-Kindi in the 9th century used cryptographic algorithms for code-breaking, based on frequency analysis.\n\nThe word algorithm is derived from the name of the 9th-century Persian mathematician Mu\u1e25ammad ibn M\u016bs\u0101 al-Khw\u0101rizm\u012b, whose nisba (identifying him as from Khwarazm) was Latinized as Algoritmi (Arabized Persian \u0627\u0644\u062e\u0648\u0627\u0631\u0632\u0645\u06cc c. 780\u2013850).\nMu\u1e25ammad ibn M\u016bs\u0101 al-Khw\u0101rizm\u012b was a mathematician, astronomer, geographer, and scholar in the House of Wisdom in Baghdad, whose name means 'the native of Khwarazm', a region that was part of Greater Iran and is now in Uzbekistan. About 825, al-Khwarizmi wrote an Arabic language treatise on the Hindu\u2013Arabic numeral system, which was translated into Latin during the 12th century. The manuscript starts with the phrase Dixit Algorizmi ('Thus spake Al-Khwarizmi'), where \"Algorizmi\" was the translator's Latinization of Al-Khwarizmi's name. Al-Khwarizmi was the most widely read mathematician in Europe in the late Middle Ages, primarily through another of his books, the Algebra. In late medieval Latin, algorismus, English 'algorism', the corruption of his name, simply meant the \"decimal number system\". In the 15th century, under the influence of the Greek word \u1f00\u03c1\u03b9\u03b8\u03bc\u03cc\u03c2 (arithmos), 'number' (cf. 'arithmetic'), the Latin word was altered to algorithmus, and the corresponding English term 'algorithm' is first attested in the 17th century; the modern sense was introduced in the 19th century.\n\nIndian mathematics was predominantly algorithmic.\nAlgorithms that are representative of the Indian mathematical tradition range from the ancient \u015aulbas\u016btr\u0101s to the medieval texts of the Kerala School.\n\nIn English, the word algorithm was first used in about 1230 and then by Chaucer in 1391. English adopted the French term, but it was not until the late 19th century that \"algorithm\" took on the meaning that it has in modern English.\n\nAnother early use of the word is from 1240, in a manual titled Carmen de Algorismo composed by Alexandre de Villedieu. It begins with:\n\nwhich translates to:\n\nThe poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.\n\nA partial formalization of the modern concept of algorithm began with attempts to solve the Entscheidungsproblem  (decision problem) posed by David Hilbert in 1928. Later formalizations were framed as attempts to define \"effective calculability\" or \"effective method\". Those formalizations included the G\u00f6del\u2013Herbrand\u2013Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936\u201337 and 1939.\n\nInformal definition\n\nAn informal definition could be \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and (for example) any prescribed bureaucratic procedure\nor cook-book recipe.\n\nIn general, a program is only an algorithm if it stops eventually\u2014even though infinite loops may sometimes prove desirable.\n\nA prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.\n\n offer an informal meaning of the word \"algorithm\" in the following quotation:\n\nNo human being can write fast enough, or long enough, or small enough\u2020 ( \u2020\"smaller and smaller without limit... you'd be trying to write on molecules, on atoms, on electrons\") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.\n\nAn \"enumerably infinite set\" is one whose elements can be put into one-to-one correspondence with the integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that \"creates\" output integers from an arbitrary \"input\" integer or integers that, in theory, can be arbitrarily large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary \"input variables\" m and n that produce an output y), but various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):\nPrecise instructions (in a language understood by \"the computer\") for a fast, efficient, \"good\" process that specifies the \"moves\" of \"the computer\" (machine or human, equipped with the necessary internally contained information and capabilities) to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and =... and \"effectively\" produce, in a \"reasonable\" time, output-integer y at a specified place and in a specified format.\n\nThe concept of algorithm is also used to define the notion of decidability\u2014a notion that is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to the customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.\n\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.\n\nFormalization\n\nAlgorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform\u2014in a specific order\u2014to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987) and Gurevich (2000):\n Minsky: \"But we will also maintain, with Turing... that any procedure which could \"naturally\" be called effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the arguments... in its favor are hard to refute\".\n\n Gurevich: \"\u2026 Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine \u2026 according to Savage [1987], an algorithm is a computational process defined by a Turing machine\".Turing machines can define computational processes that do not terminate. The informal definitions of algorithms generally require that the algorithm always terminates. This requirement renders the task of deciding whether a formal procedure is an algorithm impossible in the general case\u2014due to a major theorem of computability theory known as the halting problem.\n\nTypically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing. Stored data are regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.\n\nFor some of these computational processes, the algorithm must be rigorously defined: specified in the way it applies in all possible circumstances that could arise. This means that any conditional steps must be systematically dealt with, case-by-case; the criteria for each case must be clear (and computable).\n\nBecause an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting \"from the top\" and going \"down to the bottom\"\u2014an idea that is described more formally by flow of control.\n\nSo far, the discussion on the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception\u2014one which attempts to describe a task in discrete, \"mechanical\" means. Unique to this conception of formalized algorithms is the assignment operation, which sets the value of a variable. It derives from the intuition of \"memory\" as a scratchpad. An example of such an assignment can be found below.\n\nFor some alternate conceptions of what constitutes an algorithm, see functional programming and logic programming.\n\nExpressing algorithms\nAlgorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, drakon-charts, programming languages or control tables (processed by interpreters). Natural language expressions of algorithms tend to be verbose and ambiguous, and are rarely used for complex or technical algorithms. Pseudocode, flowcharts, drakon-charts and control tables are structured ways to express algorithms that avoid many of the ambiguities common in the statements based on natural language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but are also often used as a way to define or document algorithms.\n\nThere is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see finite-state machine, state transition table and control table for more), as flowcharts and drakon-charts (see state diagram for more), or as a form of rudimentary machine code or assembly code called \"sets of quadruples\" (see Turing machine for more).\n\nRepresentations of algorithms can be classed into three accepted levels of Turing machine description, as follows:\n 1 High-level description\n \"...prose to describe an algorithm, ignoring the implementation details. At this level, we do not need to mention how the machine manages its tape or head.\"\n 2 Implementation description\n \"...prose used to define the way the Turing machine uses its head and the way that it stores data on its tape. At this level, we do not give details of states or transition function.\"\n 3 Formal description\n Most detailed, \"lowest level\", gives the Turing machine's \"state table\".\n\nFor an example of the simple algorithm \"Add m+n\" described in all three levels, see Examples.\n\nDesign\n\nAlgorithm design refers to a method or a mathematical process for problem-solving and engineering algorithms. The design of algorithms is part of many solution theories of operation research, such as dynamic programming and divide-and-conquer. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, with examples including the template method pattern and the decorator pattern.\n\nOne of the most important aspects of algorithm design is resource (run-time, memory usage) efficiency; the big O notation is used to describe e.g. an algorithm's run-time growth as the size of its input increases.\n\nTypical steps in the development of algorithms:\n Problem definition\n Development of a model kids was inspired by a call from his daughter who\n Specification of the algorithm\n Designing an algorithm\n Checking the correctness of the algorithm\n Analysis of algorithm\n Implementation of algorithm\n Program testing\n Documentation preparation\n\nComputer algorithms\n\n\"Elegant\" (compact) programs, \"good\" (fast) programs : The notion of \"simplicity and elegance\" appears informally in Knuth and precisely in Chaitin:\nKnuth: \"... we want good algorithms in some loosely defined aesthetic sense. One criterion... is the length of time taken to perform the algorithm.... Other criteria are adaptability of the algorithm to computers, its simplicity and elegance, etc.\"\n\nChaitin: \"... a program is 'elegant,' by which I mean that it's the smallest possible program for producing the output that it does\"\n\nChaitin prefaces his definition with: \"I'll show you can't prove that a program is 'elegant\u2014such a proof would solve the Halting problem (ibid).\n\nAlgorithm versus function computable by an algorithm: For a given function multiple algorithms may exist. This is true, even without expanding the available instruction set available to the programmer. Rogers observes that \"It is... important to distinguish between the notion of algorithm, i.e. procedure and the notion of function computable by algorithm, i.e. mapping yielded by procedure. The same function may have several different algorithms\".\n\nUnfortunately, there may be a tradeoff between goodness (speed) and elegance (compactness)\u2014an elegant program may take more steps to complete a computation than one less elegant. An example that uses Euclid's algorithm appears below.\n\nComputers (and computors), models of computation: A computer (or human \"computor\") is a restricted type of machine, a \"discrete deterministic mechanical device\" that blindly follows its instructions. Melzak's and Lambek's primitive models reduced this notion to four elements: (i) discrete, distinguishable locations, (ii) discrete, indistinguishable counters (iii) an agent, and (iv) a list of instructions that are effective relative to the capability of the agent.\n\nMinsky describes a more congenial variation of Lambek's \"abacus\" model in his \"Very Simple Bases for Computability\". Minsky's machine proceeds sequentially through its five (or six, depending on how one counts) instructions unless either a conditional IF-THEN GOTO or an unconditional GOTO changes program flow out of sequence. Besides HALT, Minsky's machine includes three assignment (replacement, substitution) operations: ZERO (e.g. the contents of location replaced by 0: L \u2190 0), SUCCESSOR (e.g. L \u2190 L+1), and DECREMENT (e.g. L \u2190 L \u2212 1). Rarely must a programmer write \"code\" with such a limited instruction set. But Minsky shows (as do Melzak and Lambek) that his machine is Turing complete with only four general types of instructions: conditional GOTO, unconditional GOTO, assignment/replacement/substitution, and HALT.  However, a few different assignment instructions (e.g. DECREMENT, INCREMENT, and ZERO/CLEAR/EMPTY for a Minsky machine) are also required for Turing-completeness; their exact specification is somewhat up to the designer. The unconditional GOTO is a convenience; it can be constructed by initializing a dedicated location to zero e.g. the instruction \" Z \u2190 0 \"; thereafter the instruction IF Z=0 THEN GOTO xxx is unconditional.\n\nSimulation of an algorithm: computer (computor) language: Knuth advises the reader that \"the best way to learn an algorithm is to try it... immediately take pen and paper and work through an example\". But what about a simulation or execution of the real thing? The programmer must translate the algorithm into a language that the simulator/computer/computor can effectively execute. Stone gives an example of this: when computing the roots of a quadratic equation the computor must know how to take a square root. If they don't, then the algorithm, to be effective, must provide a set of rules for extracting a square root.\n\nThis means that the programmer must know a \"language\" that is effective relative to the target computing agent (computer/computor).\n\nBut what model should be used for the simulation? Van Emde Boas observes \"even if we base complexity theory on abstract instead of concrete machines, arbitrariness of the choice of a model remains. It is at this point that the notion of simulation enters\". When speed is being measured, the instruction set matters. For example, the subprogram in Euclid's algorithm to compute the remainder would execute much faster if the programmer had a \"modulus\" instruction available rather than just subtraction (or worse: just Minsky's \"decrement\").\n\nStructured programming, canonical structures: Per the Church\u2013Turing thesis, any algorithm can be computed by a model known to be Turing complete, and per Minsky's demonstrations, Turing completeness requires only four instruction types\u2014conditional GOTO, unconditional GOTO, assignment, HALT. Kemeny and Kurtz observe that, while \"undisciplined\" use of unconditional GOTOs and conditional IF-THEN GOTOs can result in \"spaghetti code\", a programmer can write structured programs using only these instructions; on the other hand \"it is also possible, and not too hard, to write badly structured programs in a structured language\". Tausworthe augments the three B\u00f6hm-Jacopini canonical structures: SEQUENCE, IF-THEN-ELSE, and WHILE-DO, with two more: DO-WHILE and CASE. An additional benefit of a structured program is that it lends itself to proofs of correctness using mathematical induction.\n\nCanonical flowchart symbols: The graphical aide called a flowchart, offers a way to describe and document an algorithm (and a computer program of one). Like the program flow of a Minsky machine, a flowchart always starts at the top of a page and proceeds down. Its primary symbols are only four: the directed arrow showing program flow, the rectangle (SEQUENCE, GOTO), the diamond (IF-THEN-ELSE), and the dot (OR-tie). The B\u00f6hm\u2013Jacopini canonical structures are made of these primitive shapes. Sub-structures can \"nest\" in rectangles, but only if a single exit occurs from the superstructure. The symbols, and their use to build the canonical structures are shown in the diagram.\n\nExamples\n\nAlgorithm example\nOne of the simplest algorithms is to find the largest number in a list of numbers of random order. Finding the solution requires looking at every number in the list. From this follows a simple algorithm, which can be stated in a high-level description in English prose, as:\n\nHigh-level description:\n If there are no numbers in the set then there is no highest number.\n Assume the first number in the set is the largest number in the set.\n For each remaining number in the set: if this number is larger than the current largest number, consider this number to be the largest number in the set.\n When there are no numbers left in the set to iterate over, consider the current largest number to be the largest number of the set.\n\n(Quasi-)formal description:\nWritten in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code:\n\n   Input: A list of numbers L.\n   Output: The largest number in the list L.\n\n   if L.size = 0 return null\n   largest \u2190 L[0]\n   for each item in L, do\n     if item > largest, then\n       largest \u2190 item\n   return largest\n\nEuclid's algorithm\nIn mathematics, the Euclidean algorithm, or Euclid's algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers (numbers), the largest number that divides them both without a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in his Elements (c. 300 BC). It is one of the oldest algorithms in common use. It can be used to reduce fractions to their simplest form, and is a part of many other number-theoretic and cryptographic calculations.\n\nEuclid poses the problem thus: \"Given two numbers not prime to one another, to find their greatest common measure\". He defines \"A number [to be] a multitude composed of units\": a counting number, a positive integer not including zero. To \"measure\" is to place a shorter measuring length s successively (q times) along longer length l until the remaining portion r is less than the shorter length s. In modern words, remainder r = l \u2212 q\u00d7s, q being the quotient, or remainder r is the \"modulus\", the integer-fractional part left over after the division.\n\nFor Euclid's method to succeed, the starting lengths must satisfy two requirements: (i) the lengths must not be zero, AND (ii) the subtraction must be \"proper\"; i.e., a test must guarantee that the smaller of the two numbers is subtracted from the larger (or the two can be equal so their subtraction yields zero).\n\nEuclid's original proof adds a third requirement: the two lengths must not be prime to one another. Euclid stipulated this so that he could construct a reductio ad absurdum proof that the two numbers' common measure is in fact the greatest. While Nicomachus' algorithm is the same as Euclid's, when the numbers are prime to one another, it yields the number \"1\" for their common measure. So, to be precise, the following is really Nicomachus' algorithm.\n\nComputer language for Euclid's algorithm\nOnly a few instruction types are required to execute Euclid's algorithm\u2014some logical tests (cond", "flag": 1, "segments": [[2851, 2861]], "strength": 5.5}
{"text": "Alexander III of Macedon ( ; 20/21 July 356 BC \u2013 10/11 June 323 BC), commonly known as Alexander the Great, was a king of the ancient Greek kingdom of Macedon. A member of the Argead dynasty, he was born in Pella\u2014a city in Ancient Greece\u2014in 356 BC. He succeeded his father King Philip II to the throne at the age of 20, and spent most of his ruling years conducting a lengthy military campaign throughout Western Asia and Northeastern Africa. By the age of thirty, he had created one of the largest empires in history, stretching from Greece to northwestern India. He was undefeated in battle and is widely considered to be one of history's greatest and most successful military commanders.\n\nDuring his youth, Alexander was tutored by Aristotle until the age of 16. His father Philip was assassinated in 336 BC at the wedding of Cleopatra of Macedon, Alexander's sister, and Alexander assumed the throne of the Kingdom of Macedon. In 335 BC he campaigned in the Balkans, reasserting control over Thrace and Illyria before sacking the Greek city of Thebes. Alexander was then awarded the generalship of Greece. He used his authority to launch his father's pan-Hellenic project, assuming leadership over all the Greeks in their conquest of Persia.\n\nIn 334 BC he invaded the Achaemenid Empire (Persian Empire) and began a series of campaigns that lasted 10 years. Following his conquest of Asia Minor (modern-day Turkey), Alexander broke the power of Persia in a series of decisive battles, including those at Issus and Gaugamela. He subsequently overthrew King Darius III and conquered the Achaemenid Empire in its entirety. At that point, his empire stretched from the Adriatic Sea to the Indus River. Alexander endeavored to reach the \"ends of the world and the Great Outer Sea\" and invaded India in 326 BC, achieving an important victory over King Porus at the Battle of the Hydaspes. He eventually turned back at the Beas River due to the demand of his homesick troops, dying in 323 BC in Babylon, the city he planned to establish as his capital. He did not manage to execute a series of planned campaigns that would have begun with an invasion of Arabia. In the years following his death, a series of civil wars tore his empire apart.\n\nAlexander's legacy includes the cultural diffusion and syncretism which his conquests engendered, such as Greco-Buddhism and Hellenistic Judaism. He founded more than twenty cities that bore his name, most notably Alexandria in Egypt. Alexander's settlement of Greek colonists and the resulting spread of Greek culture resulted in Hellenistic civilization, which developed through the Roman Empire into modern Western culture. The Greek language became the lingua franca of the region and was the predominant language of the Byzantine Empire up until its end in the mid-15th century AD.  Greek-speaking communities in central and far eastern Anatolia survived until the Greek genocide and the population exchange in the 1920s. Alexander became legendary as a classical hero in the mould of Achilles, featuring prominently in the history and mythic traditions of both Greek and non-Greek cultures. His military achievements and enduring, unprecedented success in battle made him the measure against which many later military leaders would compare themselves. Military academies throughout the world still teach his tactics.\n\nEarly life\n\nLineage and childhood\n\nAlexander was born in Pella, the capital of the Kingdom of Macedon, on the sixth day of the ancient Greek month of Hekatombaion, which probably corresponds to 20 July 356 BC (although the exact date is uncertain). He was the son of the king of Macedon, Philip II, and his fourth wife, Olympias, daughter of Neoptolemus I, king of Epirus. Although Philip had seven or eight wives, Olympias was his principal wife for some time, likely because she gave birth to Alexander.\n\nSeveral legends surround Alexander's birth and childhood. According to the ancient Greek biographer Plutarch, on the eve of the consummation of her marriage to Philip, Olympias dreamed that her womb was struck by a thunderbolt that caused a flame to spread \"far and wide\" before dying away. Sometime after the wedding, Philip is said to have seen himself, in a dream, securing his wife's womb with a seal engraved with a lion's image. Plutarch offered a variety of interpretations for these dreams: that Olympias was pregnant before her marriage, indicated by the sealing of her womb; or that Alexander's father was Zeus. Ancient commentators were divided about whether the ambitious Olympias promulgated the story of Alexander's divine parentage, variously claiming that she had told Alexander, or that she dismissed the suggestion as impious.\n\nOn the day Alexander was born, Philip was preparing a siege on the city of Potidea on the peninsula of Chalcidice. That same day, Philip received news that his general Parmenion had defeated the combined Illyrian and Paeonian armies and that his horses had won at the Olympic Games. It was also said that on this day, the Temple of Artemis in Ephesus, one of the Seven Wonders of the World, burnt down. This led Hegesias of Magnesia to say that it had burnt down because Artemis was away, attending the birth of Alexander. Such legends may have emerged when Alexander was king, and possibly at his instigation, to show that he was superhuman and destined for greatness from conception.\n\nIn his early years, Alexander was raised by a nurse, Lanike, sister of Alexander's future general Cleitus the Black. Later in his childhood, Alexander was tutored by the strict Leonidas, a relative of his mother, and by Lysimachus of Acarnania. Alexander was raised in the manner of noble Macedonian youths, learning to read, play the lyre, ride, fight, and hunt.\nWhen Alexander was ten years old, a trader from Thessaly brought Philip a horse, which he offered to sell for thirteen talents. The horse refused to be mounted, and Philip ordered it away. Alexander, however, detecting the horse's fear of its own shadow, asked to tame the horse, which he eventually managed. Plutarch stated that Philip, overjoyed at this display of courage and ambition, kissed his son tearfully, declaring: \"My boy, you must find a kingdom big enough for your ambitions. Macedon is too small for you\", and bought the horse for him. Alexander named it Bucephalas, meaning \"ox-head\". Bucephalas carried Alexander as far as India. When the animal died (because of old age, according to Plutarch, at age thirty), Alexander named a city after him, Bucephala.\n\nEducation\nWhen Alexander was 13, Philip began to search for a tutor, and considered such academics as Isocrates and Speusippus, the latter offering to resign from his stewardship of the Academy to take up the post. In the end, Philip chose Aristotle and provided the Temple of the Nymphs at Mieza as a classroom. In return for teaching Alexander, Philip agreed to rebuild Aristotle's hometown of Stageira, which Philip had razed, and to repopulate it by buying and freeing the ex-citizens who were slaves, or pardoning those who were in exile.\n\nMieza was like a boarding school for Alexander and the children of Macedonian nobles, such as Ptolemy, Hephaistion, and Cassander. Many of these students would become his friends and future generals, and are often known as the \"Companions\". Aristotle taught Alexander and his companions about medicine, philosophy, morals, religion, logic, and art. Under Aristotle's tutelage, Alexander developed a passion for the works of Homer, and in particular the Iliad; Aristotle gave him an annotated copy, which Alexander later carried on his campaigns.\n\nAlexander was able to quote Euripides from memory.\n\nDuring his youth, Alexander was also acquainted with Persian exiles at the Macedonian court, who received the protection of Philip II for several years as they opposed Artaxerxes III. Among them were Artabazos II and his daughter Barsine, possible future mistress of Alexander, who resided at the Macedonian court from 352 to 342 BC, as well as Amminapes, future satrap of Alexander, or a Persian nobleman named Sisines. This gave the Macedonian court a good knowledge of Persian issues, and may even have influenced some of the innovations in the management of the Macedonian state.\n\nSuda writes that Anaximenes of Lampsacus was one of Alexander's teachers, and that Anaximenes also accompanied Alexander on his campaigns.\n\nHeir of Philip II\n\nRegency and ascent of Macedon\n\nAt the age of 16, Alexander's education under Aristotle ended. Philip II had waged war against the Thracians to the north, which left Alexander in charge as regent and heir apparent.\n\nDuring Philip's absence, the Thracian tribe of Maedi revolted against Macedonia. Alexander responded quickly and drove them from their territory. The territory was colonized, and a city, named Alexandropolis, was founded.\n\nUpon Philip's return, Alexander was dispatched with a small force to subdue the revolts in southern Thrace. Campaigning against the Greek city of Perinthus, Alexander reportedly saved his father's life. Meanwhile, the city of Amphissa began to work lands that were sacred to Apollo near Delphi, a sacrilege that gave Philip the opportunity to further intervene in Greek affairs. While Philip was occupied in Thrace, Alexander was ordered to muster an army for a campaign in southern Greece. Concerned that other Greek states might intervene, Alexander made it look as though he was preparing to attack Illyria instead. During this turmoil, the Illyrians invaded Macedonia, only to be repelled by Alexander.\n\nPhilip and his army joined his son in 338 BC, and they marched south through Thermopylae, taking it after stubborn resistance from its Theban garrison. They went on to occupy the city of Elatea, only a few days' march from both Athens and Thebes. The Athenians, led by Demosthenes, voted to seek alliance with Thebes against Macedonia. Both Athens and Philip sent embassies to win Thebes's favour, but Athens won the contest. Philip marched on Amphissa (ostensibly acting on the request of the Amphictyonic League), capturing the mercenaries sent there by Demosthenes and accepting the city's surrender. Philip then returned to Elatea, sending a final offer of peace to Athens and Thebes, who both rejected it.\n\nAs Philip marched south, his opponents blocked him near Chaeronea, Boeotia. During the ensuing Battle of Chaeronea, Philip commanded the right wing and Alexander the left, accompanied by a group of Philip's trusted generals. According to the ancient sources, the two sides fought bitterly for some time. Philip deliberately commanded his troops to retreat, counting on the untested Athenian hoplites to follow, thus breaking their line. Alexander was the first to break the Theban lines, followed by Philip's generals. Having damaged the enemy's cohesion, Philip ordered his troops to press forward and quickly routed them. With the Athenians lost, the Thebans were surrounded. Left to fight alone, they were defeated.\n\nAfter the victory at Chaeronea, Philip and Alexander marched unopposed into the Peloponnese, welcomed by all cities; however, when they reached Sparta, they were refused, but did not resort to war. At Corinth, Philip established a \"Hellenic Alliance\" (modelled on the old anti-Persian alliance of the Greco-Persian Wars), which included most Greek city-states except Sparta. Philip was then named Hegemon (often translated as \"Supreme Commander\") of this league (known by modern scholars as the League of Corinth), and announced his plans to attack the Persian Empire.\n\nExile and return\nWhen Philip returned to Pella, he fell in love with and married Cleopatra Eurydice in 338 BC, the niece of his general Attalus. The marriage made Alexander's position as heir less secure, since any son of Cleopatra Eurydice would be a fully Macedonian heir, while Alexander was only half-Macedonian. During the wedding banquet, a drunken Attalus publicly prayed to the gods that the union would produce a legitimate heir.\n\nIn 337 BC, Alexander fled Macedon with his mother, dropping her off with her brother, King Alexander I of Epirus in Dodona, capital of the Molossians. He continued to Illyria, where he sought refuge with one or more Illyrian kings, perhaps with Glaukias, and was treated as a guest, despite having defeated them in battle a few years before. However, it appears Philip never intended to disown his politically and militarily trained son. Accordingly, Alexander returned to Macedon after six months due to the efforts of a family friend, Demaratus, who mediated between the two parties.\n\nIn the following year, the Persian satrap (governor) of Caria, Pixodarus, offered his eldest daughter to Alexander's half-brother, Philip Arrhidaeus. Olympias and several of Alexander's friends suggested this showed Philip intended to make Arrhidaeus his heir. Alexander reacted by sending an actor, Thessalus of Corinth, to tell Pixodarus that he should not offer his daughter's hand to an illegitimate son, but instead to Alexander. When Philip heard of this, he stopped the negotiations and scolded Alexander for wishing to marry the daughter of a Carian, explaining that he wanted a better bride for him. Philip exiled four of Alexander's friends, Harpalus, Nearchus, Ptolemy and Erigyius, and had the Corinthians bring Thessalus to him in chains.\n\nKing of Macedon\n\nAccession\n\nIn summer 336\u00a0BC, while at Aegae attending the wedding of his daughter Cleopatra to Olympias's brother, Alexander I of Epirus, Philip was assassinated by the captain of his bodyguards, Pausanias. As Pausanias tried to escape, he tripped over a vine and was killed by his pursuers, including two of Alexander's companions, Perdiccas and Leonnatus. Alexander was proclaimed king on the spot by the nobles and army at the age of 20.\n\nConsolidation of power\nAlexander began his reign by eliminating potential rivals to the throne. He had his cousin, the former Amyntas IV, executed. He also had two Macedonian princes from the region of Lyncestis killed, but spared a third, Alexander Lyncestes. Olympias had Cleopatra Eurydice and Europa, her daughter by Philip, burned alive. When Alexander learned about this, he was furious. Alexander also ordered the murder of Attalus, who was in command of the advance guard of the army in Asia Minor and Cleopatra's uncle.\n\nAttalus was at that time corresponding with Demosthenes, regarding the possibility of defecting to Athens. Attalus also had severely insulted Alexander, and following Cleopatra's murder, Alexander may have considered him too dangerous to leave alive. Alexander spared Arrhidaeus, who was by all accounts mentally disabled, possibly as a result of poisoning by Olympias.\n\nNews of Philip's death roused many states into revolt, including Thebes, Athens, Thessaly, and the Thracian tribes north of Macedon. When news of the revolts reached Alexander, he responded quickly. Though advised to use diplomacy, Alexander mustered 3,000 Macedonian cavalry and rode south towards Thessaly. He found the Thessalian army occupying the pass between Mount Olympus and Mount Ossa, and ordered his men to ride over Mount Ossa. When the Thessalians awoke the next day, they found Alexander in their rear and promptly surrendered, adding their cavalry to Alexander's force. He then continued south towards the Peloponnese.\n\nAlexander stopped at Thermopylae, where he was recognized as the leader of the Amphictyonic League before heading south to Corinth. Athens sued for peace and Alexander pardoned the rebels. The famous encounter between Alexander and Diogenes the Cynic occurred during Alexander's stay in Corinth. When Alexander asked Diogenes what he could do for him, the philosopher disdainfully asked Alexander to stand a little to the side, as he was blocking the sunlight. This reply apparently delighted Alexander, who is reported to have said \"But verily, if I were not Alexander, I would like to be Diogenes.\" At Corinth, Alexander took the title of Hegemon (\"leader\") and, like Philip, was appointed commander for the coming war against Persia. He also received news of a Thracian uprising.\n\nBalkan campaign\n\nBefore crossing to Asia, Alexander wanted to safeguard his northern borders. In the spring of 335\u00a0BC, he advanced to suppress several revolts. Starting from Amphipolis, he travelled east into the country of the \"Independent Thracians\"; and at Mount Haemus, the Macedonian army attacked and defeated the Thracian forces manning the heights. The Macedonians marched into the country of the Triballi, and defeated their army near the Lyginus river (a tributary of the Danube). Alexander then marched for three days to the Danube, encountering the Getae tribe on the opposite shore. Crossing the river at night, he surprised them and forced their army to retreat after the first cavalry skirmish.\n\nNews then reached major renovation this week. The new team is named Alexander that Cleitus, King of Illyria, and King Glaukias of the Taulantii were in open revolt against his authority. Marching west into Illyria, Alexander defeated each in turn, forcing the two rulers to flee with their troops. With these victories, he secured his northern frontier.\n\nWhile Alexander campaigned north, the Thebans and Athenians rebelled once again. Alexander immediately headed south. While the other cities again hesitated, Thebes decided to fight. The Theban resistance was ineffective, and Alexander razed the city and divided its territory between the other Boeotian cities. The end of Thebes cowed Athens, leaving all of Greece temporarily at peace. Alexander then set out on his Asian campaign, leaving Antipater as regent.\n\nConquest of the Persian Empire\n\nAsia Minor\n\nAfter his victory at the Battle of Chaeronea (338 BC), Philip II began the work of establishing himself as h\u0113gem\u1e53n () of a league which according to Diodorus was to wage a campaign against the Persians for the sundry grievances Greece suffered in 480 and free the Greek cities of the western coast and islands from Achaemenid rule. In 336 he sent Parmenion, with Amyntas, Andromenes and Attalus, and an army of 10,000 men into Anatolia to make preparations for an invasion. At first, all went well. The Greek cities on the western coast of Anatolia revolted until the news arrived that Philip had been murdered and had been succeeded by his young son Alexander. The Macedonians were demoralized by Philip's death and were subsequently defeated near Magnesia by the Achaemenids under the command of the mercenary Memnon of Rhodes.\n\nTaking over the invasion project of Philip II, Alexander's army crossed the Hellespont in 334\u00a0BC with approximately 48,100 soldiers, 6,100 cavalry and a fleet of 120 ships with crews numbering 38,000, drawn from Macedon and various Greek city-states, mercenaries, and feudally raised soldiers from Thrace, Paionia, and Illyria. He showed his intent to conquer the entirety of the Persian Empire by throwing a spear into Asian soil and saying he accepted Asia as a gift from the gods. This also showed Alexander's eagerness to fight, in contrast to his father's preference for diplomacy.\n\nAfter an initial victory against Persian forces at the Battle of the Granicus, Alexander accepted the surrender of the Persian provincial capital and treasury of Sardis; he then proceeded along the Ionian coast, granting autonomy and democracy to the cities. Miletus, held by Achaemenid forces, required a delicate siege operation, with Persian naval forces nearby. Further south, at Halicarnassus, in Caria, Alexander successfully waged his first large-scale siege, eventually forcing his opponents, the mercenary captain Memnon of Rhodes and the Persian satrap of Caria, Orontobates, to withdraw by sea. Alexander left the government of Caria to a member of the Hecatomnid dynasty, Ada, who adopted Alexander.\n\nFrom Halicarnassus, Alexander proceeded into mountainous Lycia and the Pamphylian plain, asserting control over all coastal cities to deny the Persians naval bases. From Pamphylia onwards the coast held no major ports and Alexander moved inland. At Termessos, Alexander humbled but did not storm the Pisidian city. At the ancient Phrygian capital of Gordium, Alexander \"undid\" the hitherto unsolvable Gordian Knot, a feat said to await the future \"king of Asia\". According to the story, Alexander proclaimed that it did not matter how the knot was undone and hacked it apart with his sword.\n\nThe Levant and Syria\n\nIn spring 333 BC, Alexander crossed the Taurus into Cilicia. After a long pause due to an illness, he marched on towards Syria. Though outmanoeuvered by Darius's significantly larger army, he marched back to Cilicia, where he defeated Darius at Issus. Darius fled the battle, causing his army to collapse, and left behind his wife, his two daughters, his mother Sisygambis, and a fabulous treasure. He offered a peace treaty that included the lands he had already lost, and a ransom of 10,000 talents for his family. Alexander replied that since he was now king of Asia, it was he alone who decided territorial divisions.\nAlexander proceeded to take possession of Syria, and most of the coast of the Levant. In the following year, 332\u00a0BC, he was forced to attack Tyre, which he captured after a long and difficult siege. The men of military age were massacred and the women and children sold into slavery.\n\nEgypt\n\nWhen Alexander destroyed Tyre, most of the towns on the route to Egypt quickly capitulated. However, Alexander was met with resistance at Gaza. The stronghold was heavily fortified and built on a hill, requiring a siege. When \"his engineers pointed out to him that because of the height of the mound it would be impossible... this encouraged Alexander all the more to make the\nattempt\". After three unsuccessful assaults, the stronghold fell, but not before Alexander had received a serious shoulder wound. As in Tyre, men of military age were put to the sword and the women and children were sold into slavery.\n\nEgypt was only one of a large number of territories taken by Alexander from the Persians. After his trip to Siwa, Alexander was crowned in the temple of Ptah at Memphis. It appears that the Egyptian people did not find it disturbing that he was a foreigner - nor that he was absent for virtually his entire reign. Alexander restored the temples neglected by the Persians and dedicated new monuments to the Egyptian gods. In the temple of Luxor, near Karnak, he built a chapel for the sacred barge. During his brief months in Egypt, he reformed the taxation system on the Greek models and organized the military occupation of the country, but, early in 331 BCE, he left for Asia in pursuit of the Persians.\n\nAlexander advanced on Egypt in later 332 BC, where he was regarded as a liberator. To legitimize taking power and be recognized as", "flag": 1, "segments": [[3709, 3719]], "strength": 5.5}
{"text": "Ankara (,  ; ), historically known as Ancyra and Angora, is the capital of Turkey. Located in the central part of Anatolia, the city has a population of 5.1\u00a0million in its urban center and over 5.7\u00a0million in Ankara Province, making it Turkey's second-largest city after Istanbul.\n\nServing as the capital of the ancient Celtic state of Galatia (280\u201364\u00a0BC), and later of the Roman province with the same name (25\u00a0BC\u20137th century), the city is very old, with various Hattian, Hittite, Lydian, Phrygian, Galatian, Greek, Persian, Roman, Byzantine, and Ottoman archeological sites. The Ottomans made the city the capital first of the Anatolia Eyalet (1393 \u2013 late 15th century) and then the Angora Vilayet (1867\u20131922). The historical center of Ankara is a rocky hill rising  over the left bank of the Ankara River, a tributary of the Sakarya River. The hill remains crowned by the ruins of Ankara Castle. Although few of its outworks have survived, there are well-preserved examples of Roman and Ottoman architecture throughout the city, the most remarkable being the 20\u00a0BC Temple of Augustus and Rome that boasts the Monumentum Ancyranum, the inscription recording the Res Gestae Divi Augusti.\n\nOn 23 April 1920, the Grand National Assembly of Turkey was established in Ankara, which became the headquarters of the Turkish National Movement during the Turkish War of Independence. Ankara became the new Turkish capital upon the establishment of the Republic on 29 October 1923, succeeding in this role as the former Turkish capital Istanbul following the fall of the Ottoman Empire. The government is a prominent employer, but Ankara is also an important commercial and industrial city located at the center of Turkey's road and railway networks. The city gave its name to the Angora wool shorn from Angora rabbits, the long-haired Angora goat (the source of mohair), and the Angora cat. The area is also known for its pears, honey and muscat grapes. Although situated in one of the driest regions of Turkey and surrounded mostly by steppe vegetation (except for the forested areas on the southern periphery), Ankara can be considered a green city in terms of green areas per inhabitant, at  per head.\n\nEtymology \n\nThe orthography of the name Ankara has varied over the ages. It has been identified with the Hittite cult center Ankuwa\u0161,  although this remains a matter of debate. In classical antiquity and during the medieval period, the city was known as \u00c1nkyra (, \u00a0\"anchor\") in Greek and Ancyra in Latin; the Galatian Celtic name was probably a similar variant. Following its annexation by the Seljuk Turks in 1073, the city became known in many European languages as Angora; it was also known in Ottoman Turkish as Eng\u00fcr\u00fc. The form \"Angora\" is preserved in the names of breeds of many different kinds of animals, and in the names of several locations in the US (see Angora).\n\nHistory \n\nThe region's history can be traced back to the Bronze Age Hattic civilization, which was succeeded in the 2nd millennium BC by the Hittites, in the 10th century BC by the Phrygians, and later by the Lydians, Persians, Greeks, Galatians, Romans, Byzantines, and Turks (the Seljuk Sultanate of R\u00fbm, the Ottoman Empire and finally republican Turkey).\n\nAncient history\n\nThe oldest settlements in and around the city center of Ankara belonged to the Hattic civilization which existed during the Bronze Age and was gradually absorbed c. 2000 \u2013 1700\u00a0BC by the Indo-European Hittites. The city grew significantly in size and importance under the Phrygians starting around 1000\u00a0BC, and experienced a large expansion following the mass migration from Gordion, (the capital of Phrygia), after an earthquake which severely damaged that city around that time. In Phrygian tradition, King Midas was venerated as the founder of Ancyra, but Pausanias mentions that the city was actually far older, which accords with present archeological knowledge.\n\nPhrygian rule was succeeded first by Lydian and later by Persian rule, though the strongly Phrygian character of the peasantry remained, as evidenced by the gravestones of the much later Roman period. Persian sovereignty lasted until the Persians' defeat at the hands of Alexander the Great who conquered the city in 333\u00a0BC. Alexander came from Gordion to Ankara and stayed in the city for a short period. After his death at Babylon in 323\u00a0BC and the subsequent division of his empire among his generals, Ankara, and its environs fell into the share of Antigonus.\n\nAnother important expansion took place under the Greeks of Pontos who came there around 300\u00a0BC and developed the city as a trading center for the commerce of goods between the Black Sea ports and Crimea to the north; Assyria, Cyprus, and Lebanon to the south; and Georgia, Armenia and Persia to the east. By that time the city also took its name \u1f0c\u03b3\u03ba\u03c5\u03c1\u03b1 (\u00c1nkyra, meaning anchor in Greek) which, in slightly modified form, provides the modern name of Ankara.\n\nCeltic history\n\nIn 278\u00a0BC, the city, along with the rest of central Anatolia, was occupied by a Celtic group, the Galatians, who were the first to make Ankara one of their main tribal centers, the headquarters of the Tectosages tribe. Other centers were Pessinus, today's Ball\u0131hisar, for the Trocmi tribe, and Tavium, to the east of Ankara, for the Tolistobogii tribe. The city was then known as Ancyra. The Celtic element was probably relatively small in numbers; a warrior aristocracy which ruled over Phrygian-speaking peasants. However, the Celtic language continued to be spoken in Galatia for many centuries. At the end of the 4th century, St. Jerome, a native of Dalmatia, observed that the language spoken around Ankara was very similar to that being spoken in the northwest of the Roman world near Trier.\n\nRoman history\n\nThe city was subsequently passed under the control of the Roman Empire. In 25\u00a0BC, Emperor Augustus raised it to the status of a polis and made it the capital city of the Roman province of Galatia. Ankara is famous for the Monumentum Ancyranum (Temple of Augustus and Rome) which contains the official record of the Acts of Augustus, known as the Res Gestae Divi Augusti, an inscription cut in marble on the walls of this temple. The ruins of Ancyra still furnish today valuable bas-reliefs, inscriptions and other architectural fragments. Two other Galatian tribal centers, Tavium near Yozgat, and Pessinus (Balhisar) to the west, near Sivrihisar, continued to be reasonably important settlements in the Roman period, but it was Ancyra that grew into a grand metropolis.\n\nAn estimated 200,000 people lived in Ancyra in good times during the Roman Empire, a far greater number than was to be the case from after the fall of the Roman Empire until the early 20th century. The small Ankara River ran through the center of the Roman town. It has now been covered and diverted, but it formed the northern boundary of the old town during the Roman, Byzantine and Ottoman periods. \u00c7ankaya, the rim of the majestic hill to the south of the present city center, stood well outside the Roman city, but may have been a summer resort. In the 19th century, the remains of at least one Roman villa or large house were still standing not far from where the \u00c7ankaya Presidential Residence stands today. To the west, the Roman city extended until the area of the Gen\u00e7lik Park and Railway Station, while on the southern side of the hill, it may have extended downwards as far as the site presently occupied by Hacettepe University. It was thus a sizeable city by any standards and much larger than the Roman towns of Gaul or Britannia.\n\nAncyra's importance rested on the fact that it was the junction point where the roads in northern Anatolia running north\u2013south and east\u2013west intersected, giving it major strategic importance for Rome's eastern frontier. The great imperial road running east passed through Ankara and a succession of emperors and their armies came this way. They were not the only ones to use the Roman highway network, which was equally convenient for invaders. In the second half of the 3rd century, Ancyra was invaded in rapid succession by the Goths coming from the west (who rode far into the heart of Cappadocia, taking slaves and pillaging) and later by the Arabs. For about a decade, the town was one of the western outposts of one of Palmyrean empress Zenobia in the Syrian Desert, who took advantage of a period of weakness and disorder in the Roman Empire to set up a short-lived state of her own.\n\nThe town was reincorporated into the Roman Empire under Emperor Aurelian in 272. The tetrarchy, a system of multiple (up to four) emperors introduced by Diocletian (284\u2013305), seems to have engaged in a substantial program of rebuilding and of road construction from Ancyra westwards to Germe and Dorylaeum (now Eski\u015fehir).\n\nIn its heyday, Roman Ancyra was a large market and trading center but it also functioned as a major administrative capital, where a high official ruled from the city's Praetorium, a large administrative palace or office. During the 3rd century, life in Ancyra, as in other Anatolian towns, seems to have become somewhat militarized in response to the invasions and instability of the town.\n\nByzantine history\nThe city is well known during the 4th century as a center of Christian activity (see also below), due to frequent imperial visits, and through the letters of the pagan scholar Libanius. Bishop Marcellus of Ancyra and Basil of Ancyra were active in the theological controversies of their day, and the city was the site of no less than three church synods in 314, 358 and 375, the latter two in favor of Arianism.\n\nThe city was visited by Emperor Constans I (r. 337\u2013350) in 347 and 350, Julian (r. 361\u2013363) during his Persian campaign in 362, and Julian's successor Jovian (r. 363\u2013364) in winter 363/364 (he entered his consulship while in the city). After Jovian's death soon after, Valentinian I (r. 364\u2013375) was acclaimed emperor at Ancyra, and in the next year his brother Valens (r. 364\u2013378) used Ancyra as his base against the usurper Procopius. When the province of Galatia was divided sometime in 396/99, Ancyra remained the civil capital of Galatia I, as well as its ecclesiastical center (metropolitan see). Emperor Arcadius (r. 383\u2013408) frequently used the city as his summer residence, and some information about the ecclesiastical affairs of the city during the early 5th century is found in the works of Palladius of Galatia and Nilus of Galatia.\n\nIn 479, the rebel Marcian attacked the city, without being able to capture it. In 610/11, Comentiolus, brother of Emperor Phocas (r. 602\u2013610), launched his own unsuccessful rebellion in the city against Heraclius (r. 610\u2013641). Ten years later, in 620 or more likely 622, it was captured by the Sassanid Persians during the Byzantine\u2013Sassanid War of 602\u2013628. Although the city returned to Byzantine hands after the end of the war, the Persian presence left traces in the city's archeology, and likely began the process of its transformation from a late antique city to a medieval fortified settlement.\n\nIn 654, the city was captured for the first time by the Arabs of the Rashidun Caliphate, under Muawiyah, the future founder of the Umayyad Caliphate. At about the same time, the themes were established in Anatolia, and Ancyra became capital of the Opsician Theme, which was the largest and most important theme until it was split up under Emperor Constantine V (r. 741\u2013775); Ancyra then became the capital of the new Bucellarian Theme. The city was captured at least temporarily by the Umayyad prince Maslama ibn Hisham in 739/40, the last of the Umayyads' territorial gains from the Byzantine Empire. Ancyra was attacked without success by Abbasid forces in 776 and in 798/99. In 805, Emperor Nikephoros I (r. 802\u2013811) strengthened its fortifications, a fact which probably saved it from sack during the large-scale invasion of Anatolia by Caliph Harun al-Rashid in the next year. Arab sources report that Harun and his successor al-Ma'mun (r. 813\u2013833) took the city, but this information is later invention. In 838, however, during the Amorium campaign, the armies of Caliph al-Mu'tasim (r. 833\u2013842) converged and met at the city; abandoned by its inhabitants, Ancara was razed to the ground, before the Arab armies went on to besiege and destroy Amorium. In 859, Emperor Michael III (r. 842\u2013867) came to the city during a campaign against the Arabs, and ordered its fortifications restored. In 872, the city was menaced, but not taken, by the Paulicians under Chrysocheir. The last Arab raid to reach the city was undertaken in 931, by the Abbasid governor of Tarsus, Thamal al-Dulafi, but the city again was not captured.\n\nEcclesiastical history \n\nEarly Christian martyrs of Ancyra, about whom little is known, included Proklos and Hilarios who were natives of the otherwise unknown nearby village of Kallippi, and suffered repression under the emperor Trajan (98\u2013117). In the 280s we hear of Philumenos, a Christian corn merchant from southern Anatolia, being captured and martyred in Ankara, and Eustathius.\n\nAs in other Roman towns, the reign of Diocletian marked the culmination of the persecution of the Christians. In 303, Ancyra was one of the towns where the co-emperors Diocletian and his deputy Galerius launched their anti-Christian persecution. In Ancyra, their first target was the 38-year-old Bishop of the town, whose name was Clement. Clement's life describes how he was taken to Rome, then sent back, and forced to undergo many interrogations and hardship before he, and his brother, and various companions were put to death. The remains of the church of St. Clement can be found today in a building just off I\u015f\u0131klar Caddesi in the Ulus district. Quite possibly this marks the site where Clement was originally buried. Four years later, a doctor of the town named Plato and his brother Antiochus also became celebrated martyrs under Galerius. Theodotus of Ancyra is also venerated as a saint.\n\nHowever, the persecution proved unsuccessful and in 314 Ancyra was the center of an important council of the early church; its 25 disciplinary canons constitute one of the most important documents in the early history of the administration of the Sacrament of Penance.  The synod also considered ecclesiastical policy for the reconstruction of the Christian Church after the persecutions, and in particular the treatment of lapsi\u2014Christians who had given in to forced paganism (sacrifices) to avoid martyrdom during these persecutions.\n\nThough paganism was probably tottering in Ancyra in Clement's day, it may still have been the majority religion. Twenty years later, Christianity and monotheism had taken its place. Ancyra quickly turned into a Christian city, with a life dominated by monks and priests and theological disputes. The town council or senate gave way to the bishop as the main local figurehead. During the middle of the 4th century, Ancyra was involved in the complex theological disputes over the nature of Christ, and a form of Arianism seems to have originated there.\n\nIn 362\u2013363, Emperor Julian passed through Ancyra on his way to an ill-fated campaign against the Persians, and according to Christian sources, engaged in a persecution of various holy men. The stone base for a statue, with an inscription describing Julian as \"Lord of the whole world from the British Ocean to the barbarian nations\", can still be seen, built into the eastern side of the inner circuit of the walls of Ankara Castle. The Column of Julian which was erected in honor of the emperor's visit to the city in 362 still stands today. In 375, Arian bishops met at Ancyra and deposed several bishops, among them St. Gregory of Nyssa.\n\nIn the late 4th century, Ancyra became something of an imperial holiday resort. After Constantinople became the East Roman capital, emperors in the 4th and 5th centuries would retire from the humid summer weather on the Bosporus to the drier mountain atmosphere of Ancyra. Theodosius II (408\u2013450) kept his court in Ancyra in the summers. Laws issued in Ancyra testify to the time they spent there.\n\nThe Metropolis of Ancyra continued to be a residential see of the Eastern Orthodox Church until the 20th century, with about 40,000 faithful, mostly Turkish-speaking, but that situation ended as a result of the 1923 Convention Concerning the Exchange of Greek and Turkish Populations. The earlier Armenian genocide put an end to the residential eparchy of Ancyra of the Armenian Catholic Church, which had been established in 1850. It is also a titular metropolis of the Ecumenical Patriarchate of Constantinople.\n\nBoth the Ancient Byzantine Metropolitan archbishopric and the'modern' Armenian eparchy are now listed by the Catholic Church as titular sees, with separate apostolic successions.\n\nSeljuk and Ottoman history \n\nAfter the Battle of Manzikert in 1071, the Seljuk Turks overran much of Anatolia. By 1073, the Turkish settlers had reached the vicinity of Ancyra, and the city was captured shortly after, at the latest by the time of the rebellion of Nikephoros Melissenos in 1081. In 1101, when the Crusade under Raymond IV of Toulouse arrived, the city had been under Danishmend control for some time. The Crusaders captured the city, and handed it over to the Byzantine emperor Alexios I Komnenos (r. 1081\u20131118). Byzantine rule did not last long, and the city was captured by the Seljuk Sultanate of Rum at some unknown point; in 1127, it returned to Danishmend control until 1143, when the Seljuks of Rum retook it.\n\nAfter the Battle of K\u00f6se Da\u011f in 1243, in which the Mongols defeated the Seljuks, most of Anatolia became part of the dominion of the Mongols. Taking advantage of Seljuk decline, a semi-religious cast of craftsmen and trade people named Ahiler chose Angora as their independent city-state in 1290. Orhan I, the second Bey of the Ottoman Empire, captured the city in 1356. Timur defeated Bayezid I at the Battle of Ankara in 1402 and took the city, but in 1403 Angora was again under Ottoman control.\n\nThe Levant Company maintained a factory in the town from 1639 to 1768. In the 19th century, its population was estimated at 20,000 to 60,000. It was sacked by Egyptians under Ibrahim Pasha in 1832.\n\nFrom 1867 to 1922, the city served as the capital of the Angora Vilayet, which included most of ancient Galatia.\n\nPrior to World War I, the town had a British consulate and a population of around 28,000, roughly  of whom were Christian.\n\nTurkish republican capital \n\nFollowing the Ottoman defeat in World War I, the Ottoman capital Constantinople (modern Istanbul) and much of Anatolia was occupied by the Allies, who planned to share these lands between Armenia, France, Greece, Italy and the United Kingdom, leaving for the Turks the core piece of land in central Anatolia. In response, the leader of the Turkish nationalist movement, Mustafa Kemal Atat\u00fcrk, established the headquarters of his resistance movement in Angora in 1920. After the Turkish War of Independence was won and the Treaty of S\u00e8vres was superseded by the Treaty of Lausanne (1923), the Turkish nationalists replaced the Ottoman Empire with the Republic of Turkey on 29 October 1923. A few days earlier, Angora had officially replaced Constantinople as the new Turkish capital city, on 13 October 1923, and Republican officials declared that the city's name is Ankara.\n\nAfter Ankara became the capital of the newly founded Republic of Turkey, new development divided the city into an old section, called Ulus, and a new section, called Yeni\u015fehir. Ancient buildings reflecting Roman, Byzantine, and Ottoman history and narrow winding streets mark the old section. The new section, now centered on K\u0131z\u0131lay Square, has the trappings of a more modern city: wide streets, hotels, theaters, shopping malls, and high-rises.\n\nGovernment offices and foreign embassies are also located in the new section. Ankara has experienced a phenomenal growth since it was made Turkey's capital in 1923, when it was \"a small town of no importance\". In 1924, the year after the government had moved there, Ankara had about 35,000 residents. By 1927 there were 44,553 residents and by 1950 the population had grown to 286,781. Ankara continued to grow rapidly during the latter half of the 20th century and eventually outranked Izmir as Turkey's second-largest city, after Istanbul. Ankara's urban population reached 4,587,558 in 2014, while the population of Ankara Province reached 5,150,072 inheads, a badge of shame. The whole political 2015.\n\nAfter 1930, it became known officially in Western languages as Ankara. After the late 1930s the public stopped using the name \"Angora\".\n\nPresidential Palace of Turkey is situated in Ankara. This building serves as the main residence of the president.\n\nEconomy and infrastructure \n\nThe city has exported mohair (from the Angora goat) and Angora wool (from the Angora rabbit) internationally for centuries. In the 19th century, the city also exported substantial amounts of goat and cat skins, gum, wax, honey, berries, and madder root. It was connected to Istanbul by railway before the First World War, continuing to export mohair, wool, berries, and grain.\n\nThe Central Anatolia Region is one of the primary locations of grape and wine production in Turkey, and Ankara is particularly famous for its Kalecik Karas\u0131 and Muscat grapes; and its Kavakl\u0131dere wine, which is produced in the Kavakl\u0131dere neighborhood within the \ufffd", "flag": 1, "segments": [[4783, 4793]], "strength": 5.5}
{"text": "Arabic (,   or,   or ) is a Semitic language that first emerged in the 1st to 4th centuries CE. It is the lingua franca of the Arab world and the liturgical language of Islam. It is named after the Arabs, a term initially used to describe peoples living in the Arabian Peninsula bounded by eastern Egypt in the west, Mesopotamia in the east, and the Anti-Lebanon mountains and northern Syria in the north, as perceived by ancient Greek geographers. The ISO assigns language codes to 32 varieties of Arabic, including its standard form, Modern Standard Arabic, also referred to as Literary Arabic, which is modernized Classical Arabic. This distinction exists primarily among Western linguists; Arabic speakers themselves generally do not distinguish between Modern Standard Arabic and Classical Arabic, but rather refer to both as  ( \"the eloquent Arabic\") or simply  ().\n\nArabic is widely taught in schools and universities around the world and is used to varying degrees in workplaces, governments and the media. Arabic, in its Modern Standard Arabic form, is an official language of 26 states and 1 disputed territory, the third most after English and French;\nit is also the liturgical language of the religion of Islam, since the Quran and the Hadiths were written in Classical Arabic.\n\nDuring the early Middle Ages, Arabic was a major vehicle of culture in the Mediterranean region, especially in science, mathematics and philosophy. As a result, many European languages have also borrowed many words from it. Arabic influence, mainly in vocabulary, is seen in European languages\u2014mainly Spanish and to a lesser extent Portuguese, Catalan, and Sicilian\u2014owing to both the proximity of Christian European and Muslim Arabized civilizations and the long-lasting Muslim culture and Arabic language presence, mainly in Southern Iberia, during the Al-Andalus era. The Maltese language is a Semitic language developed from a dialect of Arabic and written in the Latin alphabet. The Balkan languages, including Greek and Bulgarian, have also acquired a significant number of words of Arabic origin through contact with Ottoman Turkish.\n\nArabic has influenced many other languages around the globe throughout its history especially languages of Muslim cultures and countries that were conquered by Muslims. Some of the most influenced languages are Persian, Turkish, Hindustani (Hindi and Urdu), Kashmiri, Kurdish, Bosnian, Kazakh, Bengali, Malay (Indonesian and Malaysian), Maldivian, Pashto, Punjabi, Albanian, Armenian, Azerbaijani, Sicilian, Spanish, Greek, Bulgarian, Tagalog, Sindhi, Odia Hebrew and Hausa and some languages in parts of Africa. Conversely, Arabic has borrowed words from other languages, including Aramaic as well as Hebrew, Latin, Greek, Persian and to a lesser extent Turkish (due to the Ottoman Empire), English and French (due to their colonization of the Levant) and other Semitic languages such as Abyssinian.\n\nArabic is the liturgical language of 1.9 billion Muslims, and Arabic is one of six official languages of the United Nations. All varieties of Arabic combined are spoken by perhaps as many as 422 million speakers (native and non-native) in the Arab world, making it the fifth most spoken language in the world, and the fourth most used language on the internet in terms of users. In 2011, Bloomberg Businessweek ranked Arabic the fourth most useful language for business, after English, Standard Mandarin Chinese, and French. Arabic is written with the Arabic alphabet, which is an abjad script and is written from right to left, although the spoken varieties are sometimes written in ASCII Latin from left to right with no standardized orthography.\n\nClassification \n\nArabic is usually, but not universally, classified as a Central Semitic language. It is related to languages in other subgroups of the Semitic language group (Northwest Semitic, South Semitic, East Semitic, West Semitic), such as Aramaic, Syriac, Hebrew, Ugaritic, Phoenician, Canaanite, Amorite, Ammonite, Eblaite, epigraphic Ancient North Arabian, epigraphic Ancient South Arabian, Ethiopic, Modern South Arabian, and numerous other dead and modern languages. Linguists still differ as to the best classification of Semitic language sub-groups.\nThe Semitic languages changed a great deal between Proto-Semitic and the emergence of the Central Semitic languages, particularly in grammar. Innovations of the Central Semitic languages\u2014all maintained in Arabic\u2014include:\n The conversion of the suffix-conjugated stative formation (jalas-) into a past tense.\n The conversion of the prefix-conjugated preterite-tense formation (yajlis-) into a present tense.\n The elimination of other prefix-conjugated mood/aspect forms (e.g., a present tense formed by doubling the middle root, a perfect formed by infixing a  after the first root consonant, probably a jussive, we will use a combination national and foreign income formed by a stress shift) in favor of new moods formed by endings attached to the prefix-conjugation forms (e.g., -u for indicative, -a for subjunctive, no ending for jussive, -an or -anna for energetic).\n The development of an internal passive.\nThere are several features which Classical Arabic, the modern Arabic varieties, as well as the Safaitic and Hismaic inscriptions share which are unattested in any other Central Semitic language variety, including the Dadanitic and Taymanitic languages of the northern Hejaz. These features are evidence of common descent from a hypothetical ancestor, Proto-Arabic. The following features can be reconstructed with confidence for Proto-Arabic:\n negative particles  * ;  * to Classical Arabic \n  G-passive participle\n prepositions and adverbs,,,, \n a subjunctive in -\n -demonstratives\n leveling of the - allomorph of the feminine ending\n  complementizer and subordinator\n the use of - to introduce modal clauses\n independent object pronoun in \n vestiges of nunation\n\nHistory\n\nOld Arabic \n\nArabia boasted a wide variety of Semitic languages in antiquity. In the southwest, various Central Semitic languages both belonging to and outside of the Ancient South Arabian family (e.g. Southern Thamudic) were spoken. It is also believed that the ancestors of the Modern South Arabian languages (non-Central Semitic languages) were also spoken in southern Arabia at this time. To the north, in the oases of northern Hejaz, Dadanitic and Taymanitic held some prestige as inscriptional languages. In Najd and parts of western Arabia, a language known to scholars as Thamudic C is attested. In eastern Arabia, inscriptions in a script derived from ASA attest to a language known as Hasaitic. Finally, on the northwestern frontier of Arabia, various languages known to scholars as Thamudic B, Thamudic D, Safaitic, and Hismaic are attested. The last two share important isoglosses with later forms of Arabic, leading scholars to theorize that Safaitic and Hismaic are in fact early forms of Arabic and that they should be considered Old Arabic.\n\nLinguists generally believe that \"Old Arabic\" (a collection of related dialects that constitute the precursor of Arabic) first emerged around the 1st century CE. Previously, the earliest attestation of Old Arabic was thought to be a single 1st century CE inscription in Sabaic script at Qaryat Al-Faw, in southern present-day Saudi Arabia. However, this inscription does not participate in several of the key innovations of the Arabic language group, such as the conversion of Semitic mimation to nunation in the singular. It is best reassessed as a separate language on the Central Semitic dialect continuum.\nIt was also thought that Old Arabic coexisted alongside\u2014and then gradually displaced--epigraphic Ancient North Arabian (ANA), which was theorized to have been the regional tongue for many centuries. ANA, despite its name, was considered a very distinct language, and mutually unintelligible, from \"Arabic\". Scholars named its variant dialects after the towns where the inscriptions were discovered (Dadanitic, Taymanitic, Hismaic, Safaitic). However, most arguments for a single ANA language or language family were based on the shape of the definite article, a prefixed h-. It has been argued that the h- is an archaism and not a shared innovation, and thus unsuitable for language classification, rendering the hypothesis of an ANA language family untenable. Safaitic and Hismaic, previously considered ANA, should be considered Old Arabic due to the fact that they participate in the innovations common to all forms of Arabic.The earliest attestation of continuous Arabic text in an ancestor of the modern Arabic script are three lines of poetry by a man named Garm(')all\u0101he found in En Avdat, Israel, and dated to around 125 CE. This is followed by the Namara inscription, an epitaph of the Lakhmid king Imru' al-Qays bar 'Amro, dating to 328 CE, found at Namaraa, Syria. From the 4th to the 6th centuries, the Nabataean script evolves into the Arabic script recognizable from the early Islamic era. There are inscriptions in an undotted, 17-letter Arabic script dating to the 6th century CE, found at four locations in Syria (Zabad, Jabal 'Usays, Harran, Umm al-Jimaal). The oldest surviving papyrus in Arabic dates to 643 CE, and it uses dots to produce the modern 28-letter Arabic alphabet. The language of that papyrus and of the Qur'an are referred to by linguists as \"Quranic Arabic\", as distinct from its codification soon thereafter into \"Classical Arabic\".\n\nOld Hejazi and Classical Arabic\n\nIn late pre-Islamic times, a transdialectal and transcommunal variety of Arabic emerged in the Hejaz which continued living its parallel life after literary Arabic had been institutionally standardized in the 2nd and 3rd century of the Hijra, most strongly in Judeo-Christian texts, keeping alive ancient features eliminated from the \"learned\" tradition (Classical Arabic). This variety and both its classicizing and \"lay\" iterations have been termed Middle Arabic in the past, but they are thought to continue an Old Higazi register. It is clear that the orthography of the Qur'an was not developed for the standardized form of Classical Arabic; rather, it shows the attempt on the part of writers to record an archaic form of Old Higazi.\n\nIn the late 6th century AD, a relatively uniform intertribal \"poetic koine\" distinct from the spoken vernaculars developed based on the Bedouin dialects of Najd, probably in connection with the court of al-\u1e24\u012bra. During the first Islamic century, the majority of Arabic poets and Arabic-writing persons spoke Arabic as their mother tongue. Their texts, although mainly preserved in far later manuscripts, contain traces of non-standardized Classical Arabic elements in morphology and syntax.\n\nStandardization \n\nAbu al-Aswad al-Du'ali (c. 603\u2013689) is credited with standardizing Arabic grammar, or an-na\u1e25w ( \"the way\"), and pioneering a system of diacritics to differentiate consonants ( nuqat l-i'j\u0101m \"pointing for non-Arabs\") and indicate vocalization ( at-tashkil). Al-Khalil ibn Ahmad al-Farahidi (718 \u2013 786) compiled the first Arabic dictionary, Kit\u0101b al-'Ayn ( \"The Book of the Letter \u0639\"), and is credited with establishing the rules of Arabic prosody. Al-Jahiz (776-868) proposed to Al-Akhfash al-Akbar an overhaul of the grammar of Arabic, but it would not come to pass two centuries. The standardization of Arabic reached completion around the end of the 8th century. The first comprehensive description of the \u02bfarabiyya \"Arabic\", S\u012bbawayhi's al-Kit\u0101b, is based first of all upon a corpus of poetic texts, in addition to Qur'an usage and Bedouin informants whom he considered to be reliable speakers of the \u02bfarabiyya.\n\nSpread \nArabic spread with the spread of Islam. Following the early Muslim conquests, Arabic gained vocabulary from Middle Persian and Turkish. In the early Abbasid period, many Classical Greek terms entered Arabic through translations carried out at Baghdad's House of Wisdom.\n\nBy the 8th century, knowledge of Classical Arabic had become an essential prerequisite for rising into the higher classes throughout the Islamic world, both for Muslims and non-Muslims. For example, Maimonides, the Andalusi Jewish philosopher, authored works in Judeo-Arabic\u2014Arabic written in Hebrew script\u2014including his famous The Guide for the Perplexed ( Dal\u0101lat al-\u1e25\u0101\u02beir\u012bn).\n\nDevelopment \nIbn Jinni of Mosul, a pioneer in phonology, wrote prolifically in the 10th century on Arabic morphology and phonology in works such as Kit\u0101b Al-Mun\u1e63if, Kit\u0101b Al-Mu\u1e25tasab, and.\n\nIbn Mada' of Cordoba (1116\u20131196) realized the overhaul of Arabic grammar first proposed by Al-Jahiz 200 years prior.\n\nThe Maghrebi lexicographer Ibn Manzur compiled  (\u0644\u0633\u0627\u0646 \u0627\u0644\u0639\u0631\u0628, \"Tongue of Arabs\"), a major reference dictionary of Arabic, in 1290.\n\nNeo-Arabic \nCharles Ferguson's koine theory (Ferguson 1959) claims that the modern Arabic dialects collectively descend from a single military koine that sprang up during the Islamic conquests; this view has been challenged in recent times. Ahmad al-Jallad proposes that there were at least two considerably distinct types of Arabic on the eve of the conquests: Northern and Central (Al-Jallad 2009). The modern dialects emerged from a new contact situation produced following the conquests. Instead of the emergence of a single or multiple koines, the dialects contain several sedimentary layers of borrowed and areal features, which they absorbed at different points in their linguistic histories. According to Veersteegh and Bickerton, colloquial Arabic dialects arose from pidginized Arabic formed from contact between Arabs and conquered peoples. Pidginization and subsequent creolization among Arabs and arabized peoples could explain relative morphological and phonological simplicity of vernacular Arabic compared to Classical and MSA.\n\nIn around the 11th and 12th centuries in al-Andalus, the zajal and muwashah poetry forms developed in the dialectical Arabic of Cordoba and the Maghreb.\n\nNahda \n\nThe Nahda was a cultural and especially literary renaissance of the 19th century in which writers sought \"to fuse Arabic and European forms of expression.\" According to James L. Gelvin, \"Nahda writers attempted to simplify the Arabic language and script so that it might be accessible to a wider audience.\"\n\nIn the wake of the industrial revolution and European hegemony and colonialism, pioneering Arabic presses, such as the Amiri Press established by Muhammad Ali (1819), dramatically changed the diffusion and consumption of Arabic literature and publications. Rifa'a al-Tahtawi proposed the establishment of  in 1836 and led a translation campaign that highlighted the need for a lexical injection in Arabic, to suit concepts of the industrial and post-industrial age. In response, a number of Arabic academies modeled after the Acad\u00e9mie fran\u00e7aise were established with the aim of developing standardized additions to the Arabic lexicon to suit these transformations, first in Damascus (1919), then in Cairo (1932), Baghdad (1948), Rabat (1960), Amman (1977),  (1993), and Tunis (1993). In 1997, a bureau of Arabization standardization was added to the Educational, Cultural, and Scientific Organization of the Arab League. These academies and organizations have worked toward the Arabization of the sciences, creating terms in Arabic to describe new concepts, toward the standardization of these new terms throughout the Arabic-speaking world, and toward the development of Arabic as a world language. This gave rise to what Western scholars call Modern Standard Arabic.\n\nFrom the 1950s, Arabization became a postcolonial nationalist policy in countries such as Tunisia, Algeria, Morocco, and Sudan.\n\nClassical, Modern Standard and spoken Arabic \n\nArabic usually refers to Standard Arabic, which Western linguists divide into Classical Arabic and Modern Standard Arabic. It could also refer to any of a variety of regional vernacular Arabic dialects, which are not necessarily mutually intelligible.\n\nClassical Arabic is the language found in the Quran, used from the period of Pre-Islamic Arabia to that of the Abbasid Caliphate. Classical Arabic is prescriptive, according to the syntactic and grammatical norms laid down by classical grammarians (such as Sibawayh) and the vocabulary defined in classical dictionaries (such as the Lis\u0101n al-\u02bbArab).\n\nModern Standard Arabic (MSA) largely follows the grammatical standards of Classical Arabic and uses much of the same vocabulary. However, it has discarded some grammatical constructions and vocabulary that no longer have any counterpart in the spoken varieties and has adopted certain new constructions and vocabulary from the spoken varieties. Much of the new vocabulary is used to denote concepts that have arisen in the industrial and post-industrial era, especially in modern times. Due to its grounding in Classical Arabic, Modern Standard Arabic is removed over a millennium from everyday speech, which is construed as a multitude of dialects of this language. These dialects and Modern Standard Arabic are described by some scholars as not mutually comprehensible. The former are usually acquired in families, while the latter is taught in formal education settings. However, there have been studies reporting some degree of comprehension of stories told in the standard variety among preschool-aged children. The relation between Modern Standard Arabic and these dialects is sometimes compared to that of Classical Latin and Vulgar Latin vernaculars (which became Romance languages) in medieval and early modern Europe. This view though does not take into account the widespread use of Modern Standard Arabic as a medium of audiovisual communication in today's mass media\u2014a function Latin has never performed.\n\nMSA is the variety used in most current, printed Arabic publications, spoken by some of the Arabic media across North Africa and the Middle East, and understood by most educated Arabic speakers. \"Literary Arabic\" and \"Standard Arabic\" ( ) are less strictly defined terms that may refer to Modern Standard Arabic or Classical Arabic.\n\nSome of the differences between Classical Arabic (CA) and Modern Standard Arabic (MSA) are as follows:\n Certain grammatical constructions of CA that have no counterpart in any modern vernacular dialect (e.g., the energetic mood) are almost never used in Modern Standard Arabic.\nCase distinctions are very rare in Arabic vernaculars. As a result, MSA is generally composed without case distinctions in mind, and the proper cases are added after the fact, when necessary. Because most case endings are noted using final short vowels, which are normally left unwritten in the Arabic script, it is unnecessary to determine the proper case of most words. The practical result of this is that MSA, like English and Standard Chinese, is written in a strongly determined word order and alternative orders that were used in CA for emphasis are rare. In addition, because of the lack of case marking in the spoken varieties, most speakers cannot consistently use the correct endings in extemporaneous speech. As a result, spoken MSA tends to drop or regularize the endings except when reading from a prepared text.\n The numeral system in CA is complex and heavily tied in with the case system. This system is never used in MSA, even in the most formal of circumstances; instead, a significantly simplified system is used, approximating the system of the conservative spoken varieties.\n\nMSA uses much Classical vocabulary (e.g.,  'to go') that is not present in the spoken varieties, but deletes Classical words that sound obsolete in MSA. In addition, MSA has borrowed or coined many terms for concepts that did not exist in Quranic times, and MSA continues to evolve. Some words have been borrowed from other languages\u2014notice that transliteration mainly indicates spelling and not real pronunciation (e.g.,   'film' or   'democracy').\n\nHowever, the current preference is to avoid direct borrowings, preferring to either use loan translations (e.g.,   'branch', also used for the branch of a company or organization;   'wing', is also used for the wing of an airplane, building, air force, etc.), or to coin new words using forms within existing roots (  'apoptosis', using the root  m/w/t 'death' put into the Xth form, or   'university', based on   'to gather, unite';  'republic', based on  'multitude'). An earlier tendency was to redefine an older word although this has fallen into disuse (e.g.,   'telephone' < 'invisible caller (in Sufism)';   'newspaper' < 'palm-leaf stalk').\n\nColloquial or dialectal Arabic refers to the many national or regional varieties which constitute the everyday spoken language and evolved from Classical Arabic. Colloquial Arabic has many regional variants; geographically distant varieties usually differ enough to be mutually unintelligible, and some linguists consider them distinct languages. However, research indicates a high degree of mutual intelligibility between closely related Arabic variants for native speakers listening to words, sentences, and texts; and between more distantly related dialects in interactional situations.\n\nThe varieties are typically unwritten. They are often used in informal spoken media, such as soap operas and talk shows, as well as occasionally in certain forms of written media such as poetry and printed advertising.\n\nThe only variety of modern Arabic to have acquired official language status is Maltese, which is spoken in (predominantly Catholic) Malta and written with the Latin script. It is descended from Classical Arabic through Siculo-Arabic, but is not mutually intelligible with any other variety of Arabic. Most linguists list it as a separate language rather than as a dialect of Arabic.\n\nEven during Muhammad's lifetime, there were dialects of spoken Arabic. Muhammad spoke in the dialect of Mecca, in the western Arabian peninsula, and it was in this dialect that the Quran was written down. However, the dialects of the eastern Arabian peninsula were considered the most prestigious at the time, so the language of the Quran was ultimately converted to follow the eastern phonology. It is this phonology that underlies the modern pronunciation of Classical Arabic. The phonological differences between these two dialects account for some of the complexities of Arabic writing, most notably the writing of the glottal stop or hamzah (which was preserved in the eastern dialects but lost in western speech) and the use of  (representing a sound preserved in the western dialects but merged with  in eastern speech).\n\nLanguage and dialect\nThe sociolinguistic situation of Arabic in modern times provides a prime example of the linguistic phenomenon of diglossia, which is the normal use of two separate varieties of the same language, usually in different social situations. Tawleed is the process of giving", "flag": 1, "segments": [[1039, 1049]], "strength": 5.5}
{"text": "Sir Alfred Joseph Hitchcock  (13 August 1899\u00a0\u2013 29 April 1980) was an English filmmaker who was one of the most influential figures in the history of cinema. In a career spanning six decades, he directed over 50 feature films, many of which are still widely watched and studied today. Known as the \"Master of Suspense\", he became as well known as any of his actors thanks to his many interviews, his cameo roles in most of his films, and his hosting and producing the television anthology Alfred Hitchcock Presents (1955\u201365). His films garnered 46 Academy Award nominations, including six wins, although he never won the award for Best Director despite five nominations. \n\nHitchcock initially trained as a technical clerk and copy writer before entering the film industry in 1919 as a title card designer. His directorial debut was the British-German silent film The Pleasure Garden (1925). His first successful film, The Lodger: A Story of the London Fog (1927), helped to shape the thriller genre, and Blackmail (1929) was the first British \"talkie\". His thrillers The 39 Steps (1935) and The Lady Vanishes (1938) are ranked among the greatest British films of the 20th century. By 1939, he had international recognition and producer David O. Selznick persuaded him to move to Hollywood. A string of successful films followed, including Rebecca (1940), Foreign Correspondent (1940), Suspicion (1941), Shadow of a Doubt (1943), and Notorious (1946). Rebecca won the Academy Award for Best Picture, with Hitchcock nominated as Best Director; he was also nominated for Lifeboat (1944) and Spellbound (1945). After a brief commercial lull, he returned to form with Strangers on a Train (1951) and Dial M for Murder (1954); he then went on to direct four films often ranked among the greatest of all time: Rear Window (1954), Vertigo (1958), North by Northwest (1959) and Psycho (1960), the first and last of these garnering him Best Director nominations.   The Birds (1963) and  Marnie (1964) were also financially successful and are highly regarded by film historians. \n\nThe \"Hitchcockian\" style includes the use of camera movement to mimic a person's gaze, thereby turning viewers into voyeurs, and framing shots to maximise anxiety and fear. The film critic Robin Wood wrote that the meaning of a Hitchcock film \"is there in the method, in the progression from shot to shot. A Hitchcock film is an organism, with the whole implied in every detail and every detail related to the whole.\"  Hitchcock made multiple films with some of the biggest stars in Hollywood, including four with Cary Grant in the 1940s and 1950s, three with Ingrid Bergman in the last half of the 1940s, four with James Stewart over a ten-year span commencing in 1948, and three with Grace Kelly in the mid-1950s. Hitchcock became an American citizen in 1955.\n\nIn 2012, Hitchcock's psychological thriller Vertigo, starring Stewart, displaced Orson Welles' Citizen Kane (1941) as the British Film Institute's greatest film ever made based on its world-wide poll of hundreds of film critics., nine of his films had been selected for preservation in the United States National Film Registry,  including his personal favourite, Shadow of a Doubt (1943). He received the BAFTA Fellowship in 1971, the AFI Life Achievement Award in 1979 and was knighted in December that year, four months before his death on 29 April 1980.\n\nBiography\n\nEarly life: 1899\u20131919\n\nEarly childhood and education\n\nHitchcock was born on 13 August 1899 in the flat above his parents' leased grocer's shop at 517 High Road, Leytonstone, on the outskirts of East London (then part of Essex), the youngest of three children: William Daniel (1890\u20131943), Ellen Kathleen (\"Nellie\") (1892\u20131979), and Alfred Joseph (1899\u20131980). His parents, Emma Jane Hitchcock ( Whelan; 1863\u20131942), and William Edgar Hitchcock (1862\u20131914), were both Roman Catholics, with partial roots in Ireland; His father was a greengrocer, as his grandfather had been.\n\nThere was a large extended family, including uncle John Hitchcock with his five-bedroom Victorian house on Campion Road, Putney, complete with maid, cook, chauffeur and gardener. Every summer, his uncle rented a seaside house for the family in Cliftonville, Kent. Hitchcock said that he first became class-conscious there, noticing the differences between tourists and locals.\n\nDescribing himself as a well-behaved boy\u2014his father called him his \"little lamb without a spot\"\u2014Hitchcock said he could not remember ever having had a playmate. One of his favourite stories for interviewers was about his father sending him to the local police station with a note when he was five; the policeman looked at the note and locked him in a cell for a few minutes, saying, \"This is what we do to naughty boys.\" The experience left him, he said, with a lifelong fear of policemen; in 1973 he told Tom Snyder that he was \"scared stiff of anything\u00a0... to do with the law\" and wouldn't even drive a car in case he got a parking ticket.\n\nWhen he was six, the family moved to Limehouse and leased two stores at 130 and 175 Salmon Lane, which they ran as a fish-and-chips shop and fishmongers' respectively; they lived above the former. Hitchcock attended his first school, the Howrah House Convent in Poplar, which he entered in 1907, at age 7. According to biographer Patrick McGilligan, he stayed at Howrah House for at most two years. He also attended a convent school, the Wode Street School \"for the daughters of gentlemen and little boys\", run by the Faithful Companions of Jesus. He then attended a primary school near his home and was for a short time a boarder at Salesian College in Battersea.\n\nThe family moved again when he was 11, this time to Stepney, and on 5 October 1910 Hitchcock was sent to St Ignatius College in Stamford Hill, Tottenham (now in the London Borough of Haringey), a Jesuit grammar school with a reputation for discipline. The priests used a hard rubber cane on the boys, always at the end of the day, so the boys had to sit through classes anticipating the punishment if they had been written up for it. He later said that this is where he developed his sense of fear. The school register lists his year of birth as 1900 rather than 1899; biographer Donald Spoto says he was deliberately enrolled as a 10-year-old because he was a year behind with his schooling.\n\nWhile biographer Gene Adair reports that Hitchcock was \"an average, or slightly above-average, pupil\", Hitchcock said that he was \"usually among the four or five at the top of the class\"; at the end of his first year, his work in Latin, English, French and religious education was noted.  He told Peter Bogdanovich: \"The Jesuits taught me organisation, control and, to some degree, analysis.\"\n\nHis favourite subject was geography, and he became interested in maps, and railway, tram and bus timetables; according to John Russell Taylor, he could recite all the stops on the Orient Express. He also had a particular interest in London trams. An overwhelming majority of his films include rail or tram scenes, in particular The Lady Vanishes, Strangers on a Train and Number Seventeen. A clapperboard shows the number of the scene and the number of takes, and Hitchcock would often take the two numbers on the clapperboard and whisper the London tram route names. For example, if the clapperboard showed Scene 23; Take 3; Hitchcock would whisper \"Woodford, Hampstead\" \u2013 Woodford being the terminus of the route 23 tram, and Hampstead the end of route 3.\n\nHenley's\nHitchcock told his parents that he wanted to be an engineer, and on 25 July 1913, he left St Ignatius and enrolled in night classes at the London County Council School of Engineering and Navigation in Poplar. In a book-length interview in 1962, he told Fran\u00e7ois Truffaut that he had studied \"mechanics, electricity, acoustics, and navigation\". Then on 12 December 1914 his father, who had been suffering from emphysema and kidney disease, died at the age of 52. To support himself and his mother\u2014his older siblings had left home by then\u2014Hitchcock took a job, for 15 shillings a week (\u00a3 in ), as a technical clerk at the Henley Telegraph and Cable Company in Blomfield Street near London Wall. He continued night classes, this time in art history, painting, economics, and political science. His older brother ran the family shops, while he and his mother continued to live in Salmon Lane.\n\nHitchcock was too young to enlist when the First World War started in July 1914, and when he reached the required age of 18 in 1917, he received a C3 classification (\"free from serious organic disease, able to stand service conditions in garrisons at home\u00a0... only suitable for sedentary work\"). He joined a cadet regiment of the Royal Engineers and took part in theoretical briefings, weekend drills, and exercises. John Russell Taylor wrote that, in one session of practical exercises in Hyde Park, Hitchcock was required to wear puttees. He could never master wrapping them around his legs, and they repeatedly fell down around his ankles.\n\nAfter the war, Hitchcock took an interest in creative writing. In June 1919, he became a founding editor and business manager of Henley's in-house publication, The Henley Telegraph (sixpence a copy), to which he submitted several short stories. Henley's promoted him to the advertising department, where he wrote copy and drew graphics for electric cable advertisements. He enjoyed the job and would stay late at the office to examine the proofs; he told Truffaut that this was his \"first step toward cinema\". He enjoyed watching films, especially American cinema, and from the age of 16 read the trade papers; he watched Charlie Chaplin, D. W. Griffith and Buster Keaton, and particularly liked Fritz Lang's Der m\u00fcde Tod (1921).\n\nInter-war career: 1919\u20131939\n\nFamous Players-Lasky\n\nWhile still at Henley's, he read in a trade paper that Famous Players-Lasky, the production arm of Paramount Pictures, was opening a studio in London. They were planning to film The Sorrows of Satan by Marie Corelli, so he produced some drawings for the title cards and sent his work to the studio. They hired him, and in 1919 he began working for Islington Studios in Poole Street, Hoxton, as a title-card designer.\n\nDonald Spoto wrote that most of the staff were Americans with strict job specifications, but the English workers were encouraged to try their hand at anything, which meant that Hitchcock gained experience as a co-writer, art director and production manager on at least 18 silent films. The Times wrote in February 1922 about the studio's \"special art title department under the supervision of Mr. A. J. Hitchcock\". His work included Number 13 (1922), also known as Mrs. Peabody; it was cancelled because of financial problems\u2014the few finished scenes are lost\u2014and Always Tell Your Wife (1923), which he and Seymour Hicks finished together when Hicks was about to give up on it. Hicks wrote later about being helped by \"a fat youth who was in charge of the property room\u00a0... [n]one other than Alfred Hitchcock\".\n\nGainsborough Pictures and work in Germany\n\nWhen Paramount pulled out of London in 1922, Hitchcock was hired as an assistant director by a new firm run in the same location by Michael Balcon, later known as Gainsborough Pictures. Hitchcock worked on Woman to Woman (1923) with the director Graham Cutts, designing the set, writing the script and producing. He said: \"It was the first film that I had really got my hands onto.\" The editor and \"script girl\" on Woman to Woman was Alma Reville, his future wife. He also worked as an assistant to Cutts on The White Shadow (1924), The Passionate Adventure (1924), The Blackguard (1925), and The Prude's Fall (1925). The Blackguard was produced at the Babelsberg Studios in Potsdam, where Hitchcock watched part of the making of F. W. Murnau's film The Last Laugh (1924). He was impressed with Murnau's work and later used many of his techniques for the set design in his own productions.\n\nIn the summer of 1925, Balcon asked Hitchcock to direct The Pleasure Garden (1925), starring Virginia Valli, a co-production of Gainsborough and the German firm Emelka at the Geiselgasteig studio near Munich. Reville, by then Hitchcock's fianc\u00e9e, was assistant director-editor. Although the film was a commercial flop, Balcon liked Hitchcock's work; a Daily Express headline called him the \"Young man with a master mind\". Production of The Pleasure Garden encountered obstacles which Hitchcock would later learn from: on arrival to Brenner Pass, he failed to declare his film stock to customs and it was confiscated; one actress could not enter the water for a scene because she was on her period; budget overruns meant that he had to borrow money from the actors. Hitchcock also needed a translator to give instructions to the cast and crew.\n\nIn Germany, Hitchcock observed the nuances of German cinema and filmmaking which had a big influence on him. When he was not working, he would visit Berlin's art galleries, concerts and museums. He would also meet with actors, writers, and producers to build connections. Balcon asked him to direct a second film in Munich, The Mountain Eagle (1926), based on an original story titled Fear o' God. The film is lost, and Hitchcock called it \"a very bad movie\". A year later, Hitchcock wrote and directed The Ring; although the screenplay was credited solely to his name, Elliot Stannard assisted him with the writing. The Ring garnered positive reviews; the Bioscope magazine critic called it \"the most magnificent British film ever made\".\n\nWhen he returned to England, Hitchcock was one of the early members of the London Film Society, newly formed in 1925. Through the Society, he became fascinated by the work by Soviet filmmakers: Dziga Vertov, Lev Kuleshov, Sergei Eisenstein, and Vsevolod Pudovkin. He would also socialise with fellow English filmmakers Ivor Montagu and Adrian Brunel, and Walter C. Mycroft.\n\nHitchcock's luck came with his first thriller, The Lodger: A Story of the London Fog (1927), about the hunt for a serial killer, wearing a black cloak and carrying a black bag, is murdering young blonde women in London, and only on Tuesdays. A landlady suspects that her lodger is the killer, but he turns out to be innocent. To convey the impression footsteps were being heard from an upper floor, Hitchcock had a glass floor made so that the viewer could see the lodger pacing up and down in his room above the landlady. Hitchcock had wanted the leading man to be guilty, or for the film at least to end ambiguously, but the star was Ivor Novello, a matin\u00e9e idol, and the \"star system\" meant that Novello could not be the villain. Hitchcock told Truffaut: \"You have to clearly spell it out in big letters: 'He is innocent.'\" (He had the same problem years later with Cary Grant in Suspicion (1941).) Released in January 1927, The Lodger was a commercial and critical success in the UK. Hitchcock told Truffaut that the film was the first of his to be influenced by German Expressionism: \"In truth, you might almost say that The Lodger was my first picture.\" He made his first cameo appearances in the film; he was depicted sitting in a newsroom, and in the second, standing in a crowd as the leading man is arrested.\n\nMarriage\n\nOn 2 December 1926, Hitchcock married the English screenwriter Alma Reville at the Brompton Oratory in South Kensington. The couple honeymooned in Paris, Lake Como and St. Moritz, before returning to London to live in a leased flat on the top two floors of 153 Cromwell Road, Kensington. Reville, who was born just hours after Hitchcock, converted from Protestantism to Catholicism, apparently at the insistence of Hitchcock's mother; she was baptised on 31 May 1927 and confirmed at Westminster Cathedral by Cardinal Francis Bourne on 5 June.\n\nIn 1928, when they learned that Reville was pregnant, the Hitchcocks purchased \"Winter's Grace\", a Tudor farmhouse set in 11 acres on Stroud Lane, Shamley Green, Surrey, for \u00a32,500. Their daughter and only child, Patricia Alma Hitchcock, was born on 7 July that year. Patricia died on 9 August 2021 at 93.\n\nReville became her husband's closest collaborator; Charles Champlin wrote in 1982: \"The Hitchcock touch had four hands, and two were Alma's.\" When Hitchcock accepted the AFI Life Achievement Award in 1979, he said that he wanted to mention \"four people who have given me the most affection, appreciation and encouragement, and constant collaboration. The first of the four is a film editor, the second is a scriptwriter, the third is the mother of my daughter, Pat, and the fourth is as fine a cook as ever performed miracles in a domestic kitchen. And their names are Alma Reville.\" Reville wrote or co-wrote on many of Hitchcock's films, including Shadow of a Doubt, Suspicion and The 39 Steps.\n\nEarly sound films\n\nHitchcock began work on his tenth film, Blackmail (1929), when its production company, British International Pictures (BIP), converted its Elstree studios to sound. The film was the first British \"talkie\"; this followed the rapid development of sound films in the United States, from the use of brief sound segments in The Jazz Singer (1927) to the first full sound feature Lights of New York (1928). Blackmail began the Hitchcock tradition of using famous landmarks as a backdrop for suspense sequences, with the climax taking place on the dome of the British Museum. It also features one of his longest cameo appearances, which shows him being bothered by a small boy as he reads a book on the London Underground. In the PBS series The Men Who Made The Movies, Hitchcock explained how he used early sound recording as a special element of the film, stressing the word \"knife\" in a conversation with the woman suspected of murder. During this period, Hitchcock directed segments for a BIP revue, Elstree Calling (1930), and directed a short film, An Elastic Affair (1930), featuring two Film Weekly scholarship winners. An Elastic Affair is one of the lost films.\n\nIn 1933, Hitchcock signed a multi-film contract with Gaumont-British, once again working for Michael Balconmaking workshop at Vincennes\u2019 Old Dutch. His first film for the company, The Man Who Knew Too Much (1934), was a success; his second, The 39 Steps (1935), was acclaimed in the UK and gained him recognition in the United States. It also established the quintessential English \"Hitchcock blonde\" (Madeleine Carroll) as the template for his succession of ice-cold, elegant leading ladies. Screenwriter Robert Towne remarked, \"It's not much of an exaggeration to say that all contemporary escapist entertainment begins with The 39 Steps\". This film was one of the first to introduce the \"MacGuffin\" plot device, a term coined by the English screenwriter Angus MacPhail. The MacGuffin is an item or goal the protagonist is pursuing, one that otherwise has no narrative value; in The 39 Steps, the MacGuffin is a stolen set of design plans.\n\nHitchcock released two spy thrillers in 1936. Sabotage was loosely based on Joseph Conrad's novel, The Secret Agent (1907), about a woman who discovers that her husband is a terrorist, and Secret Agent, based on two stories in Ashenden: Or the British Agent (1928) by W. Somerset Maugham.\n\nAt this time, Hitchcock also became notorious for pranks against the cast and crew. These jokes ranged from simple and innocent to crazy and maniacal. For instance, he hosted a dinner party where he dyed all the food blue because he claimed there weren't enough blue foods. He also had a horse delivered to the dressing room of his friend, actor Gerald du Maurier. \n\nHitchcock followed up with Young and Innocent in 1937, a crime thriller based on the 1936 novel A Shilling for Candles by Josephine Tey. Starring Nova Pilbeam and Derrick De Marney, the film was relatively enjoyable for the cast and crew to make. To meet distribution purposes in America, the film's runtime was cut and this included removal of one of Hitchcock's favourite scenes: a children's tea party which becomes menacing to the protagonists.\n\nHitchcock's next major success was The Lady Vanishes (1938), \"one of the greatest train movies from the genre's golden era\", according to Philip French, in which Miss Froy (May Whitty), a British spy posing as a governess, disappears on a train journey through the fictional European country of Bandrika. The film saw Hitchcock receive the 1938 New York Film Critics Circle Award for Best Director. Benjamin Crisler of the New York Times wrote in June 1938: \"Three unique and valuable institutions the British have that we in America have not: Magna Carta, the Tower Bridge and Alfred Hitchcock, the greatest director of screen melodramas in the world.\" The film was based on the novel The Wheel Spins (1936) written by Ethel Lina White.\n\nBy 1938 Hitchcock was aware that he had reached his peak in Britain. He had received numerous offers from producers in the United States, but he turned them all down because he disliked the contractual obligations or thought the projects were repellent. However, producer David O. Selznick offered him a concrete proposal to make a film based on the sinking of, which was eventually shelved, but Selznick persuaded Hitchcock to come to Hollywood. In July 1938, Hitchcock flew to New York, and found that he was already a celebrity; he was featured in magazines and gave interviews to radio stations. In Hollywood, Hitchcock met Selznick for the first time. Selznick offered him a four-film contract, approximately $40,000 for each picture ().\n\nEarly Hollywood years: 1939\u20131945\n\nSelznick contract\nSelznick signed Hitchcock to a seven-year contract beginning in April 1939, and the Hitchcocks moved to Hollywood. The Hitchcocks lived in a spacious flat on Wilshire Boulevard, and slowly acclimatised themselves to the Los Angeles area. He and his wife Alma kept a low profile, and were not interested in attending parties or being celebrities. Hitchcock discovered his taste for fine food in West Hollywood, but still carried on his way of life from England. He was impressed with Hollywood's filmmaking culture, expansive budgets and efficiency, compared to the limits that he had often faced in Britain. In June that year, Life magazine called him the \"greatest master of melodrama in screen history\".\n\nAlthough Hitchcock and Selznick respected each other, their working arrangements were sometimes difficult. Selznick suffered from constant financial problems, and Hitchcock was often unhappy", "flag": 1, "segments": [[4061, 4071]], "strength": 5.5}
{"text": "Amsterdam (, , ) is the capital and most populous city of the Netherlands; with a population of 872,680 within the city proper, 1,558,755 in the urban area and 2,480,394 in the metropolitan area. Found within the Dutch province of North Holland, Amsterdam is colloquially referred to as the \"Venice of the North\", due to the large number of canals which form a UNESCO World Heritage Site.\n\nAmsterdam was founded at the Amstel, that was dammed to control flooding; the city's name derives from the Amstel dam. Originating as a small fishing village in the late 12th century, Amsterdam became one of the most important ports in the world during the Dutch Golden Age of the 17th century, and became the leading centre for the finance and trade sectors. In the 19th and 20th centuries, the city expanded and many new neighborhoods and suburbs were planned and built. The 17th-century canals of Amsterdam and the 19\u201320th century Defence Line of Amsterdam are on the UNESCO World Heritage List. Sloten, annexed in 1921 by the municipality of Amsterdam, is the oldest part of the city, dating to the 9th century.\n\nAmsterdam's main attractions include its historic canals, the Rijksmuseum, the Van Gogh Museum, the Stedelijk Museum, Hermitage Amsterdam, the Concertgebouw, the Anne Frank House, the Scheepvaartmuseum, the Amsterdam Museum, the Heineken Experience, the Royal Palace of Amsterdam, Natura Artis Magistra, Hortus Botanicus Amsterdam, NEMO, the red-light district and many cannabis coffee shops. It drew more than 5\u00a0million international visitors in 2014. The city is also well known for its nightlife and festival activity; with several of its nightclubs (Melkweg, Paradiso) among the world's most famous. Primarily known for its artistic heritage, elaborate canal system and narrow houses with gabled fa\u00e7ades; well-preserved legacies of the city's 17th-century Golden Age. These characteristics are arguably responsible for attracting millions of Amsterdam's visitors annually. Cycling is key to the city's character, and there are numerous biking paths and lanes spread throughout the entire city.\n\nThe Amsterdam Stock Exchange is considered the oldest \"modern\" securities market stock exchange in the world. As the commercial capital of the Netherlands and one of the top financial centres in Europe, Amsterdam is considered an alpha world city by the Globalization and World Cities (GaWC) study group. The city is also the cultural capital of the Netherlands. Many large Dutch institutions have their headquarters in the city, including: the Philips conglomerate, AkzoNobel, Booking.com, TomTom, and ING. Moreover, many of the world's largest companies are based in Amsterdam or have established their European headquarters in the city, such as leading technology companies Uber, Netflix and Tesla. In 2012, Amsterdam was ranked the second-best city to live in by the Economist Intelligence Unit (EIU) and 12th globally on quality of living for environment and infrastructure by Mercer. The city was ranked 4th place globally as top tech hub in the Savills Tech Cities 2019 report (2nd in Europe), and 3rd in innovation by Australian innovation agency 2thinknow in their Innovation Cities Index 2009. The Port of Amsterdam is the fifth largest in Europe. The KLM hub and Amsterdam's main airport, Schiphol, is the Netherlands' busiest airport as well as the third busiest in Europe and 11th busiest airport in the world. The Dutch capital is considered one of the most multicultural cities in the world, with at least 177 nationalities represented.\n\nA few of Amsterdam's notable residents throughout history include: painters Rembrandt and Van Gogh, the diarist Anne Frank, and philosopher Baruch Spinoza.\n\nHistory\n\nPrehistory\nDue to its geographical location in what used to be wet peatland, the founding of Amsterdam is of Guardian's Kate Giddings writes: \"When a younger age than the founding of other urban centers in the Low Countries. However, in and around the area of what later became Amsterdam, local farmers settled as early as three millennia ago. They lived along the prehistoric IJ river and upstream of its tributary Amstel. The prehistoric IJ was a shallow and quiet stream in peatland behind beach ridges. This secluded area could grow there into an important local settlement center, especially in the late Bronze Age, the Iron Age and the Roman Age. Neolithic and Roman artefacts have also been found downstream of this area, in the prehistoric Amstel bedding under Amsterdam's Damrak and Rokin, such as shards of Bell Beaker culture pottery (2200-2000 BC) and a granite grinding stone (2700-2750 BC). But the location of these artefacts around the river banks of the Amstel probably point to a presence of a modest semi-permanent or seasonal settlement of the previous mentioned local farmers. A permanent settlement would not have been possible, since the river mouth and the banks of the Amstel in this period in time were too wet for permanent habitation.\n\nEtymology and founding\n\nThe origins of Amsterdam is linked to the development of the peatland called Amestelle, meaning 'watery area', from Aa(m) 'river' + stelle'site at a shoreline', 'river bank'. In this area, land reclamation started as early as the late 10th century. Amestelle was located along a side arm of the IJ. This side arm took the name from the eponymous land: Amstel. Amestelle was inhabited by farmers, who lived more inland and more upstream, where the land was not as wet as at the banks of the downstream river mouth. These farmers were starting the reclamation around upstream Ouderkerk aan de Amstel, and later at the other side of the river at Amstelveen. The Van Amstel family, known in documents by this name since 1019, held the stewardship in this northwestern nook of the ecclesiastical district of the bishop of Utrecht. The family later served also under the count of Holland.\n\nA major turning point in the development of the Amstel river mouth is the All Saint's Flood of 1170. In an extremely short period of time, the shallow river IJ turned into a wide estuary, which from then on offered the Amstel an open connection to the Zuiderzee, IJssel and waterways further afield. This made the water flow of the Amstel more active, so excess water could be drained better. With drier banks, the downstream Amstel mouth became attractive for permanent habitation. Moreover, the river had grown from an insignificant peat stream into a junction of international waterways. A settlement was built here immediately after the landscape change of 1170, and right from the start of its foundation it focused on traffic, production and trade; not on farming, as opposed to how communities had lived further upstream for the past 200 years and northward for thousands of years. The construction of a dam at the mouth of the Amstel, eponymously named Dam, is historically estimated to have occurred between 1264 and 1275. The settlement first appeared in a document concerning a road toll granted by the count of Holland Floris V to the residents apud Amestelledamme 'at the dam in the Amstel' or 'at the dam of Amstelland'. This allowed the inhabitants of the village to travel freely through the County of Holland, paying no tolls at bridges, locks and dams. By 1327, the name had developed into Aemsterdam.\n\nMiddle Ages\nAmsterdam was granted city rights in either 1300 or 1306. From the 14th century on, Amsterdam flourished, largely from trade with the Hanseatic League. In 1345, an alleged Eucharistic miracle in Kalverstraat rendered the city an important place of pilgrimage until the adoption of the Protestant faith. The Miracle devotion went underground but was kept alive. In the 19th century, especially after the jubilee of 1845, the devotion was revitalised and became an important national point of reference for Dutch Catholics. The Stille Omgang\u2014a silent walk or procession in civil attire\u2014is the expression of the pilgrimage within the Protestant Netherlands since the late 19th century. In the heyday of the Silent Walk, up to 90,000 pilgrims came to Amsterdam. In the 21st century, this has reduced to about 5,000.\n\nConflict with Spain\n\nIn the 16th century, the Dutch rebelled against Philip II of Spain and his successors. The main reasons for the uprising were the imposition of new taxes, the tenth penny, and the religious persecution of Protestants by the newly introduced Inquisition. The revolt escalated into the Eighty Years' War, which ultimately led to Dutch independence. Strongly pushed by Dutch Revolt leader William the Silent, the Dutch Republic became known for its relative religious tolerance. Jews from the Iberian Peninsula, Huguenots from France, prosperous merchants and printers from Flanders, and economic and religious refugees from the Spanish-controlled parts of the Low Countries found safety in Amsterdam. The influx of Flemish printers and the city's intellectual tolerance made Amsterdam a centre for the European free press.\n\nCentre of the Dutch Golden Age \n\nThe 17th century is considered Amsterdam's Golden Age, during which it became the wealthiest city in the western world. Ships sailed from Amsterdam to the Baltic Sea, North America, and Africa, as well as present-day Indonesia, India, Sri Lanka, and Brazil, forming the basis of a worldwide trading network. Amsterdam's merchants had the largest share in both the Dutch East India Company and the Dutch West India Company. These companies acquired overseas possessions that later became Dutch colonies.\n\nAmsterdam was Europe's most important point for the shipment of goods and was the leading financial centre of the western world. In 1602, the Amsterdam office of the international trading Dutch East India Company became the world's first stock exchange by trading in its own shares. The Bank of Amsterdam started operations in 1609, acting as a full-service bank for Dutch merchant bankers and as a reserve bank.\n\nDecline and modernisation \nAmsterdam's prosperity declined during the 18th and early 19th centuries. The wars of the Dutch Republic with England and France took their toll on Amsterdam. During the Napoleonic Wars, Amsterdam's significance reached its lowest point, with Holland being absorbed into the French Empire. However, the later establishment of the United Kingdom of the Netherlands in 1815 marked a turning point.\n\nThe end of the 19th century is sometimes called Amsterdam's second Golden Age. New museums, a railway station, and the Concertgebouw were built; in this same time, the Industrial Revolution reached the city. The Amsterdam\u2013Rhine Canal was dug to give Amsterdam a direct connection to the Rhine, and the North Sea Canal was dug to give the port a shorter connection to the North Sea. Both projects dramatically improved commerce with the rest of Europe and the world. In 1906, Joseph Conrad gave a brief description of Amsterdam as seen from the seaside, in The Mirror of the Sea.\n\n20th century\u2013present\n\nShortly before the First World War, the city started to expand again, and new suburbs were built. Even though the Netherlands remained neutral in this war, Amsterdam suffered a food shortage, and heating fuel became scarce. The shortages sparked riots in which several people were killed. These riots are known as the Aardappeloproer (Potato rebellion). People started looting stores and warehouses in order to get supplies, mainly food.\n\nOn 1 January 1921, after a flood in 1916, the depleted municipalities of Durgerdam, Holysloot, Zunderdorp and Schellingwoude, all lying north of Amsterdam, were, at their own request, annexed to the city. Between the wars, the city continued to expand, most notably to the west of the Jordaan district in the Frederik Hendrikbuurt and surrounding neighbourhoods.\n\nNazi Germany invaded the Netherlands on 10 May 1940 and took control of the country. Some Amsterdam citizens sheltered Jews, thereby exposing themselves and their families to a high risk of being imprisoned or sent to concentration camps. More than 100,000 Dutch Jews were deported to Nazi concentration camps, of whom some 60,000 lived in Amsterdam. In response, the Dutch Communist Party organized the February strike attended by 300,000 people to protest against the raids. Perhaps the most famous deportee was the young Jewish girl Anne Frank, who died in the Bergen-Belsen concentration camp. At the end of the Second World War, communication with the rest of the country broke down, and food and fuel became scarce. Many citizens traveled to the countryside to forage. Dogs, cats, raw sugar beets, and tulip bulbs\u2014cooked to a pulp\u2014were consumed to stay alive. Many trees in Amsterdam were cut down for fuel, and wood was taken from the houses, apartments and other buildings of deported Jews.\n\nMany new suburbs, such as Osdorp, Slotervaart, Slotermeer and Geuzenveld, were built in the years after the Second World War.\nThese suburbs contained many public parks and wide-open spaces, and the new buildings provided improved housing conditions with larger and brighter rooms, gardens, and balconies. Because of the war and other events of the 20th century, almost the entire city centre had fallen into disrepair. As society was changing, politicians and other influential figures made plans to redesign large parts of it. There was an increasing demand for office buildings, and also for new roads, as the automobile became available to most people. A metro started operating in 1977 between the new suburb of Bijlmermeer in the city's Zuidoost (southeast) exclave and the centre of Amsterdam. Further plans were to build a new highway above the metro to connect Amsterdam Centraal and the city centre with other parts of the city.\n\nThe required large-scale demolitions began in Amsterdam's former Jewish neighborhood. Smaller streets, such as the Jodenbreestraat and Weesperstraat, were widened and almost all houses and buildings were demolished. At the peak of the demolition, the Nieuwmarktrellen (Nieuwmarkt Riots) broke out; the rioters expressed their fury about the demolition caused by the restructuring of the city.\n\nAs a result, the demolition was stopped and the highway into the city's centre was never fully built; only the metro was completed. Only a few streets remained widened. The new city hall was built on the almost completely demolished Waterlooplein. Meanwhile, large private organizations, such as Stadsherstel Amsterdam, were founded to restore the entire city centre. Although the success of this struggle is visible today, efforts for further restoration are still ongoing. The entire city centre has reattained its former splendour and, as a whole, is now a protected area. Many of its buildings have become monuments, and in July 2010 the Grachtengordel (the three concentric canals: Herengracht, Keizersgracht, and Prinsengracht) was added to the UNESCO World Heritage List.\n\nIn the 21st century, the Amsterdam city centre has attracted large numbers of tourists: between 2012 and 2015, the annual number of visitors rose from 10 to 17\u00a0million. Real estate prices have surged, and local shops are making way for tourist-oriented ones, making the centre unaffordable for the city's inhabitants. These developments have evoked comparisons with Venice, a city thought to be overwhelmed by the tourist influx.\n\nConstruction of a new metro line connecting the part of the city north of the IJ to its southern part was started in 2003. The project was controversial because its cost had exceeded its budget by a factor three by 2008, because of fears of damage to buildings in the centre, and because construction had to be halted and restarted multiple times. The new metro line was completed in 2018.\n\nSince 2014, renewed focus has been given to urban regeneration and renewal, especially in areas directly bordering the city centre, such as Frederik Hendrikbuurt. This urban renewal and expansion of the traditional centre of the city\u2014with the construction on artificial islands of the new eastern IJburg neighbourhood\u2014is part of the Structural Vision Amsterdam 2040 initiative.\n\nGeography\n\nAmsterdam is located in the Western Netherlands, in the province of North Holland, the capital of which is not Amsterdam, but rather Haarlem. The river Amstel ends in the city centre and connects to a large number of canals that eventually terminate in the IJ. Amsterdam is about  below sea level. The surrounding land is flat as it is formed of large polders. A man-made forest, Amsterdamse Bos, is in the southwest. Amsterdam is connected to the North Sea through the long North Sea Canal.\n\nAmsterdam is intensely urbanised, as is the Amsterdam metropolitan area surrounding the city. Comprising  of land, the city proper has 4,457 inhabitants per km2 and 2,275 houses per km2. Parks and nature reserves make up 12% of Amsterdam's land area.\n\nWater\nAmsterdam has more than  of canals, most of which are navigable by boat. The city's three main canals are the Prinsengracht, Herengracht and Keizersgracht.\n\nIn the Middle Ages, Amsterdam was surrounded by a moat, called the Singel, which now forms the innermost ring in the city, and gives the city centre a horseshoe shape. The city is also served by a seaport. It has been compared with Venice, due to its division into about 90 islands, which are linked by more than 1,200 bridges.\n\nClimate \n\nAmsterdam has an oceanic climate (K\u00f6ppen Cfb) strongly influenced by its proximity to the North Sea to the west, with prevailing westerly winds. \n\nAmsterdam, as well as most of the North Holland province, lies in USDA Hardiness zone 8b. Frosts mainly occur during spells of easterly or northeasterly winds from the inner European continent. Even then, because Amsterdam is surrounded on three sides by large bodies of water, as well as having a significant heat-island effect, nights rarely fall below, while it could easily be  in Hilversum,  southeast.\n\nSummers are moderately warm with a number of hot and humid days every month. The average daily high in August is, and  or higher is only measured on average on 2.5 days, placing Amsterdam in AHS Heat Zone 2. The record extremes range from  to. \nDays with more than  of precipitation are common, on average 133 days per year.\n\nAmsterdam's average annual precipitation is. A large part of this precipitation falls as light rain or brief showers. Cloudy and damp days are common during the cooler months of October through March.\n\nDemographics\n\nHistorical population\n\nIn 1300, Amsterdam's population was around 1,000 people. While many towns in Holland experienced population decline during the 15th and 16th centuries, Amsterdam's population grew, mainly due to the rise of the profitable Baltic maritime trade after the Burgundian victory in the Dutch\u2013Hanseatic War. Still, the population of Amsterdam was only modest compared to the towns and cities of Flanders and Brabant, which comprised the most urbanised area of the Low Countries.\n\nThis changed when, during the Dutch Revolt, many people from the Southern Netherlands fled to the North, especially after Antwerp fell to Spanish forces in 1585. Jewish people from Spain, Portugal and Eastern Europe similarly settled in Amsterdam, as did Germans and Scandinavians. In thirty years, Amsterdam's population more than doubled between 1585 and 1610. By 1600, its population was around 50,000. During the 1660s, Amsterdam's population reached 200,000. The city's growth levelled off and the population stabilised around 240,000 for most of the 18th century.\n\nIn 1750, Amsterdam was the fourth largest city in Western Europe, behind London (676,000), Paris (560,000) and Naples (324,000). This was all the more remarkable as Amsterdam was neither the capital city nor the seat of government of the Dutch Republic, which itself was a much smaller state than England, France or the Ottoman Empire. In contrast to those other metropolises, Amsterdam was also surrounded by large towns such as Leiden (about 67,000), Rotterdam (45,000), Haarlem (38,000) and Utrecht (30,000).\n\nThe city's population declined in the early 19th century, dipping under 200,000 in 1820. By the second half of the 19th century, industrialisation spurred renewed growth. Amsterdam's population hit an all-time high of 872,000 in 1959, before declining in the following decades due to government-sponsored suburbanisation to so-called groeikernen (growth centres) such as Purmerend and Almere. Between 1970 and 1980, Amsterdam experienced its sharp population decline, peaking at a net loss of 25,000 people in 1973. By 1985 the city had only 675,570 residents. This was soon followed by reurbanisation and gentrification, leading to renewed population growth in the 2010s. Also in the 2010s, much of Amsterdam's population growth was due to immigration to the city. Amsterdam's population failed to beat the expectations of 873,000 in 2019.\n\nImmigration\n\nIn the 16th and 17th century, non-Dutch immigrants to Amsterdam were mostly Huguenots, Flemings, Sephardi Jews and Westphalians. Huguenots came after the Edict of Fontainebleau in 1685, while the Flemish Protestants came during the Eighty Years' War. The Westphalians came to Amsterdam mostly for economic reasons \u2013 their influx continued through the 18th and 19th centuries. Before the Second World War, 10% of the city population was Jewish. Just twenty percent of them survived the Shoah.\n\nThe first mass immigration in the 20th century was by people from Indonesia, who came to Amsterdam after the independence of the Dutch East Indies in the 1940s and 1950s. In the 1960s guest workers from Turkey, Morocco, Italy, and Spain emigrated to Amsterdam. After the independence of Suriname in 1975, a large wave of Surinamese settled in Amsterdam, mostly in the Bijlmer area. Other immigrants, including refugees asylum seekers and illegal immigrants, came from Europe, America, Asia and Africa. In the 1970s and 1980s, many 'old' Amsterdammers moved to 'new' cities like Almere and Purmerend, prompted by the third planological bill of the Dutch Government. This bill promoted suburbanisation and arranged for new developments in so-called \"groeikernen\", literally cores of growth. Young professionals and artists moved into neighborhoods De Pijp and the Jordaan abandoned by these Amsterdammers. The non-Western immigrants settled mostly in the social housing projects in Amsterdam-West and the Bijlmer. Today, people of non-Western origin make up approximately one-fifth of the population of Amsterdam, and more than 30% of the city's children. Ethnic Dutch (as defined by the Dutch census) now make up a minority of the total population, although by far the largest one. Only one in three inhabitants under 15 is an autochthon, or a person who has two parents of Dutch origin. Segregation along ethnic lines is clearly visible, with people of non-Western origin, considered a separate group by Statistics Netherlands, concentrating in specific neighbourhoods especially in Nieuw-West", "flag": 1, "segments": [[835, 845]], "strength": 5.5}
{"text": "Audi AG () (commonly referred to as Audi) is a German automotive manufacturer of luxury vehicles headquartered in Ingolstadt, Bavaria, Germany. As a subsidiary of its parent company, the Volkswagen Group, Audi produces vehicles in nine production facilities worldwide.\n\nThe origins of the company are complex, going back to the early 20th century and the initial enterprises (Horch and the Audiwerke) founded by engineer August Horch; and two other manufacturers (DKW and Wanderer), leading to the foundation of Auto Union in 1932. The modern Audi era began in the 1960s, when Auto Union was acquired by Volkswagen from Daimler-Benz. After relaunching the Audi brand with the 1965 introduction of the Audi F103 series, Volkswagen merged Auto Union with NSU Motorenwerke in 1969, thus creating the present-day form of the company.\n\nThe company name is based on the Latin translation of the surname of the founder, August Horch., meaning \"listen\" in German, becomes  in Latin. The four rings of the Audi logo each represent one of four car companies that banded together to create Audi's predecessor company, Auto Union. Audi's slogan is, meaning \"Being Ahead through Technology\". Audi, along with fellow German marques BMW and Mercedes-Benz, is among the best-selling luxury automobile brands in the world.\n\nHistory\n\nBirth of the company and its name\nAutomobile company Wanderer was originally established in 1885, later becoming a branch of Audi AG. Another company, NSU, which also later merged into Audi, was founded during this time, and later supplied the chassis for Gottlieb Daimler's four-wheeler.\n\nOn 14 November 1899, August Horch (1868\u20131951) established the company A. Horch & Cie. in the Ehrenfeld district of Cologne. In 1902, he moved with his company to Reichenbach im Vogtland. On 10 May 1904, he founded the August Horch & Cie. Motorwagenwerke AG, a joint-stock company in Zwickau (State of Saxony).\n\nAfter troubles with Horch chief financial officer, August Horch left Motorwagenwerke and founded in Zwickau on 16 July 1909, his second company, the August Horch Automobilwerke GmbH. His former partners sued him for trademark infringement. The German Reichsgericht (Supreme Court) in Leipzig, eventually determined that the Horch brand belonged to his former company.\n\nSince August Horch was prohibited from using \"Horch\" as a trade name in his new car business, he called a meeting with close business friends, Paul and Franz Fikentscher from Zwickau. At the apartment of Franz Fikentscher, they discussed how to come up with a new name for the company. During this meeting, Franz's son was quietly studying Latin in a corner of the room. Several times he looked like he was on the verge of saying something but would just swallow his words and continue working, until he finally blurted out, \"Father\u00a0\u2013  audiatur et altera pars...\u00a0wouldn't it be a good idea to call it audi instead of horch?\" \"Horch!\" in German means \"Hark!\" or \"hear\", which is \"Audi\" in the singular imperative form of \"audire\" \u2013 \"to listen\" \u2013 in Latin. The idea was enthusiastically accepted by everyone attending the meeting. On 25 April 1910 the Audi Automobilwerke GmbH Zwickau (from 1915 on Audiwerke AG Zwickau) was entered in the company's register of Zwickau registration court.\n\nThe first Audi automobile, the Audi Type A 10/ Sport-Phaeton, was produced in the same year, followed by the successor Type B 10/28PS in the same year.\n\nAudi started with a 2,612\u00a0cc inline-four engine model Type A, followed by a 3,564\u00a0cc model, as well as 4,680\u00a0cc and 5,720\u00a0cc models. These cars were successful even in sporting events. The first six-cylinder model Type M, 4,655\u00a0cc appeared in 1924.\n\nAugust Horch left the Audiwerke in 1920 for a high position at the ministry of transport, but he was still involved with Audi as a member of the board of trustees. In September 1921, Audi became the first German car manufacturer to present a production car, the Audi Type K, with left-handed drive. Left-hand drive spread and established dominance during the 1920s because it provided a better view of oncoming traffic, making overtaking safer when driving on the right.\n\nThe merger of the four companies more palatable. Moving even less flammable under the logo of four rings\n\nIn August 1928, J\u00f8rgen Rasmussen, the owner of Dampf-Kraft-Wagen (DKW), acquired the majority of shares in Audiwerke AG. In the same year, Rasmussen bought the remains of the U.S. automobile manufacturer Rickenbacker, including the manufacturing equipment for 8-cylinder engines. These engines were used in Audi Zwickau and Audi Dresden models that were launched in 1929. At the same time, 6-cylinder and 4-cylinder (the \"four\" with a Peugeot engine) models were manufactured. Audi cars of that era were luxurious cars equipped with special bodywork.\n\nIn 1932, Audi merged with Horch, DKW, and Wanderer, to form Auto Union AG, Chemnitz. It was during this period that the company offered the Audi Front that became the first European car to combine a six-cylinder engine with front-wheel drive. It used a power train shared with the Wanderer, but turned 180 degrees, so that the drive shaft faced the front.\n\nBefore World War II, Auto Union used the four interlinked rings that make up the Audi badge today, representing these four brands. However, this badge was used only on Auto Union racing cars in that period while the member companies used their own names and emblems. The technological development became more and more concentrated and some Audi models were propelled by Horch- or Wanderer-built engines.\n\nReflecting the economic pressures of the time, Auto Union concentrated increasingly on smaller cars through the 1930s, so that by 1938 the company's DKW brand accounted for 17.9% of the German car market, while Audi held only 0.1%. After the final few Audis were delivered in 1939 the \"Audi\" name disappeared completely from the new car market for more than two decades.\n\nPost-World War II\n\nLike most German manufacturing, at the onset of World War II the Auto Union plants were retooled for military production, and were a target for allied bombing during the war which left them damaged.\n\nOverrun by the Soviet Army in 1945, on the orders of the Soviet Union military administration the factories were dismantled as part of war reparations. Following this, the company's entire assets were expropriated without compensation. On 17 August 1948, Auto Union AG of Chemnitz was deleted from the commercial register. These actions had the effect of liquidating Germany's Auto Union AG. The remains of the Audi plant of Zwickau became the VEB (for \"People Owned Enterprise\")  or AWZ (in English: Automobile Works Zwickau).\n\nWith no prospect of continuing production in Soviet-controlled East Germany, Auto Union executives began the process of relocating what was left of the company to West Germany. A site was chosen in Ingolstadt, Bavaria, to start a spare parts operation in late 1945, which would eventually serve as the headquarters of the reformed Auto Union in 1949.\n\nThe former Audi factory in Zwickau restarted assembly of the pre-war models in 1949. These DKW models were renamed to IFA F8 and IFA F9 and were similar to the West German versions. West and East German models were equipped with the traditional and renowned DKW two-stroke engines. The Zwickau plant manufactured the infamous Trabant until 1991, when it came under Volkswagen control\u2014effectively bringing it under the same umbrella as Audi since 1945.\n\nNew Auto Union unit\nA new West German headquartered Auto Union was launched in Ingolstadt with loans from the Bavarian state government and Marshall Plan aid. The reformed company was launched 3 September 1949 and continued DKW's tradition of producing front-wheel drive vehicles with two-stroke engines. This included production of a small but sturdy 125\u00a0cc motorcycle and a DKW delivery van, the DKW F89 L at Ingolstadt. The Ingolstadt site was large, consisting of an extensive complex of formerly military buildings which was suitable for administration as well as vehicle warehousing and distribution, but at this stage there was at Ingolstadt no dedicated plant suitable for mass production of automobiles: for manufacturing the company's first post-war mass-market passenger car plant capacity in D\u00fcsseldorf was rented from Rheinmetall-Borsig. It was only ten years later, after the company had attracted an investor, when funds became available for construction of major car plant at the Ingolstadt head office site.\n\nIn 1958, in response to pressure from Friedrich Flick, then the company's largest single shareholder, Daimler-Benz took an 87% holding in the Auto Union company, and this was increased to a 100% holding in 1959. However, small two-stroke cars were not the focus of Daimler-Benz's interests, and while the early 1960s saw major investment in new Mercedes models and in a state of the art factory for Auto Union's, the company's aging model range at this time did not benefit from the economic boom of the early 1960s to the same extent as competitor manufacturers such as Volkswagen and Opel. The decision to dispose of the Auto Union business was based on its lack of profitability.  Ironically, by the time they sold the business, it also included a large new factory and near production-ready modern four-stroke engine, which would enable the Auto Union business, under a new owner, to embark on a period of profitable growth, now producing not Auto Unions or DKWs, but using the \"Audi\" name, resurrected in 1965 after a 25-year gap.\n\nIn 1964, Volkswagen acquired a 50% holding in the business, which included the new factory in Ingolstadt, the DKW and Audi brands along with the rights to the new engine design which had been funded by Daimler-Benz, who in return retained the dormant Horch trademark and the D\u00fcsseldorf factory which became a Mercedes-Benz van assembly plant. Eighteen months later, Volkswagen bought complete control of Ingolstadt, and by 1966 were using the spare capacity of the Ingolstadt plant to assemble an additional 60,000 Volkswagen Beetles per year.  Two-stroke engines became less popular during the 1960s as customers were more attracted to the smoother four-stroke engines. In September 1965, the DKW F102 was fitted with a four-stroke engine and a facelift for the car's front and rear. Volkswagen dumped the DKW brand because of its associations with two-stroke technology, and having classified the model internally as the F103, sold it simply as the \"Audi\". Later developments of the model were named after their horsepower ratings and sold as the Audi 60, 75, 80, and Super 90, selling until 1972. Initially, Volkswagen was hostile to the idea of Auto Union as a standalone entity producing its own models having acquired the company merely to boost its own production capacity through the Ingolstadt assembly plant \u2013 to the point where Volkswagen executives ordered that the Auto Union name and flags bearing the four rings were removed from the factory buildings. Then VW chief Heinz Nordhoff explicitly forbade Auto Union from any further product development. Fearing that Volkswagen had no long-term ambition for the Audi brand, Auto Union engineers under the leadership of Ludwig Kraus developed the first Audi 100 in secret, without Nordhoff's knowledge. When presented with a finished prototype, Nordhoff was so impressed he authorised the car for production, which when launched in 1968, went on to be a huge success. With this, the resurrection of the Audi brand was now complete, this being followed by the first generation Audi 80 in 1972, which would in turn provide a template for VW's new front-wheel-drive water-cooled range which debuted from the mid-1970s onward.\n\nIn 1969, Auto Union merged with NSU, based in Neckarsulm, near Stuttgart. In the 1950s, NSU had been the world's largest manufacturer of motorcycles, but had moved on to produce small cars like the NSU Prinz, the TT and TTS versions of which are still popular as vintage race cars. NSU then focused on new rotary engines based on the ideas of Felix Wankel. In 1967, the new NSU Ro 80 was a car well ahead of its time in technical details such as aerodynamics, light weight, and safety. However, teething problems with the rotary engines put an end to the independence of NSU. The Neckarsulm plant is now used to produce the larger Audi models A6 and A8. The Neckarsulm factory is also home of the \"quattro GmbH\" (from November 2016 \"Audi Sport GmbH\"), a subsidiary responsible for development and production of Audi high-performance models: the R8 and the RS model range.\n\nModern era\n\nThe new merged company was incorporated on 1 January 1969 and was known as Audi NSU Auto Union AG, with its headquarters at NSU's Neckarsulm plant, and saw the emergence of Audi as a separate brand for the first time since the pre-war era. Volkswagen introduced the Audi brand to the United States for the 1970 model year.  That same year, the mid-sized car that NSU had been working on, the K70, originally intended to slot between the rear-engined Prinz models and the futuristic NSU Ro 80, was instead launched as a Volkswagen.\n\nAfter the launch of the Audi 100 of 1968, the Audi 80/Fox (which formed the basis for the 1973 Volkswagen Passat) followed in 1972 and the Audi 50 (later rebadged as the Volkswagen Polo) in 1974. The Audi 50 was a seminal design because it was the first incarnation of the Golf/Polo concept, one that led to a hugely successful world car. Ultimately, the Audi 80 and 100 (progenitors of the A4 and A6, respectively) became the company's biggest sellers, whilst little investment was made in the fading NSU range; the Prinz models were dropped in 1973 whilst the fatally flawed NSU Ro80 went out of production in 1977, spelling the effective end of the NSU brand. Production of the Audi 100 had been steadily moved from Ingolstadt to Neckarsulm as the 1970s had progressed, and by the appearance of the second generation C2 version in 1976, all production was now at the former NSU plant. Neckarsulm from that point onward would produce Audi's higher-end models.\n\nThe Audi image at this time was a conservative one, and so, a proposal from chassis engineer J\u00f6rg Bensinger was accepted to develop the four-wheel drive technology in Volkswagen's Iltis military vehicle for an Audi performance car and rally racing car. The performance car, introduced in 1980, was named the \"Audi Quattro\", a turbocharged coup\u00e9 which was also the first German large-scale production vehicle to feature permanent all-wheel drive through a centre differential. Commonly referred to as the \"Ur-Quattro\" (the \"Ur-\" prefix is a German augmentative used, in this case, to mean \"original\" and is also applied to the first generation of Audi's S4 and S6 Sport Saloons, as in \"UrS4\" and \"UrS6\"), few of these vehicles were produced (all hand-built by a single team), but the model was a great success in rallying. Prominent wins proved the viability of all-wheel-drive racecars, and the Audi name became associated with advances in automotive technology.\n\nIn 1985, with the Auto Union and NSU brands effectively dead, the company's official name was now shortened to simply Audi AG. At the same time the company's headquarters moved back to Ingolstadt and two new wholly owned subsidiaries; Auto Union GmbH and NSU GmbH, were formed to own and manage the historical trademarks and intellectual property of the original constituent companies (the exception being Horch, which had been retained by Daimler-Benz after the VW takeover), and to operate Audi's heritage operations.\n\nIn 1986, as the Passat-based Audi 80 was beginning to develop a kind of \"grandfather's car\" image, the type 89 was introduced. This completely new development sold extremely well. However, its modern and dynamic exterior belied the low performance of its base engine, and its base package was quite spartan (even the passenger-side mirror was an option.) In 1987, Audi put forward a new and very elegant Audi 90, which had a much superior set of standard features. In the early 1990s, sales began to slump for the Audi 80 series, and some basic construction problems started to surface.\n\nIn the early part of the 21st century, Audi set forth on a German racetrack to claim and maintain several world records, such as top speed endurance. This effort was in-line with the company's heritage from the 1930s racing era Silver Arrows.\n\nThrough the early 1990s, Audi began to shift its target market upscale to compete against German automakers Mercedes-Benz and BMW. This began with the release of the Audi V8 in 1990. It was essentially a new engine fitted to the Audi 100/200, but with noticeable bodywork differences. Most obvious was the new grille that was now incorporated in the bonnet.\n\nBy 1991, Audi had the four-cylinder Audi 80, the 5-cylinder Audi 90 and Audi 100, the turbocharged Audi 200 and the Audi V8. There was also a coup\u00e9 version of the 80/90 with both four- and five-cylinder engines.\n\nAlthough the five-cylinder engine was a successful and robust powerplant, it was still a little too different for the target market. With the introduction of an all-new Audi 100 in 1992, Audi introduced a 2.8L V6 engine. This engine was also fitted to a face-lifted Audi 80 (all 80 and 90 models were now badged 80 except for the USA), giving this model a choice of four-, five-, and six-cylinder engines, in saloon, coup\u00e9 and convertible body styles.\n\nThe five-cylinder was soon dropped as a major engine choice; however, a turbocharged  version remained. The engine, initially fitted to the 200 quattro 20V of 1991, was a derivative of the engine fitted to the Sport Quattro. It was fitted to the Audi Coup\u00e9, named the S2, and also to the Audi 100 body, and named the S4. These two models were the beginning of the mass-produced S series of performance cars.\n\nAudi 5000 unintended acceleration allegations\nSales in the United States fell after a series of recalls from 1982 to 1987 of Audi 5000 models associated with reported incidents of sudden unintended acceleration linked to six deaths and 700 accidents.  At the time, NHTSA was investigating 50 car models from 20 manufacturers for sudden surges of power.\n\nA 60 Minutes report aired 23 November 1986, featuring interviews with six people who had sued Audi after reporting unintended acceleration, showing an Audi 5000 ostensibly suffering a problem when the brake pedal was pushed. Subsequent investigation revealed that 60 Minutes had engineered the failure \u2013 fitting a canister of compressed air on the passenger-side floor, linked via a hose to a hole drilled into the transmission.\n\nAudi contended, prior to findings by outside investigators, that the problems were caused by driver error, specifically pedal misapplication.  Subsequently, the National Highway Traffic Safety Administration (NHTSA) concluded that the majority of unintended acceleration cases, including all the ones that prompted the 60 Minutes report, were caused by driver error such as confusion of pedals.  CBS did not acknowledge the test results of involved government agencies, but did acknowledge the similar results of another study.\n\nIn a review study published in 2012, NHTSA summarized its past findings about the Audi unintended acceleration problems: \"Once an unintended acceleration had begun, in the Audi 5000, due to a failure in the idle-stabilizer system (producing an initial acceleration of 0.3g), pedal misapplication resulting from panic, confusion, or unfamiliarity with the Audi 5000 contributed to the severity of the incident.\"\n\nThis summary is consistent with the conclusions of NHTSA's most technical analysis at the time: \"Audi idle-stabilization systems were prone to defects which resulted in excessive idle speeds and brief unanticipated accelerations of up to 0.3g [which is similar in magnitude to an emergency stop in a subway car]. These accelerations could not be the sole cause of [(long-duration) sudden acceleration incidents (SAI)], but might have triggered some SAIs by startling the driver.  The defective idle-stabilization system performed a type of electronic throttle control. Significantly: multiple \"intermittent malfunctions of the electronic control unit were observed and recorded... and [were also observed and] reported by Transport Canada.\"\n\nWith a series of recall campaigns, Audi made several modifications; the first adjusted the distance between the brake and accelerator pedal on automatic-transmission models. Later repairs, of 250,000 cars dating back to 1978, added a device requiring the driver to press the brake pedal before shifting out of park.  A legacy of the Audi 5000 and other reported cases of sudden unintended acceleration are intricate gear stick patterns and brake interlock mechanisms to prevent inadvertent shifting into forward or reverse. It is unclear how the defects in the idle-stabilization system were addressed.\n\nAudi's U.S. sales, which had reached 74,061 in 1985, dropped to 12,283 in 1991 and remained level for three years, \u2013 with resale values falling dramatically.  Audi subsequently offered increased warranty protection and renamed the affected models \u2013 with the 5000 becoming the 100 and 200 in 1989 \u2013 and reached the same sales levels again only by model year 2000.\n\nA 2010 BusinessWeek article \u2013 outlining possible parallels between Audi's experience and 2009\u20132010 Toyota vehicle recalls \u2013 noted a class-action lawsuit filed in 1987 by about 7,500 Audi 5000-model owners remains unsettled and remains contested in Chicago's Cook County after appeals at the Illinois state and U.S. federal levels.\n\nModel introductions\nIn the mid-to-late 1990s, Audi introduced new technologies including the use of aluminium construction. Produced from 1999 to 2005, the Audi A2 was a futuristic super mini, born from the Al2 concept, with many features that helped regain consumer confidence, like the aluminium space frame, which was a first in production car design. In the A2 Audi further expanded their TDI technology through the use of frugal three-cylinder engines. The A2 was extremely aerodynamic and was designed around a wind tunnel. The Audi A2 was criticised for its high price and was never really a sales success but it planted Audi as a cutting-edge manufacturer. The model, a Mercedes-Benz A-Class competitor, sold relatively well in Europe. However, the A2 was discontinued in 2005 and Audi decided not to develop an immediate replacement.\n\nThe next major model change came in 1995 when the Audi A4 replaced the Audi 80. The new nomenclature scheme was applied to the Audi 100 to become the Audi A6 (with a minor facelift). This also meant the S4 became the S", "flag": 1, "segments": [[991, 1001]], "strength": 5.5}
{"text": "Alexander Graham Bell (, born Alexander Bell; March 3, 1847 \u2013 August 2, 1922) was a  Scottish-born inventor, scientist, and engineer who is credited with patenting the first practical telephone. He also co-founded the American Telephone and Telegraph Company (AT&T) in 1885.\n\nBell's father, grandfather, and brother had all been associated with work on elocution and speech and both his mother and wife were deaf; profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices which eventually culminated in Bell being awarded the first U.S. patent for the telephone, on March 7, 1876. Bell considered his invention an intrusion on his real work as a scientist and refused to have a telephone in his study.\n\nMany other inventions marked Bell's later life, including groundbreaking work in optical telecommunications, hydrofoils, and aeronautics. Although Bell was not one of the 33 founders of the National Geographic Society, he had a strong influence on the magazine while serving as the second president from January 7, 1898, until 1903.\n\nBeyond his work in engineering, Bell had a deep interest in the emerging science of heredity.\n\nEarly life\nAlexander Bell was born in Edinburgh, Scotland, on March 3, 1847. The family home was at South Charlotte Street, and has a stone inscription marking it as Alexander Graham Bell's birthplace. He had two brothers: Melville James Bell (1845\u20131870) and Edward Charles Bell (1848\u20131867), both of whom would die of tuberculosis. His father was Professor Alexander Melville Bell, a phonetician, and his mother was Eliza Grace Bell (n\u00e9e Symonds). Born as just \"Alexander Bell\", at age 10, he made a plea to his father to have a middle name like his two brothers. For his 11th birthday, his father acquiesced and allowed him to adopt the name \"Graham\", chosen out of respect for Alexander Graham, a Canadian being treated by his father who had become a family friend. To close relatives and friends he remained \"Aleck\".\n\nFirst invention\nAs a child, young Bell displayed a curiosity about his world; he gathered botanical specimens and ran experiments at an early age. His best friend was Ben Herdman, a neighbour whose family operated a flour mill. At the age of 12, Bell built a homemade device that combined rotating paddles with sets of nail brushes, creating a simple dehusking machine that was put into operation at the mill and used steadily for a number of years. In return, Ben's father John Herdman gave both boys the run of a small workshop in which to \"invent\".\n\nFrom his early years, Bell showed a sensitive nature and a talent for art, poetry, and music that was encouraged by his mother. With no formal training, he mastered the piano and became the family's pianist. Despite being normally quiet and introspective, he revelled in mimicry and \"voice tricks\" akin to ventriloquism that continually entertained family guests during their occasional visits. Bell was also deeply affected by his mother's gradual deafness (she began to lose her hearing when he was 12), and learned a manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour. He also developed a technique of speaking in clear, modulated tones directly into his mother's forehead wherein she would hear him with reasonable clarity. Bell's preoccupation with his mother's deafness led him to study acoustics.\n\nHis family was long associated with the teaching of elocution: his grandfather, Alexander Bell, in London, his uncle in Dublin, and his father, in Edinburgh, were all elocutionists. His father published a variety of works on the subject, several of which are still well known, especially his The Standard Elocutionist (1860), which appeared in Edinburgh in 1868. The Standard Elocutionist appeared in 168 British editions and sold over a quarter of a million copies in the United States alone. In this treatise, his father explains his methods of how to instruct deaf-mutes (as they were then known) to articulate words and read other people's lip movements to decipher meaning. Bell's father taught him and his brothers not only to write Visible Speech but to identify any symbol and its accompanying sound. Bell became so proficient that he became a part of his father's public demonstrations and astounded audiences with his abilities. He could decipher Visible Speech representing virtually every language, including Latin, Scottish Gaelic, and even Sanskrit, accurately reciting written tracts without any prior knowledge of their pronunciation.\n\nEducation\nAs a young child, Bell, like his brothers, received his early schooling at home from his father. At an early age, he was enrolled at the Royal High School, Edinburgh, Scotland, which he left at the age of 15, having completed only the first four forms. His school record was undistinguished, marked by absenteeism and lacklustre grades. His main interest remained in the sciences, especially biology, while he treated other school subjects with indifference, to the dismay of his father. Upon leaving school, Bell travelled to London to live with his grandfather, Alexander Bell, on Harrington Square. During the year he spent with his grandfather, a love of learning was born, with long hours spent in serious discussion and study. The elder Bell took great efforts to have his young pupil learn to speak clearly and with conviction, the attributes that his pupil would need to become a teacher himself. At the age of 16, Bell secured a position as a \"pupil-teacher\" of elocution and music, in Weston House Academy at Elgin, Moray, Scotland. Although he was enrolled as a student in Latin and Greek, he instructed classes himself in return for board and \u00a310 per session. The following year, he attended the University of Edinburgh, joining his older brother Melville who had enrolled there the previous year. In 1868, not long before he departed for Canada with his family, Bell completed his matriculation exams and was accepted for admission to University College London.\n\nFirst experiments with sound\nHis father encouraged Bell's interest in speech and, in 1863, took his sons to see a unique automaton developed by Sir Charles Wheatstone based on the earlier work of Baron Wolfgang von Kempelen. The rudimentary \"mechanical man\" simulated a human voice. Bell was fascinated by the machine and after he obtained a copy of von Kempelen's book, published in German, and had laboriously translated it, he and his older brother Melville built their own automaton head. Their father, highly interested in their project, offered to pay for any supplies and spurred the boys on with the enticement of a \"big prize\" if they were successful. While his brother constructed the throat and larynx, Bell tackled the more difficult task of recreating a realistic skull. His efforts resulted in a remarkably lifelike head that could \"speak\", albeit only a few words. The boys would carefully adjust the \"lips\" and when a bellows forced air through the windpipe, a very recognizable \"Mama\" ensued, to the delight of neighbours who came to see the Bell invention.\n\nIntrigued by the results of the automaton, Bell continued to experiment with a live subject, the family's Skye Terrier, \"Trouve\". After he taught it to growl continuously, Bell would reach into its mouth and manipulate the dog's lips and vocal cords to produce a crude-sounding \"Ow ah oo ga ma ma\". With little convincing, visitors believed his dog could articulate \"How are you, grandmama?\" Indicative of his playful nature, his experiments convinced onlookers that they saw a \"talking dog\". These initial forays into experimentation with sound led Bell to undertake his first serious work on the transmission of sound, using tuning forks to explore resonance.\n\nAt age 19, Bell wrote a report on his work and sent it to philologist Alexander Ellis, a colleague of his father. Ellis immediately wrote back indicating that the experiments were similar to existing work in Germany, and also lent Bell a copy of Hermann von Helmholtz's work, The Sensations of Tone as a Physiological Basis for the Theory of Music.\n\nDismayed to find that groundbreaking work had already been undertaken by Helmholtz who had conveyed vowel sounds by means of a similar tuning fork \"contraption\", Bell pored over the German scientist's book. Working from his own erroneous mistranslation of a French edition, Bell fortuitously then made a deduction that would be the underpinning of all his future work on transmitting sound, reporting: \"Without knowing much about the subject, it seemed to me that if vowel sounds could be produced by electrical means, so could consonants, so could articulate speech.\" He also later remarked: \"I thought that Helmholtz had done it\u00a0... and that my failure was due only to my ignorance of electricity. It was a valuable blunder\u00a0... If I had been able to read German in those days, I might never have commenced my experiments!\"\n\nFamily tragedy\nIn 1865, when the Bell family moved to London, Bell returned to Weston House as an assistant master and, in his spare hours, continued experiments on sound using a minimum of laboratory equipment. Bell concentrated on experimenting with electricity to convey sound and later installed a telegraph wire from his room in Somerset College to that of a friend. Throughout late 1867, his health faltered mainly through exhaustion. His younger brother, Edward \"Ted,\" was similarly bed-ridden, suffering from tuberculosis. While Bell recovered (by then referring to himself in correspondence as \"A. G. Bell\") and served the next year as an instructor at Somerset College, Bath, England, his brother's condition deteriorated. Edward would never recover. Upon his brother's death, Bell returned home in 1867. His older brother Melville had married and moved out. With aspirations to obtain a degree at University College London, Bell considered his next years as preparation for the degree examinations, devoting his spare time at his family's residence to studying.\n\nHelping his father in Visible Speech demonstrations and lectures brought Bell to Susanna E. Hull's private school for the deaf in South Kensington, London. His first two pupils were deaf-mute girls who made remarkable progress under his tutelage. While his older brother seemed to achieve success on many fronts including opening his own elocution school, applying for a patent on an invention, and starting a family, Bell continued as a teacher. However, in May 1870, Melville died from complications due to tuberculosis, causing a family crisis. His father had also suffered a debilitating illness earlier in life and had been restored to health by a convalescence in Newfoundland. Bell's parents embarked upon a long-planned move when they realized that their remaining son was also sickly. Acting decisively, Alexander Melville Bell asked Bell to arrange for the sale of all the family property, conclude all of his brother's affairs (Bell took over his last student, curing a pronounced lisp), and join his father and mother in setting out for the \"New World\". Reluctantly, Bell also had to conclude a relationship with Marie Eccleston, who, as he had surmised, was not prepared to leave England with him.\n\nCanada\n\nIn 1870, 23-year-old Bell travelled with his parents and his brother's widow, Caroline Margaret Ottaway, to Paris, Ontario, to stay with Thomas Henderson, a Baptist minister and family friend. The Bell family soon purchased a farm of  at Tutelo Heights (now called Tutela Heights), near Brantford, Ontario. The property consisted of an orchard, large farmhouse, stable, pigsty, hen-house, and a carriage house, which bordered the Grand River.\n\nAt the homestead, Bell set up his own workshop in the converted carriage house near to what he called his \"dreaming place\", a large hollow nestled in trees at the back of the property above the river. Despite his frail condition upon arriving in Canada, Bell found the climate and environs to his liking, and rapidly improved. He continued his interest in the study of the human voice and when he discovered the Six Nations Reserve across the river at Onondaga, he learned the Mohawk language and translated its unwritten vocabulary into Visible Speech symbols. For his work, Bell was awarded the title of Honorary Chief and participated in a ceremony where he donned a Mohawk headdress and danced traditional dances.\n\nAfter setting up his workshop, Bell continued experiments based on Helmholtz's work with electricity and sound. He also modified a melodeon (a type of pump organ) so that it could transmit its music electrically over a distance. Once the family was settled in, both Bell and his father made plans to establish a teaching practice and in 1871, he accompanied his father to Montreal, where Melville was offered a position to teach his System of Visible Speech.\n\nWork with the deaf\n\nBell's father was invited by Sarah Fuller, principal of the Boston School for Deaf Mutes (which continues today as the public Horace Mann School for the Deaf), in Boston, Massachusetts, United States, to introduce the Visible Speech System by providing training for Fuller's instructors, but he declined the post in favour of his son. Travelling to Boston in April 1871, Bell proved successful in training the school's instructors. He was subsequently asked to repeat the programme at the American Asylum for Deaf-mutes in Hartford, Connecticut, and the Clarke School for the Deaf in Northampton, Massachusetts.\n\nReturning home to Brantford after six months abroad, Bell continued his experiments with his \"harmonic telegraph\". The basic concept behind his device was that messages could be sent through a single wire if each message was transmitted at a different pitch, but work on both the transmitter and receiver was needed.\n\nUnsure of his future, he first contemplated returning to London to complete his studies, but decided to return to Boston as a teacher. His father helped him set up his private practice by contacting Gardiner Greene Hubbard, the president of the Clarke School for the Deaf for a recommendation. Teaching his father's system, in October 1872, Alexander Bell opened his \"School of Vocal Physiology and Mechanics of Speech\" in Boston, which attracted a large number of deaf pupils, with his first class numbering 30 students. While he was working as a private tutor, one of his pupils was Helen Keller, who came to him as a young child unable to see, hear, or speak. She was later to say that Bell dedicated his life to the penetration of that \"inhuman silence which separates and estranges\". In 1893, Keller performed the sod-breaking ceremony for the construction of Bell's new Volta Bureau, dedicated to \"the increase and diffusion of knowledge relating to the deaf\".\n\nThroughout his lifetime, Bell sought to integrate the deaf and hard of hearing with the hearing world. To achieve complete assimilation in society, Bell encouraged speech therapy and lip reading as well as sign will be widely viewed as a victory for the American language.  He outlined this in a 1898 paper detailing his belief that with resources and effort, the deaf could be taught to read lips and speak (known as oralism) thus enabling their integration within the wider society from which many were often being excluded. Owing to his efforts to balance oralism with the teaching of sign language, Bell is often viewed negatively by those embracing Deaf culture. Ironically, Bell's last words to his deaf wife, Mabell, were signed.\n\nContinuing experimentation\n\nIn 1872, Bell became professor of Vocal Physiology and Elocution at the Boston University School of Oratory. During this period, he alternated between Boston and Brantford, spending summers in his Canadian home. At Boston University, Bell was \"swept up\" by the excitement engendered by the many scientists and inventors residing in the city. He continued his research in sound and endeavored to find a way to transmit musical notes and articulate speech, but although absorbed by his experiments, he found it difficult to devote enough time to experimentation. While days and evenings were occupied by his teaching and private classes, Bell began to stay awake late into the night, running experiment after experiment in rented facilities at his boarding house. Keeping \"night owl\" hours, he worried that his work would be discovered and took great pains to lock up his notebooks and laboratory equipment. Bell had a specially made table where he could place his notes and equipment inside a locking cover. Worse still, his health deteriorated as he suffered severe headaches. Returning to Boston in fall 1873, Bell made a far-reaching decision to concentrate on his experiments in sound.\n\nDeciding to give up his lucrative private Boston practice, Bell retained only two students, six-year-old \"Georgie\" Sanders, deaf from birth, and 15-year-old Mabel Hubbard. Each pupil would play an important role in the next developments. George's father, Thomas Sanders, a wealthy businessman, offered Bell a place to stay in nearby Salem with Georgie's grandmother, complete with a room to \"experiment\". Although the offer was made by George's mother and followed the year-long arrangement in 1872 where her son and his nurse had moved to quarters next to Bell's boarding house, it was clear that Mr. Sanders was backing the proposal. The arrangement was for teacher and student to continue their work together, with free room and board thrown in. Mabel was a bright, attractive girl who was ten years Bell's junior but became the object of his affection. Having lost her hearing after a near-fatal bout of scarlet fever close to her fifth birthday, she had learned to read lips but her father, Gardiner Greene Hubbard, Bell's benefactor and personal friend, wanted her to work directly with her teacher.\n\nThe telephone\n\nBy 1874, Bell's initial work on the harmonic telegraph had entered a formative stage, with progress made both at his new Boston \"laboratory\" (a rented facility) and at his family home in Canada a big success. While working that summer in Brantford, Bell experimented with a \"phonautograph\", a pen-like machine that could draw shapes of sound waves on smoked glass by tracing their vibrations. Bell thought it might be possible to generate undulating electrical currents that corresponded to sound waves. Bell also thought that multiple metal reeds tuned to different frequencies like a harp would be able to convert the undulating currents back into sound. But he had no working model to demonstrate the feasibility of these ideas.\n\nIn 1874, telegraph message traffic was rapidly expanding and in the words of Western Union President William Orton, had become \"the nervous system of commerce\".  Orton had contracted with inventors Thomas Edison and Elisha Gray to find a way to send multiple telegraph messages on each telegraph line to avoid the great cost of constructing new lines. When Bell mentioned to Gardiner Hubbard and Thomas Sanders that he was working on a method of sending multiple tones on a telegraph wire using a multi-reed device, the two wealthy patrons began to financially support Bell's experiments. Patent matters would be handled by Hubbard's patent attorney, Anthony Pollok.\n\nIn March 1875, Bell and Pollok visited the scientist Joseph Henry, who was then director of the Smithsonian Institution, and asked Henry's advice on the electrical multi-reed apparatus that Bell hoped would transmit the human voice by telegraph. Henry replied that Bell had \"the germ of a great invention\". When Bell said that he did not have the necessary knowledge, Henry replied, \"Get it!\" That declaration greatly encouraged Bell to keep trying, even though he did not have the equipment needed to continue his experiments, nor the ability to create a working model of his ideas. However, a chance meeting in 1874 between Bell and Thomas A. Watson, an experienced electrical designer and mechanic at the electrical machine shop of Charles Williams, changed all that.\n\nWith financial support from Sanders and Hubbard, Bell hired Thomas Watson as his assistant, and the two of them experimented with acoustic telegraphy. On June 2, 1875, Watson accidentally plucked one of the reeds and Bell, at the receiving end of the wire, heard the overtones of the reed; overtones that would be necessary for transmitting speech. That demonstrated to Bell that only one reed or armature was necessary, not multiple reeds. This led to the \"gallows\" sound-powered telephone, which could transmit indistinct, voice-like sounds, but not clear speech.\n\nThe race to the patent office\n\nIn 1875, Bell developed an acoustic telegraph and drew up a patent application for it. Since he had agreed to share U.S. profits with his investors Gardiner Hubbard and Thomas Sanders, Bell requested that an associate in Ontario, George Brown, attempt to patent it in Britain, instructing his lawyers to apply for a patent in the U.S. only after they received word from Britain (Britain would issue patents only for discoveries not previously patented elsewhere).\n\nMeanwhile, Elisha Gray was also experimenting with acoustic telegraphy and thought of a way to transmit speech using a water transmitter. On February 14, 1876, Gray filed a caveat with the U.S. Patent Office for a telephone design that used a water transmitter. That same morning, Bell's lawyer filed Bell's application with the patent office. There is considerable debate about who arrived first and Gray later challenged the primacy of Bell's patent. Bell was in Boston on February 14 and did not arrive in Washington until February 26.\n\nBell's patent 174,465, was issued to Bell on March 7, 1876, by the U.S. Patent Office. Bell's patent covered \"the method of, and apparatus for, transmitting vocal or other sounds telegraphically... by causing electrical undulations, similar in form to the vibrations of the air accompanying the said vocal or other sound\" Bell returned to Boston the same day and the next day resumed work, drawing in his notebook a diagram similar to that in Gray's patent caveat.\n\nOn March 10, 1876, three days after his patent was issued, Bell succeeded in getting his telephone to work, using a liquid transmitter similar to Gray's design. Vibration of the diaphragm caused a needle to vibrate in the water, varying the electrical resistance in the circuit. When Bell spoke the sentence \"Mr. Watson\u2014Come here\u2014I want to see you\" into the liquid transmitter, Watson, listening at the receiving end in an adjoining room, heard the words clearly.\n\nAlthough Bell was, and still is, accused of stealing the telephone from Gray, Bell used Gray's water transmitter design only after Bell's patent had been granted, and only as a proof of concept scientific experiment, to prove to his own satisfaction that intelligible \"articulate speech\" (Bell's words) could be electrically transmitted. After March 1876, Bell focused on improving the electromagnetic telephone and never used Gray's liquid transmitter in public demonstrations or commercial use.\n\nThe question of priority for the variable resistance feature of the telephone was raised by the examiner before he approved Bell's patent application. He told Bell that his claim for the variable resistance feature was also described in Gray's caveat. Bell pointed to a variable resistance device in his previous application in which he described a cup of mercury, not water. He had filed the mercury application at the patent office a year earlier on February 25, 1875, long before Elisha Gray described the water device. In addition, Gray abandoned his caveat, and because he did not contest Bell's priority, the examiner approved Bell's patent on March 3, 1876. Gray had reinvented the variable resistance telephone, but Bell was the first to write down the idea and the first to test it in a telephone.\n\nThe patent examiner, Zenas Fisk Wilber, later stated in an affidavit that he was an alcoholic who was much in debt to Bell's lawyer, Marcell", "flag": 1, "segments": [[3151, 3161]], "strength": 5.5}
{"text": "Apple Inc. is an American multinational technology company that specializes in consumer electronics, software and online services. Apple is the largest information technology company by revenue (totaling  in 2021) and, as of January 2021, it is the world's most valuable company, the fourth-largest personal computer vendor by unit sales and second-largest mobile phone manufacturer. It is one of the Big Five American information technology companies, alongside Alphabet, Amazon, Meta, and Microsoft.\n\nApple was founded as Apple Computer Company on April 1, 1976, by Steve Jobs, Steve Wozniak and Ronald Wayne to develop and sell Wozniak's Apple I personal computer. It was incorporated by Jobs and Wozniak as Apple Computer, Inc. in 1977 and the company's next computer, the Apple II became a best seller. Apple went public in 1980, to instant financial success. The company went onto develop new computers featuring innovative graphical user interfaces, including the original Macintosh, announced in a critically acclaimed advertisement, \"1984\", directed by Ridley Scott. By 1985, the high cost of its products and power struggles between executives caused problems. Wozniak stepped back from Apple amicably, while Jobs resigned to found NeXT, taking some Apple employees with him.\n\nAs the market for personal computers expanded and evolved throughout the 1990s, Apple lost considerable market share to the lower-priced duopoly of the Microsoft Windows operating system on Intel-powered PC clones (also known as \"Wintel\"). In 1997, weeks away from bankruptcy, the company bought NeXT to resolve Apple's unsuccessful operating system strategy and entice Jobs back to the company. Over the next decade, Jobs guided Apple back to profitability through a number of tactics including introducing the iMac, iPod, iPhone and iPad to critical acclaim, launching memorable advertising campaigns, opening the Apple Store retail chain, and acquiring numerous companies to broaden the company's product portfolio. Jobs resigned in 2011 for health reasons, and died two months later. He was succeeded as CEO by Tim Cook.\n\nApple became the first publicly traded U.S. company to be valued at over $1\u00a0trillion in August 2018, then $2\u00a0trillion in August 2020, and most recently $3\u00a0trillion in January 2022. The company receives criticism regarding the labor practices of its contractors, its environmental practices, and its business ethics, including anti-competitive practices and materials sourcing. The company enjoys a high level of brand loyalty, and is ranked as one of the world's most valuable brands.\n\nHistory\n\n1976\u20131980: Founding and incorporation \n\nApple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a business partnership. The company's first product was the Apple I, a computer designed and hand-built entirely by Wozniak. To finance its creation, Jobs sold his only motorized means of transportation, a VW Bus, for a few hundred dollars, and Wozniak sold his HP-65 calculator for. Wozniak debuted the first prototype Apple I at the Homebrew Computer Club in July 1976. The Apple I was sold as a motherboard with CPU, RAM, and basic textual-video chips\u2014a base kit concept which would not yet be marketed as a complete personal computer. It went on sale soon after debut for. Wozniak later said he was unaware of the coincidental mark of the beast in the number 666, and that he came up with the price because he liked \"repeating digits\".\n\nApple Computer, Inc. was incorporated on January 3, 1977, without Wayne, who had left and sold his share of the company back to Jobs and Wozniak for $800 only twelve days after having co-founded Apple. Multimillionaire Mike Markkula provided essential business expertise and funding of  to Jobs and Wozniak during the incorporation of Apple. During the first five years of operations, revenues grew exponentially, doubling about every four months. Between September 1977 and September 1980, yearly sales grew from $775,000 to $118\u00a0million, an average annual growth rate of 533%.\n\nThe Apple II, also invented by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, because of its character cell-based color graphics and open architecture. While the Apple I and early Apple II models used ordinary audio cassette tapes as storage devices, they were superseded by the introduction of a -inch floppy disk drive and interface called the Disk II in 1978.\n\nThe Apple II was chosen to be the desktop platform for the first \"killer application\" of the business world: VisiCalc, a spreadsheet program released in 1979. VisiCalc created a business market for the Apple II and gave home users an additional reason to buy an Apple II: compatibility with the office. Before VisiCalc, Apple had been a distant third place competitor to Commodore and Tandy. By the end of the 1970s, Apple had become the leading computer manufacturer in the United States.\n\nOn December 12, 1980, Apple (ticker symbol \"AAPL\") went public selling 4.6\u00a0million shares at $22 per share ($.39 per share when adjusting for stock splits ), generating over $100\u00a0million, which was more capital than any IPO since Ford Motor Company in 1956. By the end of the day, 300\u00a0millionaires were created, from a stock price of $29 per share and a market cap of $1.778\u00a0billion.\n\n1980\u20131990: Success with Macintosh \n\nA critical moment in the company's history came in December 1979 when Jobs and several Apple employees, including human\u2013computer interface expert Jef Raskin, visited Xerox PARC in to see a demonstration of the Xerox Alto, a computer using a graphical user interface. Xerox granted Apple engineers three days of access to the PARC facilities in return for the option to buy 100,000 shares (5.6\u00a0million split-adjusted shares ) of Apple at the pre-IPO price of $10 a share. After the demonstration, Jobs was immediately convinced that all future computers would use a graphical user interface, and development of a GUI began for the Apple Lisa, named after Jobs's daughter.\n\nThe Lisa division would be plagued by infighting, and in 1982 Jobs was pushed off the project. The Lisa launched in 1983 and became the first personal computer sold to the public with a GUI, but was a commercial failure due to its high price and limited software titles.\n\nJobs, angered by being pushed off the Lisa team, took over the company's Macintosh division. Wozniak and Raskin had envisioned the Macintosh as low-cost-computer with a text-based interface like the Apple II, but a plane crash in 1981 forced Wozniak to step back from the project. Jobs quickly redefined the Macintosh as a graphical system that would be cheaper than the Lisa, undercutting his former division. Jobs was also hostile to the Apple II division, which at the time, generated most of the company's revenue.\n\nIn 1984, Apple launched the Macintosh, the first personal computer to be sold without a programming language. Its debut was signified by \"1984\", a $1.5\u00a0million television advertisement directed by Ridley Scott that aired during the third quarter of Super Bowl XVIII on January 22, 1984. This is now hailed as a watershed event for Apple's success and was called a \"masterpiece\" by CNN and one of the greatest TV advertisements of all time by TV Guide.\n\nThe advertisement created great interest in the original Macintosh, and sales were initially good, but began to taper off dramatically after the first three months as reviews started to come in. Jobs had made the decision to equip the original Macintosh with 128 kilobytes of RAM, attempting to reach a  price point, which limited its speed and the software that could be used. The Macintosh would eventually ship for, a price panned by critics in light of its slow performance. In early 1985, this sales slump triggered a power struggle between Steve Jobs and CEO John Sculley, who had been hired away from Pepsi two years earlier by Jobs using the famous line, \"Do you want to sell sugar water for the rest of your life or come with me and change the world?\" Sculley decided to remove Jobs as the head of the Macintosh division, with unanimous support from the Apple board of directors.\n\nThe board of directors instructed Sculley to contain Jobs and his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from his leadership role at Apple. Informed by Jean-Louis Gass\u00e9e, Sculley found out that Jobs had been attempting to organize a boardroom coup and called an emergency meeting at which Apple's executive staff sided with Sculley and stripped Jobs of all operational duties. Jobs resigned from Apple in September 1985 and took a number of Apple employees with him to found NeXT. Wozniak had also quit his active employment at Apple earlier in 1985 to pursue other ventures, expressing his frustration with Apple's treatment of the Apple II division and stating that the company had \"been going in the wrong direction for the last five years\". Despite Wozniak's grievances, he officially remained employed by Apple, and to this day continues to work for the company as a representative, receiving a stipend estimated to be $120,000 per year for this role. Both Jobs and Wozniak remained Apple shareholders after their departures.\n\nAfter the departures of Jobs and Wozniak, Sculley worked to improve the Macintosh in 1985 by quadrupling the RAM and introducing the LaserWriter, the first reasonably priced PostScript laser printer. PageMaker, an early desktop publishing application taking advantage of the PostScript language, was also released by Aldus Corporation in July 1985. It has been suggested that the combination of Macintosh, LaserWriter and PageMaker was responsible for the creation of the desktop publishing market.\n\nThis dominant position in the desktop publishing market allowed the company to focus on higher price points, the so-called \"high-right policy\" named for the position on a chart of price vs. profits. Newer models selling at higher price points offered higher profit margin, and appeared to have no effect on total sales as power users snapped up every increase in speed. Although some worried about pricing themselves out of the market, the high-right policy was in full force by the mid-1980s, notably due to Jean-Louis Gass\u00e9e's mantra of \"fifty-five or die\", referring to the 55% profit margins of the Macintosh II.\n\nThis policy began to backfire in the last years of the decade as desktop publishing programs appeared on PC clones that offered some or much of the same functionality of the Macintosh, but at far lower price points. The company lost its dominant position in the desktop publishing market and estranged many of its original consumer customer base who could no longer afford their high-priced products. The Christmas season of 1989 was the first in the company's history to have declining sales, which led to a 20% drop in Apple's stock price. During this period, the relationship between Sculley and Gass\u00e9e deteriorated, leading Sculley to effectively demote Gass\u00e9e in January 1990 by appointing Michael Spindler as the chief operating officer. Gass\u00e9e left the company later that year.\n\n1990\u20131997: Decline and restructuring \nThe company pivoted strategy and in October 1990 introduced three lower-cost models, the Macintosh Classic, the Macintosh LC, and the Macintosh IIsi, all of which saw significant sales due to pent-up demand. In 1991, Apple introduced the hugely successful PowerBook with a design that set the current shape for almost all modern laptops. The same year, Apple introduced System 7, a major upgrade to the Macintosh operating system, adding color to the interface and introducing new networking capabilities.\n\nThe success of the lower-cost Macs and PowerBook brought increasing revenue. For some time, Apple was doing incredibly well, introducing fresh new products and generating increasing profits in the process. The magazine MacAddict named the period between 1989 and 1991 as the \"first golden age\" of the Macintosh.\nThe success of Apple's lower-cost consumer models, especially the LC, also led to the cannibalization of their higher-priced machines. To address this, management introduced several new brands, selling largely identical machines at different price points, aimed at different markets: the high-end Quadra models, the mid-range Centris line, and the consumer-marketed Performa series. This led to significant market confusion, as customers did not understand the difference between models.\n\nThe early 1990s also saw the discontinuation of the Apple II series, which was expensive to produce, and the company felt was still taking sales away from lower-cost Macintosh models. After the launch of the LC, Apple began encouraging developers to create applications for Macintosh rather than Apple II, and authorized salespers\nThe Carolina Panthers put Newton's first NFL scoreons to direct consumers towards Macintosh and away from Apple II. The Apple IIe was discontinued in 1993.\n\nThroughout this period, Microsoft continued to gain market share with its Windows graphical user interface that it sold to manufacturers of generally less expensive PC clones. While the Macintosh was more expensive, it offered a more tightly integrated user experience, but the company struggled to make the case to consumers.\n\nApple also experimented with a number of other unsuccessful consumer targeted products during the 1990s, including digital cameras, portable CD audio players, speakers, video game consoles, the eWorld online service, and TV appliances. Most notably, enormous resources were invested in the problem-plagued Newton tablet division, based on John Sculley's unrealistic market forecasts.\n\npersonal computers, while Apple was delivering a richly engineered but expensive experience. Apple relied on high profit margins and never developed a clear response; instead, they sued Microsoft for using a GUI similar to the Apple Lisa in Apple Computer, Inc. v. Microsoft Corp. The lawsuit dragged on for years before it was finally dismissed.\n\nThe major product flops and the rapid loss of market share to Windows sullied Apple's reputation, and in 1993 Sculley was replaced as CEO by Michael Spindler.\n\nWith Spindler at the helm Apple, IBM, and Motorola formed the AIM alliance in 1994 with the goal of creating a new computing platform (the PowerPC Reference Platform; PReP), which would use IBM and Motorola hardware coupled with Apple software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind and thus counter the dominance of Windows. The same year, Apple introduced the Power Macintosh, the first of many Apple computers to use Motorola's PowerPC processor.\n\nIn the wake of the alliance, Apple opened up to the idea of allowing Motorola and other companies to build Macintosh clones. Over the next two years, 75 distinct Macintosh clone models were  introduced. However, by 1996 Apple executives were worried that the clones were cannibalizing sales of their own high-end computers, where profit margins were highest.\n\nIn 1996, Spindler was replaced by Gil Amelio as CEO. Hired for his reputation as a corporate rehabilitator, Amelio made deep changes, including extensive layoffs and cost-cutting.\n\nThis period was also marked by numerous failed attempts to modernize the Macintosh operating system (MacOS). The original Macintosh operating system (System 1) was not built for multitasking (running several applications at once). The company attempted to correct this with by introducing cooperative multitasking in System 5, but the company still felt it needed a more modern approach. This led to the Pink project in 1988, A/UX that same year, Copland in 1994, and the attempted purchase of BeOS in 1996. Talks with Be stalled the CEO, former Apple executive Jean-Louis Gass\u00e9e,  demanded $300 million instead of the $125 million Apple wanted to pay.\n\nOnly weeks away from bankruptcy, Apple's board decided NeXTSTEP was a better choice for its next operating system and purchased NeXT in late 1996 for $429 million, bringing back Apple co-founder Steve Jobs.\n\n1997\u20132007: Return to profitability \nThe NeXT acquisition was finalized on February 9, 1997, and the board brought Jobs back to Apple as an advisor. On July 9, 1997, Jobs staged a boardroom coup that resulted in Amelio's resignation after overseeing a three-year record-low stock price and crippling financial losses.\n\nThe board named Jobs as interim CEO and he immediately began a review of the company's products. Jobs would order 70% of the company's products to be cancelled, resulting in the loss of 3,000 jobs, and taking Apple back to the core of its computer offerings. The next month, in August 1997, Steve Jobs convinced Microsoft to make a $150\u00a0million investment in Apple and a commitment to continue developing software for the Mac. The investment was seen as an \"antitrust insurance policy\" for Microsoft who had recently settled with the Department of Justice over anti-competitive practices. Jobs also ended the Mac clone deals and in September 1997, purchased the largest clone maker, Power Computing. On November 10, 1997, Apple introduced the Apple Store website, which was tied to a new build-to-order manufacturing that had been successfully used by PC manufacturer Dell.\n\nThe moves paid off for Jobs, at the end of his first year as CEO, the company turned a $309 million profit.\n\nOn May 6, 1998, Apple introduced a new all-in-one computer reminiscent of the original Macintosh: the iMac. The iMac was a huge success for Apple selling 800,000 units in its first five months and ushered in major shifts in the industry by abandoning legacy technologies like the 3\u00bd-inch diskette, being an early adopter of the USB connector, and coming pre-installed with internet connectivity (the \"i\" in iMac) via Ethernet and a dial-up modem. The device also had a striking eardrop shape and translucent materials, designed by Jonathan Ive, who although hired by Amelio, would go on to work collaboratively with Jobs for the next decade to chart a new course the design of Apple's products.\n\nA little more than a year later on July 21, 1999, Apple introduced the iBook, a laptop for consumers. It was the culmination of a strategy established by Jobs to produce only four products: refined versions of the Power Macintosh G3 desktop and PowerBook G3 laptop for professionals, along with the iMac desktop and iBook laptop for consumers. Jobs felt the small product line allowed for a greater focus on quality and innovation.\n\nAt around the same time, Apple also completed numerous acquisitions to create a portfolio of digital media production software for both professionals and consumers. Apple acquired of Macromedia's Key Grip digital video editing software project which was renamed Final Cut Pro when it was launched on the retail market in April 1999. The development of Key Grip also led to Apple's release of the consumer video-editing product iMovie in October 1999. Next, Apple successfully acquired the German company Astarte in April 2000, which had developed the DVD authoring software DVDirector, which Apple would sell as the professional-oriented DVD Studio Pro software product, and used the same technology to create iDVD for the consumer market. In 2000, Apple purchased the SoundJam MP audio player software from Casady & Greene. Apple renamed the program iTunes, while simplifying the user interface and adding the ability to burn CDs.\n\n2001 would be a pivotal year for the Apple with the company making three announcements that would change the course of the company.\n\nThe first announcement came on March 24, 2001, that Apple was nearly ready to release a new modern operating system, Mac OS X. The announcement came after numerous failed attempts in the early 1990s, and several years of development. Mac OS X was based on NeXTSTEP, OPENSTEP, and BSD Unix, with Apple aiming to combine the stability, reliability, and security of Unix with the ease of use afforded by an overhauled user interface, heavily influenced by NeXTSTEP. To aid users in migrating from Mac OS 9, the new operating system allowed the use of OS 9 applications within Mac OS X via the Classic Environment.\n\nIn May 2001 the company opened its first two Apple Store retail locations in Virginia and California, offering an improved presentation of the company's products. At the time, many speculated that the stores would fail, but they went on to become highly successful, and the first of more than 500 stores around the world.\n\nOn October 23, 2001, Apple debuted the iPod portable digital audio player. The product, which was first sold on November 10, 2001, was phenomenally successful with over 100\u00a0million units sold within six years.\n\nIn 2003, Apple's iTunes Store was introduced. The service offered music downloads for $0.99 a song and integration with the iPod. The iTunes Store quickly became the market leader in online music services, with over five billion downloads by June 19, 2008. Two years later, the iTunes Store was the world's largest music retailer.\n\nIn 2002, Apple purchased Nothing Real for their advanced digital compositing application Shake, as well as Emagic for the music productivity application Logic. The purchase of Emagic made Apple the first computer manufacturer to own a music software company. The acquisition was followed by the development of Apple's consumer-level GarageBand application. The release of iPhoto in the same year completed the iLife suite.\nAt the Worldwide Developers Conference keynote address on June 6, 2005, Jobs announced that Apple would move away from PowerPC processors, and the Mac would transition to Intel processors in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006, Apple made the transition to Intel chips for the entire Mac product line\u2014over one year sooner than announced. The Power Mac, iBook, and PowerBook brands were retired during the transition; the Mac Pro, MacBook, and MacBook Pro became their respective successors. On April 29, 2009, The Wall Street Journal reported that Apple was building its own team of engineers to design microchips. Apple also introduced Boot Camp in 2006 to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.\n\nApple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. When Apple surpassed Dell's market cap in January 2006, Jobs sent an email to Apple employees saying Dell's CEO Michael Dell should eat his words. Nine years prior, Dell had said that if he ran Apple he would \"shut it down and give the money back to the shareholders\".\n\n2007\u20132011: Success with mobile devices \n\nDuring his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced that Apple Computer, Inc. would thereafter be known as \"Apple Inc.\", because the company had shifted its emphasis from computers to consumer electronics. This event also saw the announcement of the iPhone and the Apple TV. The company sold 270,000 iPhone units during the first 30 hours of sales, and the device was called \"a game changer for the industry\".\n\nIn an article posted on Apple's website on February 6, 2007, Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management (DRM), thereby allowing tracks to be played on third-party players, if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May 2007. Other record labels eventually followed suit and Apple published a press release in January 2009 to announce that all songs on the iTunes Store are available without their FairPlay DRM.\n\nIn July 2008, Apple launched the App Store to sell third-party applications for the iPhone", "flag": 1, "segments": [[2705, 2715]], "strength": 5.5}
{"text": "The American Civil War (April 12, 1861 \u2013 May 9, 1865; also known by other names) was a civil war in the United States between the Union (states that remained loyal to the federal union, or \"the North\") and the Confederacy (states that voted to secede, or \"the South\"). The central cause of the war was the status of slavery, especially the expansion of slavery into territories acquired as a result of the Louisiana Purchase and the Mexican\u2013American War. On the eve of the Civil War in 1860, four million of the 32 million Americans (~13%) were enslaved black people, almost all in the South.\n\nThe practice of slavery in the United States was one of the key political issues of the 19th century. Decades of political unrest over slavery led up to the Civil War. Disunion came after Abraham Lincoln won the 1860 United States presidential election on an anti-slavery expansion platform. An initial seven southern slave states declared their secession from the country to form the Confederacy. Confederate forces seized federal forts within territory they claimed. The last minute Crittenden Compromise tried to avert conflict but failed; both sides prepared for war. Fighting broke out in April 1861 when the Confederate army began the Battle of Fort Sumter in South Carolina, just over a month after the first inauguration of Abraham Lincoln. The Confederacy grew to control at least a majority of territory in eleven states (out of the 34 U.S. states in February 1861), and asserted claims to two more. Both sides raised large volunteer and conscription armies. Four years of intense combat, mostly in the South, ensued.\n\nDuring 1861\u20131862 in the war's Western Theater, the Union made significant permanent gainsthough in the war's Eastern Theater the conflict was inconclusive. On January 1, 1863, Lincoln issued the Emancipation Proclamation, which made ending slavery a war goal, declaring all persons held as slaves in states in rebellion \"forever free.\" To the west, the Union destroyed the Confederate river navy by the summer of 1862, then much of its western armies, and seized New Orleans. The successful 1863 Union siege of Vicksburg split the Confederacy in two at the Mississippi River. In 1863, Confederate General Robert E. Lee's incursion north ended at the Battle of Gettysburg. Western successes led to General Ulysses S. Grant's command of all Union armies in 1864. Inflicting an ever-tightening naval blockade of Confederate ports, the Union marshaled resources and manpower to attack the Confederacy from all directions. This led to the fall of Atlanta in 1864 to Union General William Tecumseh Sherman and his march to the sea. The last significant battles raged around the ten-month Siege of Petersburg, gateway to the Confederate capital of Richmond.\n\nThe Civil War effectively ended on April 9, 1865, when Confederate General Lee surrendered to Union General Grant at the Battle of Appomattox Court House, after Lee had abandoned Petersburg and Richmond. Confederate generals throughout the Confederate army followed suit. The conclusion of the American Civil War lacks a clean end date: land forces continued surrendering until June 23. By the end of the war, much of the South's infrastructure was destroyed, especially its railroads. The Confederacy collapsed, slavery was abolished, and four million enslaved black people were freed. The war-torn nation then entered the Reconstruction era in a partially successful attempt to rebuild the country and grant civil rights to freed slaves.\n\nThe Civil War is one of the most studied and written about episodes in the history of the United States. It remains the subject of cultural and historiographical debate. Of particular interest is the persisting myth of the Lost Cause of the Confederacy. The American Civil War was among the earliest to use industrial warfare. Railroads, the telegraph, steamships, the ironclad warship, and mass-produced weapons saw wide use. In total the war left between 620,000 and 750,000 soldiers dead, along with an undetermined number of civilian casualties. President Lincoln was assassinated just five days after Lee's surrender. The Civil War remains the deadliest military conflict in American history. The technology and brutality of the Civil War foreshadowed the coming World Wars.\n\nCauses of secession\n\nThe causes of secession were complex and have been controversial since the war began, but most academic scholars\u00a0identify\u00a0slavery as the central cause of the war. The issue has been further complicated by historical revisionists, who have tried to offer a variety of reasons for the war. Slavery was the central source of escalating political tension in the 1850s. The Republican Party was determined to prevent any spread of slavery to the territories, which, after they were admitted as states, would give the North greater representation in Congress and the Electoral College. Many Southern leaders had threatened secession if the Republican candidate, Lincoln, won the 1860 election. After Lincoln won, many Southern leaders felt that disunion was their only option, fearing that the loss of representation would hamper their ability to promote pro-slavery acts and policies. In his second inaugural address, Lincoln said that \"slaves constituted a peculiar and powerful interest. All knew that this interest was, somehow, the cause of the war. To strengthen, perpetuate, and extend this interest was the object for which the insurgents would rend the Union, even by war; while the government claimed no right to do more than to restrict the territorial enlargement of it.\"\n\nSlavery\n\nSlavery was the main cause of disunion. Slavery had been a controversial issue during the framing of the Constitution but had been left unsettled. The issue of slavery had confounded the nation since its inception, and increasingly separated the United States into a slaveholding South and a free North. The issue was exacerbated by the rapid territorial expansion of the country, which repeatedly brought to the fore the issue of whether new territory should be slaveholding or free. The issue had dominated politics for decades leading up to the war. Key attempts to solve the issue included the Missouri Compromise and the Compromise of 1850, but these only postponed an inevitable showdown over slavery.\n\nThe motivations of the average person were not inherently those of their faction; some Northern soldiers were even indifferent on the subject of slavery, but a general pattern can be established. Confederate soldiers fought the war primarily to protect a Southern society of which slavery was an integral part. From the anti-slavery perspective, the issue was primarily whether slavery was an anachronistic evil incompatible with republicanism. The strategy of the anti-slavery forces was containment\u2014to stop the expansion of slavery and thereby put it on a path to ultimate extinction. The slaveholding interests in the South denounced this strategy as infringing upon their constitutional rights. Southern whites believed that the emancipation of slaves would destroy the South's economy, due to the large amount of capital invested in slaves and fears of integrating the ex-slave black population. In particular, many Southerners feared a repeat of 1804 Haiti massacre (also known as \"the horrors of Santo Domingo\"), in which former slaves systematically murdered most of what was left of the country's white population \u2014 including men, women, children, and even many sympathetic to abolition \u2014 after the successful slave revolt in Haiti. Historian Thomas Fleming points to the historical phrase \"a disease in the public mind\" used by critics of this idea and proposes it contributed to the segregation in the Jim Crow era following emancipation. These fears were exacerbated by the 1859 attempt of John Brown to instigate an armed slave rebellion in the South.\n\nAbolitionists\n\nThe abolitionists \u2013 those advocating the end of slavery \u2013 were very active in the decades leading up to the Civil War. They traced their philosophical roots back to the Puritans, who strongly believed that slavery was morally wrong. One of the early Puritan writings on this subject was The Selling of Joseph, by Samuel Sewall in 1700. In it, Sewall condemned slavery and the slave trade and refuted many of the era's typical justifications for slavery.\n\nThe American Revolution and the cause of liberty added tremendous impetus to the abolitionist cause. Slavery, which had been around for thousands of years, was considered normal and was not a significant issue of public debate prior to the Revolution. The Revolution changed that and made it into an issue that had to be addressed. As a result, during and shortly after the Revolution, the northern states quickly started outlawing slavery. Even in southern states, laws were changed to limit slavery and facilitate manumission. The amount of indentured servitude dropped dramatically throughout the country. An Act Prohibiting Importation of Slaves sailed through Congress with little opposition. President Thomas Jefferson supported it, and it went into effect on January 1, 1808. Benjamin Franklin and James Madison each helped found manumission societies. Influenced by the Revolution, many slave owners freed their slaves, but some, such as George Washington, did so only in their wills. The number of free blacks as a proportion of the black population in the upper South increased from less than 1 percent to nearly 10 percent between 1790 and 1810 as a result of these actions.\n\nThe establishment of the Northwest Territory as \"free soil\" \u2013 no slavery \u2013 by Manasseh Cutler and Rufus Putnam (who both came from Puritan New England) would also prove crucial. This territory (which became the states of Ohio, Michigan, Indiana, Illinois, Wisconsin and part of Minnesota) doubled the size of the United States.\n\nIn the decades leading up to the Civil War, abolitionists, such as Theodore Parker, Ralph Waldo Emerson, Henry David Thoreau and Frederick Douglass, repeatedly used the Puritan heritage of the country to bolster their cause. The most radical anti-slavery newspaper, The Liberator, invoked the Puritans and Puritan values over a thousand times. Parker, in urging New England Congressmen to support the abolition of slavery, wrote that \"The son of the Puritan... is sent to Congress to stand up for Truth and Right....\" Literature served as a means to spread the message to common folks. Key works included Twelve Years a Slave, the Narrative of the Life of Frederick Douglass, American Slavery as It Is, and the most important: Uncle Tom's Cabin, the best-selling book of the 19th century aside from the Bible.\n\nBy 1840 more than 15,000 people were members of abolitionist societies in the United States. Abolitionism in the United States became a popular expression of moralism, and led directly to the Civil War. In churches, conventions and newspapers, reformers promoted an absolute and immediate rejection of slavery. Support for abolition among the religious was not universal though. As the war approached, even the main denominations split along political lines, forming rival southern and northern churches. In 1845, for example, Baptists split into the Northern Baptists and Southern Baptists over the issue of slavery.\n\nAbolitionist sentiment was not strictly religious or moral in origin. The Whig Party became increasingly opposed to slavery because they saw it as inherently against the ideals of capitalism and the free market. Whig leader William H. Seward (who would serve in Lincoln's cabinet) proclaimed that there was an \"irrepressible conflict\" between slavery and free labor, and that slavery had left the South backward and undeveloped. As the Whig party dissolved in the 1850s, the mantle of abolition fell to its newly formed successor, the Republican Party.\n\nTerritorial crisis\n\nManifest destiny heightened the conflict over slavery, as each new territory acquired had to face the thorny question of whether to allow or disallow the \"peculiar institution\". Between 1803 and 1854, the United States achieved a vast expansion of territory through purchase, negotiation, and conquest. At first, the new states carved out of these territories entering the union were apportioned equally between slave and free states. Pro- and anti-slavery forces collided over the territories west of the Mississippi.\n\nThe Mexican\u2013American War and its aftermath was a key territorial event in the leadup to the war. As the Treaty of Guadalupe Hidalgo finalized the conquest of northern Mexico west to California in 1848, slaveholding interests looked forward to expanding into these lands and perhaps Cuba and Central America as well. Prophetically, Ralph Waldo Emerson wrote that \"Mexico will poison us\", referring to the ensuing divisions around whether the newly conquered lands would end up slave or free. Northern \"free soil\" interests vigorously sought to curtail any further expansion of slave territory. The Compromise of 1850 over California balanced a free-soil state with stronger fugitive slave laws for a political settlement after four years of strife in the 1840s. But the states admitted following California were all free: Minnesota (1858), Oregon (1859), and Kansas (1861). In the Southern states, the question of the territorial expansion of slavery westward again became explosive. Both the South and the North drew the same conclusion: \"The power to decide the question of slavery for the territories was the power to determine the future of slavery itself.\"\n\nBy 1860, four doctrines had emerged to answer the question of federal control in the territories, and they all claimed they were sanctioned by the Constitution, implicitly or explicitly. The first of these \"conservative\" theories, represented by the Constitutional Union Party, argued that the Missouri Compromise apportionment of territory north for free soil and south for slavery should become a Constitutional mandate. The Crittenden Compromise of 1860 was an expression of this view.\n\nThe second doctrine of Congressional preeminence, championed by Abraham Lincoln and the Republican Party, insisted that the Constitution did not bind legislators to a policy of balance\u2014that slavery could be excluded in a territory as it was done in the Northwest Ordinance of 1787 at the discretion of Congress; thus Congress could restrict human bondage, but never establish it. The ill-fated Wilmot Proviso announced this position in 1846. The Proviso was a pivotal moment in national politics, as it was the first time slavery had become a major congressional issue based on sectionalism, instead of party lines. Its bipartisan support by northern Democrats and Whigs, and bipartisan opposition by southerners was a dark omen of coming divisions.\n\nSenator Stephen A. Douglas proclaimed the third doctrine: territorial or \"popular\" sovereignty, which asserted that the settlers in a territory had the same rights as states in the Union to establish or disestablish slavery as a purely local matter. The Kansas\u2013Nebraska Act of 1854 legislated this doctrine. In the Kansas Territory, years of pro and anti-slavery violence and political conflict erupted; the U.S. House of Representatives voted to admit Kansas as a free state in early 1860, but its admission did not pass the Senate until January 1861, after the departure of Southern senators.\n\nThe fourth doctrine was advocated by Mississippi Senator Jefferson Davis, one of state sovereignty (\"states' rights\"), also known as the \"Calhoun doctrine\", named after the South Carolinian political theorist and statesman John C. Calhoun. Rejecting the arguments for federal authority or self-government, state sovereignty would empower states to promote the expansion of slavery as part of the federal union under the U.S. Constitution. \"States' rights\" was an ideology formulated and applied as a means of advancing slave state interests through federal authority. As historian Thomas L. Krannawitter points out, the \"Southern demand for federal slave protection represented a demand for an unprecedented expansion of Federal power.\" These four doctrines comprised the dominant ideologies presented to the American public on the matters of slavery, the territories, and the U.S. Constitution before the 1860 presidential election.\n\nStates' rights\nA long running dispute over the origin of the Civil War is to what extent states' rights triggered the conflict. The consensus among historians is that the Civil War was  fought about states' rights. But the issue is frequently referenced in popular accounts of the war and has much traction among Southerners. The South argued that just as each state had decided to join the Union, a state had the right to secede\u2014leave the Union\u2014at any time. Northerners (including pro-slavery President Buchanan) rejected that notion as opposed to the will of the Founding Fathers, who said they were setting up a perpetual union.\n\nHistorian James McPherson points out that even if Confederates genuinely fought over states' rights, it boiled down to states' right to slavery. McPherson writes concerning states' rights and other non-slavery explanations:\n\nBefore the Civil War, the Southern states used federal powers in enforcing and extending slavery at the national level, with the Fugitive Slave Act of 1850 and Dred Scott v. Sandford decision. The faction that pushed for secession often infringed on states' rights. Because of the overrepresentation of pro-slavery factions in the federal government, many Northerners, even non-abolitionists, feared the Slave Power conspiracy. Some Northern states resisted the enforcement of the Fugitive Slave Act. Historian Eric Foner stated the act \"could hardly have been designed to arouse greater opposition in the North. It overrode numerous state and local laws and legal procedures and 'commanded' individual citizens to assist, when called upon, in capturing runaways.\" He continues, \"It certainly did not reveal, on the part of slaveholders, sensitivity to states\u2019 rights.\" According to historian Paul Finkelman \"the southern states mostly complained that the northern states were asserting their states\u2019 rights and that the national government was not powerful enough to counter these northern claims.\" The Confederate constitution also \"federally\" required slavery to be legal in all Confederate states and claimed territories.\n\nSectionalism\nSectionalism resulted from the different economies, social structure, customs, and political values of the North and South. Regional tensions came to a head during the War of 1812, resulting in the Hartford Convention, which manifested Northern dissatisfaction with a foreign trade embargo that affected the industrial North disproportionately, the Three-Fifths Compromise, dilution of Northern power by new states, and a succession of Southern presidents. Sectionalism increased steadily between 1800 and 1860 as the North, which phased slavery out of existence, industrialized, urbanized, and built prosperous farms, while the deep South concentrated on plantation agriculture based on slave labor, together with subsistence agriculture for poor whites. In the 1840s and 1850s, the issue of accepting slavery (in the guise of rejecting slave-owning bishops and missionaries) split the nation's largest religious denominations (the Methodist, Baptist, and Presbyterian churches) into separate Northern and Southern denominations.\n\nHistorians have debated whether economic differences between the mainly industrial North and the mainly agricultural South helped cause the war. Most historians now disagree with the economic determinism of historian Charles A. Beard in the 1920s, and emphasize that Northern and Southern economies were largely complementary. While socially different, the sections economically benefited each other.\n\nProtectionism\nOwners of slaves preferred low-cost manual labor with no mechanization. Northern manufacturing interests supported tariffs and protectionism while Southern planters demanded free trade. The Democrats in Congress, controlled by Southerners, wrote the tariff laws in the 1830s, 1840s, and 1850s, and kept reducing rates so that the 1857 rates were the lowest since 1816. The Republicans called for an increase in tariffs in the 1860 election. The increases were only enacted in 1861 after Southerners resigned their seats in Congress. The tariff issue was a Northern grievance. However, neo-Confederate writers have claimed it as a Southern grievance. In 1860\u201361 none of the groups that proposed compromises to head off secession raised the tariff issue. Pamphleteers North and South rarely mentioned the tariff.\n\nNationalism and honor\n\nNationalism was a powerful force in the early 19th century, with famous spokesmen such as Andrew Jackson and Daniel Webster. While practically all Northerners supported the Union, Southerners were split between those loyal to the entirety of the United States (called \"Southern Unionists\") and those loyal primarily to the Southern region and then the Confederacy.\n\nPerceived insults to Southern collective honor included the enormous popularity of Uncle Tom's Cabin, and the actions of abolitionist John Brown in trying to incite a rebellion of slaves in 1859.\n\nWhile the South moved towards a Southern nationalism, leaders in the North were also becoming more nationally minded, and they rejected any notion of splitting the Union. The Republican national electoral platform of 1860 warned that Republicans regarded disunion as treason and would not tolerate it. The South ignored the warnings; Southerners did not realize how ardently the North would fight to hold the Union together.\n\nLincoln's election\n\nThe election of Abraham Lincoln in November 1860 was the final trigger for secession. Efforts at compromise, including the Corwin Amendment and the Crittenden Compromise, failed. Southern leaders feared that Lincoln would stop the expansion of slavery and put it on a course toward extinction. When Lincoln won the presidential election in 1860, the South lost any hope of compromise. Jefferson Davis claimed that all the cotton states would secede from the Union. The Confederacy was formed of seven states of the Deep South: Alabama, Florida, \nGeorgia, Louisiana, Mississippi, South Carolina, and Texas in January and February 1861. They wrote the Confederate Constitution, which provided greater states' rights than the Constitution of the United States. Until elections were held, Davis was the provisional president. Lincoln was inaugurated on March 4, 1861.\n\nAccording to Lincoln, the American people had shown that they had been successful in establishing and administering a republic, but a third challenge faced the nation: maintaining a republic based on the people's vote, in the face of an attempt to destroy it.\n\nOutbreak of the war\n\nSecession crisis\nThe election of Lincoln provoked the legislature of South Carolina to call a state convention to consider secession. Before the war, South Carolina did more than any other Southern state to advance the notion that a state had the right to nullify federal laws, and even to secede from the United States. The convention unanimously voted to shoes to bring in a $3 billion and rising secede on December 20, 1860, and adopted a secession declaration. It argued for states' rights for slave owners in the South, but contained a complaint about states' rights in the North in the form of opposition to the Fugitive Slave Act, claiming that Northern states were not fulfilling their federal obligations under the Constitution. The \"cotton states\" of Mississippi, Florida, Alabama, Georgia, Louisiana, and Texas followed suit, seceding in January and February 1861.\n\nAmong the ordinances of secession passed by the individual states, those of three\u2014Texas, Alabama, and Virginia\u2014specifically mentioned the plight of the \"slaveholding states\" at the hands of Northern abolitionists. The rest make no mention of the slavery issue and are often brief announcements of the dissolution of ties by the legislatures. However, at least four states\u2014South Carolina, Mississippi, Georgia, and Texas\u2014also passed lengthy and detailed explanations of their causes for secession, all of which laid the blame squarely on the movement to abolish slavery and that movement's influence over the politics of the Northern states. The Southern states believed slaveholding was a constitutional right because of the Fugitive Slave Clause of the Constitution. These states agreed to form a new federal government, the Confederate States of America, on February 4, 1861. They took control of federal forts and other properties within their boundaries with little resistance from outgoing President James Buchanan, whose term ended on March 4, 1861. Buchanan said that the Dred Scott decision was proof that the South had no reason for secession, and that the Union \"was intended to be perpetual\", but that \"The power by force of arms to compel a State to remain in the Union\" was not among the \"enumerated powers granted to Congress\". One-quarter of the U.S. Army\u2014the entire garrison in Texas\u2014was surrendered in February 1861 to state forces by its commanding general, David E. Twiggs, who then joined the Confederacy.\n\nAs Southerners resigned their seats in", "flag": 1, "segments": [[4594, 4604]], "strength": 5.5}
{"text": "Andy Warhol (; born Andrew Warhola Jr.; August 6, 1928 \u2013 February 22, 1987) was an American artist, film director, and producer who was a leading figure in the visual art movement known as pop art. His works explore the relationship between artistic expression, advertising, and celebrity culture that flourished by the 1960s, and span a variety of media, including painting, silkscreening, photography, film, and sculpture. Some of his best known works include the silkscreen paintings Campbell's Soup Cans (1962) and Marilyn Diptych (1962), the experimental films Empire (1964) and Chelsea Girls (1966), and the multimedia events known as the Exploding Plastic Inevitable (1966\u201367).\n\nBorn and raised in Pittsburgh, Warhol initially pursued a successful career as a commercial illustrator. After exhibiting his work in several galleries in the late 1950s, he began to receive recognition as an influential and controversial artist. His New York studio, The Factory, became a well-known gathering place that brought together distinguished intellectuals, drag queens, playwrights, Bohemian street people, Hollywood celebrities, and wealthy patrons. He promoted a collection of personalities known as Warhol superstars, and is credited with inspiring the widely used expression \"15 minutes of fame\". In the late 1960s he managed and produced the experimental rock band The Velvet Underground and founded Interview magazine. He authored numerous books, including The Philosophy of Andy Warhol and Popism: The Warhol Sixties. He lived openly as a gay man before the gay liberation movement. In June 1968, he was almost killed by radical feminist Valerie Solanas,  who shot him inside his studio. After gallbladder surgery, Warhol died of cardiac arrhythmia in February 1987 at the age of 58 in New York.\n\nWarhol has been the subject of numerous retrospective exhibitions, books, and feature and documentary films. The Andy Warhol Museum in his native city of Pittsburgh, which holds an extensive permanent collection of art and archives, is the largest museum in the United States dedicated to a single artist. A 2009 article in The Economist described Warhol as the \"bellwether of the art market\". Many of his creations are very collectible and highly valuable. The highest price ever paid for a Warhol painting is $105 million for a 1963 serigraph titled Silver Car Crash (Double Disaster). His works include some of the most expensive paintings ever sold.\n\nBiography\n\nEarly life and beginnings (1928\u20131949)\n\nWarhol was born on August 6, 1928, in Pittsburgh, Pennsylvania. He was the fourth child of Ondrej Warhola (Americanized as Andrew Warhola, Sr., 1889\u20131942) and Julia (n\u00e9e Zavack\u00e1, 1892\u20131972), whose first child was born in their homeland of Austria-Hungary and died before their move to the U.S.\n\nHis parents were working-class Lemkos emigrants from Mik\u00f3, Austria-Hungary (now called Mikov\u00e1, located in today's northeastern Slovakia). Warhol's father emigrated to the United States in 1914, and his mother joined him in 1921, after the death of Warhol's grandparents. Warhol's father worked in a coal mine. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. The family was Ruthenian Catholic and attended St. John Chrysostom Byzantine Catholic Church. Andy Warhol had two elder brothers\u2014Pavol (Paul), the eldest, was born before the family emigrated; J\u00e1n was born in Pittsburgh. Pavol's son, James Warhola, became a successful children's book illustrator.\n\nIn third grade, Warhol had Sydenham's chorea (also known as St. Vitus' Dance), the nervous system disease that causes involuntary movements of the extremities, which is believed to be a complication of scarlet fever which causes skin pigmentation blotchiness. At times when he was confined to bed, he drew, listened to the radio and collected pictures of movie stars around his bed. Warhol later described this period as very important in the development of his personality, skill-set and preferences. When Warhol was 13, his father died in an accident.\n\nAs a teenager, Warhol graduated from Schenley High School in 1945, and as a teen, Warhol also won a Scholastic Art and Writing Award. After graduating from high school, his intentions were to study art education at the University of Pittsburgh in the hope of becoming an art teacher, but his plans changed and he enrolled in the Carnegie Institute of Technology, now Carnegie Mellon University in Pittsburgh, where he studied commercial art. During his time there, Warhol joined the campus Modern Dance Club and Beaux Arts Society. He also served as art director of the student art magazine, Cano, illustrating a cover in 1948 and a full-page interior illustration in 1949. These are believed to be his first two published artworks. Warhol earned a Bachelor of Fine Arts in pictorial design in 1949. Later that year, he moved to New York City and began a career in magazine illustration and advertising.\n\n1950s\n\nWarhol's early career was dedicated to commercial and advertising art, where his first commission had been to draw shoes for Glamour magazine in the late 1940s. In the 1950s, Warhol worked as a designer for shoe manufacturer Israel Miller. While working in the shoe industry, Warhol developed his \"blotted line\" technique, applying ink to paper and then blotting the ink while still wet, which was akin to a printmaking process on the most rudimentary scale. His use of tracing paper and ink allowed him to repeat the basic image and also to create endless variations on the theme. American photographer John Coplans recalled that\n\nIn 1952, Warhol had his first solo show at the Hugo Gallery in New York, and although that show was not well received, by 1956, he was included in his first group exhibition at the Museum of Modern Art, New York. Warhol's \"whimsical\" ink drawings of shoe advertisements figured in some of his earliest showings at the Bodley Gallery in New York in 1957.\n\nWarhol habitually used the expedient of tracing photographs projected with an epidiascope. Using prints by Edward Wallowitch, his \"first boyfriend,\" the photographs would undergo a subtle transformation during Warhol's often cursory tracing of contours and hatching of shadows. Warhol used Wallowitch's photograph Young Man Smoking a Cigarette (c.1956), for a 1958 design for a book cover he submitted to Simon and Schuster for the Walter Ross pulp novel The Immortal, and later used others for his series of paintings.\n\nWith the rapid expansion of the record industry, RCA Records hired Warhol, along with another freelance artist, Sid Maurer, to design album covers and promotional materials.\n\n1960s\n\nWarhol was an early adopter of the silk screen printmaking process as a technique for making paintings. In 1962, Warhol was taught silk screen printmaking techniques by Max Arthur Cohn at his graphic arts business in Manhattan. In his book Popism: The Warhol Sixties, Warhol writes: \"When you do something exactly wrong, you always turn up something.\"\n\nIn May 1962, Warhol was featured in an article in Time magazine with his painting Big Campbell's Soup Can with Can Opener (Vegetable) (1962), which initiated his most sustained motif, the Campbell's soup can. That painting became Warhol's first to be shown in a museum when it was exhibited at the Wadsworth Atheneum in Hartford in July 1962. On July 9, 1962, Warhol's exhibition opened at the Ferus Gallery in Los Angeles with Campbell's Soup Cans, marking his West Coast debut of pop art.\n\nIn November 1962, Warhol had an exhibition at Eleanor Ward's Stable Gallery in New York. The exhibit included the works Gold Marilyn, eight of the classic \u201cMarilyn\u201d series also named \"Flavor Marilyns\", Marilyn Diptych, 100 Soup Cans, 100 Coke Bottles, and 100 Dollar Bills.  The Flavor Marilyns were selected from a group of fourteen canvases in the sub-series, each measuring 20\u2033 x 16\u2033. Some of the canvases were named after various candy Life Savers flavors, including Cherry Marilyn, Lemon Marilyn, Mint, Lavender, Grape or Licorice Marilyn. The others are identified by their background colors. Gold Marilyn, was bought by the architect Philip Johnson and donated to the Museum of Modern Art. At the exhibit, Warhol met poet John Giorno, who would star in Warhol's first film, Sleep, in 1964.\n\nIt was during the 1960s that Warhol began to make paintings of iconic American objects such as dollar bills, mushroom clouds, electric chairs, Campbell's soup cans, Coca-Cola bottles, celebrities such as Marilyn Monroe, Elvis Presley, Marlon Brando, Troy Donahue, Muhammad Ali, and Elizabeth Taylor, as well as newspaper headlines or photographs of police dogs attacking African-American protesters during the Birmingham campaign in the civil rights movement. During these years, he founded his studio, \"The Factory\" and gathered about him a wide range of artists, writers, musicians, and underground celebrities. His work became popular and controversial. Warhol had this to say about Coca-Cola:\n\nIn December 1962, New York City's Museum of Modern Art hosted a symposium on pop art, during which artists such as Warhol were attacked for \"capitulating\" to consumerism. Critics were appalled by Warhol's open acceptance of market culture, which set the tone for his reception.\n\nWarhol had his second exhibition at the Stable Gallery in the spring of 1964, which featured sculptures of commercial boxes stacked and scattered throughout the space to resemble a warehouse. For the exhibition, Warhol custom ordered wooden boxes and silkscreened graphics onto them. The sculptures\u2014Brillo Box, Del Monte Peach Box, Heinz Tomato Ketchup Box, Kellog's Cornflakes Box, Campbell's Tomato Juice Box, and Mott's Apple Juice Box\u2014sold for $200 to $400 depending on the size of the box.\n\nA pivotal event was The American Supermarket exhibition at Paul Bianchini's Upper East Side gallery in the fall of 1964. The show was presented as a typical small supermarket environment, except that everything in it\u2014from the produce, canned goods, meat, posters on the wall, etc.\u2014was created by prominent pop artists of the time, among them were sculpture Claes Oldenburg, Mary Inman and Bob Watts. Warhol designed a $12 paper shopping bag\u2014plain white with a red Campbell's soup can. His painting of a can of a Campbell's soup cost $1,500 while each autographed can sold for 3 for $18, $6.50 each. The exhibit was one of the first mass events that directly confronted the general public with both pop art and the perennial question of what art is.\n\nAs an advertisement illustrator in the 1950s, Warhol used assistants to increase his productivity. Collaboration would remain a defining (and controversial) aspect of his working methods throughout his career; this was particularly true in the 1960s. One of the most important collaborators during this period was Gerard Malanga. Malanga assisted the artist with the production of silkscreens, films, sculpture, and other works at \"The Factory\", Warhol's aluminum foil-and-silver-paint-lined studio on 47th Street (later moved to Broadway). Other members of Warhol's Factory crowd included Freddie Herko, Ondine, Ronald Tavel, Mary Woronov, Billy Name, and Brigid Berlin (from whom he apparently got the idea to tape-record his phone conversations).\n\nDuring the 1960s, Warhol also groomed a retinue of bohemian and counterculture eccentrics upon whom he bestowed the designation \"superstars\", including Nico, Joe Dallesandro, Edie Sedgwick, Viva, Ultra Violet, Holly Woodlawn, Jackie Curtis, and Candy Darling. These people all participated in the Factory films, and some\u2014like Berlin\u2014remained friends with Warhol until his death. Important figures in the New York underground art/cinema world, such as writer John Giorno and film-maker Jack Smith, also appear in Warhol films (many premiering at the New Andy Warhol Garrick Theatre and 55th Street Playhouse) of the 1960s, revealing Warhol's connections to a diverse range of artistic scenes during this time. Less well known was his support and collaboration with several teenagers during this era, who would achieve prominence later in life including writer David Dalton, photographer Stephen Shore and artist Bibbe Hansen (mother of pop musician Beck).\n\nAttempted murder: 1968 \nOn June 3, 1968, radical feminist writer Valerie Solanas shot Warhol and Mario Amaya, art critic and curator, at Warhol's studio, The Factory. Before the shooting, Solanas had been a marginal figure in the Factory scene. She authored in 1967 the SCUM Manifesto, a separatist feminist tract that advocated the elimination of men; and appeared in the 1968 Warhol film I, a Man. Earlier on the day of the attack, Solanas had been turned away from the Factory after asking for the return of a script she had given to Warhol. The script had apparently been misplaced.\n\nAmaya received only minor injuries and was released from the hospital later the same day. Warhol was seriously wounded by the attack and barely survived. He suffered physical effects for the rest of his life, including being required to wear a surgical corset. The shooting had a profound effect on Warhol's life and art.\n\nSolanas was arrested the day after the assault, after turning herself in to police. By way of explanation, she said that Warhol \"had too much control over my life\". She was subsequently diagnosed with paranoid schizophrenia and eventually sentenced to three years under the control of the Department of Corrections. After the shooting, the Factory scene heavily increased its security, and for many the \"Factory 60s\" ended (\"The superstars from the old Factory days didn't come around to the new Factory much\").\n\nWarhol had this to say about the attack:\n\nIn 1969, Warhol and British journalist John Wilcock founded Interview magazine.\n\n1970s\n\nWarhol had a retrospective exhibition at the Whitney Museum of American Art in 1971. His famous portrait of Chinese Communist leader Mao Zedong was created in 1973. In 1975, he published The Philosophy of Andy Warhol (1975). An idea expressed in the book: \"Making money is art, and working is art and good business is the best art.\"\n\nCompared to the success and scandal of Warhol's work in the 1960s, the 1970s were a much quieter decade, as he became more entrepreneurial. He socialized at various nightspots in New York City, including Max's Kansas City and, later in the 1970s, Studio 54. He was generally regarded as quiet, shy, and a meticulous observer. Art critic Robert Hughes called him \"the white mole of Union Square\".\n\nIn 1977, Warhol was commissioned by art collector Richard Weisman to create, Athletes, ten portraits consisting of the leading athletes of the day.\n\nAccording to Bob Colacello, Warhol devoted much of his time to rounding up new, rich patrons for portrait commissions\u2014including Shah of Iran Mohammad Reza Pahlavi, his wife Empress Farah Pahlavi, his sister Princess Ashraf Pahlavi, Mick Jagger, Liza Minnelli, John Lennon, Diana Ross, and Brigitte Bardot. In 1979, reviewers disliked his exhibits of portraits of 1970s personalities and celebrities, calling them superficial, facile and commercial, with no depth or indication of the significance of the subjects.\n\nIn 1979, Warhol and his longtime friend Stuart Pivar founded the New York Academy of Art.\n\n1980s\nWarhol had a re-emergence of critical and financial success in the 1980s, partially due to his affiliation and friendships with a number of prolific younger artists, who were dominating the \"bull market\" of 1980s New York art: Jean-Michel Basquiat, Julian Schnabel, David Salle and other so-called Neo-Expressionists, as well as members of the Transavantgarde movement in Europe, including Francesco Clemente and Enzo Cucchi. Warhol also earned street credibility and graffiti artist Fab Five Freddy paid homage to Warhol by painting an entire train with Campbell soup cans.\n\nWarhol was also being criticized for becoming merely a \"business artist\". Critics panned his 1980 exhibition Ten Portraits of Jews of the Twentieth Century at the Jewish Museum in Manhattan, which Warhol\u2014who was uninterested in Judaism and Jews\u2014had described in his diary as \"They're going to sell.\" In hindsight, however, some critics have come to view Warhol's superficiality and commerciality as \"the most brilliant mirror of our times,\" contending that \"Warhol had captured something irresistible about the zeitgeist of American culture in the 1970s.\"\n\nWarhol also had an appreciation for intense Hollywood glamour. He once said: \"I love Los Angeles. I love Hollywood. They're so beautiful. Everything's plastic, but I love plastic. I want to be plastic.\" Warhol occasionally walked the fashion runways and did product endorsements, represented by Zoli Agency and later Ford Models.\n\nBefore the 1984 Sarajevo Winter Olympics, he teamed with 15 other artists, including David Hockney and Cy Twombly, and contributed a Speed Skater print to the Art and Sport collection. The Speed Skater was used for the official Sarajevo Winter Olympics poster.\n\nIn 1984, Vanity Fair commissioned Warhol to produce a portrait of Prince, in order to accompany an article that celebrated the success of Purple Rain and its accompanying movie. Referencing the many celebrity portraits produced by Warhol across his career, Orange Prince (1984) was created using a similar composition to the Marilyn \"Flavors\" series from 1962, among some of Warhol's first celebrity portraits. Prince is depicted in a pop color palette commonly used by Warhol, in bright orange with highlights of bright green and blue. The facial features and hair are screen-printed in black over the orange background.\n\nIn September 1985, Warhol's joint exhibition with Basquiat, Paintings, opened to negative reviews at the Tony Shafrazi Gallery. That month, despite apprehension from Warhol, his silkscreen series Reigning Queens was shown at the Leo Castelli Gallery. In the Andy Warhol Diaries, Warhol wrote, \"They were supposed to be only for Europe\u2014nobody here cares about royalty and it'll be another bad review.\"\n\nIn January 1987, Warhol traveled to Milan for the opening of his last exhibition, Last Supper, at the Palazzo delle Stelline. The next month, Warhol and jazz musician Miles Davis modeled for Koshin Satoh's fashion show at the Tunnel in New York City on February 17, 1987.\n\nDeath\n\nWarhol died in Manhattan at 6:32\u00a0a.m. on February 22, 1987, at age 58. According to news reports, he had been making a good recovery from gallbladder surgery at New York Hospital before dying in his sleep from a sudden post-operative irregular heartbeat. Prior to his diagnosis and operation, Warhol delayed having his recurring gallbladder problems checked, as he was afraid to enter hospitals and see doctors. His family sued the hospital for inadequate care, saying that the arrhythmia was caused by improper care and water intoxication. The malpractice case was quickly settled out of court; Warhol's family received an undisclosed sum of money.\n\nShortly before Warhol's death, doctors expected Warhol to survive the surgery, though a re-evaluation of the case about thirty years after his death showed many indications that Warhol's surgery was in fact riskier than originally thought. It was widely reported at the time that Warhol died of a \"routine\" surgery, though when considering factors such as his age, a family history of gallbladder problems, his previous gunshot wound, and his medical state in the weeks leading up to the procedure, the potential risk of death following the surgery appeared to have been significant.\n\nWarhol's brothers took his body back to Pittsburgh, where an open-coffin wake was held at the Thomas P. Kunsak Funeral Home. The solid bronze casket had gold-plated rails and white upholstery. Warhol was dressed in a black cashmere suit, a paisley tie, a platinum wig, and sunglasses. He was laid out holding a small prayer book and a red rose. The funeral liturgy was held at the Holy Ghost Byzantine Catholic Church on Pittsburgh's North Side. The eulogy was given by Monsignor Peter Tay. Yoko Ono and John Richardson were speakers. The coffin was covered with white roses and asparagus ferns. After the liturgy, the coffin was driven to St. John the Baptist Byzantine Catholic Cemetery in Bethel Park, a south suburb of Pittsburgh.\n\nAt the grave, the priest said a brief prayer and sprinkled holy water on the casket. Before the coffin was lowered, Warhol's friend and advertising director of Interview Paige Powell dropped a copy of the magazine, an Interview T-shirt, and a bottle of the Est\u00e9e Lauder perfume \"Beautiful\" into the grave. Warhol was buried next to his mother and father. A memorial service was held in Manhattan for Warhol at St. Patrick's Cathedral on April 1, 1987.\n\nArt works\n\nPaintings \nBy the beginning of the 1960s, pop art was an experimental form that several artists were independently adopting; some of these pioneers, such as Roy Lichtenstein, would later become synonymous with the movement. Warhol, who would become famous as the \"Pope of Pop\", turned to this new style, where popular subjects could be part of the artist's palette. His early paintings show images taken from cartoons and advertisements, hand-painted with paint drips. Marilyn Monroe was a pop art painting that Warhol had done and it was very popular. Those drips emulated the style of successful abstract expressionists (such as Willem de Kooning). Warhol's first pop art paintings were displayed in April 1961, serving as the backdrop for New York Department Store Bonwit Teller's window display. This was the same stage his Pop Art contemporaries Jasper Johns, James Rosenquist and Robert Rauschenberg had also once graced.\n\nIt was the gallerist MurielThe occupants of a bus were told by authorities they Latow who came up with the ideas for both the soup cans and Warhol's dollar paintings. On November 23, 1961, Warhol wrote Latow a check for $50 which, according to the 2009 Warhol biography, Pop, The Genius of Warhol, was payment for coming up with the idea of the soup cans as subject matter. For his first major exhibition, Warhol painted his famous cans of Campbell's soup, which he claimed to have had for lunch for most of his life.\n\nFrom these beginnings, he developed his later style and subjects. Instead of working on a signature subject matter, as he started out to do, he worked more and more on a signature style, slowly eliminating the handmade from the artistic process. Warhol frequently used silk-screening; his later drawings were traced from slide projections. At the height of his fame as a painter, Warhol had several assistants who produced his silk-screen multiples, following his directions to make different versions and variations.\n\nWarhol produced both comic and serious works; his subject could be a soup can or an electric chair. Warhol used the same techniques\u2014silkscreens, reproduced serially, and often", "flag": 1, "segments": [[4757, 4767]], "strength": 5.5}
{"text": "was a Japanese filmmaker and painter who directed thirty films in a career spanning over five decades. He is regarded as one of the most important and influential filmmakers in film history.\n\nKurosawa entered the Japanese film industry in 1936, following a brief stint as a painter. After years of working on numerous films as an assistant director and scriptwriter, he made his debut as a director during World War II with the popular action film Sanshiro Sugata. After the war, the critically acclaimed Drunken Angel (1948), in which Kurosawa cast the then little-known actor Toshiro Mifune in a starring role, cemented the director's reputation as one of the most important young filmmakers in Japan. The two men would go on to collaborate on another fifteen films.\n\nRashomon, which premiered in Tokyo, became the surprise winner of the Golden Lion at the 1951 Venice Film Festival. The commercial and critical success of that film opened up Western film markets for the first time to the products of the Japanese film industry, which in turn led to international recognition for other Japanese filmmakers. Kurosawa directed approximately one film per year throughout the 1950s and early 1960s, including a number of highly regarded (and often adapted) films, such as Ikiru (1952), Seven Samurai (1954) and Yojimbo (1961). After the 1960s he became much less prolific; even so, his later work\u2014including two of his final films, Kagemusha (1980) and Ran (1985)\u2014continued to receive great acclaim.\n\nIn 1990, he accepted the Academy Award for Lifetime Achievement. Posthumously, he was named \"Asian of the Century\" in the \"Arts, Literature, and Culture\" category by AsianWeek magazine and CNN, cited there as being among the five people who most prominently contributed to the improvement of Asia in the 20th century. His career has been honored by many retrospectives, critical studies and biographies in both print and video, and by releases in many consumer media.\n\nBiography\n\nChildhood to war years (1910\u20131945)\n\nChildhood and youth (1910\u20131935) \nKurosawa was born on March 23, 1910, in \u014cimachi in the \u014cmori district of Tokyo. His father Isamu (1864\u20131948), a member of a samurai family from Akita Prefecture, worked as the director of the Army's Physical Education Institute's lower secondary school, while his mother Shima (1870\u20131952) came from a merchant's family living in Osaka. Akira was the eighth and youngest child of the moderately wealthy family, with two of his siblings already grown up at the time of his birth and one deceased, leaving Kurosawa to grow up with three sisters and a brother.\n\nIn addition to promoting physical exercise, Isamu Kurosawa was open to Western traditions and considered theatre and motion pictures to have educational merit. He encouraged his children to watch films; young Akira viewed his first movies at the age of six. An important formative influence was his elementary school teacher Mr. Tachikawa, whose progressive educational practices ignited in his young pupil first a love of drawing and then an interest in education in general. During this time, the boy also studied calligraphy and Kendo swordsmanship.\n\nAnother major childhood influence was Heigo Kurosawa (1906-1933), Akira's older brother by four years. In the aftermath of the Great Kant\u014d earthquake of 1923, Heigo took the thirteen-year-old Akira to view the devastation. When the younger brother wanted to look away from the corpses of humans and beasts scattered everywhere, Heigo forbade him to do so, encouraging Akira instead to face his fears by confronting them directly. Some commentators have suggested that this incident would influence Kurosawa's later artistic career, as the director was seldom hesitant to confront unpleasant truths in his work.\n\nHeigo was academically gifted, but soon after failing to secure a place in Tokyo's foremost high school, he began to detach himself from the rest of the family, preferring to concentrate on his interest in foreign literature. In the late 1920s, Heigo became a benshi (silent film narrator) for Tokyo theaters showing foreign films and quickly made a name for himself. Akira, who at this point planned to become a painter, moved in with him, and the two brothers became inseparable. With Heigo's guidance, Akira devoured not only films but also theater and circus performances, while exhibiting his paintings and working for the left-wing Proletarian Artists' League. However, he was never able to make a living with his art, and, as he began to perceive most of the proletarian movement as \"putting unfulfilled political ideals directly onto the canvas\", he lost his enthusiasm for painting.\n\nWith the increasing production of talking pictures in the early 1930s, film narrators like Heigo began to lose work, and Akira moved back in with his parents. In July 1933, Heigo committed suicide. Kurosawa has commented on the lasting sense of loss he felt at his brother's death and the chapter of his autobiography (Something Like an Autobiography) that describes it\u2014written nearly half a century after the event\u2014is titled, \"A Story I Don't Want to Tell\". Only four months later, Kurosawa's eldest brother also died, leaving Akira, at age 23, the only one of the Kurosawa brothers still living, together with his three surviving sisters.\n\nDirector in training (1935\u20131941) \n\nIn 1935, the new film studio Photo Chemical Laboratories, known as P.C.L. (which later became the major studio Toho), advertised for assistant directors. Although he had demonstrated no previous interest in film as a profession, Kurosawa submitted the required essay, which asked applicants to discuss the fundamental deficiencies of Japanese films and find ways to overcome them. His half-mocking view was that if the deficiencies were fundamental, there was no way to correct them. Kurosawa's essay earned him a call to take the follow-up exams, and director Kajir\u014d Yamamoto, who was among the examiners, took a liking to Kurosawa and insisted that the studio hire him. The 25-year-old Kurosawa joined P.C.L. in February 1936.\n\nDuring his five years as an assistant director, Kurosawa worked under numerous directors, but by far the most important figure in his development was Yamamoto. Of his 24 films as A.D., he worked on 17 under Yamamoto, many of them comedies featuring the popular actor Ken'ichi Enomoto, known as \"Enoken\". Yamamoto nurtured Kurosawa's talent, promoting him directly from third assistant director to chief assistant director after a year. Kurosawa's responsibilities increased, and he worked at tasks ranging from stage construction and film development to location scouting, script polishing, rehearsals, lighting, dubbing, editing, and second-unit directing. In the last of Kurosawa's films as an assistant director for Yamamoto, Horse (Uma, 1941), Kurosawa took over most of the production, as his mentor was occupied with the shooting of another film.\n\nYamamoto advised Kurosawa that a good director needed to master screenwriting. Kurosawa soon realized that the potential earnings from his scripts were much higher than what he was paid as an assistant director. He later wrote or co-wrote all his films, and frequently penned screenplays for other directors such as Satsuo Yamamoto's film, A Triumph of Wings (Tsubasa no gaika, 1942). This outside scriptwriting would serve Kurosawa as a lucrative sideline lasting well into the 1960s, long after he became famous.\n\nWartime films and marriage (1942\u20131945) \nIn the two years following the release of Horse in 1941, Kurosawa searched for a story he could use to launch his directing career. Towards the end of 1942, about a year after the Japanese attack on Pearl Harbor, novelist Tsuneo Tomita published his Musashi Miy was spent on the budget as at 31 December 2017amoto-inspired judo novel, Sanshiro Sugata, the advertisements for which intrigued Kurosawa. He bought the book on its publication day, devoured it in one sitting, and immediately asked Toho to secure the film rights. Kurosawa's initial instinct proved correct as, within a few days, three other major Japanese studios also offered to buy the rights. Toho prevailed, and Kurosawa began pre-production on his debut work as director.\n\nShooting of Sanshiro Sugata began on location in Yokohama in December 1942. Production proceeded smoothly, but getting the completed film past the censors was an entirely different matter. The censorship office considered the work to be objectionably \"British-American\" by the standards of wartime Japan, and it was only through the intervention of director Yasujir\u014d Ozu, who championed the film, that Sanshiro Sugata was finally accepted for release on March 25, 1943. (Kurosawa had just turned 33.) The movie became both a critical and commercial success. Nevertheless, the censorship office would later decide to cut out some 18 minutes of footage, much of which is now considered lost.\n\nHe next turned to the subject of wartime female factory workers in The Most Beautiful, a propaganda film which he shot in a semi-documentary style in early 1944. To elicit realistic performances from his actresses, the director had them live in a real factory during the shoot, eat the factory food and call each other by their character names. He would use similar methods with his performers throughout his career.\n\nDuring production, the actress playing the leader of the factory workers, Y\u014dko Yaguchi, was chosen by her colleagues to present their demands to the director. She and Kurosawa were constantly at odds, and it was through these arguments that the two paradoxically became close. They married on May 21, 1945, with Yaguchi two months pregnant (she never resumed her acting career), and the couple would remain together until her death in 1985. They had two children, both surviving Kurosawa : a son, Hisao, born December 20, 1945, who served as producer on some of his father's last projects, and Kazuko, a daughter, born April 29, 1954, who became a costume designer.\n\nShortly before his marriage, Kurosawa was pressured by the studio against his will to direct a sequel to his debut film. The often blatantly propagandistic Sanshiro Sugata Part II, which premiered in May 1945, is generally considered one of his weakest pictures.\n\nKurosawa decided to write the script for a film that would be both censor-friendly and less expensive to produce. The Men Who Tread on the Tiger's Tail, based on the Kabuki play Kanjinch\u014d and starring the comedian Enoken, with whom Kurosawa had often worked during his assistant director days, was completed in September 1945. By this time, Japan had surrendered and the occupation of Japan had begun. The new American censors interpreted the values allegedly promoted in the picture as overly \"feudal\" and banned the work. It was not released until 1952, the year another Kurosawa film, Ikiru, was also released. Ironically, while in production, the film had already been savaged by Japanese wartime censors as too Western and \"democratic\" (they particularly disliked the comic porter played by Enoken), so the movie most probably would not have seen the light of day even if the war had continued beyond its completion.\n\nEarly postwar years to Red Beard (1946\u201365)\n\nFirst postwar works (1946\u201350) \nAfter the war, Kurosawa, influenced by the democratic ideals of the Occupation, sought to make films that would establish a new respect towards the individual and the self. The first such film, No Regrets for Our Youth (1946), inspired by both the 1933 Takigawa incident and the Hotsumi Ozaki wartime spy case, criticized Japan's prewar regime for its political oppression. Atypically for the director, the heroic central character is a woman, Yukie (Setsuko Hara), who, born into upper-middle-class privilege, comes to question her values in a time of political crisis. The original script had to be extensively rewritten and, because of its controversial theme and gender of its protagonist, the completed work divided critics. Nevertheless, it managed to win the approval of audiences, who turned variations on the film's title into a postwar catchphrase.\n\nHis next film, One Wonderful Sunday premiered in July 1947 to mixed reviews. It is a relatively uncomplicated and sentimental love story dealing with an impoverished postwar couple trying to enjoy, within the devastation of postwar Tokyo, their one weekly day off. The movie bears the influence of Frank Capra, D. W. Griffith and F. W. Murnau, each of whom was among Kurosawa's favorite directors. Another film released in 1947 with Kurosawa's involvement was the action-adventure thriller, Snow Trail, directed by Senkichi Taniguchi from Kurosawa's screenplay. It marked the debut of the intense young actor Toshiro Mifune. It was Kurosawa who, with his mentor Yamamoto, had intervened to persuade Toho to sign Mifune, during an audition in which the young man greatly impressed Kurosawa, but managed to alienate most of the other judges.\n\nDrunken Angel is often considered the director's first major work. Although the script, like all of Kurosawa's occupation-era works, had to go through rewrites due to American censorship, Kurosawa felt that this was the first film in which he was able to express himself freely. A gritty story of a doctor who tries to save a gangster (yakuza) with tuberculosis, it was also the first time that Kurosawa directed Mifune, who went on to play major roles in all but one of the director's next 16 films (the exception being Ikiru). While Mifune was not cast as the protagonist in Drunken Angel, his explosive performance as the gangster so dominates the drama that he shifted the focus from the title character, the alcoholic doctor played by Takashi Shimura, who had already appeared in several Kurosawa movies. However, Kurosawa did not want to smother the young actor's immense vitality, and Mifune's rebellious character electrified audiences in much the way that Marlon Brando's defiant stance would startle American film audiences a few years later. The film premiered in Tokyo in April 1948 to rave reviews and was chosen by the prestigious Kinema Junpo critics poll as the best film of its year, the first of three Kurosawa movies to be so honored.\n\nKurosawa, with producer S\u014djir\u014d Motoki and fellow directors and friends Kajiro Yamamoto, Mikio Naruse and Senkichi Taniguchi, formed a new independent production unit called Film Art Association (Eiga Geijutsu Ky\u014dkai). For this organization's debut work, and first film for Daiei studios, Kurosawa turned to a contemporary play by Kazuo Kikuta and, together with Taniguchi, adapted it for the screen. The Quiet Duel starred Toshiro Mifune as an idealistic young doctor struggling with syphilis, a deliberate attempt by Kurosawa to break the actor away from being typecast as gangsters. Released in March 1949, it was a box office success, but is generally considered one of the director's lesser achievements.\n\nHis second film of 1949, also produced by Film Art Association and released by Shintoho, was Stray Dog. It is a detective movie (perhaps the first important Japanese film in that genre) that explores the mood of Japan during its painful postwar recovery through the story of a young detective, played by Mifune, and his fixation on the recovery of his handgun, which was stolen by a penniless war veteran who proceeds to use it to rob and murder. Adapted from an unpublished novel by Kurosawa in the style of a favorite writer of his, Georges Simenon, it was the director's first collaboration with screenwriter Ryuzo Kikushima, who would later help to script eight other Kurosawa films. A famous, virtually wordless sequence, lasting over eight minutes, shows the detective, disguised as an impoverished veteran, wandering the streets in search of the gun thief; it employed actual documentary footage of war-ravaged Tokyo neighborhoods shot by Kurosawa's friend, Ishir\u014d Honda, the future director of Godzilla. The film is considered a precursor to the contemporary police procedural and buddy cop film genres.\n\nScandal, released by Shochiku in April 1950, was inspired by the director's personal experiences with, and anger towards, Japanese yellow journalism. The work is an ambitious mixture of courtroom drama and social problem film about free speech and personal responsibility, but even Kurosawa regarded the finished product as dramatically unfocused and unsatisfactory, and almost all critics agree. However, it would be Kurosawa's second film of 1950, Rashomon, that would ultimately win him, and Japanese cinema, a whole new international audience.\n\nInternational recognition (1950\u201358) \nAfter finishing Scandal, Kurosawa was approached by Daiei studios to make another film for them. Kurosawa picked a script by an aspiring young screenwriter, Shinobu Hashimoto, who would eventually work on nine of his films. Their first joint effort was based on Ry\u016bnosuke Akutagawa's experimental short story \"In a Grove\", which recounts the murder of a samurai and the rape of his wife from various different and conflicting points-of-view. Kurosawa saw potential in the script, and with Hashimoto's help, polished and expanded it and then pitched it to Daiei, who were happy to accept the project due to its low budget.\n\nThe shooting of Rashomon began on July 7, 1950, and, after extensive location work in the primeval forest of Nara, wrapped on August 17. Just one week was spent in hurried post-production, hampered by a studio fire, and the finished film premiered at Tokyo's Imperial Theatre on August 25, expanding nationwide the following day. The movie was met by lukewarm reviews, with many critics puzzled by its unique theme and treatment, but it was nevertheless a moderate financial success for Daiei.\n\nKurosawa's next film, for Shochiku, was The Idiot, an adaptation of the novel by the director's favorite writer, Fyodor Dostoyevsky. The story is relocated from Russia to Hokkaido, but otherwise adheres closely to the original, a fact seen by many critics as detrimental to the work. A studio-mandated edit shortened it from Kurosawa's original cut of 265 minutes to just 166 minutes, making the resulting narrative exceedingly difficult to follow. The severely edited film version is widely considered to be one of the director's least successful works and the original full-length version no longer exists. Contemporary reviews of the much shortened edited version were very negative, but the film was a moderate success at the box office, largely because of the popularity of one of its stars, Setsuko Hara.\n\nMeanwhile, unbeknownst to Kurosawa, Rashomon had been entered in the Venice Film Festival, due to the efforts of Giuliana Stramigioli, a Japan-based representative of an Italian film company, who had seen and admired the movie and convinced Daiei to submit it. On September 10, 1951, Rashomon was awarded the festival's highest prize, the Golden Lion, shocking not only Daiei but the international film world, which at the time was largely unaware of Japan's decades-old cinematic tradition.\n\nAfter Daiei briefly exhibited a subtitled print of the film in Los Angeles, RKO purchased distribution rights to Rashomon in the United States. The company was taking a considerable gamble. It had put out only one prior subtitled film in the American market, and the only previous Japanese talkie commercially released in New York had been Mikio Naruse's comedy, Wife! Be Like a Rose, in 1937: a critical and box-office flop. However, Rashomons commercial run, greatly helped by strong reviews from critics and even the columnist Ed Sullivan, earned $35,000 in its first three weeks at a single New York theatre, an almost unheard-of sum at the time.\n\nThis success in turn led to a vogue in America and the West for Japanese movies throughout the 1950s, replacing the enthusiasm for Italian neorealist cinema. By the end of 1952 Rashomon was released in Japan, the United States, and most of Europe. Among the Japanese film-makers whose work, as a result, began to win festival prizes and commercial release in the West were Kenji Mizoguchi (The Life of Oharu, Ugetsu, Sansho the Bailiff) and, somewhat later, Yasujir\u014d Ozu (Tokyo Story, An Autumn Afternoon)\u2014artists highly respected in Japan but, before this period, almost totally unknown in the West. Kurosawa's growing reputation among Western audiences in the 1950s would make Western audiences more sympathetic to the reception of later generations of Japanese film-makers ranging from Kon Ichikawa, Masaki Kobayashi, Nagisa Oshima and Shohei Imamura to Juzo Itami, Takeshi Kitano and Takashi Miike.\n\nHis career boosted by his sudden international fame, Kurosawa, now reunited with his original film studio, Toho (which would go on to produce his next 11 films), set to work on his next project, Ikiru. The movie stars Takashi Shimura as a cancer-ridden Tokyo bureaucrat, Watanabe, on a final quest for meaning before his death. For the screenplay, Kurosawa brought in Hashimoto as well as writer Hideo Oguni, who would go on to co-write twelve Kurosawa films. Despite the work's grim subject matter, the screenwriters took a satirical approach, which some have compared to the work of Brecht, to both the bureaucratic world of its hero and the U.S. cultural colonization of Japan. (American pop songs figure prominently in the film.) Because of this strategy, the film-makers are usually credited with saving the picture from the kind of sentimentality common to dramas about characters with terminal illnesses. Ikiru opened in October 1952 to rave reviews\u2014it won Kurosawa his second Kinema Junpo \"Best Film\" award\u2014and enormous box office success. It remains the most acclaimed of all the artist's films set in the modern era.\n\nIn December 1952, Kurosawa took his Ikiru screenwriters, Shinobu Hashimoto and Hideo Oguni, for a forty-five-day secluded residence at an inn to create the screenplay for his next movie, Seven Samurai. The ensemble work was Kurosawa's first proper samurai film, the genre for which he would become most famous. The simple story, about a poor farming village in Sengoku period Japan that hires a group of samurai to defend it against an impending attack by bandits, was given a full epic treatment, with a huge cast (largely consisting of veterans of previous Kurosawa productions) and meticulously detailed action, stretching out to almost three-and-a-half hours of screen time.\n\nThree months were spent in pre-production and a month in rehearsals. Shooting took up 148 days spread over almost a year, interrupted by production and financing troubles and Kurosawa's health problems. The film finally opened in April 1954, half a year behind its original release date and about three times over budget, making it at the time the most expensive Japanese film ever made. (However, by Hollywood standards, it was a quite modestly budgeted production, even for that time.) The film received positive critical reaction and became a big", "flag": 1, "segments": [[1692, 1702]], "strength": 5.5}
{"text": "Ancient Egypt was a civilization of ancient Africa, concentrated along the lower reaches of the Nile River, situated in the place that is now the country Egypt. Ancient Egyptian civilization followed prehistoric Egypt and coalesced around 3100BC (according to conventional Egyptian chronology) with the political unification of Upper and Lower Egypt under Menes (often identified with Narmer). The history of ancient Egypt occurred as a series of stable kingdoms, separated by periods of relative instability known as Intermediate Periods: the Old Kingdom of the Early Bronze Age, the Middle Kingdom of the Middle Bronze Age and the New Kingdom of the Late Bronze Age.\n\nEgypt reached the pinnacle of its power in the New Kingdom, ruling much of Nubia and a sizable portion of the Near East, after which it entered a period of slow decline. During the course of its history Egypt was invaded or conquered by a number of foreign powers, including the Hyksos, the Libyans, the Nubians, the Assyrians, the Achaemenid Persians, and the Macedonians under the command of Alexander the Great. The Greek Ptolemaic Kingdom, formed in the aftermath of Alexander's death, ruled Egypt until 30BC, when, under Cleopatra, it fell to the Roman Empire and became a Roman province.\n\nThe success of ancient Egyptian civilization came partly from its ability to adapt to the conditions of the Nile River valley for agriculture. The predictable flooding and controlled irrigation of the fertile valley produced surplus crops, which supported a more dense population, and social development and culture. With resources to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military intended to assert Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of a pharaoh, who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.\n\nThe many achievements of the ancient Egyptians include the quarrying, surveying and construction techniques that supported the building of monumental pyramids, temples, and obelisks; a system of mathematics, a practical and effective system of medicine, irrigation systems and agricultural production techniques, the first known planked boats, Egyptian faience and glass technology, new forms of literature, and the earliest known peace treaty, made with the Hittites. Ancient Egypt has left a lasting legacy. Its art and architecture were widely copied, and its antiquities carried off to far corners of the world. Its monumental ruins have inspired the imaginations of travelers and writers for millennia. A newfound respect for antiquities and excavations in the early modern period by Europeans and Egyptians led to the scientific investigation of Egyptian civilization and a greater appreciation of its cultural legacy.\n\nHistory\n\nThe Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization. Nomadic modern human hunter-gatherers began living in the Nile valley through the end of the Middle Pleistocene some 120,000 years ago. By the late Paleolithic period, the arid climate of Northern Africa became increasingly hot and dry, forcing the populations of the area to concentrate along the river region.\n\nPredynastic period\n\nIn Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were covered in treed savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.\n\nBy about 5500\u00a0BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt was the Badarian culture, which probably originated in the Western Desert; it was known for its high-quality ceramics, stone tools, and its use of copper.\n\nThe Badari was followed by the Naqada culture: the Amratian (Naqada I), the Gerzeh (Naqada II), and Semainean (Naqada III). These brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. In Naqada II times, early evidence exists of contact with the Near East, particularly Canaan and the Byblos coast. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Nekhen (in Greek, Hierakonpolis), and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east, initiating a period of Egypt-Mesopotamia relations.\n\nThe Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually were developed into a full system of hieroglyphs for writing the ancient Egyptian language.\n\nEarly Dynastic Period (c. 3150\u20132686 BC)\n\nThe Early Dynastic Period was approximately contemporary to the early Sumerian-Akkadian civilisation of Mesopotamia and of ancient Elam. The third-centuryBC Egyptian priest Manetho grouped the long line of kings from Menes to his own time into 30 dynasties, a system still used today. He began his official history with the king named \"Meni\" (or Menes in Greek), who was believed to have united the two kingdoms of Upper and Lower Egypt.\n\nThe transition to a unified state happened more gradually than ancient Egyptian writers represented, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have been the king Narmer, who is depicted wearing royal regalia on the ceremonial Narmer Palette, in a symbolic act of unification. In the Early Dynastic Period, which began about 3000BC, the first of the Dynastic kings solidified control over lower Egypt by establishing a capital at Memphis, from which he could control the labour force and agriculture of the fertile delta region, as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the kings during the early dynastic period was reflected in their elaborate mastaba tombs and mortuary cult structures at Abydos, which were used to celebrate the deified king after his death. The strong institution of kingship developed by the kings served to legitimize state control over the land, labour, and resources that were essential to the survival and growth of ancient Egyptian civilization.\n\nOld Kingdom (2686\u20132181 BC)\n\nMajor advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity and resulting population, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, drafted peasants to work on construction projects, and established a justice system to maintain peace and order. \n\nWith the rising importance of central administration in Egypt, a new class of educated scribes and officials arose who were granted estates by the king in payment for their services. Kings also made land grants to their mortuary cults and local temples, to ensure that these institutions had the resources to worship the king after his death. Scholars believe that five centuries of these practices slowly eroded the economic vitality of Egypt, and that the economy could no longer afford to support a large centralized administration. As the power of the kings diminished, regional governors called nomarchs began to challenge the supremacy of the office of king. This, coupled with severe droughts between 2200 and 2150BC, is believed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.\n\nFirst Intermediate Period (2181\u20132055 BC)\n\nAfter Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. Regional governors could not rely on the king for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the king, used their new-found independence to establish a thriving culture in the provinces. Once in control of their own resources, the provinces became economically richer\u2014which was demonstrated by larger and better burials among all social classes. In bursts of creativity, provincial artisans adopted and adapted cultural motifs formerly restricted to the royalty of the Old Kingdom, and scribes developed literary styles that expressed the optimism and originality of the period.\n\nFree from their loyalties to the king, local rulers began competing with each other for territorial control and political power. By 2160BC, rulers in Herakleopolis controlled Lower Egypt in the north, while a rival clan based in Thebes, the Intef family, took control of Upper Egypt in the south. As the Intefs grew in power and expanded their control northward, a clash between the two rival dynasties became inevitable. Around 2055BC the northern Theban forces under Nebhepetre Mentuhotep II finally defeated the Herakleopolitan rulers, reuniting the Two Lands. They inaugurated a period of economic and cultural renaissance known as the Middle Kingdom.\n\nMiddle Kingdom (2134\u20131690 BC)\n\nThe kings of the Middle Kingdom restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects. Mentuhotep II and his Eleventh Dynasty successors ruled from Thebes, but the vizier Amenemhat I, upon assuming the kingship at the beginning of the Twelfth Dynasty around 1985BC, shifted the kingdom's capital to the city of Itjtawy, located in Faiyum. From Itjtawy, the kings of the Twelfth Dynasty undertook a far-sighted land reclamation and irrigation scheme to increase agricultural output in the region. Moreover, the military reconquered territory in Nubia that was rich in quarries and gold mines, while laborers built a defensive structure in the Eastern Delta, called the \"Walls of the Ruler\", to defend against foreign attack.\n\nWith the kings having secured the country militarily and politically and with vast agricultural and mineral wealth at their disposal, the nation's population, arts, and religion flourished. In contrast to elitist Old Kingdom attitudes towards the gods, the Middle Kingdom displayed an increase in expressions of personal piety. Middle Kingdom literature featured sophisticated themes and characters written in a confident, eloquent style. The relief and portrait sculpture of the period captured subtle, individual details that reached new heights of technical sophistication.\n\nThe last great ruler of the Middle Kingdom, Amenemhat III, allowed Semitic-speaking Canaanite settlers from the Near East into the Delta region to provide a sufficient labour force for his especially active mining and building campaigns. These ambitious building and mining activities, however, combined with severe Nile floods later in his reign, strained the economy and precipitated the slow decline into the Second Intermediate Period during the later Thirteenth and Fourteenth dynasties. During this decline, the Canaanite settlers began to assume greater control of the Delta region, eventually coming to power in Egypt as the Hyksos.\n\nSecond Intermediate Period (1674\u20131549 BC) and the Hyksos\n\nAround 1785BC, as the power of the Middle Kingdom kings weakened, a Western Asian people called the Hyksos, who had already settled in the Delta, seized control of Egypt and established their capital at Avaris, forcing the former central government to retreat to Thebes. The king was treated as a vassal and expected to pay tribute. The Hyksos (\"foreign rulers\") retained Egyptian models of government and identified as kings, thereby integrating Egyptian elements into their culture. They and other invaders introduced new tools of warfare into Egypt, most notably the composite bow and the horse-drawn chariot.\n\nAfter retreating south, the native Theban kings found themselves trapped between the Canaanite Hyksos ruling the north and the Hyksos' Nubian allies, the Kushites, to the south. After years of vassalage, Thebes gathered enough strength to challenge the Hyksos in a conflict that lasted more than 30 years, until 1555BC. The kings Seqenenre Tao II and Kamose were ultimately able to defeat the Nubians to the south of Egypt, but failed to defeat the Hyksos. That task fell to Kamose's successor, Ahmose I, who successfully waged a series of campaigns that permanently eradicated the Hyksos' presence in Egypt. He established a new dynasty and, in the New Kingdom that followed, the military became a central priority for the kings, who sought to expand Egypt's borders and attempted to gain mastery of the Near East. them through water. However, a finding by researchers\n\nNew Kingdom (1549\u20131069 BC)\n\nThe New Kingdom pharaohs established a period of unprecedented prosperity by securing their borders and strengthening diplomatic ties with their neighbours, including the Mitanni Empire, Assyria, and Canaan. Military campaigns waged under Tuthmosis I and his grandson Tuthmosis III extended the influence of the pharaohs to the largest empire Egypt had ever seen. Beginning with Merneptah the rulers of Egypt adopted the title of pharaoh.\n\nBetween their reigns, Hatshepsut, a queen who established herself as pharaoh, launched many building projects, including the restoration of temples damaged by the Hyksos, and sent trading expeditions to Punt and the Sinai. When Tuthmosis III died in 1425BC, Egypt had an empire extending from Niya in north west Syria to the Fourth Cataract of the Nile in Nubia, cementing loyalties and opening access to critical imports such as bronze and wood.\n\nThe New Kingdom pharaohs began a large-scale building campaign to promote the god Amun, whose growing cult was based in Karnak. They also constructed monuments to glorify their own achievements, both real and imagined. The Karnak temple is the largest Egyptian temple ever built.\n\nAround 1350BC, the stability of the New Kingdom was threatened when Amenhotep IV ascended the throne and instituted a series of radical and chaotic reforms. Changing his name to Akhenaten, he touted the previously obscure sun deity Aten as the supreme deity, suppressed the worship of most other deities, and moved the capital to the new city of Akhetaten (modern-day Amarna). He was devoted to his new religion and artistic style. After his death, the cult of the Aten was quickly abandoned and the traditional religious order restored. The subsequent pharaohs, Tutankhamun, Ay, and Horemheb, worked to erase all mention of Akhenaten's heresy, now known as the Amarna Period.\n\nAround 1279BC, Ramesses II, also known as Ramesses the Great, ascended the throne, and went on to build more temples, erect more statues and obelisks, and sire more children than any other pharaoh in history. A bold military leader, Ramesses II led his army against the Hittites in the Battle of Kadesh (in modern Syria) and, after fighting to a stalemate, finally agreed to the first recorded peace treaty, around 1258BC.\n\nEgypt's wealth, however, made it a tempting target for invasion, particularly by the Libyan Berbers to the west, and the Sea Peoples, a conjectured confederation of seafarers from the Aegean Sea. Initially, the military was able to repel these invasions, but Egypt eventually lost control of its remaining territories in southern Canaan, much of it falling to the Assyrians. The effects of external threats were exacerbated by internal problems such as corruption, tomb robbery, and civil unrest. After regaining their power, the high priests at the temple of Amun in Thebes accumulated vast tracts of land and wealth, and their expanded power splintered the country during the Third Intermediate Period.\n\nThird Intermediate Period (1069\u2013653 BC)\n\nFollowing the death of Ramesses XI in 1078BC, Smendes assumed authority over the northern part of Egypt, ruling from the city of Tanis. The south was effectively controlled by the High Priests of Amun at Thebes, who recognized Smendes in name only. During this time, Libyans had been settling in the western delta, and chieftains of these settlers began increasing their autonomy. Libyan princes took control of the delta under Shoshenq I in 945BC, founding the so-called Libyan or Bubastite dynasty that would rule for some 200 years. Shoshenq also gained control of southern Egypt by placing his family members in important priestly positions. Libyan control began to erode as a rival dynasty in the delta arose in Leontopolis, and Kushites threatened from the south.\n\nAround 727BC the Kushite king Piye invaded northward, seizing control of Thebes and eventually the Delta, which established the 25th Dynasty. During the 25th Dynasty, Pharaoh Taharqa created an empire nearly as large as the New Kingdom's. Twenty-fifth Dynasty pharaohs built, or restored, temples and monuments throughout the Nile valley, including at Memphis, Karnak, Kawa, and Jebel Barkal. During this period, the Nile valley saw the first widespread construction of pyramids (many in modern Sudan) since the Middle Kingdom.\n\nEgypt's far-reaching prestige declined considerably toward the end of the Third Intermediate Period. Its foreign allies had fallen under the Assyrian sphere of influence, and by 700BC war between the two states became inevitable. Between 671 and 667BC the Assyrians began the Assyrian conquest of Egypt. The reigns of both Taharqa and his successor, Tanutamun, were filled with constant conflict with the Assyrians, against whom Egypt enjoyed several victories. Ultimately, the Assyrians pushed the Kushites back into Nubia, occupied Memphis, and sacked the temples of Thebes.\n\nLate Period (653\u2013332 BC)\n\nThe Assyrians left control of Egypt to a series of vassals who became known as the Saite kings of the Twenty-Sixth Dynasty. By 653BC, the Saite king Psamtik I was able to oust the Assyrians with the help of Greek mercenaries, who were recruited to form Egypt's first navy. Greek influence expanded greatly as the city-state of Naukratis became the home of Greeks in the Nile Delta. The Saite kings based in the new capital of Sais witnessed a brief but spirited resurgence in the economy and culture, but in 525BC, the powerful Persians, led by Cambyses II, began their conquest of Egypt, eventually capturing the pharaoh Psamtik III at the Battle of Pelusium. Cambyses II then assumed the formal title of pharaoh, but ruled Egypt from Iran, leaving Egypt under the control of a satrap. A few successful revolts against the Persians marked the 5th centuryBC, but Egypt was never able to permanently overthrow the Persians.\n\nFollowing its annexation by Persia, Egypt was joined with Cyprus and Phoenicia in the sixth satrapy of the Achaemenid Persian Empire. This first period of Persian rule over Egypt, also known as the Twenty-Seventh Dynasty, ended in 402BC, when Egypt regained independence under a series of native dynasties. The last of these dynasties, the Thirtieth, proved to be the last native royal house of ancient Egypt, ending with the kingship of Nectanebo II. A brief restoration of Persian rule, sometimes known as the Thirty-First Dynasty, began in 343BC, but shortly after, in 332BC, the Persian ruler Mazaces handed Egypt over to Alexander the Great without a fight.\n\nPtolemaic period (332\u201330 BC)\n\nIn 332BC, Alexander the Great conquered Egypt with little resistance from the Persians and was welcomed by the Egyptians as a deliverer. The administration established by Alexander's successors, the Macedonian Ptolemaic Kingdom, was based on an Egyptian model and based in the new capital city of Alexandria. The city showcased the power and prestige of Hellenistic rule, and became a seat of learning and culture, centered at the famous Library of Alexandria. The Lighthouse of Alexandria lit the way for the many ships that kept trade flowing through the city\u2014as the Ptolemies made commerce and revenue-generating enterprises, such as papyrus manufacturing, their top priority.\n\nHellenistic culture did not supplant native Egyptian culture, as the Ptolemies supported time-honored traditions in an effort to secure the loyalty of the populace. They built new temples in Egyptian style, supported traditional cults, and portrayed themselves as pharaohs. Some traditions merged, as Greek and Egyptian gods were syncretized into composite deities, such as Serapis, and classical Greek forms of sculpture influenced traditional Egyptian motifs. Despite their efforts to appease the Egyptians, the Ptolemies were challenged by native rebellion, bitter family rivalries, and the powerful mob of Alexandria that formed after the death of Ptolemy IV. In addition, as Rome relied more heavily on imports of grain from Egypt, the Romans took great interest in the political situation in the country. Continued Egyptian revolts, ambitious politicians, and powerful opponents from the Near East made this situation unstable, leading Rome to send forces to secure the country as a province of its empire.\n\nRoman period (30 BC \u2013 AD 641)\n\nEgypt became a province of the Roman Empire in 30BC, following the defeat of Mark Antony and Ptolemaic Queen Cleopatra VII by Octavian (later Emperor Augustus) in the Battle of Actium. The Romans relied heavily on grain shipments from Egypt, and the Roman army, under the control of a prefect appointed by the emperor, quelled rebellions, strictly enforced the collection of heavy taxes, and prevented attacks by bandits, which had become a notorious problem during the period. Alexandria became an increasingly important center on the trade route with the orient, as exotic luxuries were in high demand in Rome.\n\nAlthough the Romans had a more hostile attitude than the Greeks towards the Egyptians, some traditions such as mummification and worship of the traditional gods continued. The art of mummy portraiture flourished, and some Roman emperors had themselves depicted as pharaohs, though not to the extent that the Ptolemies had. The former lived outside Egypt and did not perform the ceremonial functions of Egyptian kingship. Local administration became Roman in style and closed", "flag": 1, "segments": [[2953, 2963]], "strength": 5.5}
{"text": "ABBA (, ) are  a Swedish pop group formed in Stockholm in 1972 by Agnetha F\u00e4ltskog, Bj\u00f6rn Ulvaeus, Benny Andersson, and Anni-Frid Lyngstad. The group's name is an acronym of the first letters of their first names arranged as a palindrome. One of the most popular and successful musical groups of all time, they became one of the best-selling music acts in the history of popular music, topping the charts worldwide from 1974 to 1983, and in 2021.\n\nIn 1974, ABBA were Sweden's first winner of the Eurovision Song Contest with the song \"Waterloo\", which in 2005 was chosen as the best song in the competition's history as part of the 50th anniversary celebration of the contest. During the band's main active years, it consisted of two married couples: F\u00e4ltskog and Ulvaeus, and Lyngstad and Andersson. With the increase of their popularity, their personal lives suffered, which eventually resulted in the collapse of both marriages. The relationship changes were reflected in the group's music, with latter compositions featuring darker and more introspective lyrics. After ABBA separated in December 1982, Andersson and Ulvaeus continued their success writing music for multiple audiences including stage, musicals and movies, while F\u00e4ltskog and Lyngstad pursued solo careers.\n\nTen years after the group broke up, a compilation, ABBA Gold, was released, becoming a worldwide best-seller. In 1999, ABBA's music was adapted into Mamma Mia!, a successful musical that toured worldwide and, as of November 2021, is still in the top-ten longest running productions on both Broadway (closed in 2015) and the West End (still running). A film of the same name, released in 2008, became the highest-grossing film in the United Kingdom that year. A sequel, Mamma Mia! Here We Go Again, was released in 2018.\n\nIn 2016, the group reunited and started working on a digital avatar concert tour. Newly recorded songs were announced in 2018. Voyage, their first new album in 40 years, was released on November 5, 2021. ABBA Voyage, a concert residency featuring ABBA as virtual avatars \u2013 dubbed 'ABBAtars' \u2013 is due to take place in London from May to December 2022.\n\nABBA is one of the best-selling music artists of all time, with record sales estimated to be between 150 million to 385 million sold worldwide and the group were ranked 3rd best-selling singles artists in the United Kingdom with a total of 11.3 million singles sold by 3 November 2012. ABBA were the first group from a non-English-speaking country to achieve consistent success in the charts of English-speaking countries, including the United States, United Kingdom, Republic of Ireland, Canada, Australia, New Zealand and South Africa. They are the best-selling Swedish band of all time and the best-selling band originating in continental Europe. ABBA had eight consecutive number-one albums in the UK. The group also enjoyed significant success in Latin America and recorded a collection of their hit songs in Spanish. ABBA were inducted into the Vocal Group Hall of Fame in 2002. The group were inducted into the Rock and Roll Hall of Fame in 2010, the first and only recording artists to receive this honour from outside an Anglophone country. In 2015, their song \"Dancing Queen\" was inducted into the Recording Academy's Grammy Hall of Fame.\n\nHistory\n\n1958\u20131970: Before ABBA\n\nMember origins and collaboration \nBenny Andersson (born 16 December 1946 in Stockholm, Sweden) became (at age 18) a member of a popular Swedish pop-rock group, the Hep Stars, that performed, among other things, covers of international hits. The Hep Stars were known as \"the Swedish Beatles\". They also set up Hep House, their equivalent of Apple Corps. Andersson played the keyboard and eventually started writing original songs for his band, many of which became major hits, including \"No Response\", which hit number three in 1965, and \"Sunny Girl\", \"Wedding\", and \"Consolation\", all of which hit number one in 1966. Andersson also had a fruitful songwriting collaboration with Lasse Berghagen, with whom he wrote his first Svensktoppen entry, \"Sagan om lilla Sofie\" (\"The tale of Little Sophie\") in 1968.\n\nBj\u00f6rn Ulvaeus (born 25 April 1945 in Gothenburg, Sweden) also began his musical career at the age of 18 (as a singer and guitarist), when he fronted the Hootenanny Singers, a popular Swedish folk\u2013skiffle group. Ulvaeus started writing English-language songs for his group, and even had a brief solo career alongside. The Hootenanny Singers and the Hep Stars sometimes crossed paths while touring. In June 1966, Ulvaeus and Andersson decided to write a song together. Their first attempt was \"Isn't It Easy to Say\", a song was later recorded by the Hep Stars. Stig Anderson was the manager of the Hootenanny Singers and founder of the Polar Music label. He saw potential in the collaboration, and encouraged them to write more. The two also began playing occasionally with the other's bands on stage and on record, although it was not until 1969 that the pair wrote and produced some of their first real hits together: \"Ljuva sextital\" (\"Sweet Sixties\"), recorded by Brita Borg, and the Hep Stars' 1969 hit \"Speleman\" (\"Fiddler\").\n\nAndersson wrote and submitted the song \"Hej, Clown\" for Melodifestivalen 1969, the national festival to select the Swedish entry to the Eurovision Song Contest. The song tied for first place, but re-voting relegated Andersson's song to second place. On that occasion Andersson briefly met his future spouse, singer Anni-Frid Lyngstad, who also participated in the contest. A month later, the two had become a couple. As their respective bands began to break up during 1969, Andersson and Ulvaeus teamed up and recorded their first album together in 1970, called Lycka (\"Happiness\"), which included original songs sung by both men. Their partners were often present in the recording studio, and sometimes added backing vocals; F\u00e4ltskog even co-wrote a song with the two. Ulvaeus still occasionally recorded and performed with the Hootenanny Singers until the middle of 1974, and Andersson took part in producing their records.\n\nAnni-Frid \"Frida\" Lyngstad (born 15 November 1945 in Bj\u00f8rk\u00e5sen in Ballangen, Norway) sang from the age of 13 with various dance bands, and worked mainly in a jazz-oriented cabaret style. She also formed her own band, the Anni-Frid Four. In the middle of 1967, she won a national talent competition with \"En ledig dag\" (\"A Day Off\") a Swedish version of the bossa nova song \"A Day in Portofino\", which is included in the EMI compilation Frida 1967\u20131972. The first prize was a recording contract with EMI Sweden and to perform live on the most popular TV shows in the country. This TV performance, amongst many others, is included in the 3\u00bd-hour documentary Frida \u2013 The DVD. Lyngstad released several schlager style singles on EMI without much success. When Benny Andersson started to produce her recordings in 1971, she had her first number-one single, \"Min egen stad\" (\"My Own Town\"), written by Benny and featuring all the future ABBA members on backing vocals. Lyngstad toured and performed regularly in the folkpark circuit and made appearances on radio and TV. She met Ulvaeus briefly in 1963 during a talent contest, and F\u00e4ltskog during a TV show in early 1968.\n\nLyngstad linked up with her future bandmates in 1969. On 1 March 1969, she participated in the Melodifestival, where she met Andersson for the first time. A few weeks later they met again during a concert tour in southern Sweden and they soon became a couple. Andersson produced her single \"Peter Pan\" in September 1969\u2014her first collaboration with Benny & Bj\u00f6rn, as they had written the song. Andersson would then produce Lyngstad's debut studio album, Frida, which was released in March 1971. Lyngstad also played in several revues and cabaret shows in Stockholm between 1969 and 1973. After ABBA formed, she recorded another successful album in 1975, Frida ensam, which included a Swedish rendition of \"Fernando\", a hit on the Swedish radio charts before the English version was released.\n\nAgnetha F\u00e4ltskog (born 5 April 1950 in J\u00f6nk\u00f6ping, Sweden) sang with a local dance band headed by Bernt Enghardt who sent a demo recording of the band to Karl Gerhard Lundkvist. The demo tape featured a song written and sung by Agnetha: \"Jag var s\u00e5 k\u00e4r\" (\"I Was So in Love\"). Lundkvist was so impressed with her voice that he was convinced she would be a star. After going through considerable effort to locate the singer, he arranged for Agnetha to come to Stockholm and to record two of her own songs. This led to Agnetha at the age of 18 having a number-one record in Sweden with a self-composed song, which later went on to sell over 80,000 copies. She was soon noticed by the critics and songwriters as a talented singer/songwriter of schlager style songs. F\u00e4ltskog's main inspiration in her early years was singers such as Connie Francis. Along with her own compositions, she recorded covers of foreign hits and performed them on tours in Swedish folkparks. Most of her biggest hits were self-composed, which was quite unusual for a female singer in the 1960s. Agnetha released four solo LPs between 1968 and 1971. She had many successful singles in the Swedish charts.\n\nDuring filming of a Swedish TV special in May 1969, F\u00e4ltskog met Ulvaeus and they married on 6 July 1971. F\u00e4ltskog and Ulvaeus eventually were involved in each other's recording sessions, and soon even Andersson and Lyngstad added backing vocals to F\u00e4ltskog's third studio album, Som jag \u00e4r (\"As I Am\") (1970). In 1972, F\u00e4ltskog starred as Mary Magdalene in the original Swedish production of Jesus Christ Superstar and attracted favourable reviews. Between 1967 and 1975, F\u00e4ltskog released five studio albums.\n\nFirst live performance and the start of \"Festfolket\" \nAn attempt at combining their talents occurred in April 1970 when the two couples went on holiday together to the island of Cyprus. What started as singing for fun on the beach ended up as an improvised live performance in front of the United Nations soldiers stationed on the island. Andersson and Ulvaeus were at this time recording their first album together, Lycka, which was to be released in September 1970. F\u00e4ltskog and Lyngstad added backing vocals on several tracks during June, and the idea of their working together saw them launch a stage act, \"Festfolket\" (which translates from Swedish to \"Party People\" and in pronunciation also \"engaged couples\"), on 1 November 1970 in Gothenburg.\n\nThe cabaret show attracted generally negative reviews, except for the performance of the Andersson and Ulvaeus hit \"Hej, gamle man\" (\"Hello, Old Man\")\u2013the first Bj\u00f6rn and Benny recording to feature all four. They also performed solo numbers from respective albums, but the lukewarm reception convinced the foursome to shelve plans for working together for the time being, and each soon concentrated on individual projects again.\n\nFirst record together \"Hej, gamle man\" \n\"Hej, gamle man\", a song about an old Salvation Army soldier, became the quartet's first hit. The record was credited to Bj\u00f6rn & Benny and reached number five on the sales charts and number one on Svensktoppen, staying on the latter chart (which was not a chart linked to sales or airplay) for 15 weeks.\n\nIt was during 1971 that the four artists began working together more, adding vocals to the others' recordings. F\u00e4ltskog, Andersson and Ulvaeus toured together in May, while Lyngstad toured on her own. Frequent recording sessions brought the foursome closer together during the summer.\n\n1970\u20131973: Forming the group \nAfter the 1970 release of Lycka, two more singles credited to \"Bj\u00f6rn & Benny\" were released in Sweden, \"Det kan ingen doktor hj\u00e4lpa\" (\"No Doctor Can Help with That\") and \"T\u00e4nk om jorden vore ung\" (\"Imagine If Earth Was Young\"), with more prominent vocals by F\u00e4ltskog and Lyngstad\u2013and moderate chart success.\n\nF\u00e4ltskog and Ulvaeus, now married, started performing together with Andersson on a regular basis at the Swedish folkparks in the middle of 1971.\n\nStig Anderson, founder and owner of Polar Music, was determined to break into the mainstream international market with music by Andersson and Ulvaeus. \"One day the pair of you will write a song that becomes a worldwide hit,\" he predicted. Stig Anderson encouraged Ulvaeus and Andersson to write a song for Melodifestivalen, and after two rejected entries in 1971, Andersson and Ulvaeus submitted their new song \"S\u00e4g det med en s\u00e5ng\" (\"Say It with a Song\") for the 1972 contest, choosing newcomer Lena Anderson to perform. The song came in third place, encouraging Stig Anderson, and became a hit in Sweden.\n\nThe first signs of foreign success came as a surprise, as the Andersson and Ulvaeus single \"She's My Kind of Girl\" was released through Epic Records in Japan in March 1972, giving the duo a Top 10 hit. Two more singles were released in Japan, \"En Carousel\" (\"En Karusell\" in Scandinavia, an earlier version of \"Merry-Go-Round\") and \"Love Has Its Ways\" (a song they wrote with K\u014dichi Morita).\n\nFirst hit as Bj\u00f6rn, Benny, Agnetha & Anni-Frid \nUlvaeus and Andersson persevered with their songwriting and experimented with new sounds and vocal arrangements. \"People Need Love\" was released in June 1972, featuring guest vocals by the women, who were now given much greater prominence. Stig Anderson released it as a single, credited to Bj\u00f6rn & Benny, Agnetha & Anni-Frid. The song peaked at number 17 in the Swedish combined single and album charts, enough to convince them they were on to something. The single also became the first record to chart for the quartet in the United States, where it peaked at number 114 on the Cashbox singles chart and number 117 on the Record World singles chart. Labelled as Bj\u00f6rn & Benny (with Svenska Flicka- meaning Swedish Girl), it was released there through Playboy Records. This association with Playboy caused much confusion, many mistaking it for soft-core porn, including the record companies in the US and the UK, according to Ulvaeus, since it was common in Sweden at the time. According to Stig Anderson, \"People Need Love\" could have been a much bigger American hit, but a small label like Playboy Records did not have the distribution resources to meet the demand for the single from retailers and radio programmers.\n\n\"Ring Ring\" \n\nIn 1973, the band and their manager Stig Anderson decided to have another try at Melodifestivalen, this time with the song \"Ring Ring\". The studio sessions were handled by Michael B. Tretow, who experimented with a \"wall of sound\" production technique that became a distinctive new sound thereafter associated with ABBA. Stig Anderson arranged an English translation of the lyrics by Neil Sedaka and Phil Cody and they thought this would be a success. However, on 10 February 1973, the song came third in Melodifestivalen; thus it never reached the Eurovision Song Contest itself. Nevertheless, the group released their debut studio album, also called Ring Ring. The album did well and the \"Ring Ring\" single was a hit in many parts of Europe and also in South Africa. However, Stig Anderson felt that the true breakthrough could only come with a UK or US hit.\n\nWhen Agnetha F\u00e4ltskog gave birth to her daughter Linda in 1973, she was replaced for a short period by Inger Brundin on a trip to West Germany.\n\nOfficial naming \nIn 1973, Stig Anderson, tired of unwieldy names, started to refer to the group privately and publicly as ABBA (a palindrome). At first, this was a play on words, as Abba is also the name of a well-known fish-canning company in Sweden, and itself an abbreviation. However, since the fish-canners were unknown outside Sweden, Anderson came to believe the name would work in international markets. A competition to find a suitable name for the group was held in a Gothenburg newspaper and it was officially announced in the summer that the group were to be known as \"ABBA\". The group negotiated with the canners for the rights to the name. Fred Bronson reported for Billboard that F\u00e4ltskog told him in a 1988 interview that \"[ABBA] had to ask permission and the factory said, 'O.K., as long as you don't make us feel ashamed for what you're doing. \"ABBA\" is an acronym formed from the first letters of each group member's first name: Agnetha, Bj\u00f6rn, Benny, Anni-Frid. The earliest known example of \"ABBA\" written on paper is on a recording session sheet from the Metronome Studio in Stockholm dated 16 October 1973. This was first written as \"Bj\u00f6rn, Benny, Agnetha & Frida\", but was subsequently crossed out with \"ABBA\" written in large letters on top.\n\nOfficial logo \n\nTheir official logo, distinct with the backward 'B', was designed by Rune S\u00f6derqvist, who designed most of ABBA's record sleeves. The ambigram first appeared on the French compilation album, Golden Double Album, released in May 1976 by Disques Vogue, and would henceforth be used for all official releases.\n\nThe idea for the official logo was made by the German photographer  on a velvet jumpsuit photo shoot for the teenage magazine Bravo. In the photo, the ABBA members held giant initial letters of their names. After the pictures were made, Heilemann found out that Benny Andersson reversed his letter \"B\"; this prompted discussions about the mirrored \"B\", and the members of ABBA agreed on the mirrored letter. From 1976 onward, the first \"B\" in the logo version of the name was \"mirror-image\" reversed on the band's promotional material, thus becoming the group's registered trademark.\n\nFollowing their acquisition of the group's catalogue, PolyGram began using variations of the ABBA logo, employing a different font. In 1992, Polygram added a crown emblem to it for the first release of the ABBA Gold: Greatest Hits compilation. After Universal Music purchased PolyGram (and, thus, ABBA's label Polar Music International), control of the group's catalogue returned to Stockholm. Since then, the original logo has been reinstated on all official products.\n\n1973\u20131976: Breakthrough\n\nEurovision Song Contest 1974 \n\nAs the group entered the Melodifestivalen with \"Ring Ring\" but failed to qualify as the 1973 Swedish entry, Stig Anderson immediately started planning for the 1974 contest. Ulvaeus, Andersson and Stig Anderson believed in the possibilities of using the Eurovision Song Contest as a way to make the music business aware of them as songwriters, as well as the band itself. In late 1973, they were invited by Swedish television to contribute a song for the Melodifestivalen 1974 and from a number of new songs, the upbeat song \"Waterloo\" was chosen; the group were now inspired by the growing glam rock scene in England.\n\nABBA won their nation's hearts on Swedish television on 9 February 1974, and with this third attempt were far more experienced and better prepared for the Eurovision Song Contest. Winning the 1974 Eurovision Song Contest on 6 April 1974 (and singing \"Waterloo\" in English instead of their native tongue) gave ABBA the chance to tour Europe and perform on major television shows; thus the band saw the \"Waterloo\" single chart in many European countries. Following their success at the Eurovision Song Contest, ABBA spent an evening of glory partying in the appropriately named first-floor Napoleon suite of The Grand Brighton Hotel.\n\n\"Waterloo\" was ABBA's first major hit in numerous countries, becoming their first number-one single in nine western and northern European countries, including the big markets of the UK and West Germany, and in South Africa. It also made the top ten in several other countries, including rising to number three in Spain, number four in Australia and France, and number seven in Canada. In the United States, the song peaked at number six on the Billboard Hot 100 chart, paving the way for their first album and their first trip as a group there. Albeit a short promotional visit, it included their first performance on American television, The Mike Douglas Show. The album Waterloo only peaked at number 145 on the Billboard 200 chart, but received unanimous high praise from the US critics: Los Angeles Times called it \"a compelling and fascinating debut album that captures the spirit of mainstream pop quite effectively... an immensely enjoyable and pleasant project\", while Creem characterised it as \"a perfect blend of exceptional, lovable compositions\".\n\nABBA's follow-up single, \"Honey, Honey\", peaked at number 27 on the US Billboard Hot 100, reached the top twenty in several other countries, and was a number-two hit in West Germany although it only reached the top 30 in Australia and the US. In the United Kingdom, ABBA's British record label, Epic, decided to re-release a remixed version are \"becoming \"the new reality for our of \"Ring Ring\" instead of \"Honey, Honey\", and a cover version of the latter by Sweet Dreams peaked at number 10. Both records debuted on the UK chart within one week of each other. \"Ring Ring\" failed to reach the Top 30 in the UK, increasing growing speculation that the group were simply a Eurovision one-hit wonder.\n\nPost-Eurovision \nIn November 1974, ABBA embarked on their first European tour, playing dates in Denmark, West Germany and Austria. It was not as successful as the band had hoped, since most of the venues did not sell out. Due to a lack of demand, they were even forced to cancel a few shows, including a sole concert scheduled in Switzerland. The second leg of the tour, which took them through Scandinavia in January 1975, was very different. They played to full houses everywhere and finally got the reception they had aimed for. Live performances continued in the middle of 1975 when ABBA embarked on a fourteen open-air date tour of Sweden and Finland. Their Stockholm show at the Gr\u00f6na Lund amusement park had an estimated audience of 19,200. Bj\u00f6rn Ulvaeus later said that \"", "flag": 1, "segments": [[4759, 4769]], "strength": 5.5}
{"text": "Arsenic is a chemical element with the symbol As and atomic number 33. Arsenic occurs in many minerals, usually in combination with sulfur and metals, but also as a pure elemental crystal. Arsenic is a metalloid. It has various allotropes, but only the gray form, which has a metallic appearance, is important to industry.\n\nThe primary use of arsenic is in alloys of lead (for example, in car batteries and ammunition). Arsenic is a common n-type dopant in semiconductor electronic devices. It is also a component of the III-V compound semiconductor gallium arsenide. Arsenic and its compounds, especially the trioxide, are used in the production of pesticides, treated wood products, herbicides, and insecticides. These applications are declining with the increasing recognition of the toxicity of arsenic and its compounds.\n\nA few species of bacteria are able to use arsenic compounds as respiratory metabolites expected a Marvel superhero movie to be as big and. Trace quantities of arsenic are an essential dietary element in rats, hamsters, goats, chickens, and presumably other species. A role in human metabolism is not known. However, arsenic poisoning occurs in multicellular life if quantities are larger than needed. Arsenic contamination of groundwater is a problem that affects millions of people across the world.\n\nThe United States' Environmental Protection Agency states that all forms of arsenic are a serious risk to human health. The United States' Agency for Toxic Substances and Disease Registry ranked arsenic as number 1 in its 2001 Priority List of Hazardous Substances at Superfund sites. Arsenic is classified as a Group-A carcinogen.\n\nCharacteristics\n\nPhysical characteristics \n\nThe three most common arsenic allotropes are gray, yellow, and black arsenic, with gray being the most common. Gray arsenic (\u03b1-As, space group Rm No. 166) adopts a double-layered structure consisting of many interlocked, ruffled, six-membered rings. Because of weak bonding between the layers, gray arsenic is brittle and has a relatively low Mohs hardness of 3.5. Nearest and next-nearest neighbors form a distorted octahedral complex, with the three atoms in the same double-layer being slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 5.73\u00a0g/cm3. Gray arsenic is a semimetal, but becomes a semiconductor with a bandgap of 1.2\u20131.4\u00a0eV if amorphized. Gray arsenic is also the most stable form. \nYellow arsenic is soft and waxy, and somewhat similar to tetraphosphorus (). Both have four atoms arranged in a tetrahedral structure in which each atom is bound to each of the other three atoms by a single bond. This unstable allotrope, being molecular, is the most volatile, least dense, and most toxic. Solid yellow arsenic is produced by rapid cooling of arsenic vapor,. It is rapidly transformed into gray arsenic by light. The yellow form has a density of 1.97\u00a0g/cm3. Black arsenic is similar in structure to black phosphorus.\nBlack arsenic can also be formed by cooling vapor at around 100\u2013220\u00a0\u00b0C and by crystallization of amorphous arsenic in the presence of mercury vapors. It is glassy and brittle. It is also a poor electrical conductor. As arsenic's triple point is at 3.628 MPa (35.81 atm), it does not have a melting point at standard pressure but instead sublimes from solid to vapor at 887 K (615\u00a0\u00b0C or 1137\u00a0\u00b0F).\n\nIsotopes \n\nArsenic occurs in nature as a monoisotopic element, composed of one stable isotope, 75As. As of 2003, at least 33 radioisotopes have also been synthesized, ranging in atomic mass from 60 to 92. The most stable of these is 73As with a half-life of 80.30\u00a0days. All other isotopes have half-lives of under one day, with the exception of 71As (t1/2=65.30 hours), 72As (t1/2=26.0 hours), 74As (t1/2=17.77 days), 76As (t1/2=1.0942 days), and 77As (t1/2=38.83 hours). Isotopes that are lighter than the stable 75As tend to decay by \u03b2+ decay, and those that are heavier tend to decay by \u03b2\u2212 decay, with some exceptions.\n\nAt least 10 nuclear isomers have been described, ranging in atomic mass from 66 to 84. The most stable of arsenic's isomers is 68mAs with a half-life of 111\u00a0seconds.\n\nChemistry \n\nArsenic has a similar electronegativity and ionization energies to its lighter congener phosphorus and accordingly readily forms covalent molecules with most of the nonmetals. Though stable in dry air, arsenic forms a golden-bronze tarnish upon exposure to humidity which eventually becomes a black surface layer. When heated in air, arsenic oxidizes to arsenic trioxide; the fumes from this reaction have an odor resembling garlic. This odor can be detected on striking arsenide minerals such as arsenopyrite with a hammer. It burns in oxygen to form arsenic trioxide and arsenic pentoxide, which have the same structure as the more well-known phosphorus compounds, and in fluorine to give arsenic pentafluoride. Arsenic (and some arsenic compounds) sublimes upon heating at atmospheric pressure, converting directly to a gaseous form without an intervening liquid state at. The triple point is 3.63\u00a0MPa and. Arsenic makes arsenic acid with concentrated nitric acid, arsenous acid with dilute nitric acid, and arsenic trioxide with concentrated sulfuric acid; however, it does not react with water, alkalis, or non-oxidising acids. Arsenic reacts with metals to form arsenides, though these are not ionic compounds containing the As3\u2212 ion as the formation of such an anion would be highly endothermic and even the group 1 arsenides have properties of intermetallic compounds. Like germanium, selenium, and bromine, which like arsenic succeed the 3d transition series, arsenic is much less stable in the group oxidation state of +5 than its vertical neighbors phosphorus and antimony, and hence arsenic pentoxide and arsenic acid are potent oxidizers.\n\nCompounds \n\nCompounds of arsenic resemble in some respects those of phosphorus which occupies the same group (column) of the periodic table. The most common oxidation states for arsenic are: \u22123 in the arsenides, which are alloy-like intermetallic compounds, +3 in the arsenites, and +5 in the arsenates and most organoarsenic compounds. Arsenic also bonds readily to itself as seen in the square As ions in the mineral skutterudite. In the +3 oxidation state, arsenic is typically pyramidal owing to the influence of the lone pair of electrons.\n\nInorganic compounds \n\nOne of the simplest arsenic compound is the trihydride, the highly toxic, flammable, pyrophoric arsine (AsH3). This compound is generally regarded as stable, since at room temperature it decomposes only slowly. At temperatures of 250\u2013300\u00a0\u00b0C decomposition to arsenic and hydrogen is rapid. Several factors, such as humidity, presence of light and certain catalysts (namely aluminium) facilitate the rate of decomposition. It oxidises readily in air to form arsenic trioxide and water, and analogous reactions take place with sulfur and selenium instead of oxygen.\n\nArsenic forms colorless, odorless, crystalline oxides As2O3 (\"white arsenic\") and As2O5 which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic(V) acid is a weak acid and the salts are called arsenates, the most common arsenic contamination of groundwater, and a problem that affects many people. Synthetic arsenates include Scheele's Green (cupric hydrogen arsenate, acidic copper arsenate), calcium arsenate, and lead hydrogen arsenate. These three have been used as agricultural insecticides and poisons.\n\nThe protonation steps between the arsenate and arsenic acid are similar to those between phosphate and phosphoric acid. Unlike phosphorous acid, arsenous acid is genuinely tribasic, with the formula As(OH)3.\n\nA broad variety of sulfur compounds of arsenic are known. Orpiment (As2S3) and realgar (As4S4) are somewhat abundant and were formerly used as painting pigments. In As4S10, arsenic has a formal oxidation state of +2 in As4S4 which features As-As bonds so that the total covalency of As is still 3. Both orpiment and realgar, as well as As4S3, have selenium analogs; the analogous As2Te3 is known as the mineral kalgoorlieite, and the anion As2Te\u2212 is known as a ligand in cobalt complexes.\n\nAll trihalides of arsenic(III) are well known except the astatide, which is unknown. Arsenic pentafluoride (AsF5) is the only important pentahalide, reflecting the lower stability of the +5 oxidation state; even so, it is a very strong fluorinating and oxidizing agent. (The pentachloride is stable only below \u221250\u00a0\u00b0C, at which temperature it decomposes to the trichloride, releasing chlorine gas.)\n\nAlloys \n\nArsenic is used as the group 5 element in the III-V semiconductors gallium arsenide, indium arsenide, and aluminium arsenide. The valence electron count of GaAs is the same as a pair of Si atoms, but the band structure is completely different which results in distinct bulk properties. Other arsenic alloys include the II-V semiconductor cadmium arsenide.\n\nOrganoarsenic compounds \n\nA large variety of organoarsenic compounds are known. Several were developed as chemical warfare agents during World War I, including vesicants such as lewisite and vomiting agents such as adamsite. Cacodylic acid, which is of historic and practical interest, arises from the methylation of arsenic trioxide, a reaction that has no analogy in phosphorus chemistry.  Cacodyl was the first organometallic compound known (even though arsenic is not a true metal) and was named from the Greek \u03ba\u03b1\u03ba\u03c9\u03b4\u03af\u03b1 \"stink\" for its offensive odor; it is very poisonous.\n\nOccurrence and production \n\nArsenic comprises about 1.5\u00a0ppm\u00a0(0.00015%) of the Earth's crust, and is the 53rd most abundant element. Typical background concentrations of arsenic do not exceed 3\u00a0ng/m3 in the atmosphere; 100\u00a0mg/kg in soil; 400\u00a0\u03bcg/kg in vegetation; 10\u00a0\u03bcg/L in freshwater and 1.5 \u03bcg/L in seawater.\n\nMinerals with the formula MAsS and MAs2 (M = Fe, Ni, Co) are the dominant commercial sources of arsenic, together with realgar (an arsenic sulfide mineral) and native (elemental) arsenic. An illustrative mineral is arsenopyrite (FeAsS), which is structurally related to iron pyrite. Many minor As-containing minerals are known. Arsenic also occurs in various organic forms in the environment.\n\nIn 2014, China was the top producer of white arsenic with almost 70% world share, followed by Morocco, Russia, and Belgium, according to the British Geological Survey and the United States Geological Survey. Most arsenic refinement operations in the US and Europe have closed over environmental concerns. Arsenic is found in the smelter dust from copper, gold, and lead smelters, and is recovered primarily from copper refinement dust.\n\nOn roasting arsenopyrite in air, arsenic sublimes as arsenic(III) oxide leaving iron oxides, while roasting without air results in the production of gray arsenic. Further purification from sulfur and other chalcogens is achieved by sublimation in vacuum, in a hydrogen atmosphere, or by distillation from molten lead-arsenic mixture.\n\nHistory \n\nThe word arsenic has its origin in the Syriac word  (al) zarniqa, from Arabic al-zarn\u012b\u1e35   'the orpiment\u2019, based on Persian zar 'gold' from the word  zarnikh, meaning \"yellow\" (literally \"gold-colored\") and hence \"(yellow) orpiment\". It was adopted into Greek as arsenikon (), a form that is folk etymology, being the neuter form of the Greek word arsenikos (), meaning \"male\", \"virile\".\n\nThe Greek word was adopted in Latin as arsenicum, which in French became arsenic, from which the English word arsenic is taken. Arsenic sulfides (orpiment, realgar) and oxides have been known and used since ancient times. Zosimos (circa 300 AD) describes roasting sandarach (realgar) to obtain cloud of arsenic (arsenic trioxide), which he then reduces to gray arsenic. As the symptoms of arsenic poisoning are not very specific, it was frequently used for murder until the advent of the Marsh test, a sensitive chemical test for its presence. (Another less sensitive but more general test is the Reinsch test.) Owing to its use by the ruling class to murder one another and its potency and discreetness, arsenic has been called the \"poison of kings\" and the \"king of poisons\".\n\nDuring the Bronze Age, arsenic was often included in bronze, which made the alloy harder (so-called \"arsenical bronze\").\nThe isolation of arsenic was described by Jabir ibn Hayyan before 815 AD. Albertus Magnus (Albert the Great, 1193\u20131280) later isolated the element from a compound in 1250, by heating soap together with arsenic trisulfide. In 1649, Johann Schr\u00f6der published two ways of preparing arsenic. Crystals of elemental (native) arsenic are found in nature, although rare.\n\nCadet's fuming liquid (impure cacodyl), often claimed as the first synthetic organometallic compound, was synthesized in 1760 by Louis Claude Cadet de Gassicourt by the reaction of potassium acetate with arsenic trioxide.\n\nIn the Victorian era, \"arsenic\" (\"white arsenic\" or arsenic trioxide) was mixed with vinegar and chalk and eaten by women to improve the complexion of their faces, making their skin paler to show they did not work in the fields. The accidental use of arsenic in the adulteration of foodstuffs led to the Bradford sweet poisoning in 1858, which resulted in 21 deaths. Wallpaper production also began to use dyes made from arsenic, which was thought to increase the pigment's brightness.\n\nTwo arsenic pigments have been widely used since their discovery \u2013 Paris Green and Scheele's Green. After the toxicity of arsenic became widely known, these chemicals were used less often as pigments and more often as insecticides. In the 1860s, an arsenic byproduct of dye production, London Purple, was widely used. This was a solid mixture of arsenic trioxide, aniline, lime, and ferrous oxide, insoluble in water and very toxic by inhalation or ingestion But it was later replaced with Paris Green, another arsenic-based dye. With better understanding of the toxicology mechanism, two other compounds were used starting in the 1890s. Arsenite of lime and arsenate of lead were used widely as insecticides until the discovery of DDT in 1942.\n\nApplications\n\nAgricultural \n\nThe toxicity of arsenic to insects, bacteria, and fungi led to its use as a wood preservative. In the 1930s, a process of treating wood with chromated copper arsenate (also known as CCA or Tanalith) was invented, and for decades, this treatment was the most extensive industrial use of arsenic. An increased appreciation of the toxicity of arsenic led to a ban of CCA in consumer products in 2004, initiated by the European Union and United States. However, CCA remains in heavy use in other countries (such as on Malaysian rubber plantations).\n\nArsenic was also used in various agricultural insecticides and poisons. For example, lead hydrogen arsenate was a common insecticide on fruit trees, but contact with the compound sometimes resulted in brain damage among those working the sprayers. In the second half of the 20th century, monosodium methyl arsenate (MSMA) and disodium methyl arsenate (DSMA) \u2013 less toxic organic forms of arsenic \u2013 replaced lead arsenate in agriculture. These organic arsenicals were in turn phased out by 2013 in all agricultural activities except cotton farming.\n\nThe biogeochemistry of arsenic is complex and includes various adsorption and desorption processes. The toxicity of arsenic is connected to its solubility and is affected by pH. Arsenite () is more soluble than arsenate () and is more toxic; however, at a lower pH, arsenate becomes more mobile and toxic. It was found that addition of sulfur, phosphorus, and iron oxides to high-arsenite soils greatly reduces arsenic phytotoxicity.\n\nArsenic is used as a feed additive in poultry and swine production, in particular in the U.S. to increase weight gain, improve feed efficiency, and prevent disease. An example is roxarsone, which had been used as a broiler starter by about 70% of U.S. broiler growers. Alpharma, a subsidiary of Pfizer Inc., which produces roxarsone, voluntarily suspended sales of the drug in response to studies showing elevated levels of inorganic arsenic, a carcinogen, in treated chickens. A successor to Alpharma, Zoetis, continues to sell nitarsone, primarily for use in turkeys.\n\nArsenic is intentionally added to the feed of chickens raised for human consumption. Organic arsenic compounds are less toxic than pure arsenic, and promote the growth of chickens. Under some conditions, the arsenic in chicken feed is converted to the toxic inorganic form.\n\nA 2006 study of the remains of the Australian racehorse, Phar Lap, determined that the 1932 death of the famous champion was caused by a massive overdose of arsenic. Sydney veterinarian Percy Sykes stated, \"In those days, arsenic was quite a common tonic, usually given in the form of a solution (Fowler's Solution)... It was so common that I'd reckon 90 per cent of the horses had arsenic in their system.\"\n\nMedical use \n\nDuring the 17th, 18th, and 19th centuries, a number of arsenic compounds were used as medicines, including arsphenamine (by Paul Ehrlich) and arsenic trioxide (by Thomas Fowler). Arsphenamine, as well as neosalvarsan, was indicated for syphilis, but has been superseded by modern antibiotics. However, arsenicals such as melarsoprol are still used for the treatment of trypanosomiasis, since although these drugs have the disadvantage of severe toxicity, the disease is almost uniformly fatal if untreated.\n\nArsenic trioxide has been used in a variety of ways over the past 500 years, most commonly in the treatment of cancer, but also in medications as diverse as Fowler's solution in psoriasis. The US Food and Drug Administration in the year 2000 approved this compound for the treatment of patients with acute promyelocytic leukemia that is resistant to all-trans retinoic acid.\n\nA 2008 paper reports success in locating tumors using arsenic-74 (a positron emitter). This isotope produces clearer PET scan images than the previous radioactive agent, iodine-124, because the body tends to transport iodine to the thyroid gland producing signal noise. Nanoparticles of arsenic have shown ability to kill cancer cells with lesser cytotoxicity than other arsenic formulations.\n\nIn subtoxic doses, soluble arsenic compounds act as stimulants, and were once popular in small doses as medicine by people in the mid-18th to 19th centuries; its use as a stimulant was especially prevalent as sport animals such as race horses or with work dogs.\n\nAlloys \n\nThe main use of arsenic is in alloying with lead. Lead components in car batteries are strengthened by the presence of a very small percentage of arsenic. Dezincification of brass (a copper-zinc alloy) is greatly reduced by the addition of arsenic. \"Phosphorus Deoxidized Arsenical Copper\" with an arsenic content of 0.3% has an increased corrosion stability in certain environments. Gallium arsenide is an important semiconductor material, used in integrated circuits. Circuits made from GaAs are much faster (but also much more expensive) than those made from silicon. Unlike silicon, GaAs has a direct bandgap, and can be used in laser diodes and LEDs to convert electrical energy directly into light.\n\nMilitary \n\nAfter World War I, the United States built a stockpile of 20,000 tons of weaponized lewisite (ClCH=CHAsCl2), an organoarsenic vesicant (blister agent) and lung irritant. The stockpile was neutralized with bleach and dumped into the Gulf of Mexico in the 1950s. During the Vietnam War, the United States used Agent Blue, a mixture of sodium cacodylate and its acid form, as one of the rainbow herbicides to deprive North Vietnamese soldiers of foliage cover and rice.\n\nOther uses \n Copper acetoarsenite was used as a green pigment known under many names, including Paris Green and Emerald Green. It caused numerous arsenic poisonings. Scheele's Green, a copper arsenate, was used in the 19th century as a coloring agent in sweets.\n Arsenic is used in bronzing and pyrotechnics.\n As much as 2% of produced arsenic is used in lead alloys for lead shot and bullets.\n Arsenic is added in small quantities to alpha-brass to make it dezincification-resistant. This grade of brass is used in plumbing fittings and other wet environments.\n Arsenic is also used for taxonomic sample preservation.\n Arsenic was used as an opacifier in ceramics, creating white glazes. \n Until recently, arsenic was used in optical glass. Modern glass manufacturers, under pressure from environmentalists, have ceased using both arsenic and lead.\n\nBiological role\n\nBacteria \nSome species of bacteria obtain their energy in the absence of oxygen by oxidizing various fuels while reducing arsenate to arsenite. Under oxidative environmental conditions some bacteria use arsenite as fuel, which they oxidize to arsenate. The enzymes involved are known as arsenate reductases (Arr).\n\nIn 2008, bacteria were discovered that employ a version of photosynthesis in the absence of oxygen with arsenites as electron donors, producing arsenates (just as ordinary photosynthesis uses water as electron donor, producing molecular oxygen). Researchers conjecture that, over the course of history, these photosynthesizing organisms produced the arsenates that allowed the arsenate-reducing bacteria to thrive. One strain PHS-1 has been isolated and is related to the gammaproteobacterium Ectothiorhodospira shaposhnikovii. The mechanism is unknown, but an encoded Arr enzyme may function in reverse to its known homologues.\n\nIn 2011, it was postulated that a strain of Halomon", "flag": 1, "segments": [[195, 205]], "strength": 5.5}
{"text": "An atom is the smallest unit of ordinary matter that forms a chemical element. Every solid, liquid, gas, and plasma is composed of neutral or ionized atoms. Atoms are extremely small, typically around 100\u00a0picometers across. They are so small that accurately predicting their behavior using classical physics\u2014as if they were tennis balls, for example\u2014is not possible due to quantum effects.\n\nEvery atom is composed of a nucleus and one or more electrons bound to the nucleus. The nucleus is made of one or more protons and a number of neutrons. Only the most common variety of hydrogen has no neutrons. More than 99.94% of an atom's mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, then the atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively \u2013 such atoms are called ions.\n\nThe electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay.\n\nThe number of protons in the nucleus is the atomic number and it defines to which chemical element the atom belongs. For example, any atom that contains 29 protons is copper. The number of neutrons defines the isotope of the element. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature. Chemistry is the discipline that studies these changes.\n\nHistory of atomic theory\n\nIn philosophy\n\nThe basic idea that matter is made up of tiny, indivisible particles appears in many ancient cultures such as those of Greece and India. The word atom is derived from the ancient Greek word atomos (a combination of the negative term \"a-\" and \"\u03c4\u03bf\u03bc\u03ae,\" the term for \"cut\") that means \"uncuttable\". This ancient idea was based in philosophical reasoning rather than scientific reasoning; modern atomic theory is not based on these old concepts. Nonetheless, the term \"atom\" was used throughout the ages by thinkers who suspected that matter was ultimately granular in nature. It has since been discovered that \"atoms\" can be split, but the misnomer is still used.\n\nDalton's law of multiple proportions\n\nIn the early 1800s, the English chemist John Dalton compiled experimental data gathered by himself and other scientists and discovered a pattern now known as the \"law of multiple proportions\". He noticed that in chemical compounds which contain a particular chemical element, the content of that element in these compounds will differ by ratios of small whole numbers. This pattern suggested to Dalton that each chemical element combines with other elements by some basic and consistent unit of mass.\n\nFor example, there are two types of tin oxide: one is a black powder that is 88.1% tin and 11.9% oxygen, and the other is a white powder that is 78.7% tin and 21.3% oxygen. Adjusting these figures, in the black oxide there is about 13.5\u00a0g of oxygen for every 100\u00a0g of tin, and in the white oxide there is about 27\u00a0g of oxygen for every 100\u00a0g of tin. 13.5 and 27 form a ratio of 1:2. In these oxides, for every tin atom there are one or two oxygen atoms respectively (SnO and SnO2).\n\nAs a second example, Dalton considered two iron oxides: a black powder which is 78.1% iron and 21.9% oxygen, and a red powder which is 70.4% iron and 29.6% oxygen. Adjusting these figures, in the black oxide there is about 28\u00a0g of oxygen for every 100\u00a0g of iron, and in the red oxide there is about 42 catch-up. It's reportedly raising the level\u00a0g of oxygen for every 100\u00a0g of iron. 28 and 42 form a ratio of 2:3. In these respective oxides, for every two atoms of iron, there are two or three atoms of oxygen (Fe2O2 and Fe2O3).\n\nAs a final example: nitrous oxide is 63.3% nitrogen and 36.7% oxygen, nitric oxide is 44.05% nitrogen and 55.95% oxygen, and nitrogen dioxide is 29.5% nitrogen and 70.5% oxygen. Adjusting these figures, in nitrous oxide there is 80\u00a0g of oxygen for every 140\u00a0g of nitrogen, in nitric oxide there is about 160\u00a0g of oxygen for every 140\u00a0g of nitrogen, and in nitrogen dioxide there is 320\u00a0g of oxygen for every 140\u00a0g of nitrogen. 80, 160, and 320 form a ratio of 1:2:4. The respective formulas for these oxides are N2O, NO, and NO2.\n\nKinetic theory of gases\n\nIn the late 18th century, a number of scientists found that they could better explain the behavior of gases by describing them as collections of sub-microscopic particles and modelling their behavior using statistics and probability. Unlike Dalton's atomic theory, the kinetic theory of gases describes not how gases react chemically with each other to form compounds, but how they behave physically: diffusion, viscosity, conductivity, pressure, etc.\n\nBrownian motion\nIn 1827, botanist Robert Brown used a microscope to look at dust grains floating in water and discovered that they moved about erratically, a phenomenon that became known as \"Brownian motion\". This was thought to be caused by water molecules knocking the grains about. In 1905, Albert Einstein proved the reality of these molecules and their motions by producing the first statistical physics analysis of Brownian motion. French physicist Jean Perrin used Einstein's work to experimentally determine the mass and dimensions of molecules, thereby providing physical evidence for the particle nature of matter.\n\nDiscovery of the electron\n\nIn 1897, J. J. Thomson discovered that cathode rays are not electromagnetic waves but made of particles that are 1,800 times lighter than hydrogen (the lightest atom). Thomson concluded that these particles came from the atoms within the cathode \u2014 they were subatomic particles. He called these new particles corpuscles but they were later renamed electrons. Thomson also showed that electrons were identical to particles given off by photoelectric and radioactive materials. It was quickly recognized that electrons are the particles that carry electric currents in metal wires. Thomson concluded that these electrons emerged from the very atoms of the cathode in his instruments, which meant that atoms are not indivisible as the name atomos suggests.\n\nDiscovery of the nucleus\n\nJ. J. Thomson thought that the negatively-charged electrons were distributed throughout the atom in a sea of positive charge that was distributed across the whole volume of the atom. This model is sometimes known as the plum pudding model.\n\nErnest Rutherford and his colleagues Hans Geiger and Ernest Marsden came to have doubts about the Thomson model after they encountered difficulties when they tried to build an instrument to measure the charge-to-mass ratio of alpha particles (these are positively-charged particles emitted by certain radioactive substances such as radium). The alpha particles were being scattered by the air in the detection chamber, which made the measurements unreliable.  Thomson had encountered a similar problem in his work on cathode rays, which he solved by creating a near-perfect vacuum in his instruments. Rutherford didn't think he'd run into this same problem because alpha particles are much heavier than electrons. According to Thomson's model of the atom, the positive charge in the atom is not concentrated enough to produce an electric field strong enough to deflect an alpha particle, and the electrons are so lightweight they should be pushed aside effortlessly by the much heavier alpha particles. Yet there was scattering, so Rutherford and his colleagues decided to investigate this scattering carefully.\n\nBetween 1908 and 1913, Rutheford and his colleagues performed a series of experiments in which they bombarded thin foils of metal with alpha particles. They spotted alpha particles being deflected by angles greater than 90\u00b0. To explain this, Rutherford proposed that the positive charge of the atom is not distributed throughout the atom's volume as Thomson believed, but is concentrated in a tiny nucleus at the center. Only such an intense concentration of charge could produce an electric field strong enough to deflect the alpha particles as observed.\n\nDiscovery of isotopes\nWhile experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one type of atom at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for different atoms that belong to the same element. J. J. Thomson created a technique for isotope separation through his work on ionized gases, which subsequently led to the discovery of stable isotopes.\n\nBohr model\n\nIn 1913, the physicist Niels Bohr proposed a model in which the electrons of an atom were assumed to orbit the nucleus but could only do so in a finite set of orbits, and could jump between these orbits only in discrete changes of energy corresponding to absorption or radiation of a photon. This quantization was used to explain why the electrons' orbits are stable (given that normally, charges in acceleration, including circular motion, lose kinetic energy which is emitted as electromagnetic radiation, see synchrotron radiation) and why elements absorb and emit electromagnetic radiation in discrete spectra.\n\nLater in the same year Henry Moseley provided additional experimental evidence in favor of Niels Bohr's theory. These results refined Ernest Rutherford's and Antonius van den Broek's model, which proposed that the atom contains in its nucleus a number of positive nuclear charges that is equal to its (atomic) number in the periodic table. Until these experiments, atomic number was not known to be a physical and experimental quantity. That it is equal to the atomic nuclear charge remains the accepted atomic model today.\n\nChemical bonds between atoms were explained by Gilbert Newton Lewis in 1916, as the interactions between their constituent electrons. As the chemical properties of the elements were known to largely repeat themselves according to the periodic law, in 1919 the American chemist Irving Langmuir suggested that this could be explained if the electrons in an atom were connected or clustered in some manner. Groups of electrons were thought to occupy a set of electron shells about the nucleus.\n\nThe Bohr model of the atom was the first complete physical model of the atom. It described the overall structure of the atom, how atoms bond to each other, and predicted the spectral lines of hydrogen. Bohr's model was not perfect and was soon superseded by the more accurate Schr\u00f6dinger model, but it was sufficient to evaporate any remaining doubts that matter is composed of atoms. For chemists, the idea of the atom had been a useful heuristic tool, but physicists had doubts as to whether matter really is made up of atoms as nobody had yet developed a complete physical model of the atom.\n\nThe Schr\u00f6dinger model\nThe Stern\u2013Gerlach experiment of 1922 provided further evidence of the quantum nature of atomic properties. When a beam of silver atoms was passed through a specially shaped magnetic field, the beam was split in a way correlated with the direction of an atom's angular momentum, or spin. As this spin direction is initially random, the beam would be expected to deflect in a random direction. Instead, the beam was split into two directional components, corresponding to the atomic spin being oriented up or down with respect to the magnetic field.\n\nIn 1925, Werner Heisenberg published the first consistent mathematical formulation of quantum mechanics (matrix mechanics). One year earlier, Louis de Broglie had proposed the de Broglie hypothesis: that all particles behave like waves to some extent, and in 1926 Erwin Schr\u00f6dinger used this idea to develop the Schr\u00f6dinger equation, a mathematical model of the atom (wave mechanics) that described the electrons as three-dimensional waveforms rather than point particles.\n\nA consequence of using waveforms to describe particles is that it is mathematically impossible to obtain precise values for both the position and momentum of a particle at a given point in time; this became known as the uncertainty principle, formulated by Werner Heisenberg in 1927. In this concept, for a given accuracy in measuring a position one could only obtain a range of probable values for momentum, and vice versa.\nThis model was able to explain observations of atomic behavior that previous models could not, such as certain structural and spectral patterns of atoms larger than hydrogen. Thus, the planetary model of the atom was discarded in favor of one that described atomic orbital zones around the nucleus where a given electron is most likely to be observed.\n\nDiscovery of the neutron\nThe development of the mass spectrometer allowed the mass of atoms to be measured with increased accuracy. The device uses a magnet to bend the trajectory of a beam of ions, and the amount of deflection is determined by the ratio of an atom's mass to its charge. The chemist Francis William Aston used this instrument to show that isotopes had different masses. The atomic mass of these isotopes varied by integer amounts, called the whole number rule. The explanation for these different isotopes awaited the discovery of the neutron, an uncharged particle with a mass similar to the proton, by the physicist James Chadwick in 1932. Isotopes were then explained as elements with the same number of protons, but different numbers of neutrons within the nucleus.\n\nFission, high-energy physics and condensed matter\nIn 1938, the German chemist Otto Hahn, a student of Rutherford, directed neutrons onto uranium atoms expecting to get transuranium elements. Instead, his chemical experiments showed barium as a product. A year later, Lise Meitner and her nephew Otto Frisch verified that Hahn's result were the first experimental nuclear fission. In 1944, Hahn received the Nobel Prize in Chemistry. Despite Hahn's efforts, the contributions of Meitner and Frisch were not recognized.\n\nIn the 1950s, the development of improved particle accelerators and particle detectors allowed scientists to study the impacts of atoms moving at high energies. Neutrons and protons were found to be hadrons, or composites of smaller particles called quarks. The standard model of particle physics was developed that so far has successfully explained the properties of the nucleus in terms of these sub-atomic particles and the forces that govern their interactions.\n\nStructure\n\nSubatomic particles\n\nThough the word atom originally denoted a particle that cannot be cut into smaller particles, in modern scientific usage the atom is composed of various subatomic particles. The constituent particles of an atom are the electron, the proton and the neutron.\n\nThe electron is by far the least massive of these particles at, with a negative electrical charge and a size that is too small to be measured using available techniques. It was the lightest particle with a positive rest mass measured, until the discovery of neutrino mass. Under ordinary conditions, electrons are bound to the positively charged nucleus by the attraction created from opposite electric charges. If an atom has more or fewer electrons than its atomic number, then it becomes respectively negatively or positively charged as a whole; a charged atom is called an ion. Electrons have been known since the late 19th century, mostly thanks to J.J. Thomson; see history of subatomic physics for details.\n\nProtons have a positive charge and a mass 1,836 times that of the electron, at. The number of protons in an atom is called its atomic number. Ernest Rutherford (1919) observed that nitrogen under alpha-particle bombardment ejects what appeared to be hydrogen nuclei. By 1920 he had accepted that the hydrogen nucleus is a distinct particle within the atom and named it proton.\n\nNeutrons have no electrical charge and have a free mass of 1,839 times the mass of the electron, or. Neutrons are the heaviest of the three constituent particles, but their mass can be reduced by the nuclear binding energy. Neutrons and protons (collectively known as nucleons) have comparable dimensions\u2014on the order of \u2014although the'surface' of these particles is not sharply defined. The neutron was discovered in 1932 by the English physicist James Chadwick.\n\nIn the Standard Model of physics, electrons are truly elementary particles with no internal structure, whereas protons and neutrons are composite particles composed of elementary particles called quarks. There are two types of quarks in atoms, each having a fractional electric charge. Protons are composed of two up quarks (each with charge +) and one down quark (with a charge of \u2212). Neutrons consist of one up quark and two down quarks. This distinction accounts for the difference in mass and charge between the two particles.\n\nThe quarks are held together by the strong interaction (or strong force), which is mediated by gluons. The protons and neutrons, in turn, are held to each other in the nucleus by the nuclear force, which is a residuum of the strong force that has somewhat different range-properties (see the article on the nuclear force for more). The gluon is a member of the family of gauge bosons, which are elementary particles that mediate physical forces.\n\nNucleus\n\nAll the bound protons and neutrons in an atom make up a tiny atomic nucleus, and are collectively called nucleons. The radius of a nucleus is approximately equal to \u00a0femtometres, where  is the total number of nucleons. This is much smaller than the radius of the atom, which is on the order of 105\u00a0fm. The nucleons are bound together by a short-ranged attractive potential called the residual strong force. At distances smaller than 2.5 fm this force is much more powerful than the electrostatic force that causes positively charged protons to repel each other.\n\nAtoms of the same element have the same number of protons, called the atomic number. Within a single element, the number of neutrons may vary, determining the isotope of that element. The total number of protons and neutrons determine the nuclide. The number of neutrons relative to the protons determines the stability of the nucleus, with certain isotopes undergoing radioactive decay.\n\nThe proton, the electron, and the neutron are classified as fermions. Fermions obey the Pauli exclusion principle which prohibits identical fermions, such as multiple protons, from occupying the same quantum state at the same time. Thus, every proton in the nucleus must occupy a quantum state different from all other protons, and the same applies to all neutrons of the nucleus and to all electrons of the electron cloud.\n\nA nucleus that has a different number of protons than neutrons can potentially drop to a lower energy state through a radioactive decay that causes the number of protons and neutrons to more closely match. As a result, atoms with matching numbers of protons and neutrons are more stable against decay, but with increasing atomic number, the mutual repulsion of the protons requires an increasing proportion of neutrons to maintain the stability of the nucleus.\n\nThe number of protons and neutrons in the atomic nucleus can be modified, although this can require very high energies because of the strong force. Nuclear fusion occurs when multiple atomic particles join to form a heavier nucleus, such as through the energetic collision of two nuclei. For example, at the core of the Sun protons require energies of 3 to 10 keV to overcome their mutual repulsion\u2014the coulomb barrier\u2014and fuse together into a single nucleus. Nuclear fission is the opposite process, causing a nucleus to split into two smaller nuclei\u2014usually through radioactive decay. The nucleus can also be modified through bombardment by high energy subatomic particles or photons. If this modifies the number of protons in a nucleus, the atom changes to a different chemical element.\n\nIf the mass of the nucleus following a fusion reaction is less than the sum of the masses of the separate particles, then the difference between these two values can be emitted as a type of usable energy (such as a gamma ray, or the kinetic energy of a beta particle), as described by Albert Einstein's mass-energy equivalence formula,, where  is the mass loss and  is the speed of light. This deficit is part of the binding energy of the new nucleus, and it is the non-recoverable loss of the energy that causes the fused particles to remain together in a state that requires this energy to separate.\n\nThe fusion of two nuclei that create larger nuclei with lower atomic numbers than iron and nickel\u2014a total nucleon number of about 60\u2014is usually an exothermic process that releases more energy than is required to bring them together. It is this energy-releasing process that makes nuclear fusion in stars a self-sustaining reaction. For heavier nuclei, the binding energy per nucleon in the nucleus begins to decrease. That means fusion processes producing nuclei that have atomic numbers higher than about 26, and atomic masses higher than about 60, is an endothermic process. These more massive nuclei can not undergo an energy-producing fusion reaction that can sustain the hydrostatic equilibrium of a star.\n\nElectron cloud\n\nThe electrons in an atom are attracted to the protons in the nucleus by the electromagnetic force. This force binds the electrons inside an electrostatic potential well surrounding the smaller nucleus, which means that an external source of energy is needed for the electron to escape. The closer an electron is to the nucleus, the greater the attractive force. Hence electrons bound near the center of the potential well require more energy to escape than those at greater separations.\n\nElectrons, like other particles, have properties of both a particle and a wave. The electron cloud is a region inside the potential well where each electron forms a type of three-dimensional standing wave\u2014a wave form that does not move relative to the nucleus. This behavior is defined by an atomic orbital, a mathematical function that characterises the probability that an electron appears to be at a particular location when its position is measured. Only a discrete (or quantized) set of these orbitals exist around the nucleus, as other possible wave patterns rapidly decay into a more stable form. Orbitals can have one or more ring or node structures, and differ from each other in size, shape and orientation.\n\nEach atomic orbital corresponds to a particular energy level of the electron. The electron can change its state to a higher energy level by absorbing a photon with sufficient energy to boost it into the new quantum state. Likewise, through spontaneous emission, an electron in a higher energy state can drop to a lower energy state while radiating the excess energy as a photon. These characteristic energy values, defined by the differences in the energies of the quantum states, are responsible for atomic spectral lines.\n\nThe amount of energy needed to remove or add an electron\u2014the electron binding energy\u2014is far less than the binding energy of nucleons. For example, it requires only 13.6\u00a0eV to strip a ground-state electron from a hydrogen atom, compared to 2.23\u00a0million eV for splitting a deuterium nucleus. Atoms are electrically neutral if they have an equal number of protons and electrons. Atoms that have either a deficit or a surplus of electrons are called ions. Electrons that are farthest from the nucleus may be transferred to other nearby atoms or shared between atoms. By this mechanism, atoms are able to bond into molecules and other types of chemical compounds like ionic and covalent network crystals.\n\nProperties\n\nNuclear properties\n\n", "flag": 1, "segments": [[895, 905]], "strength": 5.5}
{"text": "Aluminium (or aluminum in American English and Canadian English) is a chemical element with the symbol\u00a0Al and atomic number\u00a013. Aluminium has a density lower than those of other common metals, at approximately one third that of steel. It has a great affinity towards oxygen, and forms a protective layer of oxide on the surface when exposed to air. Aluminium visually resembles silver, both in its color and in its great ability to reflect light. It is soft, non-magnetic and ductile. It has one stable isotope, 27Al; this isotope is very common, making aluminium the twelfth most common element in the Universe. The radioactivity of 26Al is used in radiodating.\n\nChemically, aluminium is a post-transition metal in the boron group; as is common for the group, aluminium forms compounds primarily in the +3 oxidation state. The aluminium cation Al3+ is small and highly charged; as such, it is polarizing, and bonds aluminium forms tend towards covalency. The strong affinity towards oxygen leads to aluminium's common association with oxygen in nature in the form of oxides; for this reason, aluminium is found on Earth primarily in rocks in the crust, where it is the third most abundant element after oxygen and silicon, rather than in the mantle, and virtually never as the free metal.\n\nThe discovery of aluminium was announced in 1825 by Danish physicist Hans Christian \u00d8rsted. The first industrial production of aluminium was initiated by French chemist Henri \u00c9tienne Sainte-Claire Deville in 1856. Aluminium became much more available to the public with the Hall\u2013H\u00e9roult process developed independently by French engineer Paul H\u00e9roult and American engineer Charles Martin Hall in 1886, and the mass production of aluminium led to its extensive use in industry and everyday life. In World Wars I and II, aluminium was a crucial strategic resource for aviation. In 1954, aluminium became the most produced non-ferrous metal, surpassing copper. In the 21st century, most aluminium was consumed in transportation, engineering, construction, and packaging in the United States, Western Europe, and Japan.\n\nDespite its prevalence in the environment, no living organism is known to use aluminium salts metabolically, but aluminium is well tolerated by plants and animals. Because of the abundance of these salts, the potential for a biological role for them is of continuing interest, and studies continue.\n\nPhysical characteristics\n\nIsotopes \n\nOf aluminium isotopes, only  is stable. This situation is common for elements with an odd atomic number. It is the only primordial aluminium isotope, i.e. the only one that has existed on Earth in its current form since the formation of the planet. Nearly all aluminium on Earth is present as this isotope, which makes it a mononuclidic element and means that its standard atomic weight is virtually the same as that of the isotope. This makes aluminium very useful in nuclear magnetic resonance (NMR), as its single stable isotope has a high NMR sensitivity. The standard atomic weight of aluminium is low in comparison with many other metals.\n\nAll other isotopes of aluminium are radioactive. The most stable of these is 26Al: while it was present along with stable 27Al in the interstellar medium from which the Solar System formed, having been produced by stellar nucleosynthesis as well, its half-life is only 717,000\u00a0years and therefore a detectable amount has not survived since the formation of the planet. However, minute traces of 26Al are produced from argon in the atmosphere by spallation caused by cosmic ray protons. The ratio of 26Al to 10Be has been used for radiodating of geological processes over 105 to 106\u00a0year time scales, in particular transport, deposition, sediment storage, burial times, and erosion. Most meteorite scientists believe that the energy released by the decay of 26Al was responsible for the melting and differentiation of some asteroids after their formation 4.55\u00a0billion years ago.\n\nThe remaining isotopes of aluminium, with mass numbers ranging from 22 to 43, all have half-lives well under an hour. Three metastable states are known, all with half-lives under a minute.\n\nElectron shell \n\nAn aluminium atom has 13 electrons, arranged in an electron configuration of [Ne]\u00a03s2\u00a03p1, with three electrons beyond a stable noble gas configuration. Accordingly, the combined first three ionization energies of aluminium are far lower than the fourth ionization energy alone. Such an electron configuration is shared with the other well-characterized members of its group, boron, gallium, indium, and thallium; it is also expected for nihonium. Aluminium can relatively easily surrender its three outermost electrons in many chemical reactions (see below). The electronegativity of aluminium is 1.61 (Pauling scale).\n\nA free aluminium atom has a radius of 143\u00a0pm. With the three outermost electrons removed, the radius shrinks to 39\u00a0pm for a 4-coordinated atom or 53.5\u00a0pm for a 6-coordinated atom. At standard temperature and pressure, aluminium atoms (when not affected by atoms of other elements) form a face-centered cubic crystal system bound by metallic bonding provided by atoms' outermost electrons; hence aluminium (at these conditions) is a metal. This crystal system is shared by many other metals, such as lead and copper; the size of a unit cell of aluminium is comparable to that of those other metals. The system, however, is not shared by the other members of its group; boron has ionization energies too high to allow metallization, thallium has a hexagonal close-packed structure, and gallium and indium have unusual structures that are not close-packed like those of aluminium and thallium. The few electrons that are available for metallic bonding in aluminium metal are a probable cause for it being soft with a low melting point and low electrical resistivity.\n\nBulk \n\nAluminium metal has an appearance ranging from silvery white to dull gray, depending on the surface roughness. A fresh film of aluminium serves as a good reflector (approximately 92%) of visible light and an excellent reflector (as much as 98%) of medium and far infrared radiation. Aluminium mirrors are the most reflective of all metal mirrors for the near ultraviolet and far infrared light, and one of the most reflective in the visible spectrum, nearly on par with silver, and the two therefore look similar. Aluminium is also good at reflecting solar radiation, although prolonged exposure to sunlight in air adds wear to the surface of the metal; this may be prevented if aluminium is anodized, which adds a protective layer of oxide on the surface.\n\nThe density of aluminium is 2.70\u00a0g/cm3, about 1/3 that of steel, much lower than other commonly encountered metals, making aluminium parts easily identifiable through their lightness. Aluminium's low density compared to most other metals arises from the fact that its nuclei are much lighter, while difference in the unit cell size does not compensate for this difference. The only lighter metals are the metals of groups 1 and 2, which apart from beryllium and magnesium are too reactive for structural use (and beryllium is very toxic). Aluminium is not as strong or stiff as steel, but the low density makes up for this in the aerospace industry and for many other applications where light weight and relatively high strength are crucial.\n\nPure aluminium is quite soft and lacking in strength. In most applications various aluminium alloys are used instead because of their higher strength and hardness. The yield strength of pure aluminium is 7\u201311 MPa, while aluminium alloys have yield strengths ranging from 200 MPa to 600 MPa. Aluminium is ductile, with a percent elongation of 50-70%, and malleable allowing it to be easily drawn and extruded. It is also easily machined and cast.\n\nAluminium is an excellent thermal and electrical conductor, having around 60% the conductivity of copper, both thermal and electrical, while having only 30% of copper's density. Aluminium is capable of superconductivity, with a superconducting critical temperature of 1.2 kelvin and a critical magnetic field of about 100 gauss (10 milliteslas). It is paramagnetic and thus essentially unaffected by static magnetic fields. The high electrical conductivity, however, means that it is strongly affected by alternating magnetic fields through the induction of eddy currents.\n\nChemistry \n\nAluminium combines characteristics of pre- and post-transition metals. Since it has few available electrons for metallic bonding, like its heavier group 13 congeners, it has the characteristic physical properties of a post-transition metal, with longer-than-expected interatomic distances. Furthermore, as Al3+ is a small and highly charged cation, it is strongly polarizing and bonding in aluminium compounds tends towards covalency; this behavior is similar to that of beryllium (Be2+), and the two display an example of a diagonal relationship.\n\nThe underlying core under aluminium's valence shell is that of the preceding noble gas, whereas those of its heavier congeners gallium, indium, thallium, and nihonium also include a filled d-subshell and in some cases a filled f-subshell. Hence, the inner electrons of aluminium shield the valence electrons almost completely, unlike those of aluminium's heavier congeners. As such, aluminium is the most electropositive metal in its group, and its hydroxide is in fact more basic than that of gallium. Aluminium also bears minor similarities to the metalloid boron in the same group: AlX3 compounds are valence isoelectronic to BX3 compounds (they have the same valence electronic structure), and both behave as Lewis acids and readily form adducts. Additionally, one of the main motifs of boron chemistry is regular icosahedral structures, and aluminium forms an important part of many icosahedral quasicrystal alloys, including the Al\u2013Zn\u2013Mg class.\n\nAluminium has a high chemical affinity to oxygen, which renders it suitable for use as a reducing agent in the thermite reaction. A fine powder of aluminium metal reacts explosively on contact with liquid oxygen; under normal conditions, however, aluminium forms a thin oxide layer (~5\u00a0nm at room temperature) that protects the metal from further corrosion by oxygen, water, or dilute acid, a process termed passivation. Because of its general resistance to corrosion, aluminium is one of the few metals that retains silvery reflectance in finely powdered form, making it an important component of silver-colored paints. Aluminium is not attacked by oxidizing acids because of its passivation. This allows aluminium to be used to store reagents such as nitric acid, concentrated sulfuric acid, and some organic acids.\n\nIn hot concentrated hydrochloric acid, aluminium reacts with water with evolution of hydrogen, and in aqueous sodium hydroxide or potassium hydroxide at room temperature to form aluminates\u2014protective passivation under these conditions is negligible. Aqua regia also dissolves aluminium. Aluminium is corroded by dissolved chlorides, such as common sodium chloride, which is why household plumbing is never made from aluminium. The oxide layer on aluminium is also destroyed by contact with mercury due to amalgamation or with salts of some electropositive metals. As such, the strongest aluminium alloys are less corrosion-resistant due to galvanic reactions with alloyed copper, and aluminium's corrosion resistance is greatly reduced by aqueous salts, particularly in the presence of dissimilar metals.\n\nAluminium reacts with most nonmetals upon heating, forming compounds such as aluminium nitride (AlN), aluminium sulfide (Al2S3), and the aluminium halides (AlX3). It also forms a wide range of intermetallic compounds involving metals from every group on the periodic table.\n\nInorganic compounds \n\nThe vast majority of compounds, including all aluminium-containing minerals and all commercially significant aluminium compounds, feature aluminium in the oxidation state 3+. The coordination number of such compounds varies, but generally Al3+ is either six- or four-coordinate. Almost all compounds of aluminium(III) are colorless.\n\nIn aqueous solution, Al3+ exists as the hexaaqua cation [Al(H2O)6]3+, which has an approximate Ka of 10\u22125. Such solutions are acidic as this cation can act as a proton donor and progressively hydrolyze until a precipitate of aluminium hydroxide, Al(OH)3, forms. This is useful for clarification of water, as the precipitate nucleates on suspended particles in the water, hence removing them. Increasing the pH even further leads to the hydroxide dissolving again as aluminate, [Al(H2O)2(OH)4]\u2212, is formed.\n\nAluminium hydroxide forms both salts and aluminates and dissolves in acid and alkali, as well as on fusion with acidic and basic oxides. This behavior of Al(OH)3 is termed amphoterism and is characteristic of weak Bradie and J. K. Dickie wholy basic cations that form insoluble hydroxides and whose hydrated species can also donate their protons. One effect of this is that aluminium salts with weak acids are hydrolyzed in water to the aquated hydroxide and the corresponding nonmetal hydride: for example, aluminium sulfide yields hydrogen sulfide. However, some salts like aluminium carbonate exist in aqueous solution but are unstable as such; and only incomplete hydrolysis takes place for salts with strong acids, such as the halides, nitrate, and sulfate. For similar reasons, anhydrous aluminium salts cannot be made by heating their \"hydrates\": hydrated aluminium chloride is in fact not AlCl3\u00b76H2O but [Al(H2O)6]Cl3, and the Al\u2013O bonds are so strong that heating is not sufficient to break them and form Al\u2013Cl bonds instead:\n\n2[Al(H2O)6]Cl3  Al2O3 + 6 HCl + 9 H2O\n\nAll four trihalides are well known. Unlike the structures of the three heavier trihalides, aluminium fluoride (AlF3) features six-coordinate aluminium, which explains its involatility and insolubility as well as high heat of formation. Each aluminium atom is surrounded by six fluorine atoms in a distorted octahedral arrangement, with each fluorine atom being shared between the corners of two octahedra. Such {AlF6} units also exist in complex fluorides such as cryolite, Na3AlF6. AlF3 melts at  and is made by reaction of aluminium oxide with hydrogen fluoride gas at.\n\nWith heavier halides, the coordination numbers are lower. The other trihalides are dimeric or polymeric with tetrahedral four-coordinate aluminium centers. Aluminium trichloride (AlCl3) has a layered polymeric structure below its melting point of  but transforms on melting to Al2Cl6 dimers. At higher temperatures those increasingly dissociate into trigonal planar AlCl3 monomers similar to the structure of BCl3. Aluminium tribromide and aluminium triiodide form Al2X6 dimers in all three phases and hence do not show such significant changes of properties upon phase change. These materials are prepared by treating aluminium metal with the halogen. The aluminium trihalides form many addition compounds or complexes; their Lewis acidic nature makes them useful as catalysts for the Friedel\u2013Crafts reactions. Aluminium trichloride has major industrial uses involving this reaction, such as in the manufacture of anthraquinones and styrene; it is also often used as the precursor for many other aluminium compounds and as a reagent for converting nonmetal fluorides into the corresponding chlorides (a transhalogenation reaction).\n\nAluminium forms one stable oxide with the chemical formula Al2O3, commonly called alumina. It can be found in nature in the mineral corundum, \u03b1-alumina; there is also a \u03b3-alumina phase. Its crystalline form, corundum, is very hard (Mohs hardness 9), has a high melting point of, has very low volatility, is chemically inert, and a good electrical insulator, it is often used in abrasives (such as toothpaste), as a refractory material, and in ceramics, as well as being the starting material for the electrolytic production of aluminium metal. Sapphire and ruby are impure corundum contaminated with trace amounts of other metals. The two main oxide-hydroxides, AlO(OH), are boehmite and diaspore. There are three main trihydroxides: bayerite, gibbsite, and nordstrandite, which differ in their crystalline structure (polymorphs). Many other intermediate and related structures are also known. Most are produced from ores by a variety of wet processes using acid and base. Heating the hydroxides leads to formation of corundum. These materials are of central importance to the production of aluminium and are themselves extremely useful. Some mixed oxide phases are also very useful, such as spinel (MgAl2O4), Na-\u03b2-alumina (NaAl11O17), and tricalcium aluminate (Ca3Al2O6, an important mineral phase in Portland cement).\n\nThe only stable chalcogenides under normal conditions are aluminium sulfide (Al2S3), selenide (Al2Se3), and telluride (Al2Te3). All three are prepared by direct reaction of their elements at about  and quickly hydrolyze completely in water to yield aluminium hydroxide and the respective hydrogen chalcogenide. As aluminium is a small atom relative to these chalcogens, these have four-coordinate tetrahedral aluminium with various polymorphs having structures related to wurtzite, with two-thirds of the possible metal sites occupied either in an orderly (\u03b1) or random (\u03b2) fashion; the sulfide also has a \u03b3 form related to \u03b3-alumina, and an unusual high-temperature hexagonal form where half the aluminium atoms have tetrahedral four-coordination and the other half have trigonal bipyramidal five-coordination. \n\nFour pnictides \u2013 aluminium nitride (AlN), aluminium phosphide (AlP), aluminium arsenide (AlAs), and aluminium antimonide (AlSb) \u2013 are known. They are all III-V semiconductors isoelectronic to silicon and germanium, all of which but AlN have the zinc blende structure. All four can be made by high-temperature (and possibly high-pressure) direct reaction of their component elements.\n\nAluminium alloys well with most other metals (with the exception of most alkali metals and group 13 metals) and over 150 intermetallics with other metals are known. Preparation involves heating fixed metals together in certain proportion, followed by gradual cooling and annealing. Bonding in them is predominantly metallic and the crystal structure primarily depends on efficiency of packing.\n\nThere are few compounds with lower oxidation states. A few aluminium(I) compounds exist: AlF, AlCl, AlBr, and AlI exist in the gaseous phase when the respective trihalide is heated with aluminium, and at cryogenic temperatures. A stable derivative of aluminium monoiodide is the cyclic adduct formed with triethylamine, Al4I4(NEt3)4. Al2O and Al2S also exist but are very unstable. Very simple aluminium(II) compounds are invoked or observed in the reactions of Al metal with oxidants. For example, aluminium monoxide, AlO, has been detected in the gas phase after explosion and in stellar absorption spectra. More thoroughly investigated are compounds of the formula R4Al2 which contain an Al\u2013Al bond and where R is a large organic ligand.\n\nOrganoaluminium compounds and related hydrides \n\nA variety of compounds of empirical formula AlR3 and AlR1.5Cl1.5 exist. The aluminium trialkyls and triaryls are reactive, volatile, and colorless liquids or low-melting solids. They catch fire spontaneously in air and react with water, thus necessitating precautions when handling them. They often form dimers, unlike their boron analogues, but this tendency diminishes for branched-chain alkyls (e.g. Pri, Bui, Me3CCH2); for example, triisobutylaluminium exists as an equilibrium mixture of the monomer and dimer. These dimers, such as trimethylaluminium (Al2Me6), usually feature tetrahedral Al centers formed by dimerization with some alkyl group bridging between both aluminium atoms. They are hard acids and react readily with ligands, forming adducts. In industry, they are mostly used in alkene insertion reactions, as discovered by Karl Ziegler, most importantly in \"growth reactions\" that form long-chain unbranched primary alkenes and alcohols, and in the low-pressure polymerization of ethene and propene. There are also some heterocyclic and cluster organoaluminium compounds involving Al\u2013N bonds.\n\nThe industrially most important aluminium hydride is lithium aluminium hydride (LiAlH4), which is used in as a reducing agent in organic chemistry. It can be produced from lithium hydride and aluminium trichloride. The simplest hydride, aluminium hydride or alane, is not as important. It is a polymer with the formula (AlH3)n, in contrast to the corresponding boron hydride that is a dimer with the formula (BH3)2.\n\nNatural occurrence\n\nSpace \n\nAluminium's per-particle abundance in the Solar System is 3.15 ppm (parts per million). It is the twelfth most abundant of all elements and third most abundant among the elements that have odd atomic numbers, after hydrogen and nitrogen. The only stable isotope of aluminium, 27Al, is the eighteenth most abundant nucleus in the Universe. It is created almost entirely after fusion of carbon in massive stars that will later become Type II supernovas: this fusion creates 26Mg, which, upon capturing free protons and neutrons becomes aluminium. Some smaller quantities of 27Al are created in hydrogen burning shells of evolved stars, where 26Mg can capture free protons. Essentially all aluminium now in existence is 27Al. 26Al was present in the early Solar System with abundance of 0.005% relative to 27Al but its half-life of 728,000 years is too short for any original nuclei to survive; 26Al is therefore extinct. Unlike for 27Al, hydrogen burning is the primary source of 26Al, with the nuclide emerging after a nucleus of 25Mg catches a free proton. However, the trace quantities of 26Al that do exist are the most common gamma ray emitter in the interstellar gas; if the original 26Al were still present, gamma ray maps of the Milky Way would be brighter.\n\nEarth \n\nOverall, the Earth is about 1.59% aluminium by mass (seventh in abundance by mass). Aluminium occurs in greater proportion in the Earth's crust than in the Universe at large, because aluminium easily forms the oxide and becomes bound into rocks and stays in the Earth's crust, while less reactive metals sink to the core. In the Earth's crust,", "flag": 1, "segments": [[2770, 2780]], "strength": 5.5}
{"text": "The Amazing Spider-Man is an American comic book series published by Marvel Comics, featuring the fictional superhero Spider-Man as its main protagonist. Being in the mainstream continuity of the franchise, it began publication in 1963 as a bimonthly periodical (as Amazing Fantasy had been), quickly being increased to monthly, and was published continuously, with a brief interruption in 1995, until its second volume with a new numbering order in 1999. In 2003, the series reverted to the numbering order of the first volume. The title has occasionally been published biweekly, and was published three times a month from 2008 to 2010.\n\nAfter DC Comics' relaunch of Action Comics and Detective Comics with new No. 1 issues in 2011, it had been the highest-numbered American comic still in circulation until it was cancelled. The title ended its 50-year run as a continuously published comic with the landmark issue #700 in December 2012. It was replaced by The Superior Spider-Man as part of the Marvel NOW! relaunch of Marvel's comic lines.\n\nVolume 3 of The Amazing Spider-Man was published in April 2014, following the conclusion of The Superior Spider-Man story arc. In late 2015, the series was relaunched with a 4th volume, following the 2015 Secret Wars event. The 5th and current volume began in 2018, as part of Marvel's Fresh Start series of comic relaunches.\n\nPublication history\nWriter-editor Stan Lee and artist and co-plotter Steve Ditko created the character of Spider-Man, and the pair produced 38 issues from March 1963 to July 1966. Ditko left after the 38th issue, while Lee remained as writer until issue 100. Since then, many writers and artists have taken over the monthly comic through the years, chronicling the adventures of Marvel's most identifiable hero.\n\nThe Amazing Spider-Man has been the character's flagship series for his first fifty years in publication, and was the only monthly series to star Spider-Man until Peter Parker, The Spectacular Spider-Man, in 1976, although 1972 saw the debut of Marvel Team-Up, with the vast majority of issues featuring Spider-Man along with a rotating cast of other Marvel characters. Most of the major characters and villains of the Spider-Man saga have been introduced in Amazing, and with few exceptions, it is where most key events in the character's history have occurred. The title was published continuously until No. 441 (Nov. 1998) when Marvel Comics relaunched it as vol. 2 No. 1 (Jan. 1999), but on Spider-Man's 40th anniversary, this new title reverted to using the numbering of the original series, beginning again with issue No. 500 (Dec. 2003) and lasting until the final issue, No. 700 (Feb. 2013).\n\n1960s\nDue to strong sales on the character's first appearance in Amazing Fantasy No. 15, Spider-Man was given his own ongoing series in March 1963. The initial years of the series, under Lee and Ditko, chronicled Spider-Man's nascent career as a masked super-human vigilante with his civilian life as hard-luck yet perpetually good-humored and well-meaning teenager Peter Parker. Peter balanced his career as Spider-Man with his job as a freelance photographer for The Daily Bugle under the bombastic editor-publisher J. Jonah Jameson to support himself and his frail Aunt May. At the same time, Peter dealt with public hostility towards Spider-Man and the antagonism of his classmates Flash Thompson and They don\u2019t have to feed themselves by Liz Allan at Midtown High School, while embarking on a tentative, ill-fated romance with Jameson's secretary, Betty Brant.\n\nBy focusing on Parker's everyday problems, Lee and Ditko created a groundbreakingly flawed, self-doubting superhero, and the first major teenaged superhero to be a protagonist and not a sidekick. Ditko's quirky art provided a stark contrast to the more cleanly dynamic stylings of Marvel's most prominent artist, Jack Kirby, and combined with the humor and pathos of Lee's writing to lay the foundation for what became an enduring mythos.\n\nMost of Spider-Man's key villains and supporting characters were introduced during this time. Issue No. 1 (March 1963) featured the first appearances of J. Jonah Jameson and his astronaut son John Jameson, and the supervillain the Chameleon. It included the hero's first encounter with the superhero team the Fantastic Four. Issue No. 2 (May 1963) featured the first appearance of the Vulture and the Tinkerer as well as the beginning of Parker's freelance photography career at the newspaper The Daily Bugle.\n\nThe Lee-Ditko era continued to usher in a significant number of villains and supporting characters, including Doctor Octopus in No. 3 (July 1963); the Sandman and Betty Brant in No. 4 (Sept. 1963); the Lizard in No. 6 (Nov. 1963); Living Brain in (#8, January 1964); Electro in No. 9 (March 1964); Mysterio in No. 13 (June 1964); the Green Goblin in No. 14 (July 1964); Kraven The Hunter in No. 15 (Aug. 1964); reporter Ned Leeds in No. 18 (Nov. 1964); and the Scorpion in No. 20 (Jan. 1965). The Molten Man was introduced in No. 28 (Sept. 1965) which also featured Parker's graduation from high school. Peter began attending Empire State University in No. 31 (Dec. 1965), the issue which featured the first appearances of friends and classmates Gwen Stacy and Harry Osborn. Harry's father, Norman Osborn first appeared in No. 23 (April 1965) as a member of Jameson's country club but is not named nor revealed as Harry's father until No. 37 (June 1966).\n\nOne of the most celebrated issues of the Lee-Ditko run is No. 33 (Feb. 1966), the third part of the story arc \"If This Be My Destiny...!\", which features the dramatic scene of Spider-Man, through force of will and thoughts of family, escaping from being pinned by heavy machinery. Comics historian Les Daniels noted that \"Steve Ditko squeezes every ounce of anguish out of Spider-Man's predicament, complete with visions of the uncle he failed and the aunt he has sworn to save.\" Peter David observed that \"After his origin, this two-page sequence from Amazing Spider-Man No. 33 is perhaps the best-loved sequence from the Stan Lee/Steve Ditko era.\" Steve Saffel stated the \"full page Ditko image from The Amazing Spider-Man No. 33 is one of the most powerful ever to appear in the series and influenced writers and artists for many years to come.\" and Matthew K. Manning wrote that \"Ditko's illustrations for the first few pages of this Lee story included what would become one of the most iconic scenes in Spider-Man's history.\" The story was chosen as No. 15 in the 100 Greatest Marvels of All Time poll of Marvel's readers in 2001. Editor Robert Greenberger wrote in his introduction to the story that \"These first five pages are a modern-day equivalent to Shakespeare as Parker's soliloquy sets the stage for his next action. And with dramatic pacing and storytelling, Ditko delivers one of the great sequences in all comics.\"\n\nAlthough credited only as artist for most of his run, Ditko would eventually plot the stories as well as draw them, leaving Lee to script the dialogue. A rift between Ditko and Lee developed, and the two men were not on speaking terms long before Ditko completed his last issue, The Amazing Spider-Man No. 38 (July 1966). The exact reasons for the Ditko-Lee split have never been fully explained. Spider-Man successor artist John Romita Sr., in a 2010 deposition, recalled that Lee and Ditko \"ended up not being able to work together because they disagreed on almost everything, cultural, social, historically, everything, they disagreed on characters...\"\n\nIn successor penciler Romita Sr.'s first issue, No. 39 (Aug. 1966), nemesis the Green Goblin discovers Spider-Man's secret identity and reveals his own to the captive hero. Romita's Spider-Man \u2013 more polished and heroic-looking than Ditko's \u2013 became the model for two decades. The Lee-Romita era saw the introduction of such characters as Daily Bugle managing editor Robbie Robertson in No. 52 (Sept. 1967) and NYPD Captain George Stacy, father of Parker's girlfriend Gwen Stacy, in No. 56 (Jan. 1968). The most important supporting character to be introduced during the Romita era was Mary Jane Watson, who made her first full appearance in No. 42, (Nov. 1966), although she first appeared in No. 25 (June 1965) with her face obscured and had been mentioned since No. 15 (Aug. 1964). Peter David wrote in 2010 that Romita \"made the definitive statement of his arrival by pulling Mary Jane out from behind the oversized potted plant [that blocked the readers' view of her face in issue #25] and placing her on panel in what would instantly become an iconic moment.\" Romita has stated that in designing Mary Jane, he \"used Ann-Margret from the movie Bye Bye Birdie as a guide, using her coloring, the shape of her face, her red hair and her form-fitting short skirts.\"\n\nLee and Romita toned down the prevalent sense of antagonism in Parker's world by improving Parker's relationship with the supporting characters and having stories focused as much on the social and college lives of the characters as they did on Spider-Man's adventures. The stories became more topical, addressing issues such as civil rights, racism, prisoners' rights, the Vietnam War, and political elections.\n\nIssue No. 50 (June 1967) introduced the highly enduring criminal mastermind the Kingpin, who would become a major force as well in the superhero series Daredevil. Other notable first appearances in the Lee-Romita era include the Rhino in No. 41 (Oct. 1966), the Shocker in No. 46 (March 1967), the Prowler in No. 78 (Nov. 1969), and the Kingpin's son, Richard Fisk, in No. 83 (April 1970).\n\n1970s\n\nSeveral spin-off series debuted in the 1970s: Marvel Team-Up in 1972, and The Spectacular Spider-Man in 1976. A short-lived series titled Giant-Size Spider-Man began in July 1974 and ran six issues through 1975. Spidey Super Stories, a series aimed at children ages 6\u201310, ran for 57 issues from October 1974 through 1982.\nThe flagship title's second decade took a grim turn with a story in #89-90 (Oct.-Nov. 1970) featuring the death of Captain George Stacy. This was the first Spider-Man story to be penciled by Gil Kane, who would alternate drawing duties with Romita for the next year-and-a-half and would draw several landmark issues.\n\nOne such story took place in the controversial issues #96\u201398 (May\u2013July 1971). Writer-editor Lee defied the Comics Code Authority with this story, in which Parker's friend Harry Osborn, was hospitalized after over-dosing on pills. Lee wrote this story upon a request from the U. S. Department of Health, Education, and Welfare for a story about the dangers of drugs. Citing its dictum against depicting drug use, even in an anti-drug context, the CCA refused to put its seal on these issues. With the approval of Marvel publisher Martin Goodman, Lee had the comics published without the seal. The comics sold well and Marvel won praise for its socially conscious efforts. The CCA subsequently loosened the Code to permit negative depictions of drugs, among other new freedoms.\n\n\"The Six Arms Saga\" of #100\u2013102 (Sept.\u2013Nov. 1971) introduced Morbius, the Living Vampire. The second installment was the first Amazing Spider-Man story not written by co-creator Lee, with Roy Thomas taking over writing the book for several months before Lee returned to write #105\u2013110 (Feb.-July 1972). Lee, who was going on to become Marvel Comics' publisher, with Thomas becoming editor-in-chief, then turned writing duties over to 19-year-old Gerry Conway, who scripted the series through 1975. Romita penciled Conway's first half-dozen issues, which introduced the gangster Hammerhead in No. 113 (Oct. 1972). Kane then succeeded Romita as penciler, although Romita would continue inking Kane for a time.\n\nIssues 121\u2013122 (June\u2013July 1973, by Conway-Kane-Romita), which featured the death of Gwen Stacy at the hands of the Green Goblin in \"The Night Gwen Stacy Died\" in issue No. 121. Her demise and the Goblin's apparent death one issue later formed a story arc widely considered as the most defining in the history of Spider-Man. The aftermath of the story deepened both the characterization of Mary Jane Watson and her relationship with Parker.\n\nIn 1973, Gil Kane was succeeded by Ross Andru, whose run lasted from issue No. 125 (October 1973) to No. 185 (October 1978). Issue#129 (Feb. 1974) introduced the Punisher, who would become one of Marvel Comics' most popular characters. The Conway-Andru era featured the first appearances of the Man-Wolf in #124\u2013125 (Sept.-Oct. 1973); the near-marriage of Doctor Octopus and Aunt May in No. 131 (April 1974); Harry Osborn stepping into his father's role as the Green Goblin in #135\u2013137 (Aug.-Oct.1974); and the original \"Clone Saga\", containing the introduction of Spider-Man's clone, in #147\u2013149 (Aug.-Oct. 1975).\n\nArchie Goodwin and Gil Kane produced the title's 150th issue (Nov. 1975) before Len Wein became writer with issue No. 151. During Wein's tenure, Harry Osborn and Liz Allen dated and became engaged; J. Jonah Jameson was introduced to his eventual second wife, Marla Madison; and Aunt May suffered a heart attack. Wein's last story on Amazing was a five-issue arc in #176\u2013180 (Jan.-May 1978) featuring a third Green Goblin (Harry Osborn's psychiatrist, Bart Hamilton).\n\nMarv Wolfman, Marvel's editor-in-chief from 1975 to 1976, succeeded Wein as writer, and in his first issue, No. 182 (July 1978), had Parker propose marriage to Watson who refused, in the following issue. Keith Pollard succeeded Ross Andru as artist shortly afterward, and with Wolfman introduced the likable rogue the Black Cat (Felicia Hardy) in No. 194 (July 1979). As a love interest for Spider-Man, the Black Cat would go on to be an important supporting character for the better part of the next decade, and remain a friend and occasional lover into the 2010s.\n\n1980s\n\nThe Amazing Spider-Man No. 200 (Jan. 1980) featured the return and death of the burglar who killed Spider-Man's Uncle Ben. Writer Marv Wolfman and penciler Keith Pollard both left the title by mid-year, succeeded by Dennis O'Neil, a writer known for groundbreaking 1970s work at rival DC Comics, and penciler John Romita Jr. O'Neil wrote two issues of The Amazing Spider-Man Annual which were both drawn by Frank Miller.  The 1980 Annual featured a team-up with Doctor Strange while the 1981 Annual showcased a meeting with the Punisher. Roger Stern, who had written nearly 20 issues of sister title The Spectacular Spider-Man, took over Amazing with issue No. 224 (January 1982). During his two years on the title, Stern augmented the backgrounds of long-established Spider-Man villains, and with Romita Jr. created the mysterious supervillain the Hobgoblin in #238\u2013239 (March\u2013April 1983). Fans engaged with the mystery of the Hobgoblin's secret identity, which continued throughout #244\u2013245 and 249\u2013251 (Sept.-Oct. 1983 and Feb.-April 1984). One lasting change was the reintroduction of Mary Jane Watson as a more serious, mature woman who becomes Peter's confidante after she reveals that she knows his secret identity.  Stern also wrote \"The Kid Who Collects Spider-Man\" in The Amazing Spider-Man No. 248 (January 1984), a story which ranks among his most popular.\n\nBy mid-1984, Tom DeFalco and Ron Frenz took over scripting and penciling. DeFalco helped establish Parker and Watson's mature relationship, laying the foundation for the characters' wedding in 1987. Notably, in No. 257 (Oct. 1984), Watson tells Parker that she knows he is Spider-Man, and in No. 259 (Dec. 1984), she reveals to Parker the extent of her troubled childhood. Other notable issues of the DeFalco-Frenz era include No. 252 (May 1984), with the first appearance of Spider-Man's black costume, which the hero would wear almost exclusively for the next four years' worth of comics; the debut of criminal mastermind the Rose, in No. 253 (June 1984); the revelation in No. 258 (Nov. 1984) that the black costume is a living being, a symbiote; and the introduction of the female mercenary Silver Sable in No. 265 (June 1985).\n\nTom DeFalco and Ron Frenz were both removed from The Amazing Spider-Man in 1986 by editor Jim Owsley under acrimonious circumstances. A succession of artists including Alan Kupperberg, John Romita Jr., and Alex Saviuk penciled the series from 1987 to 1988; Owsley wrote the book for the first half of 1987, scripting the five-part \"Gang War\" story (#284\u2013288) that DeFalco plotted. Former Spectacular Spider-Man writer Peter David scripted No. 289 (June 1987), which revealed Ned Leeds as being the Hobgoblin although this was retconned in 1996 by Roger Stern into Leeds not being the original Hobgoblin after all.\n\nDavid Michelinie took over as writer in the next issue, for a story arc in #290\u2013292 (July\u2013Sept. 1987) that led to the marriage of Peter Parker and Mary Jane Watson in Amazing Spider-Man Annual No. 21. The \"Kraven's Last Hunt\" storyline by writer J.M. DeMatteis and artists Mike Zeck and Bob McLeod crossed over into The Amazing Spider-Man No. 293 and 294. Issue No. 298 (March 1988) was the first Spider-Man comic to be drawn by future industry star Todd McFarlane, the first regular artist on The Amazing Spider-Man since Frenz's departure. McFarlane revolutionized Spider-Man's look. His depiction \u2013 \"Ditko-esque\" poses, large-eyed, with wiry, contorted limbs, and messy, knotted, convoluted webbing \u2013 influenced the way virtually all subsequent artists would draw the character. McFarlane's other significant contribution to the Spider-Man canon was the design for what would become one of Spider-Man's most wildly popular antagonists, the supervillain Venom. Issue No. 299 (April 1988) featured Venom's first appearance (a last-page cameo) before his first full appearance in No. 300 (May 1988). The latter issue featured Spider-Man reverting to his original red-and-blue costume.\n\nOther notable issues of the Michelinie-McFarlane era include No. 312 (Feb. 1989), featuring the Green Goblin vs. the Hobgoblin; and #315\u2013317 (May\u2013July 1989), with the return of Venom. In July 2012, Todd McFarlane's original cover art for The Amazing Spider-Man No. 328 sold for a bid of $657,250, making it the most expensive American comic book art ever sold at auction.\n\n1990s\nWith a civilian life as a married man, the Spider-Man of the 1990s was different from the superhero of the previous three decades. McFarlane left the title in 1990 to write and draw a new series titled simply Spider-Man. His successor, Erik Larsen, penciled the book from early 1990 to mid-1991. After issue No. 350, Larsen was succeeded by Mark Bagley, who had won the 1986 Marvel Tryout Contest and was assigned a number of low-profile penciling jobs followed by a run on New Warriors in 1990. Bagley penciled the flagship Spider-Man title from 1991 to 1996. During that time, Bagley's rendition of Spider-Man was used extensively for licensed material and merchandise.\n\nIssues #361\u2013363 (April\u2013June 1992) introduced Carnage, a second symbiote nemesis for Spider-Man. The series' 30th-anniversary issue, No. 365 (Aug. 1992), was a double-sized, hologram-cover issue with the cliffhanger ending of Peter Parker's parents, long thought dead, reappearing alive. It would be close to two years before they were revealed to be impostors, who are killed in No. 388 (April 1994), scripter Michelinie's last issue. His 1987\u20131994 stint gave him the second-longest run as writer on the title, behind Stan Lee.\n\nIssue No. 375 was released with a gold foil cover. There was an error affecting some issues and which are missing the majority of the foil.\n\nWith No. 389, writer J. M. DeMatteis, whose Spider-Man credits included the 1987 \"Kraven's Last Hunt\" story arc and a 1991\u20131993 run on The Spectacular Spider-Man, took over the title. From October 1994 to June 1996, Amazing stopped running stories exclusive to it, and ran installments of multi-part stories that crossed over into all the Spider-Man books. One of the few self-contained stories during this period was in No. 400 (April 1995), which featured the death of Aunt May \u2013 later revealed to have been faked (although the death still stands in the MC2 continuity). The \"Clone Saga\" culminated with the revelation that the Spider-Man who had appeared in the previous 20 years of comics was a clone of the real Spider-Man. This plot twist was massively unpopular with many readers, and was later reversed in the \"Revelations\" story arc that crossed over the Spider-Man books in late 1996.\n\nThe Clone Saga tied into a publishing gap after No. 406 (Oct. 1995), when the title was temporarily replaced by The Amazing Scarlet Spider #1\u20132 (Nov.-Dec. 1995), featuring Ben Reilly. The series picked up again with No. 407 (Jan. 1996), with Tom DeFalco returning as writer. Bagley completed his 5\u00bd-year run by September 1996. A succession of artists, including Ron Garney, Steve Skroce, Joe Bennett, Rafael Kayanan and John Byrne penciled the book until the final issue, No. 441 (Nov. 1998), after which Marvel rebooted the title with vol. 2, No. 1 (Jan. 1999).\n\nRelaunch and the 2000s\nMarvel began The Amazing Spider-Man relaunching the 'Amazing' comic book series with (vol. 2) #1 (Jan. 1999). Howard Mackie wrote the first 29 issues. The relaunch included the Sandman being regressed to his criminal ways and the \"death\" of Mary Jane, which was ultimately reversed. Other elements included the introduction of a new Spider-Woman (who was spun off into her own short-lived series) and references to John Byrne's miniseries Spider-Man: Chapter One, which was launched at the same time as the reboot. Byrne also penciled issues #1\u201318 (from 1999 to 2000) and wrote #13\u201314, John Romita Jr. took his place soon after in October 2000", "flag": 1, "segments": [[727, 737]], "strength": 5.5}
{"text": "Berthold Konrad Hermann Albert Speer (; ; 19 March 1905\u00a0\u2013 1 September 1981) was a German architect who served as the Minister of Armaments and War Production in Nazi Germany during most of World War II. A close ally of Adolf Hitler, he was convicted at the Nuremberg trials and sentenced to 20 years in prison.\n\nAn architect by training, Speer joined the Nazi Party in 1931. His architectural skills made him increasingly prominent within the Party, and he became a member of Hitler's inner circle. Hitler commissioned him to design and construct structures including the Reich Chancellery and the Nazi party rally grounds in Nuremberg. In 1937, Hitler appointed Speer as General Building Inspector for Berlin. In this capacity he was responsible for the Central Department for Resettlement that evicted Jewish tenants from their homes in Berlin. In February 1942, Speer was appointed as Reich Minister of Armaments and War Production. Using misleading statistics, he promoted himself as having performed an \"armaments miracle\" that was widely credited with keeping Germany in the war. In 1944, Speer established a task force to increase production of fighter aircraft. It became instrumental in the exploitation of slave labor for the benefit of the German war effort.\n\nAfter the war, Speer was among the 24 \"major war criminals\" arrested and charged with the crimes of the Nazi regime at the Nuremberg trials. He was found guilty of war crimes and crimes against humanity, principally for the use of slave labor, narrowly avoiding a death sentence. Having served his full term, Speer was released in 1966. He used his writings from the time of imprisonment as the basis for two autobiographical books, Inside the Third Reich and Spandau: The Secret Diaries. Speer's books were a success; the public was fascinated by an inside view of the Third Reich. Speer died of a stroke in 1981. Little remains of his personal architectural work.\n\nThrough his autobiographies and interviews, Speer carefully constructed an image of himself as a man who deeply regretted having failed to discover the monstrous crimes of the Third Reich. He continued to deny explicit knowledge of, and responsibility for the Holocaust. This image dominated his historiography in the decades following the war, giving rise to the \"Speer Myth\": the perception of him as an apolitical technocrat responsible for revolutionizing the German war machine. The myth began to fall apart in the 1980s, when the armaments miracle was attributed to Nazi propaganda. Adam Tooze wrote in The Wages of Destruction that the idea that Speer was an apolitical technocrat was \"absurd\". Martin Kitchen, writing in Speer: Hitler's Architect, stated that much of the increase in Germany's arms production was actually due to systems instituted by Speer's predecessor (Fritz Todt) and furthermore that Speer was intimately involved in the \"Final Solution\".\n\nEarly years and personal life\nSpeer was born in Mannheim, into an upper-middle-class family. He was the second of three sons of Luise M\u00e1thilde Wilhelmine (Hommel) and Albert Friedrich Speer. In 1918, the family leased their Mannheim residence and moved to a home they had in Heidelberg. Henry T. King, deputy prosecutor at the Nuremberg trials who later wrote a book about Speer said, \"Love and warmth were lacking in the household of Speer's youth.\" His brothers, Ernst and Hermann, bullied him throughout his childhood. Speer was active in sports, taking up skiing and mountaineering. He followed in the footsteps of his father and grandfather and studied architecture.\n\nSpeer began his architectural studies at the University of Karlsruhe instead of a more highly acclaimed institution because the hyperinflation crisis of 1923 limited his parents' income. In 1924, when the crisis had abated, he transferred to the \"much more reputable\" Technical University of Munich. In 1925, he transferred again, this time to the Technical University of Berlin where he studied under Heinrich Tessenow, whom Speer greatly admired. After passing his exams in 1927, Speer became Tessenow's assistant, a high honor for a man of 22. As such, Speer taught some of his classes while continuing his own postgraduate studies. In Munich Speer began a close friendship, ultimately spanning over 50 years, with Rudolf Wolters, who also studied under Tessenow.\n\nIn mid-1922, Speer began courting Margarete (Margret) Weber (1905\u20131987), the daughter of a successful craftsman who employed 50 workers. The relationship was frowned upon by Speer's class-conscious mother, who felt the Webers were socially inferior. Despite this opposition, the two married in Berlin on 28 August 1928; seven years elapsed before Margarete was invited to stay at her in-laws' home. The couple would have six children together, but Albert Speer grew increasingly distant from his family after 1933. He remained so even after his release from imprisonment in 1966, despite their efforts to forge closer bonds.\n\nParty architect and government functionary\n\nJoining the Nazis (1931\u20131934)\n\nIn January 1931, Speer applied for Nazi Party membership, and on 1 March 1931, he became member number 474,481. The same year, with stipends shrinking amid the Depression, Speer surrendered his position as Tessenow's assistant and moved to Mannheim, hoping to make a living as an architect. After he failed to do so, his father gave him a part-time job as manager of his properties. In July\u00a01932, the Speers visited Berlin to help out the Party before the Reichstag elections. While they were there his friend, Nazi Party official Karl Hanke recommended the young architect to Joseph Goebbels to help renovate the Party's Berlin headquarters. When the commission was completed, Speer returned to Mannheim and remained there as Hitler took office in January\u00a01933.\n\nThe organizers of the 1933 Nuremberg Rally asked Speer to submit designs for the rally, bringing him into contact with Hitler for the first time. Neither the organizers nor Rudolf Hess were willing to decide whether to approve the plans, and Hess sent Speer to Hitler's Munich apartment to seek his approval. This work won Speer his first national post, as Nazi Party \"Commissioner for the Artistic and Technical Presentation of Party Rallies and Demonstrations\".\n\nShortly after Hitler came into power, he began to make plans to rebuild the chancellery. At the end of 1933, he contracted Paul Troost to renovate the entire building. Hitler appointed Speer, whose work for Goebbels had impressed him, to manage the building site for Troost. As Chancellor, Hitler had a residence in the building and came by every day to be briefed by Speer and the building supervisor on the progress of the renovations. After one of these briefings, Hitler invited Speer to lunch, to the architect's great excitement. Speer quickly became part of Hitler's inner circle; he was expected to call on him in the morning for a walk or chat, to provide consultation on architectural matters, and to discuss Hitler's ideas. Most days he was invited to dinner.\n\nIn the English version of his memoirs, Speer says that his political commitment merely consisted of paying his \"monthly dues\". He assumed his German readers would not be so gullible and told them the Nazi Party offered a \"new mission\". He was more forthright in an interview with William Hamsher in which he said he joined the party in order to save \"Germany from Communism\". After the war, he claimed to have had little interest in politics at all and had joined almost by chance. Like many of those in power in the Third Reich, he was not an ideologue, \"nor was he anything more than an instinctive anti-Semite.\" The historian Magnus Brechtken, discussing Speer, said he did not give anti-Jewish public speeches and that his anti-Semitism can best be understood through his actions\u2014which were anti-Semitic. Brechtken added that, throughout Speer's life, his central motives were to gain power, rule, and acquire wealth.\n\nNazi architect (1934\u20131937)\n\nWhen Troost died on 21 January 1934, Speer effectively replaced him as the Party's chief architect. Hitler appointed Speer as head of the Chief Office for Construction, which placed him nominally on Hess's staff.\n\nOne of Speer's first commissions after Troost's death was the Zeppelinfeld stadium in Nuremberg. It was used for Nazi propaganda rallies and can be seen in Leni Riefenstahl's propaganda film Triumph of the Will. The building was able to hold 340,000 people. Speer insisted that as many events as possible be held at night, both to give greater prominence to his lighting effects and to hide the overweight Nazis. Nuremberg was the site of many official Nazi buildings. Many more buildings were planned. If built, the German Stadium would have accommodated 400,000 spectators. Speer modified Werner March's design for the Olympic Stadium being built for the 1936 Summer Olympics. He added a stone exterior that pleased Hitler. Speer designed the German Pavilion for the 1937 international exposition in Paris.\n\nBerlin's General Building Inspector (1937\u20131942)\n\nOn 30 January 1937, Hitler appointed Speer as General Building Inspector for the Reich Capital. This carried with it the rank of State Secretary in the Reich government and gave him extraordinary powers over the Berlin city government. He was to report directly to Hitler, and was independent of both the mayor and the Gauleiter of Berlin. Hitler ordered Speer to develop plans to rebuild Berlin. These centered on a three-mile-long grand boulevard running from north to south, which Speer called the Prachtstrasse, or Street of Magnificence; he also referred to it as the \"North\u2013South Axis\". At the northern end of the boulevard, Speer planned to build the Volkshalle, a huge domed assembly hall over  high, with floor space for 180,000 people. At the southern end of the avenue, a great triumphal arch, almost  high and able to fit the Arc de Triomphe inside its opening, was planned. The existing Berlin railroad termini were to be dismantled, and two large new stations built. Speer hired Wolters as part of his design team, with special responsibility for the Prachtstrasse. The outbreak of World War II in 1939 led to the postponement, and later the abandonment, of these plans.\n\nPlans to build a new Reich chancellery had been underway since 1934. Land had been purchased by the end of 1934 and starting in March 1936 the first buildings were demolished to create space at Vo\u00dfstra\u00dfe. Speer was involved virtually from the beginning. In the aftermath of the Night of the Long Knives, he had been commissioned to renovate the Borsig Palace on the corner of Vo\u00dfstra\u00dfe and Wilhelmstra\u00dfe as headquarters of the Sturmabteilung (SA). He completed the preliminary work for the new chancellery by May 1936. In June 1936 he charged a personal honorarium of 30,000 Reichsmark and estimated the chancellery would be completed within three to four years. Detailed plans were completed in July 1937 and the first shell of the new chancellery was complete on 1 January 1938. On 27 January 1938, Speer received plenipotentiary powers from Hitler to finish the new chancellery by 1 January 1939. For propaganda Hitler claimed during the topping-out ceremony on 2 August 1938, that he had ordered Speer to complete the new chancellery that year. Shortages of labor meant the construction workers had to work in ten-to-twelve-hour shifts. The Schutzstaffel (SS) built two concentration camps in 1938 and used the inmates to quarry stone for its construction. A brick factory was built near the Oranienburg concentration camp at Speer's behest; when someone commented on the poor conditions there, Speer stated, \"The Yids got used to making bricks while in Egyptian captivity\". The chancellery was completed in early January 1939. The building itself was hailed by Hitler as the \"crowning glory of the greater German political empire\".\n\nDuring the Chancellery project, the pogrom of Kristallnacht took place. Speer made no mention of it in the first draft of Inside the Third Reich. It was only on the urgent advice of his publisher that he added a mention of seeing the ruins of the Central Synagogue in Berlin from his car. Kristallnacht accelerated Speer's ongoing efforts to dispossess Berlin's Jews from their homes. From 1939 on, Speer's Department used the Nuremberg Laws to evict Jewish tenants of non-Jewish landlords in Berlin, to make way for non-Jewish tenants displaced by redevelopment or bombing. Eventually, 75,000 Jews were displaced by these measures. Speer denied he knew they were being put on Holocaust trains and claimed that those displaced were, \"Completely free and their families were still in their apartments\". He also said: \"\u00a0... en route to my ministry on the city highway, I could see\u00a0... crowds of people on the platform of nearby Nikolassee Railroad Station. I knew that these must be Berlin Jews who were being evacuated. I am sure that an oppressive feeling struck me as I drove past. I presumably had a sense of somber events.\" Matthias Schmidt said Speer had personally inspected concentration camps and described his comments as an \"outright farce\". Martin Kitchen described Speer's often repeated line that he knew nothing of the \"dreadful things\" as hollow\u2014because not only was he fully aware of the fate of the Jews he was actively participating in their persecution.\n\nAs Germany started World War II in Europe, Speer instituted quick-reaction squads to construct roads or clear away debris; before long, these units would be used to clear bomb sites. Speer used forced Jewish labor on these projects, in addition to regular German workers. Construction stopped on the Berlin and N\u00fcremberg plans at the outbreak of war. Though stockpiling of materials and other work continued, this slowed to a halt as more resources were needed for the armament industry. Speer's offices undertook building work for each branch of the military, and for the SS, using slave labor. Speer's building work made him among the wealthiest of the Nazi elite.\n\nMinister of Armaments\n\nAppointment and increasing power\n\nIn 1941, Speer was elected to the Reichstag from electoral constituency 2 (Berlin-West). On 8 February 1942, Reich Minister of Armaments and Munitions Fritz Todt died in a plane crash shortly after taking off from Hitler's eastern headquarters at Rastenburg. Speer arrived there the previous evening and accepted Todt's offer to fly with him to Berlin. Speer cancelled some hours before take-off because the previous night he had been up late in a meeting with Hitler. Hitler appointed Speer in Todt's place. Martin Kitchen, a British historian, says that the choice was not surprising. Speer was loyal to Hitler, and his experience building prisoner of war camps and other structures for the military qualified him for the job. Speer succeeded Todt not only as Reich Minister but in all his other powerful positions, including Inspector General of German Roadways, Inspector General for Water and Energy and Head of the Nazi Party's Office of Technology. At the same time, Hitler also appointed Speer as head of the Organisation Todt, a massive, government-controlled construction company. Characteristically Hitler did not give Speer any clear remit; he was left to fight his contemporaries in the regime for power and control. As an example, he wanted to be given power over all armaments issues under Hermann G\u00f6ring's Four Year Plan. G\u00f6ring was reluctant to grant this. However Speer secured Hitler's support, and on 1 March 1942, G\u00f6ring signed a decree naming Speer \"General Plenipotentiary for Armament Tasks\" in the Four Year Plan. Speer proved to be ambitious, unrelenting and ruthless. Speer set out to gain control not just of armaments production in the army, but in the whole armed forces. It did not immediately dawn on his political rivals that his calls for rationalization and reorganization were hiding his desire to sideline them and take control. By April 1942, Speer had persuaded G\u00f6ring to create a three-member Central Planning Board within the Four Year Plan, which he used to obtain supreme authority over procurement and allocation of raw materials and scheduling of production in order to consolidate German war production in a single agency.\n\nSpeer was f\u00eated at the time, and in the post-war era, for performing an \"armaments miracle\" in which German war production dramatically increased. This \"miracle\" was brought to a halt in the summer of 1943 by, among other factors, the first sustained Allied bombing. Other factors probably contributed to the increase more than Speer himself. Germany's armaments production had already begun to result in increases under his predecessor, Todt. Naval armaments were not under Speer's supervision until October 1943, nor the Luftwaffe's armaments until June of the following year. Yet each showed comparable increases in production despite not being under Speer's control. Another factor that produced the boom in ammunition was the policy of allocating more coal to the steel industry. Production of every type of weapon peaked in June and July 1944, but there was now a severe shortage of fuel. After August 1944, oil from the Romanian fields was no longer available. Oil production became so low that any possibility of offensive action became impossible and weaponry lay idle.\n\nAs Minister of Armaments, Speer was responsible for supplying weapons to the army. With Hitler's full agreement, he decided to prioritize tank production, and he was given unrivaled power to ensure success. Hitler was closely involved with the design of the tanks, but kept changing his mind about the specifications. This delayed the program, and Speer was unable to remedy the situation. In consequence, despite tank production having the highest priority, relatively little of the armaments budget was spent on it. This led to a significant German Army failure at the Battle of Prokhorovka, a major turning point on the Eastern Front against the Soviet Red Army.\n\nAs head of Organisation Todt, Speer was directly involved in the construction and alteration of concentration camps. He agreed to expand Auschwitz and some other camps, allocating 13.7 million Reichsmarks for the work to be carried out. This allowed an extra 300 huts to be built at Auschwitz, increasing the total human capacity to 132,000. Included in the building works but only this few. Once this house has been was material to build gas chambers, crematoria and morgues. The SS called this \"Professor Speer's Special Programme\".\n\nSpeer realized that with six million workers drafted into the armed forces, there was a labor shortage in the war economy, and not enough workers for his factories. In response, Hitler appointed Fritz Sauckel as a \"manpower dictator\" to obtain new workers. Speer and Sauckel cooperated closely to meet Speer's labor demands. Hitler gave Sauckel a free hand to obtain labor, something that delighted Speer, who had requested 1,000,000 \"voluntary\" laborers to meet the need for armament workers. Sauckel had whole villages in France, Holland and Belgium forcibly rounded up and shipped to Speer's factories. Sauckel obtained new workers often using the most brutal methods. In occupied areas of the Soviet Union, that had been subject to partisan action, civilian men and women were rounded up en masse and sent to work forcibly in Germany. By April 1943, Sauckel had supplied 1,568,801 \"voluntary\" laborers, forced laborers, prisoners of war and concentration camp prisoners to Speer for use in his armaments factories. It was for the maltreatment of these people, that Speer was principally convicted at the Nuremberg Trials.\n\nConsolidation of arms production\n\nFollowing his appointment as Minister of Armaments, Speer was in control of armaments production solely for the Army. He coveted control of the production of armaments for the Luftwaffe and Kriegsmarine as well. He set about extending his power and influence with unexpected ambition. His close relationship with Hitler provided him with political protection, and he was able to outwit and outmaneuver his rivals in the regime. Hitler's cabinet was dismayed at his tactics, but, regardless, he was able to accumulate new responsibilities and more power. By July 1943, he had gained control of armaments production for the Luftwaffe and Kriegsmarine. In August 1943, he took control of most of the Ministry of Economics, to become, in Admiral D\u00f6nitz's words, \"Europe's economic dictator\". His formal title was changed on 2 September 1943, to \"Reich Minister for Armaments and War Production\". He had become one of the most powerful people in Nazi Germany.\n\nSpeer and his hand-picked director of submarine construction Otto Merker believed that the shipbuilding industry was being held back by outdated methods, and revolutionary new approaches imposed by outsiders would dramatically improve output. This belief proved incorrect, and Speer and Merker's attempt to build the Kriegsmarines new generation of submarines, the Type XXI and Type XXIII, as prefabricated sections at different facilities rather than at single dockyards contributed to the failure of this strategically important program. The designs were rushed into production, and the completed submarines were crippled by flaws which resulted from the way they had been constructed. While dozens of submarines were built, few ever entered service.\n\nIn December 1943, Speer visited Organisation Todt workers in Lapland, while there he seriously damaged his knee and was incapacitated for several months. He was under the dubious care of Professor Karl Gebhardt at a medical clinic called Hohenlychen where patients \"mysteriously failed to survive\". In mid-January 1944, Speer had a lung embolism and fell seriously ill. Concerned about retaining power, he did not appoint a deputy and continued to direct work of the Armaments Ministry from his bedside. Speer's illness coincided with the Allied \"Big Week\", a series of bombing raids on the German aircraft factories that were a devastating blow to aircraft production. His political rivals used the opportunity to undermine his authority and damage his reputation with Hitler. He lost Hitler's unconditional support and began to lose power.\n\nIn response to the Allied Big Week, Adolf Hitler authorized the creation of a Fighter Staff committee. Its aim was to ensure the preservation and growth of fighter aircraft production. The task force was established by 1 March 1944, orders of Speer, with support from Erhard Milch of the Reich Aviation Ministry. Production of German fighter aircraft more than doubled between 1943 and 1944. The growth, however, consisted in large part of models that were becoming obsolescent and proved easy prey for Allied aircraft. On 1 August 1944, Speer merged the Fighter Staff into a newly formed Armament Staff committee.\n\nThe Fighter Staff committee was instrumental in bringing about the increased exploitation of slave labor in the war economy. The SS provided 64,000 prisoners for 20 separate projects from various concentration camps including Mittelbau-Dora. Prisoners worked for Junkers, Messerschmitt, Henschel and BMW, among others. To increase production, Speer introduced a system of punishments for his workforce. Those who feigned illness, slacked off, sabotaged production or tried to escape were denied food or sent to concentration camps. In 1944, this became endemic; over half a million workers were arrested. By this time, 140,000 people were working in Speer's underground factories. These factories were death-traps; discipline was brutal, with regular executions. There were so many corpses at the Dora underground factory, for example, that", "flag": 1, "segments": [[3913, 3923]], "strength": 5.5}
{"text": "The Alps are the highest and most extensive mountain range system that lies entirely in Europe, stretching approximately  across eight Alpine countries (from west to east): France, Switzerland, Monaco, Italy, Liechtenstein, Austria, Germany, and Slovenia. \n\nThe Alpine arch generally extends from Nice on the western Mediterranean to Trieste on the Adriatic and Vienna at the beginning of the Pannonian Basin. The mountains were formed over tens of millions of years as the African and Eurasian tectonic plates collided. Extreme shortening  caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as Mont Blanc and the Matterhorn. \n\nMont Blanc spans the French\u2013Italian border, and at  is the highest mountain in the Alps. The Alpine region area contains 128 peaks higher than.\n\nThe altitude and size of the range affect the climate in Europe; in the mountains, precipitation levels vary greatly and climatic conditions consist of distinct zones. Wildlife such as ibex live in the higher peaks to elevations of, and plants such as Edelweiss grow in rocky areas in lower elevations as well as in higher elevations. \n\nEvidence of human habitation in the Alps goes back to the Palaeolithic era. A mummified man, determined to be 5,000 years old, was discovered on a glacier at the Austrian\u2013Italian border in 1991.\n\nBy the 6th century BC, the Celtic La T\u00e8ne culture was well established. Hannibal famously crossed the Alps with a herd of elephants, and the Romans had settlements in the region. In 1800, Napoleon crossed one of the mountain passes with an army of 40,000. The 18th and 19th centuries saw an influx of naturalists, writers, and artists, in particular, the Romantics, followed by the golden age of alpinism as mountaineers began to ascend the peaks.\n\nThe Alpine region has a strong cultural identity. The traditional culture of farming, cheesemaking, and woodworking still exists in Alpine villages, although the tourist industry began to grow early in the 20th century and expanded greatly after World War II to become the dominant industry by the end of the century. \n\nThe Winter Olympic Games have been hosted in the Swiss, French, Italian, Austrian and German Alps. At present, the region is home to 14\u00a0million people and has 120\u00a0million annual visitors.\n\nEtymology and toponymy \n\nThe English word Alps comes from the Latin Alpes.\n\nThe Latin word Alpes could possibly come from the adjective albus (\"white\"), or could possibly come from the Greek goddess Alphito, whose name is related to alphita, the \"white flour\"; alphos, a dull white leprosy; and finally the Proto-Indo-European word *alb\u02b0\u00f3s. Similarly, the river god Alpheus is also supposed to derive from the Greek alphos and means whitish.\n\nIn his commentary on the Aeneid of Vergil, the late fourth-century grammarian Maurus Servius Honoratus says that all high mountains are called Alpes by Celts.  \n\nAccording to the Oxford English Dictionary, the Latin Alpes might possibly derive from a pre-Indo-European word *alb \"hill\"; \"Albania\" is a related derivation. Albania, a name not native to the region known as the country of Albania, has been used as a name for a number of mountainous areas across Europe. \n\nIn Roman times, \"Albania\" was a name for the eastern Caucasus, while in the English languages \"Albania\" (or \"Albany\") was occasionally used as a name for Scotland, although it is more likely derived from the Latin word albus, the color white.\n\nIn modern languages the term alp, alm, albe or alpe refers to a grazing pastures in the alpine regions below the glaciers, not the peaks. \n\nAn alp refers to a high mountain pasture, typically near or above the tree line, where cows and other livestock are taken to be grazed during the summer months and where huts and hay barns can be found, sometimes constituting tiny hamlets. Therefore, the term \"the Alps\", as a reference to the mountains, is a misnomer. The term for the mountain peaks varies by nation and language: words such as Horn, Kogel, Kopf, Gipfel, Spitze, Stock, and Berg are used in German-speaking regions; Mont, Pic, T\u00eate, Pointe, Dent, Roche, and Aiguille in French-speaking regions; and Monte, Picco, Corno, Punta, Pizzo, or Cima in Italian-speaking regions.\n\nGeography \n\nThe Alps are a crescent shaped geographic feature of central Europe that ranges in an  arc (curved line) from east to west and is  in width. The mean height of the mountain peaks is. The range stretches from the Mediterranean Sea north above the Po basin, extending through France from Grenoble, and stretching eastward through mid and southern Switzerland. The range continues onward toward Vienna, Austria, and east to the Adriatic Sea and Slovenia. \n\nTo the south it dips into northern Italy and to the north extends to the southern border of Bavaria in Germany. In areas like Chiasso, Switzerland, and Allg\u00e4u, Bavaria, the demarcation between the mountain range and the flatlands are clear; in other places such as Geneva, the demarcation is less clear.\n\nThe countries with the greatest alpine territory are Austria (28.7% of the total area), Italy (27.2%), France (21.4%) and Switzerland (13.2%).\n\nThe highest portion of the range is divided by the glacial trough of the Rh\u00f4ne valley, from Mont Blanc to the Matterhorn and Monte Rosa on the southern side, and the Bernese Alps on the northern. The peaks in the easterly portion of the range, in Austria and Slovenia, are smaller than those in the central and western portions. \n\nThe variances in nomenclature in the region spanned by the Alps makes classification of the mountains and subregions difficult, but a general classification is that of the Eastern Alps and Western Alps with the divide between the two occurring in eastern Switzerland according to geologist Stefan Schmid, near the Spl\u00fcgen Pass.\n \nThe highest peaks of the Western Alps and Eastern Alps, respectively, are Mont Blanc, at  and Piz Bernina at. The second-highest major peaks are Monte Rosa at  and Ortler, at, respectively.\n\nSeries of lower mountain ranges run parallel to the main chain of the Alps, including the French Prealps in France and the Jura Mountains in Switzerland and France. The secondary chain of the Alps follows the watershed from the Mediterranean Sea to the Wienerwald, passing over many of the highest and most well-known peaks in the Alps. \nFrom the Colle di Cadibona to Col de Tende it runs westwards, before turning to the northwest and then, near the Colle della Maddalena, to the north. Upon reaching the Swiss border, the line of the main chain heads approximately east-northeast, a heading it follows until its end near Vienna.\n\nThe northeast end of the Alpine arc directly on the Danube, which flows into the Black Sea, is the Leopoldsberg near Vienna. In contrast, the southeastern part of the Alps ends on the Adriatic Sea in the area around Trieste towards Duino and Barcola.\n\nPasses \n\nThe Alps have been crossed for war and commerce, and by pilgrims, students and tourists. Crossing routes by road, train or foot are known as passes, and usually consist of depressions in the mountains in which a valley leads from the plains and hilly pre-mountainous zones. \n\nIn the medieval period hospices were established by religious orders at the summits of many of the main passes. The most important passes are the Col de l'Iseran (the highest), the Col Agnel, the Brenner Pass, the Mont-Cenis, the Great St. Bernard Pass, the Col de Tende, the Gotthard Pass, the Semmering Pass, the Simplon Pass, and the Stelvio Pass.\n\nCrossing the Italian-Austrian border, the Brenner Pass separates the \u00d6tztal Alps and Zillertal Alps and has been in use as a trading route since the 14th century. The lowest of the Alpine passes at, the Semmering crosses from Lower Austria to Styria; since the 12th century when a hospice was built there, it has seen continuous use. A railroad with a tunnel  long was built along the route of the pass in the mid-19th century. With a summit of, the Great St. Bernard Pass is one of the highest in the Alps, crossing the Italian-Swiss border east of the Pennine Alps along the flanks of Mont Blanc. The pass was used by Napoleon Bonaparte to cross 40,000 troops in 1800.\n\nThe Mont Cenis pass has been a major commercial and military road between Western Europe and Italy. The pass was crossed by many troops on their way to the Italian peninsula. From Constantine I, Pepin the Short and Charlemagne to Henry IV, Napol\u00e9on and more recently the German Gebirgsj\u00e4gers during World War II.\n\nNow the pass has been supplanted by the Fr\u00e9jus Highway Tunnel (opened 1980) and Rail Tunnel (opened 1871).\n\nThe Saint Gotthard Pass crosses from Central Switzerland to Ticino; in 1882 the  Saint Gotthard Railway Tunnel was opened connecting Lucerne in Switzerland, with Milan in Italy. 98 years later followed Gotthard Road Tunnel ( long) connecting the A2 motorway in G\u00f6schenen on the north side with Airolo on the south side, exactly like the railway tunnel.\n\nOn 1 June 2016 the world's longest railway tunnel, the Gotthard Base Tunnel was opened, which connects Erstfeld in canton of Uri with Bodio in canton of Ticino by two single tubes of. \n\nIt is the first tunnel that traverses the Alps on a flat route.\n\nFrom 11 December 2016, it has been part of the regular railway timetable and used hourly as standard ride between Basel/Lucerne/Zurich and Bellinzona/Lugano/Milan.\n\nThe highest pass in the alps is the col de l'Iseran in Savoy (France) at, followed by the Stelvio Pass in northern Italy at ; the road was built in the 1820s.\n\nHighest mountains \n\nThe Union Internationale des Associations d'Alpinisme (UIAA) has defined a list of 82 \"official\" Alpine summits that reach at least. The list includes not only mountains, but also subpeaks with little prominence that are considered important mountaineering objectives. Below are listed the 29 \"four-thousanders\" with at least  of prominence.\n\nWhile Mont Blanc was first climbed in 1786 and the Jungfrau in 1811, most of the Alpine four-thousanders were climbed during the second half of the 19th century, notably Piz Bernina (1850), the Dom (1858), the Grand Combin (1859), the Weisshorn (1861) and the Barre des \u00c9crins (1864); the ascent of the Matterhorn in 1865 marked the end of the golden age of alpinism. Karl Blodig (1859\u20131956) was among the first to successfully climb all the major 4,000\u00a0m peaks. He completed his series of ascents in 1911. Many of the big Alpine three-thousanders were climbed in the early 19th century, notably the Grossglockner (1800) and the Ortler (1804), although some of them were climbed only much later, such at Mont Pelvoux (1848 23 that is set to be ratified soon on the), Monte Viso (1861) and La Meije (1877).\n\nThe first British Mont Blanc ascent was in 1788; the first female ascent in 1819. By the mid-1850s Swiss mountaineers had ascended most of the peaks and were eagerly sought as mountain guides. Edward Whymper reached the top of the Matterhorn in 1865 (after seven attempts), and in 1938 the last of the six great north faces of the Alps was climbed with the first ascent of the Eiger Nordwand (north face of the Eiger).\n\nGeology and orogeny \n\nImportant geological concepts were established as naturalists began studying the rock formations of the Alps in the 18th century. In the mid-19th century the now-defunct theory of geosynclines was used to explain the presence of \"folded\" mountain chains but by the mid-20th century the theory of plate tectonics became widely accepted.\n\nThe formation of the Alps (the Alpine orogeny) was an episodic process that began about 300\u00a0million years ago. In the Paleozoic Era the Pangaean supercontinent consisted of a single tectonic plate; it broke into separate plates during the Mesozoic Era and the Tethys sea developed between Laurasia and Gondwana during the Jurassic Period. The Tethys was later squeezed between colliding plates causing the formation of mountain ranges called the Alpide belt, from Gibraltar through the Himalayas to Indonesia\u2014a process that began at the end of the Mesozoic and continues into the present. The formation of the Alps was a segment of this orogenic process, caused by the collision between the African and the Eurasian plates that began in the late Cretaceous Period.\n\nUnder extreme compressive stresses and pressure, marine sedimentary rocks were uplifted, creating characteristic recumbent folds, or nappes, and thrust faults. As the rising peaks underwent erosion, a layer of marine flysch sediments was deposited in the foreland basin, and the sediments became involved in younger nappes (folds) as the orogeny progressed. Coarse sediments from the continual uplift and erosion were later deposited in foreland areas as molasse. The molasse regions in Switzerland and Bavaria were well-developed and saw further upthrusting of flysch.\n\nThe Alpine orogeny occurred in ongoing cycles through to the Paleogene causing differences in nappe structures, with a late-stage orogeny causing the development of the Jura Mountains. A series of tectonic events in the Triassic, Jurassic and Cretaceous periods caused different paleogeographic regions. The Alps are subdivided by different lithology (rock composition) and nappe structure according to the orogenic events that affected them. The geological subdivision differentiates the Western, Eastern Alps and Southern Alps: the Helveticum in the north, the Penninicum and Austroalpine system in the centre and, south of the Periadriatic Seam, the Southern Alpine system.\n\nAccording to geologist Stefan Schmid, because the Western Alps underwent a metamorphic event in the Cenozoic Era while the Austroalpine peaks underwent an event in the Cretaceous Period, the two areas show distinct differences in nappe formations. Flysch deposits in the Southern Alps of Lombardy probably occurred in the Cretaceous or later.\n\nPeaks in France, Italy and Switzerland lie in the \"Houilli\u00e8re zone\", which consists of basement with sediments from the Mesozoic Era. High \"massifs\" with external sedimentary cover are more common in the Western Alps and were affected by Neogene Period thin-skinned thrusting whereas the Eastern Alps have comparatively few high peaked massifs. Similarly the peaks in eastern Switzerland extending to western Austria (Helvetic nappes) consist of thin-skinned sedimentary folding that detached from former basement rock.\n\nIn simple terms, the structure of the Alps consists of layers of rock of European, African and oceanic (Tethyan) origin. The bottom nappe structure is of continental European origin, above which are stacked marine sediment nappes, topped off by nappes derived from the African plate. The Matterhorn is an example of the ongoing orogeny and shows evidence of great folding. The tip of the mountain consists of gneisses from the African plate; the base of the peak, below the glaciated area, consists of European basement rock. The sequence of Tethyan marine sediments and their oceanic basement is sandwiched between rock derived from the African and European plates.\n\nThe core regions of the Alpine orogenic belt have been folded and fractured in such a manner that erosion created the characteristic steep vertical peaks of the Swiss Alps that rise seemingly straight out of the foreland areas. Peaks such as Mont Blanc, the Matterhorn, and high peaks in the Pennine Alps, the Brian\u00e7onnais, and Hohe Tauern consist of layers of rock from the various orogenies including exposures of basement rock.\n\nDue to the ever-present geologic instability, earthquakes continue in the Alps to this day. Typically, the largest earthquakes in the alps have been between magnitude 6 and 7 on the Richter scale.\n\nMinerals \nThe Alps are a source of minerals that have been mined for thousands of years. In the 8th to 6th centuries BC during the Hallstatt culture, Celtic tribes mined copper; later the Romans mined gold for coins in the Bad Gastein area. Erzberg in Styria furnishes high-quality iron ore for the steel industry. Crystals, such as cinnabar, amethyst, and quartz, are found throughout much of the Alpine region. The cinnabar deposits in Slovenia are a notable source of cinnabar pigments.\n\nAlpine crystals have been studied and collected for hundreds of years, and began to be classified in the 18th century. Leonhard Euler studied the shapes of crystals, and by the 19th century crystal hunting was common in Alpine regions. David Friedrich Wiser amassed a collection of 8000 crystals that he studied and documented. In the 20th century Robert Parker wrote a well-known work about the rock crystals of the Swiss Alps; at the same period a commission was established to control and standardize the naming of Alpine minerals.\n\nGlaciers \n\nIn the Miocene Epoch the mountains underwent severe erosion because of glaciation, which was noted in the mid-19th century by naturalist Louis Agassiz who presented a paper proclaiming the Alps were covered in ice at various intervals\u2014a theory he formed when studying rocks near his Neuch\u00e2tel home which he believed originated to the west in the Bernese Oberland. Because of his work he came to be known as the \"father of the ice-age concept\" although other naturalists before him put forth similar ideas.\n\nAgassiz studied glacier movement in the 1840s at the Unteraar Glacier where he found the glacier moved  per year, more rapidly in the middle than at the edges. His work was continued by other scientists and now a permanent laboratory exists inside a glacier under the Jungfraujoch, devoted exclusively to the study of Alpine glaciers.\n\nGlaciers pick up rocks and sediment with them as they flow. This causes erosion and the formation of valleys over time. The Inn valley is an example of a valley carved by glaciers during the ice ages with a typical terraced structure caused by erosion. Eroded rocks from the most recent ice age lie at the bottom of the valley while the top of the valley consists of erosion from earlier ice ages. Glacial valleys have characteristically steep walls (reliefs); valleys with lower reliefs and talus slopes are remnants of glacial troughs or previously infilled valleys. Moraines, piles of rock picked up during the movement of the glacier, accumulate at edges, centre and the terminus of glaciers.\n\nAlpine glaciers can be straight rivers of ice, long sweeping rivers, spread in a fan-like shape (Piedmont glaciers), and curtains of ice that hang from vertical slopes of the mountain peaks. The stress of the movement causes the ice to break and crack loudly, perhaps explaining why the mountains were believed to be home to dragons in the medieval period. The cracking creates unpredictable and dangerous crevasses, often invisible under new snowfall, which cause the greatest danger to mountaineers.\n\nGlaciers end in ice caves (the Rh\u00f4ne Glacier), by trailing into a lake or river, or by shedding snowmelt on a meadow. Sometimes a piece of glacier will detach or break resulting in flooding, property damage and loss of life.\n\nHigh levels of precipitation cause the glaciers to descend to permafrost levels in some areas whereas in other, more arid regions, glaciers remain above about the  level. The  of the Alps covered by glaciers in 1876 had shrunk to  by 1973, resulting in decreased river run-off levels. Forty percent of the glaciation in Austria has disappeared since 1850, and 30% of that in Switzerland.\n\nRivers and lakes \n\nThe Alps provide lowland Europe with drinking water, irrigation, and hydroelectric power. Although the area is only about 11% of the surface area of Europe, the Alps provide up to 90% of water to lowland Europe, particularly to arid areas and during the summer months. Cities such as Milan depend on 80% of water from Alpine runoff. Water from the rivers is used in at least 550 hydroelectricity power plants, considering only those producing at least 10MW of electricity.\n\nMajor European rivers flow from the Alps, such as the Rhine, the Rh\u00f4ne, the Inn, and the Po, all of which have headwaters in the Alps and flow into neighbouring countries, finally emptying into the North Sea, the Mediterranean Sea, the Adriatic Sea and the Black Sea. Other rivers such as the Danube have major tributaries flowing into them that originate in the Alps. \n\nThe Rh\u00f4ne is second to the Nile as a freshwater source to the Mediterranean Sea; the river begins as glacial meltwater, flows into Lake Geneva, and from there to France where one of its uses is to cool nuclear power plants. The Rhine originates in a  area in Switzerland and represents almost 60% of water exported from the country. Tributary valleys, some of which are complicated, channel water to the main valleys which can experience flooding during the snowmelt season when rapid runoff causes debris torrents and swollen rivers.\n\nThe rivers form lakes, such as Lake Geneva, a crescent-shaped lake crossing the Swiss border with Lausanne on the Swiss side and the town of Evian-les-Bains on the French side. In Germany, the medieval St. Bartholomew's chapel was built on the south side of the K\u00f6nigssee, accessible only by boat or by climbing over the abutting peaks.\n\nAdditionally, the Alps have led to the creation of large lakes in Italy. For instance, the Sarca, the primary inflow of Lake Garda, originates in the Italian Alps. The Italian Lakes are a popular tourist destination since the Roman Era for their mild climate.\n\nScientists have been studying the impact of climate change and water use. For example, each year more water is diverted from rivers for snowmaking in the ski resorts, the effect of which is yet unknown. Furthermore, the decrease of glaciated areas combined with a succession of winters with lower-than-expected precipitation may have a future impact on the rivers in", "flag": 1, "segments": [[2566, 2576]], "strength": 5.5}
{"text": "Dame Agatha Mary Clarissa Christie, Lady Mallowan,  (n\u00e9e Miller; 15\u00a0September 1890\u00a0\u2013 12\u00a0January 1976) was an English writer known for her 66 detective novels and 14 short story collections, particularly those revolving around fictional detectives Hercule Poirot and Miss Marple. She also wrote the world's longest-running play, The Mousetrap, which has been performed in the West End since 1952, as well as six novels under the pseudonym Mary Westmacott. In 1971, she was made a Dame (DBE) for her contributions to literature. Guinness World Records lists Christie as the best-selling fiction writer of all time, her novels having sold more than two billion copies.\n\nChristie was born into a wealthy upper-middle-class family in Torquay, Devon, and was largely home-schooled. She was initially an unsuccessful writer with six consecutive rejections, but this changed in 1920 when The Mysterious Affair at Styles, featuring detective Hercule Poirot, was published. Her first husband was Archibald Christie; they married in 1914 and had one child before divorcing in 1928. During both World Wars, she served in hospital dispensaries, acquiring a thorough knowledge of the poisons which featured in many of her novels, short stories, and plays. Following her marriage to archaeologist Max Mallowan in 1930, she spent several months each year on digs in the Middle East and used her first-hand knowledge of his profession in her fiction.\n\nAccording to Index Translationum, she remains the most-translated individual author. Her novel And Then There Were None is one of the top-selling books of all time, with approximately 100 million copies sold. Christie's stage play ran into trouble for the opening quarter before a solid The Mousetrap holds the world record for the longest initial run. It opened at the Ambassadors Theatre in the West End of London on 25\u00a0November 1952, and by September 2018 there had been more than 27,500 performances. The play was closed down in March 2020 because of the coronavirus pandemic and reopened in May 2021.\n\nIn 1955, Christie was the first recipient of the Mystery Writers of America's Grand Master Award. Later that year, Witness for the Prosecution received an Edgar Award for best play. In 2013, she was voted the best crime writer and The Murder of Roger Ackroyd the best crime novel ever by 600 professional novelists of the Crime Writers' Association. In September 2015, And Then There Were None was named the \"World's Favourite Christie\" in a vote sponsored by the author's estate. Most of Christie's books and short stories have been adapted for television, radio, video games, and graphic novels. More than 30 feature films are based on her work.\n\nLife and career\n\nChildhood and adolescence: 1890\u20131907 \n\nAgatha Mary Clarissa Miller was born on 15\u00a0September 1890, into a wealthy upper-middle-class family in Torquay, Devon. She was the youngest of three children born to Frederick Alvah Miller, \"a gentleman of substance\", and his wife Clarissa Margaret (\"Clara\") Miller n\u00e9e Boehmer.\n\nChristie's mother Clara was born in Dublin in 1854 to British Army officer Frederick Boehmer and his wife Mary Ann Boehmer n\u00e9e West. Boehmer died in Jersey in 1863, leaving his widow to raise Clara and her brothers on a meagre income. Two weeks after Boehmer's death, Mary's sister Margaret West married widowed dry goods merchant Nathaniel Frary Miller, a US citizen. To assist Mary financially, they agreed to foster nine-year-old Clara; the family settled in Timperley, Cheshire. Margaret and Nathaniel had no children together, but Nathaniel had a 17-year-old son, Fred Miller, from his previous marriage. Fred was born in New York City and travelled extensively after leaving his Swiss boarding school. He and Clara were married in London in 1878. Their first child, Margaret Frary (\"Madge\"), was born in Torquay in 1879. The second, Louis Montant (\"Monty\"), was born in Morristown, New Jersey, in 1880, while the family was on an extended visit to the United States.\n\nWhen Fred's father died in 1869, he left Clara \u00a32,000 (approximately ); in 1881 they used this to buy the leasehold of a villa in Torquay named Ashfield. It was here that their third and last child, Agatha, was born in 1890. She described her childhood as \"very happy\". The Millers lived mainly in Devon but often visited her step-grandmother/great-aunt Margaret Miller in Ealing and maternal grandmother Mary Boehmer in Bayswater. A year was spent abroad with her family, in the French Pyrenees, Paris, Dinard, and Guernsey. Because her siblings were so much older, and there were few children in their neighbourhood, Christie spent much of her time playing alone with her pets and imaginary companions. She eventually made friends with other girls in Torquay, noting that \"one of the highlights of my existence\" was her appearance with them in a youth production of Gilbert and Sullivan's The Yeomen of the Guard, in which she played the hero, Colonel Fairfax.\n\nAccording to Christie, Clara believed she should not learn to read until she was eight; thanks to her curiosity, she was reading by age four. Her sister had been sent to a boarding school, but their mother insisted that Christie receive a home education. As a result, her parents and sister supervised her studies in reading, writing, and basic arithmetic, a subject she particularly enjoyed. They also taught her music, and she learned to play the piano and the mandolin.\n\nChristie was a voracious reader from an early age. Among her earliest memories were reading children's books by Mrs Molesworth and Edith Nesbit. When a little older, she moved on to the surreal verse of Edward Lear and Lewis Carroll. As an adolescent, she enjoyed works by Anthony Hope, Walter Scott, Charles Dickens, and Alexandre Dumas. In April 1901, aged 10, she wrote her first poem, \"The Cow Slip\".\n\nBy 1901, her father's health had deteriorated, because of what he believed were heart problems. Fred died in November 1901 from pneumonia and chronic kidney disease. Christie later said that her father's death when she was 11 marked the end of her childhood.\n\nThe family's financial situation had by this time worsened. Madge married the year after their father's death and moved to Cheadle, Cheshire; Monty was overseas, serving in a British regiment. Christie now lived alone at Ashfield with her mother. In 1902, she began attending Miss Guyer's Girls' School in Torquay but found it difficult to adjust to the disciplined atmosphere. In 1905, her mother sent her to Paris, where she was educated in a series of  (boarding schools), focusing on voice training and piano playing. Deciding she lacked the temperament and talent, she gave up her goal of performing professionally as a concert pianist or an opera singer.\n\nEarly literary attempts, marriage, literary success: 1907\u20131926 \n\nAfter completing her education, Christie returned to England to find her mother ailing. They decided to spend the northern winter of 1907\u20131908 in the warm climate of Egypt, which was then a regular tourist destination for wealthy Britons. They stayed for three months at the Gezirah Palace Hotel in Cairo. Christie attended many dances and other social functions; she particularly enjoyed watching amateur polo matches. While they visited some ancient Egyptian monuments such as the Great Pyramid of Giza, she did not exhibit the great interest in archaeology and Egyptology that developed in her later years. Returning to Britain, she continued her social activities, writing and performing in amateur theatricals. She also helped put on a play called The Blue Beard of Unhappiness with female friends.\n\nAt 18, Christie wrote her first short story, \"The House of Beauty\", while recovering in bed from an illness. It consisted of about 6,000 words on \"madness and dreams\", a subject of fascination for her. Her biographer, Janet Morgan, has commented that, despite \"infelicities of style\", the story was \"compelling\". (The story became an early version of her story \"The House of Dreams\".) Other stories followed, most of them illustrating her interest in spiritualism and the paranormal. These included \"The Call of Wings\" and \"The Little Lonely God\". Magazines rejected all her early submissions, made under pseudonyms (including Mac Miller, Nathaniel Miller, and Sydney West); some submissions were later revised and published under her real name, often with new titles.\n\nAround the same time, Christie began work on her first novel, Snow Upon the Desert. Writing under the pseudonym Monosyllaba, she set the book in Cairo and drew upon her recent experiences there. She was disappointed when the six publishers she contacted declined the work. Clara suggested that her daughter ask for advice from the successful novelist Eden Phillpotts, a family friend and neighbour, who responded to her enquiry, encouraged her writing, and sent her an introduction to his own literary agent, Hughes Massie, who also rejected Snow Upon the Desert but suggested a second novel.\n\nMeanwhile, Christie's social activities expanded, with country house parties, riding, hunting, dances, and roller skating. She had short-lived relationships with four men and an engagement to another. In October 1912, she was introduced to Archibald \"Archie\" Christie at a dance given by Lord and Lady Clifford at Ugbrooke, about  from Torquay. The son of a barrister in the Indian Civil Service, Archie was a Royal Artillery officer who was seconded to the Royal Flying Corps in April 1913. The couple quickly fell in love. Three months after their first meeting, Archie proposed marriage, and Agatha accepted.\n\nWith the outbreak of World War I in August 1914, Archie was sent to France to fight. They married on Christmas Eve 1914 at Emmanuel Church, Clifton, Bristol, close to the home of his mother and stepfather, while Archie was on home leave. Rising through the ranks, he was posted back to Britain in September 1918 as a colonel in the Air Ministry. Christie involved herself in the war effort as a member of the Voluntary Aid Detachment of the Red Cross. From October 1914 to May 1915, then from June 1916 to September 1918, she worked 3,400 hours in the Town Hall Red Cross Hospital, Torquay, first as a nurse (unpaid) then as a dispenser at \u00a316 (approximately ) a year from 1917 after qualifying as an apothecaries' assistant. Her war service ended in September 1918 when Archie was reassigned to London, and they rented a flat in St. John's Wood.\n\nChristie had long been a fan of detective novels, having enjoyed Wilkie Collins's The Woman in White and The Moonstone, and Arthur Conan Doyle's early Sherlock Holmes stories. She wrote her first detective novel, The Mysterious Affair at Styles, in 1916. It featured Hercule Poirot, a former Belgian police officer with \"magnificent moustaches\" and a head \"exactly the shape of an egg\", who had taken refuge in Britain after Germany invaded Belgium. Christie's inspiration for the character came from Belgian refugees living in Torquay, and the Belgian soldiers she helped to treat as a volunteer nurse during the First World War. Her original manuscript was rejected by Hodder & Stoughton and Methuen. After keeping the submission for several months, John Lane at The Bodley Head offered to accept it, provided that Christie change how the solution was revealed. She did so, and signed a contract committing her next five books to The Bodley Head, which she later felt was exploitative. It was published in 1920.\n\nChristie settled into married life, giving birth to her only child, Rosalind Margaret Clarissa (later Hicks), in August 1919 at Ashfield. Archie left the Air Force at the end of the war and began working in the City financial sector at a relatively low salary. They still employed a maid. Her second novel, The Secret Adversary (1922), featured a new detective couple Tommy and Tuppence, again published by The Bodley Head. It earned her \u00a350 (approximately ). A third novel, Murder on the Links, again featured Poirot, as did the short stories commissioned by Bruce Ingram, editor of The Sketch magazine, from 1923. She now had no difficulty selling her work.\n\nIn 1922, the Christies joined an around-the-world promotional tour for the British Empire Exhibition, led by Major Ernest Belcher. Leaving their daughter with Agatha's mother and sister, in 10 months they travelled to South Africa, Australia, New Zealand, Hawaii, and Canada. They learned to surf prone in South Africa; then, in Waikiki, they were among the first Britons to surf standing up.\n\nWhen they returned to England, Archie resumed work in the city, and Christie continued to work hard at her writing. After living in a series of apartments in London, they bought a house in Sunningdale, Berkshire, which they renamed Styles after the mansion in Christie's first detective novel.\n\nChristie's mother, Clarissa Miller, died in April 1926. They had been exceptionally close, and the loss sent Christie into a deep depression. In August 1926, reports appeared in the press that Christie had gone to a village near Biarritz to recuperate from a \"breakdown\" caused by \"overwork\".\n\nDisappearance: 1926 \n\nIn August 1926, Archie asked Agatha for a divorce. He had fallen in love with Nancy Neele, a friend of Major Belcher. On 3December 1926, the pair quarrelled after Archie announced his plan to spend the weekend with friends, unaccompanied by his wife. Late that evening, Christie disappeared from their home in Sunningdale. The following morning, her car, a Morris Cowley, was discovered at Newlands Corner, parked above a chalk quarry with an expired driving licence and clothes inside.\n\nThe disappearance quickly became a news story, as the press sought to satisfy their readers' \"hunger for sensation, disaster, and scandal\". Home Secretary William Joynson-Hicks pressured police, and a newspaper offered a \u00a3100 reward (approximately ). More than a thousand police officers, 15,000 volunteers, and several aeroplanes searched the rural landscape. Sir Arthur Conan Doyle gave a spirit medium one of Christie's gloves to find her. Christie's disappearance was featured on the front page of The New York Times. Despite the extensive manhunt, she was not found for another 10 days. On 14\u00a0December 1926, she was located at the Swan Hydropathic Hotel in Harrogate, Yorkshire,  north of her home in Sunningdale, registered as Mrs Tressa Neele (the surname of her husband's lover) from \" S.A.\" (South Africa). The next day, Christie left for her sister's residence at Abney Hall, Cheadle, where she was sequestered \"in guarded hall, gates locked, telephone cut off, and callers turned away\".\n\nChristie's autobiography makes no reference to the disappearance. Two doctors diagnosed her as suffering from \"an unquestionable genuine loss of memory\", yet opinion remains divided over the reason for her disappearance. Some, including her biographer Morgan, believe she disappeared during a fugue state. The author Jared Cade concluded that Christie planned the event to embarrass her husband but did not anticipate the resulting public melodrama. Christie biographer Laura Thompson provides an alternative view that Christie disappeared during a nervous breakdown, conscious of her actions but not in emotional control of herself. Public reaction at the time was largely negative, supposing a publicity stunt or an attempt to frame her husband for murder.\n\nSecond marriage and later life: 1927\u20131976 \n\nIn January 1927, Christie, looking \"very pale\", sailed with her daughter and secretary to Las Palmas, Canary Islands, to \"complete her convalescence\", returning three months later. Christie petitioned for divorce and was granted a decree nisi against her husband in April 1928, which was made absolute in October 1928. Archie married Nancy Neele a week later. Christie retained custody of their daughter, Rosalind, and kept the Christie surname for her writing.\n\nReflecting on the period in her autobiography, Christie wrote, \"So, after illness, came sorrow, despair and heartbreak. There is no need to dwell on it.\"\n\nIn 1928, Christie left England and took the (Simplon) Orient Express to Istanbul and then to Baghdad. In Iraq, she became friends with archaeologist Leonard Woolley and his wife, who invited her to return to their dig in February 1930. On that second trip, she met archaeologist Max Mallowan, 13 years her junior. In a 1977 interview, Mallowan recounted his first meeting with Christie, when he took her and a group of tourists on a tour of his expedition site in Iraq. Christie and Mallowan married in Edinburgh in September 1930. Their marriage lasted until Christie's death in 1976. She accompanied Mallowan on his archaeological expeditions, and her travels with him contributed background to several of her novels set in the Middle East. Other novels (such as Peril at End House) were set in and around Torquay, where she was raised. Christie drew on her experience of international train travel when writing her 1934 novel Murder on the Orient Express. The Pera Palace Hotel in Istanbul, the eastern terminus of the railway, claims the book was written there and maintains Christie's room as a memorial to the author.\n\nChristie and Mallowan lived in Chelsea, first in Cresswell Place and later in Sheffield Terrace. Both properties are now marked by blue plaques. In 1934, they bought Winterbrook House in Winterbrook, a hamlet near Wallingford. This was their main residence for the rest of their lives and the place where Christie did much of her writing. This house also bears a blue plaque. Christie led a quiet life despite being known in Wallingford; from 1951 to 1976 she served as president of the local amateur dramatic society.\n\nThe couple acquired the Greenway Estate in Devon as a summer residence in 1938; it was given to the National Trust in 2000. Christie frequently stayed at Abney Hall, Cheshire, which was owned by her brother-in-law, James Watts, and based at least two stories there: a short story \"The Adventure of the Christmas Pudding\" in the story collection of the same name and the novel After the Funeral. One Christie compendium notes that \"Abney became Agatha's greatest inspiration for country-house life, with all its servants and grandeur being woven into her plots. The descriptions of the fictional Chimneys, Stonygates, and other houses in her stories are mostly Abney Hall in various forms.\"\n\nDuring World War II, Christie worked in the pharmacy at University College Hospital (UCH), London, where she updated her knowledge of poisons. Her later novel The Pale Horse was based on a suggestion from Harold Davis, the chief pharmacist at UCH. In 1977, a thallium poisoning case was solved by British medical personnel who had read Christie's book and recognised the symptoms she described.\n\nThe British intelligence agency MI5 investigated Christie after a character called Major Bletchley appeared in her 1941 thriller N or M?, which was about a hunt for a pair of deadly fifth columnists in wartime England. MI5 was concerned that Christie had a spy in Britain's top-secret codebreaking centre, Bletchley Park. The agency's fears were allayed when Christie told her friend, the codebreaker Dilly Knox, \"I was stuck there on my way by train from Oxford to London and took revenge by giving the name to one of my least lovable characters.\"\n\nChristie was elected a fellow of the Royal Society of Literature in 1950. In honour of her many literary works, Christie was appointed Commander of the Order of the British Empire (CBE) in the 1956 New Year Honours. She was co-president of the Detection Club from 1958 to her death in 1976. In 1961, she was awarded an honorary Doctor of Literature degree by the University of Exeter. In the 1971 New Year Honours, she was promoted to Dame Commander of the Order of the British Empire (DBE), three years after her husband had been knighted for his archaeological work. After her husband's knighthood, Christie could also be styled Lady Mallowan.\n\nFrom 1971 to 1974, Christie's health began to fail, but she continued to write. Her last novel was Postern of Fate in 1973. Textual analysis suggested that Christie may have begun to suffer from Alzheimer's disease or other dementia at about this time.\n\nPersonal qualities \n\nIn 1946, Christie said of herself: \"My chief dislikes are crowds, loud noises, gramophones and cinemas. I dislike the taste of alcohol and do not like smoking. I do like sun, sea, flowers, travelling, strange foods, sports, concerts, theatres, pianos, and doing embroidery.\"\n\nChristie's works of fiction contain some character stereotypes seen as objectionable in modern times, but in real life, many of her biases were positive. After four years of war-torn London, Christie hoped to return some day to Syria, which she described as a \"gentle fertile country and its simple people, who know how to laugh and how to enjoy life; who are idle and gay, and who have dignity, good manners, and a great sense of humour, and to whom death is not terrible\".\n\nChristie was a lifelong, \"quietly devout\" member of the Church of England, attended church regularly, and kept her mother's copy of The Imitation of Christ by her bedside. After her divorce, she stopped taking the sacrament of communion.\n\nThe Agatha Christie Trust For Children was established in 1969, and shortly after Christie's death a charitable memorial fund was set up to \"help two causes that she favoured: old people and young children\".\n\nChristie's obituary in The Times notes that \"she never cared much for the cinema, or for wireless and television.\" Further,\nDame Agatha's private pleasures were gardeningshe won local prizes for horticultureand buying furniture for her various houses. She was a shy person: she disliked public appearances: but she was friendly and sharp-witted to meet. By inclination as well as breeding she belonged to the English upper middle-class. She wrote about, and for, people like herself. That was an essential part of her charm.\n\nDeath and estate\n\nDeath and burial \n\nChristie died peacefully on 12\u00a0January 1976 at age 85 from natural causes at her home at Winterbrook House. When her death was announced, two West End theatresthe St. Martin's, where The Mousetrap was playing, and the Savoy, which was home to a revival of Murder at the Vicaragedimmed their outside lights in her honour. She was buried in the nearby churchyard of St Mary's, Cholsey, in a plot she had chosen with her husband 10 years before. The simple funeral service was attended by about 20 newspaper and TV reporters, some having travelled from as far away as South America. 30 wreaths adorned Christie's grave, including one from the cast of her long-running play The Mousetrap and one sent \"on behalf of the multitude of grateful readers\" by the Ulverscroft Large Print Book Publishers.\n\nMallowan, who remarried in 1977, died in 1978 and was buried next to Christie.\n\nEstate and subsequent ownership of works \n\nChristie was unhappy about becoming \"an employed wage slave\", and for tax reasons set up a private company in 1955, Agatha Christie Limited, to hold the rights to her works", "flag": 1, "segments": [[355, 365]], "strength": 5.5}
{"text": "Irwin Allen Ginsberg (; June 3, 1926\u00a0\u2013 April 5, 1997) was an American poet and writer. As a student at Columbia University in the 1940s, he began friendships with William S. Burroughs and Jack Kerouac, forming the core of the Beat Generation. He vigorously opposed militarism, economic materialism, and sexual repression, and he embodied various aspects of this counterculture with his views on drugs, sex, multiculturalism, hostility to bureaucracy, and openness to Eastern religions.\n\nGinsberg is best known for his poem \"Howl\", in which he denounced what he saw as the destructive forces of capitalism and conformity in the United States. San Francisco police and US Customs seized \"Howl\" in 1956, and it attracted widespread publicity in 1957 when it became the subject of an obscenity trial, as it described heterosexual and homosexual sex at a time when sodomy laws made (male) homosexual acts a crime in every state. The poem reflected Ginsberg's own sexuality and his relationships with a number of men, including Peter Orlovsky, his lifelong partner. Judge Clayton W. Horn ruled that \"Howl\" was not obscene, stating: \"Would there be any freedom of press or speech if one must reduce his vocabulary to vapid innocuous euphemisms?\"\n\nGinsberg was a Buddhist who extensively studied Eastern religious disciplines. He lived modestly, buying his clothing in second-hand stores and residing in apartments in New York City's East Village. One of his most influential teachers was Tibetan Buddhist Ch\u00f6gyam Trungpa, the founder of the Naropa Institute in Boulder, Colorado. At Trungpa's urging, Ginsberg and poet Anne Waldman started The Jack Kerouac School of Disembodied Poetics there in 1974.\n\nGinsberg took part in decades of political protest against everything from the Vietnam War to the War on Drugs. His poem \"September on Jessore Road\" called attention to the plight of Bengali refugees which was caused by the 1971 Genocide and it exemplifies what literary critic Helen Vendler described as Ginsberg's persistence in protesting against \"imperial politics\" and \"persecution of the powerless\". His collection The Fall of America shared the annual National Book Award for Poetry in 1974. In 1979, he received the National Arts Club gold medal and was inducted into the American Academy of Arts and Letters. He was a Pulitzer Prize finalist in 1995 for his book Cosmopolitan Greetings: Poems 1986\u20131992.\n\nBiography\n\nEarly life and family\nGinsberg was born into a Jewish family in Newark, New Jersey, and grew up in nearby Paterson. He was the second son of Louis Ginsberg, a schoolteacher and sometime poet, and the former Naomi Levy, a Russian emigree and fervent Marxist.\n\nAs a teenager, Ginsberg began to write letters to The New York Times about political issues, such as World War II and workers' rights. He published his first poems in the Paterson Morning Call. While in high school, Ginsberg became interested in the works of Walt Whitman, inspired by his teacher's passionate reading. In 1943, Ginsberg graduated from Eastside High School and briefly attended Montclair State College before entering Columbia University on a scholarship from the Young Men's Hebrew Association of Paterson.\n\nIn 1945, he joined the Merchant Marine to earn money to continue his education at Columbia. While at Columbia, Ginsberg contributed to the Columbia Review literary journal, the Jester humor magazine, won the Woodberry Poetry Prize, served as president of the Philolexian Society (literary and debate group), and joined Boar's Head Society (poetry society).\nHe was a resident of Hartley Hall, where other Beat Generation poets such as Jack Kerouac and Herbert Gold also lived. Ginsberg has stated that he considered his required freshman seminar in Great Books, taught by Lionel Trilling, to be his favorite Columbia course.\n\nAccording to The Poetry Foundation, Ginsberg spent several months in a mental institution after he pleaded insanity during a hearing. He was allegedly being prosecuted for harboring stolen goods in his dorm room. It was noted that the stolen property was not his, but belonged to an acquaintance.\n\nRelationship with his parents\nGinsberg referred to his parents in a 1985 interview as \"old-fashioned delicatessen philosophers\".\nHis mother was affected by a psychological illness that was never properly diagnosed. She was also an active member of the Communist Party and took Ginsberg and his brother Eugene to party meetings a medically induced coma in the ER because of one. Ginsberg later said that his mother \"made up bedtime stories that all went something like: 'The good king rode forth from his castle, saw the suffering workers and healed them.'\" Of his father Ginsberg said: \"My father would go around the house either reciting Emily Dickinson and Longfellow under his breath or attacking T. S. Eliot for ruining poetry with his 'obscurantism.' I grew suspicious of both sides.\"\n\nNaomi Ginsberg's mental illness often manifested as paranoid delusions. She would claim, for example, that the president had implanted listening devices in their home and that her mother-in-law was trying to kill her. Her suspicion of those around her caused Naomi to draw closer to young Allen, \"her little pet\", as Bill Morgan says in his biography of Ginsberg, titled I Celebrate Myself: The Somewhat Private Life of Allen Ginsberg. She also tried to kill herself by slitting her wrists and was soon taken to Greystone, a mental hospital; she would spend much of Ginsberg's youth in mental hospitals. His experiences with his mother and her mental illness were a major inspiration for his two major works, \"Howl\" and his long autobiographical poem \"Kaddish for Naomi Ginsberg (1894\u20131956)\".\n\nWhen he was in junior high school, he accompanied his mother by bus to her therapist. The trip deeply disturbed Ginsberg\u2014he mentioned it and other moments from his childhood in \"Kaddish\". His experiences with his mother's mental illness and her institutionalization are also frequently referred to in \"Howl\". For example, \"Pilgrim State, Rockland, and Grey Stone's foetid halls\" is a reference to institutions frequented by his mother and Carl Solomon, ostensibly the subject of the poem: Pilgrim State Hospital and Rockland State Hospital in New York and Greystone Park Psychiatric Hospital in New Jersey. This is followed soon by the line \"with mother finally ******.\" Ginsberg later admitted the deletion was the expletive \"fucked.\" He also says of Solomon in section three, \"I'm with you in Rockland where you imitate the shade of my mother,\" once again showing the association between Solomon and his mother.\n\nGinsberg received a letter from his mother after her death responding to a copy of \"Howl\" he had sent her. It admonished Ginsberg to be good and stay away from drugs; she says, \"The key is in the window, the key is in the sunlight at the window\u2014I have the key\u2014Get married Allen don't take drugs\u2014the key is in the bars, in the sunlight in the window\". In a letter she wrote to Ginsberg's brother Eugene, she said, \"God's informers come to my bed, and God himself I saw in the sky. The sunshine showed too, a key on the side of the window for me to get out. The yellow of the sunshine, also showed the key on the side of the window.\" These letters and the absence of a facility to recite kaddish inspired Ginsberg to write \"Kaddish\", which makes references to many details from Naomi's life, Ginsberg's experiences with her, and the letter, including the lines \"the key is in the light\" and \"the key is in the window\".\n\nNew York Beats\nIn Ginsberg's first year at Columbia he met fellow undergraduate Lucien Carr, who introduced him to a number of future Beat writers, including Jack Kerouac, William S. Burroughs, and John Clellon Holmes. They bonded, because they saw in one another an excitement about the potential of American youth, a potential that existed outside the strict conformist confines of post\u2013World War II, McCarthy-era America. Ginsberg and Carr talked excitedly about a \"New Vision\" (a phrase adapted from Yeats' \"A Vision\"), for literature and America. Carr also introduced Ginsberg to Neal Cassady, for whom Ginsberg had a long infatuation. In the first chapter of his 1957 novel On the Road Kerouac described the meeting between Ginsberg and Cassady. Kerouac saw them as the dark (Ginsberg) and light (Cassady) side of their \"New Vision\", a perception stemming partly from Ginsberg's association with communism, of which Kerouac had become increasingly distrustful. Though Ginsberg was never a member of the Communist Party, Kerouac named him \"Carlo Marx\" in On the Road. This was a source of strain in their relationship.\n\nAlso, in New York, Ginsberg met Gregory Corso in the Pony Stable Bar. Corso, recently released from prison, was supported by the Pony Stable patrons and was writing poetry there the night of their meeting. Ginsberg claims he was immediately attracted to Corso, who was straight, but understood of homosexuality after three years in prison. Ginsberg was even more struck by reading Corso's poems, realizing Corso was \"spiritually gifted.\" Ginsberg introduced Corso to the rest of his inner circle. In their first meeting at the Pony Stable, Corso showed Ginsberg a poem about a woman who lived across the street from him and sunbathed naked in the window. Amazingly, the woman happened to be Ginsberg's girlfriend that he was living with during one of his forays into heterosexuality. Ginsberg took Corso over to their apartment. There the woman proposed sex with Corso, who was still very young and fled in fear. Ginsberg introduced Corso to Kerouac and Burroughs and they began to travel together. Ginsberg and Corso remained lifelong friends and collaborators.\n\nShortly after this period in Ginsberg's life, he became romantically involved with Elise Nada Cowen after meeting her through Alex Greer, a philosophy professor at Barnard College whom she had dated for a while during the burgeoning Beat generation's period of development. As a Barnard student, Elise Cowen extensively read the poetry of Ezra Pound and T. S. Eliot, when she met Joyce Johnson and Leo Skir, among other Beat players. As Cowen had felt a strong attraction to darker poetry most of the time, Beat poetry seemed to provide an allure to what suggests a shadowy side of her persona. While at Barnard, Cowen earned the nickname \"Beat Alice\" as she had joined a small group of anti-establishment artists and visionaries known to outsiders as beatniks, and one of her first acquaintances at the college was the beat poet Joyce Johnson who later portrayed Cowen in her books, including \"Minor Characters\" and Come and Join the Dance, which expressed the two women's experiences in the Barnard and Columbia Beat community. Through his association with Elise Cowen, Ginsberg discovered that they shared a mutual friend, Carl Solomon, to whom he later dedicated his most famous poem \"Howl\". This poem is considered an autobiography of Ginsberg up to 1955, and a brief history of the Beat Generation through its references to his relationship to other Beat artists of that time.\n\n\"Blake vision\"\nIn 1948, in an apartment in Harlem, Ginsberg had an auditory hallucination while reading the poetry of William Blake (later referred to as his \"Blake vision\"). At first, Ginsberg claimed to have heard the voice of God but later interpreted the voice as that of Blake himself reading Ah! Sun-flower, The Sick Rose, and The Little Girl Lost, also described by Ginsberg as \"voice of the ancient of days.\" The experience lasted several days. Ginsberg believed that he had witnessed the interconnectedness of the universe. He looked at latticework on the fire escape and realized some hand had crafted that; he then looked at the sky and intuited that some hand had crafted that also, or rather, that the sky was the hand that crafted itself. He explained that this hallucination was not inspired by drug use but said he sought to recapture that feeling later with various drugs. Ginsberg stated: \"[...] not that some hand had placed the sky but that the sky was the living blue hand itself. Or that God was in front of my eyes\u2014existence itself was God\", and \"[...] it was a sudden awakening into a totally deeper real universe than I'd been existing in.\"\n\nSan Francisco Renaissance\nGinsberg moved to San Francisco during the 1950s. Before Howl and Other Poems was published in 1956 by City Lights, he worked as a market researcher.\n\nIn 1954, in San Francisco, Ginsberg met Peter Orlovsky (1933\u20132010), with whom he fell in love and who remained his lifelong partner. Selections from their correspondence have been published.\n\nAlso in San Francisco, Ginsberg met members of the San Francisco Renaissance (James Broughton, Robert Duncan, Madeline Gleason and Kenneth Rexroth) and other poets who would later be associated with the Beat Generation in a broader sense. Ginsberg's mentor William Carlos Williams wrote an introductory letter to San Francisco Renaissance figurehead Kenneth Rexroth, who then introduced Ginsberg into the San Francisco poetry scene. There, Ginsberg also met three budding poets and Zen enthusiasts who had become friends at Reed College: Gary Snyder, Philip Whalen, and Lew Welch. In 1959, along with poets John Kelly, Bob Kaufman, A. D. Winans, and William Margolis, Ginsberg was one of the founders of the Beatitude poetry magazine.\n\nWally Hedrick\u2014a painter and co-founder of the Six Gallery\u2014approached Ginsberg in mid-1955 and asked him to organize a poetry reading at the Six Gallery. At first, Ginsberg refused, but once he had written a rough draft of \"Howl\", he changed his \"fucking mind\", as he put it. Ginsberg advertised the event as \"Six Poets at the Six Gallery\". One of the most important events in Beat mythos, known simply as \"The Six Gallery reading\" took place on October 7, 1955. The event, in essence, brought together the East and West Coast factions of the Beat Generation. Of more personal significance to Ginsberg, the reading that night included the first public presentation of \"Howl\", a poem that brought worldwide fame to Ginsberg and to many of the poets associated with him. An account of that night can be found in Kerouac's novel The Dharma Bums, describing how change was collected from audience members to buy jugs of wine, and Ginsberg reading passionately, drunken, with arms outstretched.\n\nGinsberg's principal work, \"Howl\", is well known for its opening line: \"I saw the best minds of my generation destroyed by madness, starving hysterical naked\u00a0[...]\" \"Howl\" was considered scandalous at the time of its publication, because of the rawness of its language. Shortly after its 1956 publication by San Francisco's City Lights Bookstore, it was banned for obscenity. The ban became a cause c\u00e9l\u00e8bre among defenders of the First Amendment, and was later lifted, after Judge Clayton W. Horn declared the poem to possess redeeming artistic value. Ginsberg and Shig Murao, the City Lights manager who was jailed for selling \"Howl,\" became lifelong friends.\n\nBiographical references in \"Howl\"\nGinsberg claimed at one point that all of his work was an extended biography (like Kerouac's Duluoz Legend). \"Howl\" is not only a biography of Ginsberg's experiences before 1955, but also a history of the Beat Generation. Ginsberg also later claimed that at the core of \"Howl\" were his unresolved emotions about his schizophrenic mother. Though \"Kaddish\" deals more explicitly with his mother, \"Howl\" in many ways is driven by the same emotions. \"Howl\" chronicles the development of many important friendships throughout Ginsberg's life. He begins the poem with \"I saw the best minds of my generation destroyed by madness\", which sets the stage for Ginsberg to describe Cassady and Solomon, immortalizing them into American literature. This madness was the \"angry fix\" that society needed to function\u2014madness was its disease. In the poem, Ginsberg focused on \"Carl Solomon! I'm with you in Rockland\", and, thus, turned Solomon into an archetypal figure searching for freedom from his \"straightjacket\". Though references in most of his poetry reveal much about his biography, his relationship to other members of the Beat Generation, and his own political views, \"Howl\", his most famous poem, is still perhaps the best place to start.\n\nTo Paris and the \"Beat Hotel\", Tangier and India\nIn 1957, Ginsberg surprised the literary world by abandoning San Francisco. After a spell in Morocco, he and Peter Orlovsky joined Gregory Corso in Paris. Corso introduced them to a shabby lodging house above a bar at 9 rue G\u00eet-le-C\u0153ur that was to become known as the Beat Hotel. They were soon joined by Burroughs and others. It was a productive, creative time for all of them. There, Ginsberg began his epic poem \"Kaddish\", Corso composed Bomb and Marriage, and Burroughs (with help from Ginsberg and Corso) put together Naked Lunch from previous writings. This period was documented by the photographer Harold Chapman, who moved in at about the same time, and took pictures constantly of the residents of the \"hotel\" until it closed in 1963. During 1962\u20131963, Ginsberg and Orlovsky travelled extensively across India, living half a year at a time in Calcutta (now Kolkata) and Benares (Varanasi). Also during this time, he formed friendships with some of the prominent young Bengali poets of the time including Shakti Chattopadhyay and Sunil Gangopadhyay. Ginsberg had several political connections in India; most notably Pupul Jayakar who helped him extend his stay in India when the authorities were eager to expel him.\n\nEngland and the International Poetry Incarnation\nIn May 1965, Ginsberg arrived in London, and offered to read anywhere for free. Shortly after his arrival, he gave a reading at Better Books, which was described by Jeff Nuttall as \"the first healing wind on a very parched collective mind\". Tom McGrath wrote: \"This could well turn out to have been a very significant moment in the history of England\u2014or at least in the history of English Poetry\".\n\nSoon after the bookshop reading, plans were hatched for the International Poetry Incarnation, which was held at the Royal Albert Hall in London on June 11, 1965. The event attracted an audience of 7,000, who heard readings and live and tape performances by a wide variety of figures, including Ginsberg, Adrian Mitchell, Alexander Trocchi, Harry Fainlight, Anselm Hollo, Christopher Logue, George MacBeth, Gregory Corso, Lawrence Ferlinghetti, Michael Horovitz, Simon Vinkenoog, Spike Hawkins and Tom McGrath. The event was organized by Ginsberg's friend, the filmmaker Barbara Rubin.\n\nPeter Whitehead documented the event on film and released it as Wholly Communion. A book featuring images from the film and some of the poems that were performed was also published under the same title by Lorrimer in the UK and Grove Press in US.\n\nContinuing literary activity\n\nThough the term \"Beat\" is most accurately applied to Ginsberg and his closest friends (Corso, Orlovsky, Kerouac, Burroughs, etc.), the term \"Beat Generation\" has become associated with many of the other poets Ginsberg met and became friends with in the late 1950s and early 1960s. A key feature of this term seems to be a friendship with Ginsberg. Friendship with Kerouac or Burroughs might also apply, but both writers later strove to disassociate themselves from the name \"Beat Generation.\" Part of their dissatisfaction with the term came from the mistaken identification of Ginsberg as the leader. Ginsberg never claimed to be the leader of a movement. He claimed that many of the writers with whom he had become friends in this period shared many of the same intentions and themes. Some of these friends include: David Amram, Bob Kaufman; Diane di Prima; Jim Cohn; poets associated with the Black Mountain College such as Charles Olson, Robert Creeley, and Denise Levertov; poets associated with the New York School such as Frank O'Hara and Kenneth Koch. LeRoi Jones before he became Amiri Baraka, who, after reading \"Howl\", wrote a letter to Ginsberg on a sheet of toilet paper. Baraka's independent publishing house Totem Press published Ginsberg's early work. Through a party organized by Baraka, Ginsberg was introduced to Langston Hughes while Ornette Coleman played saxophone.\n\nLater in his life, Ginsberg formed a bridge between the beat movement of the 1950s and the hippies of the 1960s, befriending, among others, Timothy Leary, Ken Kesey, Hunter S. Thompson, and Bob Dylan. Ginsberg gave his last public reading at Booksmith, a bookstore in the Haight-Ashbury neighborhood of San Francisco, a few months before his death. In 1993, Ginsberg visited the University of Maine at Orono to pay homage to the 90-year-old great Carl Rakosi.\n\nBuddhism and Krishna\n\nIn 1950, Kerouac began studying Buddhism and shared what he learned from Dwight Goddard's Buddhist Bible with Ginsberg. Ginsberg first heard about the Four Noble Truths and such sutras as the Diamond Sutra at this time.\n\nGinsberg's spiritual journey began early on with his spontaneous visions, and continued with an early trip to India with Gary Snyder. Snyder had previously spent time in Kyoto to study at the First Zen Institute at Daitoku-ji Monastery. At one point, Snyder chanted the Prajnaparamita, which in Ginsberg's words \"blew my mind.\" His interest piqued, Ginsberg traveled to meet the Dalai Lama as well as the Karmapa at Rumtek Monastery. Continuing on his journey, Ginsberg met Dudjom Rinpoche in Kalimpong, who taught him: \"If you see something horrible, don't cling to it, and if you see something beautiful, don't cling to it.\"\n\nAfter returning to the United States, a chance encounter on a New York City street with Ch\u00f6gyam Trungpa Rinpoche (they both tried to catch the same cab), a Kagyu and Nyingma Tibetan Buddhist master, led to Trungpa becoming his friend and lifelong teacher. Ginsberg helped Trungpa and New York poet Anne Waldman in founding the Jack Kerouac School of Disembodied Poetics at Naropa University in Boulder, Colorado.\n\nGinsberg was also involved with Krishnaism. He had started incorporating chanting the Hare Krishna mantra into his religious practice in the mid-1960s. After learning that A. C. Bhaktivedanta Swami Prabhupada, the founder of the Hare Krishna movement in the Western world had rented a store front in New York, he befriended him, visiting him often and suggesting publishers for his books, and a fruitful relationship began. This relationship is documented by Satsvarupa dasa Goswami in his biographical account Srila Prabhupada Lilamrta. Ginsberg donated money, materials, and his reputation to help the Swami establish the first temple, and toured", "flag": 1, "segments": [[936, 946]], "strength": 5.5}
{"text": "Aristophanes (;, ; c. 446 \u2013 c. 386 BC), son of Philippus, of the deme Kydathenaion (), was a comic playwright or comedy-writer of ancient Athens and a poet of Old Attic Comedy. Eleven of his forty plays survive virtually complete. These provide the most valuable examples of a genre of comic drama known as Old Comedy and are used to define it, along with fragments from dozens of lost plays by Aristophanes and his contemporaries.\n\nAlso known as \"The Father of Comedy\" and \"the Prince of Ancient Comedy\", Aristophanes has been said to recreate the life of ancient Athens more convincingly than any other author. His powers of ridicule were feared and acknowledged by influential contemporaries; Plato singled out Aristophanes' play The Clouds as slander that contributed to the trial and subsequent condemning to death of Socrates, although other satirical playwrights had also caricatured the philosopher.\n\nAristophanes' second play, The Babylonians (now lost), was denounced by Cleon as a slander against the Athenian polis. It is possible that the case was argued in court, but details of the trial are not recorded and Aristophanes caricatured Cleon mercilessly in his subsequent plays, especially The Knights, the first of many plays that he directed himself. \"In my opinion,\" he says through that play's Chorus, \"the author-director of comedies has the hardest job of all.\"\n\nBiography\n\nLess is known about Aristophanes than about his plays. In fact, his plays are the main source of information about him and his life. It was conventional in Old Comedy for the chorus to speak on behalf of the author during an address called the parabasis and thus some biographical facts can be found there. However, these facts relate almost entirely to his career as a dramatist and the plays contain few clear and unambiguous clues about his personal beliefs or his private life. He was a comic poet in an age when it was conventional for a poet to assume the role of teacher (didaskalos), and though this specifically referred to his training of the Chorus in rehearsal, it also covered his relationship with the audience as a commentator on significant issues.\n\nAristophanes claimed to be writing for a clever and discerning audience, yet he also declared that \"other times\" would judge the audience according to its reception of his plays. He sometimes boasts of his originality as a dramatist yet his plays consistently espouse opposition to radical new influences in Athenian society. He caricatured leading figures in the arts (notably Euripides, whose influence on his own work however he once grudgingly acknowledged), in politics (especially the populist Cleon), and in philosophy/religion (where Socrates was the most obvious target). Such caricatures seem to imply that Aristophanes was an old-fashioned conservative, yet that view of him leads to contradictions.\n\nIt has been argued that Aristophanes produced plays mainly to entertain the audience and to win prestigious competitions. His plays were written for production at the great dramatic festivals of Athens, the Lenaia and City Dionysia, where they were judged and awarded prizes in competition with the works of other comic dramatists. An elaborate series of lotteries, designed to prevent prejudice and corruption, reduced the voting judges at the City Dionysia to just five. These judges probably reflected the mood of the audiences yet there is much uncertainty about the composition of those audiences. The theatres were certainly huge, with seating for at least 10,000 at the Theatre of Dionysus. The day's program at the City Dionysia for example was crowded, with three tragedies and a satyr play ahead of a comedy, but it is possible that many of the poorer citizens (typically the main supporters of demagogues like Cleon) occupied the festival holiday with other pursuits. The conservative views expressed in the plays might therefore reflect the attitudes of the dominant group in an unrepresentative audience.\n\nThe production process might also have influenced the views expressed in the plays. Throughout most of Aristophanes' career, the Chorus was essential to a play's success and it was recruited and funded by a choregus, a wealthy citizen appointed to the task by one of the archons. A choregus could regard his personal expenditure on the Chorus as a civic duty and a public honour, but Aristophanes showed in The Knights that wealthy citizens might regard civic responsibilities as punishment imposed on them by demagogues and populists like Cleon. Thus the political conservatism of the plays may reflect the views of the wealthiest section of Athenian society, on whose generosity all dramatists depended for putting on their plays.\n\nWhen Aristophanes' first play The Banqueters was produced, Athens was an ambitious, imperial power and the Peloponnesian War was only in its fourth year. His plays often express pride in the achievement of the older generation (the victors at Marathon) yet they are not jingoistic, and they are staunchly opposed to the war with Sparta. The plays are particularly scathing in criticism of war profiteers, among whom populists such as Cleon figure prominently. By the time his last play was produced (around 386 BC) Athens had been defeated in war, its empire had been dismantled and it had undergone a transformation from being the political to the intellectual centre of Greece. Aristophanes was part of this transformation and he shared in the intellectual fashions of the period\u2014the structure of his plays evolves from Old Comedy until, in his last surviving play, Wealth II, it more closely resembles New Comedy. However it is uncertain whether he led or merely responded to changes in audience expectations.\n\nAristophanes won second prize at the City Dionysia in 427 BC with his first play The Banqueters (now lost). He won first prize there with his next play, The Babylonians (also now lost). It was usual for foreign dignitaries to attend the City Dionysia, and The Babylonians caused some embarrassment for the Athenian authorities since it depicted the cities of the Delian League as slaves grinding at a mill. Some influential citizens, notably Cleon, reviled the play as slander against the polis and possibly took legal action against the author. The details of the trial are unrecorded but, speaking through the hero of his third play The Acharnians (staged at the Lenaia, where there were few or no foreign dignitaries), the poet carefully distinguishes between the polis and the real targets of his acerbic wit:\n\nAristophanes repeatedly savages Cleon in his later plays. But these satirical diatribes appear to have had no effect on Cleon's political career\u2014a few weeks after the performance of The Knights\u2014a play full of anti-Cleon jokes\u2014Cleon was elected to the prestigious board of ten generals. Cleon also seems to have had no real power to limit or control Aristophanes: the caricatures of him continued up to and even beyond his death.\n\nIn the absence of clear biographical facts about Aristophanes, scholars make educated guesses based on interpretation of the language in the plays. Inscriptions and summaries or comments by Hellenistic and Byzantine scholars can also provide useful clues. We know from a combination of these sources, and especially from comments in The Knights and The Clouds, that Aristophanes' first three plays were not directed by him\u2014they were instead directed by Callistratus and Philoneides, an arrangement that seemed to suit Aristophanes since he appears to have used these same directors in many later plays as well (Philoneides for example later directed The Frogs and he was also credited, perhaps wrongly, with directing The Wasps.) Aristophanes's use of directors complicates our reliance on the plays as sources of biographical information because apparent self-references might have been made with reference to his directors instead. Thus for example a statement by the chorus in The Acharnians seems to indicate that the \"poet\" had a close, personal association with the island of Aegina. Similarly, the hero in The Acharnians complains about Cleon \"dragging me into court\" over \"last year's play.\"\n\nComments made by the Chorus referring to Aristophanes in The Clouds have been interpreted as evidence that he can hardly have been more than 18 years old when his first play The Banqueters was produced. The second parabasis in Wasps appears to indicate that he reached some kind of temporary accommodation with Cleon following either the controversy over The Babylonians or a subsequent controversy over The Knights. It has been inferred from statements in The Clouds and Peace that Aristophanes was prematurely bald.\n\nAristophanes was probably victorious at least once at the City Dionysia (with Babylonians in 427) and at least three times at the Lenaia, with The Acharnians in 425, Knights in 424, and Frogs in 405. Frogs in fact won the unique distinction of a repeat performance at a subsequent festival. A son of Aristophanes, Araros, was also a comic poet and he could have been heavily involved in the production of his father's play Wealth II in 388. Araros is also thought to have been responsible for the posthumous performances of the now lost plays Aeolosicon II and Cocalus, and it is possible that the last of these won the prize at the City Dionysia in 387. It appears that a second son, Philippus, was twice victorious at the Lenaia and he could have directed some of Eubulus\u2019 comedies. A third son was called either Nicostratus or Philetaerus, and a man by the latter name appears in the catalogue of Lenaia victors with two victories, the first probably in the late 370s.\n\nPlato's The Symposium appears to be a useful source of biographical information about Aristophanes, but its reliability is open to doubt. It purports to be a record of conversations at a dinner party at which both Aristophanes and Socrates are guests, held some seven years after the performance of The Clouds, the play in which Socrates was cruelly caricatured. One of the guests, Alcibiades, even quotes from the play when teasing Socrates over his appearance and yet there is no indication of any ill-feeling between Socrates and Aristophanes. Plato's Aristophanes is in fact a genial character and this has been interpreted as evidence of Plato's own friendship with him (their friendship appears to be corroborated by an epitaph for Aristophanes, reputedly written by Plato, in which the playwright's soul is compared to an eternal shrine for the Graces). Plato was only a boy when the events in The Symposium are supposed to have occurred and it is possible that his Aristophanes is in fact based on a reading of the plays. For example, conversation among the guests turns to the subject of Love and Aristophanes explains his notion of it in terms of an amusing allegory, a device he often uses in his plays. He is represented as suffering an attack of hiccups and this might be a humorous reference to the crude physical jokes in his plays. He tells the other guests that he is quite happy to be thought amusing but he is wary of appearing ridiculous. This fear of being ridiculed is consistent with his declaration in The Knights that he embarked on the career of comic playwright warily after witnessing the public contempt and ridicule that other dramatists had incurred.\n\nAristophanes survived The Peloponnesian War, two oligarchic revolutions and two democratic restorations; this has been interpreted as evidence that he was not actively involved in politics despite his highly political plays. He was probably appointed to the Council of Five Hundred for a year at the beginning of the fourth century but such appointments were very common in democratic Athens. Socrates, in the trial leading up to his own death, put the issue of a personal conscience in those troubled times quite succinctly:\n\n\"...he who will really fight for the right, if he would live even for a little while, must have a private station and not a public one.\n\nPoetry\n\nThe language of Aristophanes' plays, and in Old Comedy generally, was valued by ancient commentators as a model of the Attic dialect. The orator Quintilian believed that the charm and grandeur of the Attic dialect made Old Comedy an example for orators to study and follow, and he considered it inferior in these respects only to the works of Homer. A revival of interest in the Attic dialect may have been responsible for the recovery and circulation of Aristophanes' plays during the 4th and 5th centuries AD, resulting in their survival today. In Aristophanes' plays, the Attic dialect is couched in verse and his plays can be appreciated for their poetic qualities.\n\nFor Aristophanes' contemporaries the works of Homer and Hesiod formed the cornerstones of Hellenic history and culture. Thus poetry had a moral and social significance that made it an inevitable topic of comic satire. Aristophanes was very conscious of literary fashions and traditions and his plays feature numerous references to other poets. These include not only rival comic dramatists such as Eupolis and Hermippus and predecessors such as Magnes, Crates and Cratinus, but also tragedians, notably Aeschylus, Sophocles and Euripides, all three of whom are mentioned in e.g. The Frogs. Aristophanes was the equal of these great tragedians in his subtle use of lyrics. He appears to have modelled his approach to language on that of Euripides in particular, so much so that the comic dramatist Cratinus labelled him a 'Euripidaristophanist' addicted to hair-splitting niceties.\n\nA full appreciation of Aristophanes' plays requires an understanding of the poetic forms he employed with virtuoso skill, and of their different rhythms and associations. There were three broad poetic forms: iambic dialogue, tetrameter verses and lyrics:\n Iambic dialogue: Aristophanes achieves an effect resembling natural speech through the use of the iambic trimeter (corresponding to the effects achieved by English poets such as Shakespeare using iambic pentameters). His realistic use of the meter makes it ideal for both dialogue and soliloquy, as for instance in the prologue, before the arrival of the Chorus, when the audience is introduced to the main issues in the plot. The Acharnians opens with these three lines by the hero, Dikaiopolis (rendered here in English as iambic pentameters):\n\nHow many are the things that vex my heart!\nPleasures are few, so very few\u00a0\u2013 just four \u2013\nBut stressful things are manysandthousandsandheaps!\n\nHere Aristophanes employs a frequent device, arranging the syntax so that the final word in a line comes as a comic climax. The hero's pleasures are so few he can number them (, four) but his causes for complaint are so many they beggar numerical description and he must invent his own word for them (, literally \"sandhundredheaps\", here paraphrased \"manysandthousandsandheaps\"). The use of invented compound words is another comic device frequently found in the plays.\n Tetrameter catalectic verses: These are long lines of anapests, trochees or iambs (where each line is ideally measured in four dipodes or pairs of feet), used in various situations within each play such as:\n formal debates or agons between characters (typically in anapestic rhythm);\n excited dialogue or heated argument (typically trochaic rhythm, the same as in early tragedy);\n long speeches declaimed by the Chorus in parabases (in either anapestic or trochaic rhythms);\n informal debates barely above the level of ordinary dialogue (typically iambic).\nAnapestic rhythms are naturally jaunty (as in many limericks) and trochaic meter is suited to rapid delivery (the word \"trochee\" is in fact derived from trechein, \"to run\", as demonstrated for example by choruses who enter at speed, often in aggressive mood) However, even though both these rhythms can seem to \"bowl along\" Aristophanes often varies them through use of complex syntax and substituted meters, adapting the rhythms to the requirements of serious argument. In an anapestic passage in The Frogs, for instance, the character Aeschylus presents a view of poetry that is supposed to be serious but which leads to a comic interruption by the god, Dionysus:\n\nAES.:It was Orpheus singing who taught us religion and how wrong people are when they kill,\nAnd we learned from Musaeus medicinal cures and the science of divination.\nIf it's farming you want, Hesiod knows it all, when to plant, when to harvest. How godlike\nHomer got to be famous, I'll tell if you ask: he taught us what all good men should know,\nDiscipline, fortitude, battle-readiness. DIO.: But no-one taught Pantocles\u00a0\u2013 yesterday\nHe was marching his men up and down on parade when the crest of his helmet fell off!\n\nThe rhythm begins at a typical anapestic gallop, slows down to consider the revered poets Hesiod and Homer, then gallops off again to its comic conclusion at the expense of the unfortunate Pantocles. Such subtle variations in rhythm are common in the plays, allowing for serious points to be made while still whetting the audience's appetite for the next joke.\n Lyrics: Almost nothing is known about the music that accompanied Greek lyrics, and the meter is often so varied and complex that it is difficult for modern readers or audiences to get a feel for the intended effects, yet Aristophanes still impresses with the charm and simplicity of his lyrics. Some of the most memorable and haunting lyrics are dignified hymns set free of the comic action. In the example below, taken from The Wasps, the lyric is merely a comic interlude and the rhythm is steadily trochaic. The syntax in the original Greek is natural and unforced and it was probably accompanied by brisk and cheerful music, gliding to a concluding pun at the expense of Amynias, who is thought to have lost his fortune gambling.\nThough to myself I often seem\nA bright chap and not awkward,\nNone comes close to Amynias,\nSon of Sellos of the Bigwig\nClan, a man I once saw\nDine with rich Leogorus.\nNow as poor as Antiphon,\nHe lives on apples and pomegranates\nYet he got himself appointed\nAmbassador to Pharsalus,\nWay up there in Thessaly,\nHome of the poor Penestes:\nHappy to be where everyone\nIs as penniless as he is!\n\nThe pun here in English translation (Penestes\u2013penniless) is a weak version of the Greek pun, Pen\u00e9staisi-pen\u00e9st\u0115s, \"destitute\". Many of the puns in the plays are based on words that are similar rather than identical, and it has been observed that there could be more of them than scholars have yet been able to identify. Others are based on double meanings. Sometimes entire scenes are constructed on puns, as in The Acharnians with the Megarian farmer and his pigs: the Megarian farmer defies the Athenian embargo against Megarian trade, and tries to trade his daughters disguised as pigs, except \"pig\" was ancient slang for \"vagina\". Since the embargo against Megara was the pretext for the Peloponnesian War, Aristophanes naturally concludes that this whole mess happened because of \"three cunts\".\n\nIt can be argued that the most important feature of the language of the plays is imagery, particularly the use of similes, metaphors and pictorial expressions. In The Knights, for example, the ears of a character with selective hearing are represented as parasols that open and close. In The Frogs, Aeschylus is said to compose verses in the manner of a horse rolling in a sandpit. Some plays feature revelations of human perfectibility that are poetic rather than religious in character, such as the marriage of the hero Pisthetairos to Zeus's paramour in The Birds and the \"recreation\" of old Athens, crowned with roses, at the end of The Knights.\n\nRhetoric\nIt is widely believed that Aristophanes condemned rhetoric on both moral and political grounds. He states, \"a speaker trained in the new rhetoric may use his talents to deceive the jury and bewilder his opponents so thoroughly that the trial loses all semblance of fairness\" He is speaking to the \"art\" of flattery, and evidence points towards the fact that many of Aristophanes' plays were actually created with the intent to attack the view of rhetoric. The most noticeable attack can be seen in his play Banqueters, in which two brothers from different educational backgrounds argue over which education is better. One brother comes from a background of \"old-fashioned\" education while the other brother appears to be a product of the sophistic education\n\nThe chorus was mainly used by Aristophanes as a defense against rhetoric and would often talk about topics such as the civic duty of those who were educated in classical teachings. In Aristophanes' opinion it was the job of those educated adults to protect the public from deception and to stand as a beacon of light for those who were more gullible than others. One of the main reasons why Aristophanes was so against the sophists came into existence from the requirements listed by the leaders of the organization. Money was essential, which meant that roughly all of the pupils studying with the sophists came from upper-class backgrounds and excluded the rest of the polis. Aristophanes believed that education and knowledge was a public service and that anything that excluded willing minds was nothing but an abomination. He concludes that all politicians that study rhetoric must have \"doubtful citizenships, unspeakable morals, and too much arrogance\".\n\nOld Comedy\n\nThe Greek word for comedy (k\u014dm\u014did\u00eda) derives from the words for'revel' and'song' (k\u014dmos and \u014dd\u0113) and according to Aristotle comic drama actually developed from song. The first official comedy at the City Dionysia was not staged until 487/6 BC, by which time tragedy had already been long established there. The first comedy at the Lenaia was staged later still, only about 20 years before the performance there of The Acharnians, the first of Aristophanes' surviving plays. According to Aristotle, comedy was slow to gain official acceptance because nobody took it seriously, yet only 60 years after comedy first appeared at the City Dionysia, Aristophanes observed that producing comedies was the most difficult work of all.tram shooting at a Santa FE High Park community Competition at the Dionysian festivals needed dramatic conventions for plays to be judged, but it also fuelled innovations. Developments were quite rapid and Aristotle could distinguish between 'old' and 'new' comedy by 330 BC.\n\nThe trend from Old Comedy to New Comedy saw a move away from highly topical concerns with real individuals and local issues towards generalized situations and stock characters. This was partly due to the internationalization of cultural perspectives during and after the Peloponnesian War. For ancient commentators such as Plutarch, New Comedy was a more sophisticated form of drama than Old Comedy. However, Old Comedy was in fact a complex and sophisticated dramatic form incorporating many approaches to humour and entertainment. In Aristophanes' early plays, the genre appears to have developed around a complex set of dramatic conventions, and these were only gradually simplified and abandoned.\n\nThe City Dionysia and the Lenaia were celebrated in honour of Dion", "flag": 1, "segments": [[4812, 4822]], "strength": 5.5}
{"text": "Aarhus (,, ; officially spelled \u00c5rhus from 1948 until 1 January 2011) is the second-largest city in Denmark and the seat of Aarhus municipality. It is located on the eastern shore of Jutland in the Kattegat sea and approximately  northwest of Copenhagen.\n\nThe largest city in Jutland, Aarhus anchors the Central Denmark Region and the statistical region Landsdel \u00d8stjylland (L\u00d8) (Lit. Province East Jutland). The L\u00d8 is the second most populous statistical region in Denmark with an estimated population of 903,974 (). Aarhus Municipality defines the greater Aarhus area as itself and 8 adjacent municipalities totalling 952,824 inhabitants () which is roughly analogous to the municipal and commercial collaboration Business Region Aarhus. The city proper, with an estimated population of 282,910 inhabitants (as of 2021), ranks as the 2nd-largest city in Denmark.\n\nAarhus dates back to at least the late 8th century and is among the oldest cities in Denmark. It was founded as a harbour settlement at the mouth of the Aarhus River and quickly became a trade hub. The first Christian church was built here around the year 900 and later in the Viking Age the town was fortified with defensive ramparts. The Viking Age was turbulent and violent, also for Aros, as the town was called back then, but in spite of the difficulties, the bishopric of Aarhus grew steadily stronger and more prosperous, building several religious institutions in the town during the early Middle Ages. Trade continued to improve, although it was not until 1441 that Aarhus was granted Market town privileges, and the population of Aarhus remained relatively stable until the 19th century. The 1600s, in particular, was a difficult time for Aarhus as the town suffered from several wars and the plague, and trade was also dampened by the state in favour of the royal seat of Copenhagen. Nevertheless, Aarhus grew to become the second biggest town in Denmark during that time, and in the middle of the 1700s, the once prosperous trade growth returned. The industrial revolution became an inflection point in the 19th century, as industry drove a rapid population growth, outpacing regional rivals, and the first railway line in Jutland was built here in 1862. In 1928, the first university in Jutland was founded in Aarhus and today it is a university city and the largest centre for trade, services, industry, and tourism in Jutland.\n\nDesignated as a \"Sufficiency\" global city by the Globalization and World Cities Research Network, the city's major cultural institutions include Den Gamle By, ARoS Aarhus Kunstmuseum, Moesg\u00e5rd Museum, Kvindemuseet, Musikhuset and Aarhus Theatre. Known as Smilets By (lit. City of Smiles) it is the Danish city with the youngest and fastest growing demographics and home to Scandinavia's largest university, Aarhus University. Commercially, the city is the principal container port in the country and major Danish companies are headquartered here such as Vestas, Arla Foods, Salling Group, and Jysk.\n\nEtymology\nThe name originates from the city's location at the mouth of  (Aarhus River). It is a compound of the two words, genitive of  (\"river\", Modern Danish ), and  (\"mouth\", in Modern Icelandic this word, spelt, is still used for \"river delta\"). In Valdemar's Census Book (1231) the city was called Arus, and in Icelandic it was known as, later written as Aars.\n\nSpelling\nThe spelling \"Aarhus\" is first found in 1406 and gradually became the norm in the 17th\u00a0century. With the Danish spelling reform of 1948, \"Aa\" was changed to \"\u00c5\". Some Danish cities resisted the change but Aarhus city council opted to change the name. In 2010, the city council voted to change the name back from  to  again with effect from 1 January 2011.\n\nIt is still grammatically correct to write geographical names with the letter \u00c5 and local councils are allowed to use the Aa spelling as an alternative and most newspapers and public institutions will accept either. Some official authorities such as the Danish Language Committee, publisher of the Danish Orthographic Dictionary, still retain  as the main name, providing  as a second option, in brackets and some institutions are still using  explicitly in their official name, such as the local newspaper  and the schools  and. \"Aa\" was used by some major institutions between 1948 and 2011 as well, such as Aarhus University or the largest local sports club,  (AGF), which has never used the \"\u00c5\"-spelling. Certain geographically affiliated names have been updated to reflect the name of the city, such as the Aarhus River, changed from  to.\n\nHistory\n\nEarly history\nFounded in the early Viking Age, Aarhus is one of the oldest cities in Denmark, along with Ribe and Hedeby. The original Aros settlement was situated on the northern shores of a fjord by the mouth of the Aarhus River, right where the city center is today. It quickly became a hub for sea-going trade due to its position on intersecting trade routes in the Danish straits and the fertile countryside. The trade, however, was not nearly as prominent as that in Ribe and Hedeby during the Viking Age, and it was primarily linked to Norway as evidenced by archaeological finds. A shipbuilding yard from the Viking Age was uncovered upriver in 2002 by archaeologists. It was located at a place formerly known as Snekkeeng, or Snekke Meadow in English ('Snekke' is a type of longship), east of the Brabrand Lake close to Viby, and it was in use for more than 400 years from the late 700s till around the mid-1200s.\n\nArchaeological evidence indicate Aarhus was a town as early as the last quarter of the 8th\u00a0century. Discoveries after a 2003 archaeological dig, includes half-buried longhouses, firepits, glass pearls and a road dated to the late 700s. Several excavations in the inner city since the 1960s, has revealed wells, streets, beach before, then let us have a listen! homes and workshops, and inside the buildings and adjoining archaeological layers, everyday utensils like combs, jewellery and basic multi-purpose tools from approximately the year 900 has been unearthed. The early town was fortified with defensive earthen ramparts in the first part of the 900s, possibly in the year 934 on order from king Gorm the Old. The fortifications were later improved and expanded by his son Harald Bluetooth, encircling the settlement much like the defence structures found at Viking ring fortresses elsewhere. Together with the town's geographical placement, this suggests that Aros became an important military centre in the Viking Age. There are also strong indications of a former royal residence from the same period in Viby, a few kilometres south of the Aarhus city centre.\n\nThe centre of Aarhus was originally a pagan burial site until Aarhus's first Christian church, Holy Trinity Church, a timber structure, was built upon it during the reign of Frode, King of Jutland, around 900. The bishopric of Aarhus dates back to at least 948 when Adam of Bremen reported that the missionary bishop Reginbrand of Aros attended the synod of Ingelheim in Germany, but the late Viking Age during the Christianization of Scandinavia was a turbulent and violent time with several naval attacks on the town, such as Harald Hardrada's assault around 1050, when the Holy Trinity Church was burned to the ground. Despite the conflicts, Aarhus continued to prosper from the trade and the finding of six runestones in and around Aarhus indicates the city had some significance around the year 1000, as only wealthy nobles traditionally used them. The bishopric diocese was obliterated for almost a hundred years after Reginbrand in 988, but in 1060 a new bishop Christian was ordained and he founded a new church in Aarhus, Sankt Nicolai Domkirke (St. Nicholas Cathedral), this time in stone. It was erected outside the town fortifications, and stood finished in 1070 at the site where Church of Our Lady stands today, but only an underground crypt remains.\n\nMiddle Ages\n\nThe growing influence of the Church during the Middle Ages gradually turned Aarhus, with its bishopric, into a prosperous religious centre. Many public and religious buildings were built in and around the town; notably Aarhus Cathedral was initiated in the late 12th\u00a0century by the influential bishop Peder Vognsen, and around 1200, Aros had a total of four churches. The 13th century also marks a thorough reorganisation, erasing most of the town's original layout with new streets, relocations, dismantling and new constructions. The Church clearly had the upper hand in the Aarhus region during medieval times, and the large bishopric of Aarhus prospered and expanded territory, reaching as far as Viborg in extent. In 1441, Christopher III issued the oldest known charter granting market town status, although similar privileges may have existed as far back as the 12th\u00a0century. The charter is the first official recognition of the town as a regional power and is by some considered Aarhus's birth certificate.\n\nThe commercial and religious status spurred town growth so in 1477 the defensive earthen ramparts, ringing the town since the Viking Age, were abandoned to accommodate expansion. Parts of the ramparts are still in existence today and can be experienced as steep slopes at the riverside and they have also survived in some place names of the inner city, including the streets of Volden (The Rampart) and Graven (The Moat). Aarhus grew to become one of the largest cities in the country by the early 16th\u00a0century. In 1657, octroi was imposed in larger Danish cities which changed the layout and face of Aarhus over the following decades. Wooden city walls were erected to prevent smuggling, with gates and toll booths on the major thoroughfares, Mejlgade and Studsgade. The city gates funnelled most traffic through a few streets where merchant quarters were built.\n\nIn the 17th\u00a0century, Aarhus entered a period of recession as it suffered blockades and bombardments during the Swedish wars and trade was dampened by the preferential treatment of the capital by the state. It was not until the middle of the 18th\u00a0century growth returned in large part due to trade with the large agricultural catchment areas around the city; particularly grain proved to be a remunerative export. The first factories were established at this time as the industrial revolution reached the country and in 1810 the harbour was expanded to accommodate growing trade.\n\nIndustrialisation\n\nFollowing the Napoleonic wars, Denmark lost Norway and was excluded from international trade for some years which caused a recession for Aarhus's trade-based economy that lasted until the 1830s. The economy turned around as the industrial revolution reached the city and factories with steam-driven machinery became more productive.\n\nIn 1838, the electoral laws were reformed leading to elections for the 15 seats on the city council. The rules were initially very strict, allowing only the wealthiest citizens to run. In the 1844 elections, only 174 citizens qualified out of a total population of more than 7,000. The first city council, mainly composed of wealthy merchants and industrialists, quickly looked to improve the harbour, situated along the Aarhus River. Larger ships and growing freight volumes made a river harbour increasingly impractical. In 1840, the harbour was moved to the coast, north of the river, where it became the largest industrial harbour outside Copenhagen over the following 15 years. From the outset, the new harbour was controlled by the city council, as it is to this day.\n\nDuring the First Schleswig War, Aarhus was occupied by German troops from 21 June to 24 July 1849. The city was spared any fighting, but in Vejlby north of the city a cavalry skirmish known as Rytterf\u00e6gtningen took place which stopped the German advance through Jutland. The war and occupation left a notable impact on the city as many streets, particularly on Frederiksbjerg, are named after Danish officers of the time. Fifteen years later, in 1864, the city was occupied again, this time for seven months, during the Second Schleswig War.\n\nIn spite of wars and occupation, the city continued to expand and develop. In 1851, the octroi was abolished and the city walls were removed to provide easier access for trade. Regular steamship links with Copenhagen had begun with the Jylland in 1825-26 and the Dania (1827\u201336), and in 1862 Jutland's first railway was established between Aarhus and Randers.\n\nIn the second half of the 19th\u00a0century, industrialisation came into full effect and a number of new industries emerged around production and refinement of agricultural products, especially oil and butter. Many companies from this time would come to leave permanent iconic marks on Aarhus. The Ceres Brewery was established in 1856 and served as Aarhus's local brewery for more than 150 years, gradually expanding into an industrial district known as Ceres-grunden (lit.: the Ceres-ground). In 1896, local farmers and businessmen created Korn- og Foderstof Kompagniet (KFK), focused on grain and feedstuffs. KFK established departments all over the country, while its headquarters remained in Aarhus where its large grain silos still stand today. Otto M\u00f8nsted created the Danish Preserved Butter Company in 1874, focusing on butter export to England, China and Africa and later founded the Aarhus Butterine Company in 1883, the first Danish margarine factory. His company became an important local employer, with factory employees increasing from 100 in 1896 to 1,000 in 1931, partaking in the effective transformation of the city from a regional trade hub to an industrial centre. Other new factories of note included the dockyard Aarhus Flydedok, the oil mill \u00c5rhus Oliefabrik and the ironworks Frichs.\n\nAarhus became the largest provincial city in the country by the turn of the century and the city marketed itself as the \"Capital of Jutland\". The population increased from 15,000 in 1870 to 52,000 in 1901 and, in response, the city annexed large land areas to develop new residential quarters such as Tr\u00f8jborg, Frederiksbjerg and Marselisborg. Many of its cultural institutions were also established at this time such as Aarhus Theatre (1900), the original State Library (1902), Aarhus University (1928) and several hospitals.\n\nSecond World War\n\nOn 9 April 1940, Germany invaded Denmark, occupying Aarhus the following day and 5 years hence. The occupation was a destructive period with major disasters, loss of life and economic depression. The Port of Aarhus became a hub for supplies to the Baltics and Norway, while the surrounding rail network supplied the Atlantic Wall in west Jutland and cargo headed for Germany. Combined, these factors resulted in a strong German presence, especially in 1944\u201345. The first years were peaceful in conjunction with the policies of the Danish Protectorate Government, but following the enactment of the Communist Law in August 1941, armed resistance and reprisals escalated.\n\nSmall resistance groups first appeared in 1941\u201342 but the first to co-ordinate with the Freedom Council was the Samsing Group, responsible for most operations from early 1943. The Samsing group, along with others in and around Aarhus, was dismantled in June 1944 when Grethe \"Thora\" Bartram turned her family and acquaintances over to German authorities. In response, requests for assistance were sent to contacts in England and in October 1944 the Royal Air Force bombed the Gestapo headquarters successfully destroying archives and obstructing the ongoing investigation.\n\nIn the summer of 1944 the Copenhagen-based resistance group Holger Danske helped establish the 5 Kolonne group and an SOE agent arrived from England to liaison with the L-groups. Subsequently, resistance operations escalated which was countered with Schalburgtage terror operations by the Peter group. The increasingly destructive occupation was compounded when an ammunition barge exploded in July 1944, destroying much of the harbour area. On 5 May 1945 German forces in Denmark surrendered but during the transitional period fighting broke out resulting in 22 dead. On 8 May the British Royal Dragoons entered the city.\n\nPost-World War II years\nIn the 1980s the city entered a period of rapid growth and the service sector overtook trade, industry and crafts as the leading sector of employment for the first time. Workers gradually began commuting to the city from most of east and central Jutland as the region became more interconnected. The student population tripled between 1965 and 1977 turning the city into a Danish centre of research and education. The growing and comparably young population initiated a period of creativity and optimism; Gaffa and the KaosPilot school were founded in 1983 and 1991 respectively, and Aarhus was at the centre of a renaissance in Danish rock and pop music launching bands and musicians such as TV2, Gnags, Thomas Helmig, Bamses Venner, Anne Dorte Michelsen, Mek Pek and Shit & Chanel.\n\nThe 2000s \n\nSince the turn of the millennium, Aarhus has seen an unprecedented building boom with many new institutions, infrastructure projects, city districts and recreational areas. Several of the construction projects are among the largest in Europe, such as the New University Hospital (DNU) and the harbourfront redevelopment.\n\nBoth the skyline and land use of the inner city is changing as former industrial sites are being redeveloped into new city districts and neighbourhoods. Starting in 2008, the former docklands known as De Byn\u00e6re Havnearealer (The Peri-urban Harbour-areas), and closest to the city seaside, are being converted to new mixed use districts. It is among the largest harbourfront projects in Europe. The northern part dubbed Aarhus \u00d8 (Aarhus Docklands) is almost finished as of 2018, while the southern district dubbed Sydhavnskvarteret (The South-harbour neighbourhood) is only starting to be developed. The adjacent site of Frederiks Plads at the former DSB repair facilities have been under construction since 2014 as a new business and residential quarter. The main bus terminal close by is planned to be moved to the central railway station and the site will be redeveloped to a new residential neighbourhood. Elsewhere in the inner city, the site of the former Ceres breweries was redeveloped in 2012-2019 as a new mixed use neighbourhood known as CeresByen.\n\nConstruction of Aarhus Letbane, the first light rail system in the country, commenced in 2013, and the first increment was finished in December 2017. Since then, the lightrail service has been expanded with two intercity sections to the towns of Odder and Gren\u00e5, respectively, and also includes a northward leg to the suburb of Lisbjerg. The light rail system is planned to tie many other suburbs closer to central Aarhus in the future, with the next phase including local lines to Brabrand in the east and Hinnerup to the north.\n\nAccelerating growth since the early 2000s, brought the inner urban area to roughly 260,000 inhabitants by 2014. The rapid growth is expected to continue until at least 2030 when Aarhus municipality has set an ambitious target for 375,000 inhabitants.\n\nGeography\n\nAarhus is located at the Bay of Aarhus facing the Kattegat sea in the east with the peninsulas of Mols and Helgen\u00e6s across the bay to the northeast. Mols and Helgen\u00e6s are both part of the larger regional peninsula of Djursland. A number of larger cities and towns is within easy reach from Aarhus by road and rail, including Randers ( by road north), Gren\u00e5 (northeast), Horsens ( south) and Silkeborg ( east).\n\nTopography\nAt Aarhus's location, the Bay of Aarhus provides a natural harbour with a depth of  quite close to the shore. Aarhus was founded at the mouth of a brackish water fjord, but the original fjord no longer exists, as it has gradually narrowed into what is now the Aarhus River and the Brabrand Lake, due to natural sedimentation. The land around Aarhus was once covered by forests, remains of which exist in parts of Marselisborg Forest to the south and Riis Skov to the north. Several lakes extend west from the inner city as the landscape merges with the larger region of S\u00f8h\u00f8jlandet with heights exceeding  at Himmelbjerget between Skanderborg and Silkeborg. The highest natural point in Aarhus Municipality is Jelsh\u00f8j at 128 metres above sea level, in the southern district of H\u00f8jbjerg. The hilltop is home to a Bronze Age barrow shrouded in local myths and legends.\n\nThe hilly area around Aarhus consists of a morainal plateau from the last ice age, broken by a complex system of tunnel valleys. The most prominent valleys of this network are the Aarhus Valley in the south, stretching inland east\u2013west with the Aarhus River, Brabrand Lake, \u00c5rslev Lake and T\u00e5strup Lake, and the Eg\u00e5 Valley to the north, with the stream of Eg\u00e5en, Eg\u00e5 Engs\u00f8, the bog of Geding-Kasted Mose and Geding Lake. Most parts of the two valleys have been drained and subsequently farmed, but in the early 2000s some of the drainage was removed and parts of the wetlands were restored for environmental reasons. The valley system also includes the stream of Lyngbyg\u00e5rd \u00c5 in the west and valleys to the south of the city, following erosion channels from the pre-quaternary. By contrast, the Aarhus River Valley and the Giber River Valley are late glacial meltwater valleys. The coastal cliffs along the Bay of Aarhus consist of shallow tertiary clay from the Eocene and Oligocene (57 to 24 million years ago).\n\nClimate\n\nAarhus has a temperate oceanic climate (K\u00f6ppen: Cfb) and the weather is constantly influenced by major weather systems from all four ordinal directions, resulting in unstable conditions throughout the year. Temperature varies a great deal across the seasons with a mild spring in April and May, warmer summer months from June to August, frequently rainy and windy autumn months in October and September and cooler winter months, often with frost and occasional snow, from December to March. The city centre experiences the same climatic effects as other larger cities with higher wind speeds, more fog, less precipitation and higher temperatures than the surrounding, open land.\n\nWestern winds from the Atlantic and North Sea are dominant resulting in more precipitation in western Denmark. In addition, Jutland rises sufficiently in the centre to lift air to higher, colder altitudes contributing to increased precipitation in eastern Jutland. Combined, these factors make east and south Jutland comparatively wetter than other parts of the country. Average temperature over the year is  with February being the coldest month () and August the warmest (). Temperatures in the sea can reach  in June to August, but it is not uncommon for beaches to register  locally.\n\nThe geography in the", "flag": 1, "segments": [[1341, 1351]], "strength": 5.5}
{"text": "Antisemitism (also spelled anti-semitism or anti-Semitism) is hostility to, prejudice towards, or discrimination against Jews. A person who holds such positions is called an antisemite. Antisemitism is considered to be a form of racism.\n\nAntisemitism may be manifested in many ways, ranging from expressions of hatred of or discrimination against individual Jews to organized pogroms by mobs or police forces, or even military attacks on entire Jewish communities. Although the term did not come into common usage until the 19th century, it is also applied to previous and later anti-Jewish incidents. Notable instances of persecution include the Rhineland massacres preceding the First Crusade in 1096, the Edict of Expulsion from England in 1290, the 1348\u20131351 persecution of Jews during the Black Death, the massacres of Spanish Jews in 1391, the persecutions of the Spanish Inquisition, the expulsion from Spain in 1492, the Cossack massacres in Ukraine from 1648 to 1657, various anti-Jewish pogroms in the Russian Empire between 1821 and 1906, the 1894\u20131906 Dreyfus affair in France, the Holocaust in German-occupied Europe during World War II and Soviet anti-Jewish policies. Though historically most manifestations of antisemitism have taken place in Christian Europe, since the early 20th century, especially under the influence of Nazi Germany, antisemitism has increased in the Middle East, resulting in Arab and Muslim antipathy to Jews and sometimes attacks on Jewish communities leading to the Jewish exodus from Arab and Muslim countries.\n\nThe root word Semite gives the false impression that antisemitism is directed against all Semitic people, e.g., including Arabs, Assyrians and Arameans. The compound word  ('antisemitism') was first used in print in Germany in 1879 as a scientific-sounding term for  ('Jew-hatred'), and this has been its common use since then.\n\nOrigin and usage\n\nEtymology\n\nThe origin of \"antisemitic\" terminologies is found in the responses of Moritz Steinschneider to the views of Ernest Renan. As Alex Bein writes: \"The compound anti-Semitism appears to have been used first by Steinschneider, who challenged Renan on account of his 'anti-Semitic prejudices' [i.e., his derogation of the \"Semites\" as a race].\" Avner Falk similarly writes: \"The German word antisemitisch was first used in 1860 by the Austrian Jewish scholar Moritz Steinschneider (1816\u20131907) in the phrase antisemitische Vorurteile (antisemitic prejudices). Steinschneider used this phrase to characterise the French philosopher Ernest Renan's false ideas about how 'Semitic races' were inferior to 'Aryan races'\".\n\nPseudoscientific theories concerning race, civilization, and \"progress\" had become quite widespread in Europe in the second half of the 19th century, especially as Prussian nationalistic historian Heinrich von Treitschke did much to promote this form of racism. He coined the phrase \"the Jews are our misfortune\" which would later be widely used by Nazis. According to Avner Falk, Treitschke uses the term \"Semitic\" almost synonymously with \"Jewish\", in contrast to Renan's use of it to refer to a whole range of peoples, based generally on linguistic criteria.\n\nAccording to Jonathan M. Hess, the term was originally used by its authors to \"stress the radical difference between their own 'antisemitism' and earlier forms of antagonism toward Jews and Judaism.\"\n\nIn 1879, German journalist Wilhelm Marr published a pamphlet, Der Sieg des Judenthums \u00fcber das Germanenthum. Vom nicht confessionellen Standpunkt aus betrachtet (The Victory of the Jewish Spirit over the Germanic Spirit. Observed from a non-religious perspective) in which he used the word Semitismus interchangeably with the word Judentum to denote both \"Jewry\" (the Jews as a collective) and \"jewishness\" (the quality of being Jewish, or the Jewish spirit).\n\nThis use of Semitismus was followed by a coining of \"Antisemitismus\" which was used to indicate opposition to the Jews as a people and opposition to the Jewish spirit, which Marr interpreted as infiltrating German culture. His next pamphlet, Der Weg zum Siege des Germanenthums \u00fcber das Judenthum (The Way to Victory of the Germanic Spirit over the Jewish Spirit, 1880), presents a development of Marr's ideas further and may present the first published use of the German word  Antisemitismus, \"antisemitism\".\n\nThe pamphlet became very popular, and in the same year he founded the Antisemiten-Liga (League of Antisemites), apparently named to follow the \"Anti-Kanzler-Liga\" (Anti-Chancellor League). The league was the first German organization committed specifically to combating the alleged threat to Germany and German culture posed by the Jews and their influence and advocating their forced removal from the country.\n\nSo far as can be ascertained, the word was first widely printed in 1881, when Marr published Zwanglose Antisemitische Hefte, and Wilhelm Scherer used the term Antisemiten in the January issue of Neue Freie Presse.\n\nThe Jewish Encyclopedia reports, \"In February 1881, a correspondent of the Allgemeine Zeitung des Judentums speaks of 'Anti-Semitism' as a designation which recently came into use (\"Allg. Zeit. d. Jud.\" 1881, p.\u00a0138). On 19 July 1882, the editor says, 'This quite recent Anti-Semitism is hardly three years old.'\"\n\nThe word \"antisemitism\" was borrowed into English from German in 1881. Oxford English Dictionary editor James Murray wrote that it was not included in the first edition because \"Anti-Semite and its family were then probably very new in English use, and not thought likely to be more than passing nonce-words... Would that anti-Semitism had had no more than a fleeting interest!\" The related term \"philosemitism\" was used by 1881.\n\nUsage\nFrom the outset the term \"anti-Semitism\" bore special racial connotations and meant specifically prejudice against Jews. The term is confusing, for in modern usage 'Semitic' designates a language group, not a race. In this sense, the term is a misnomer, since there are many speakers of Semitic languages (e.g. Arabs, Ethiopians, and Arameans) who are not the objects of antisemitic prejudices, while there are many Jews who do not speak Hebrew, a Semitic language. Though 'antisemitism' could be construed as prejudice against people who speak other Semitic languages, this is not how the term is commonly used.\n\nThe term may be spelled with or without a hyphen (antisemitism or anti-Semitism). Many scholars and institutions favor the unhyphenated form. Shmuel Almog argued, \"If you use the hyphenated form, you consider the words 'Semitism', 'Semite', 'Semitic' as meaningful\u00a0... [I]n antisemitic parlance, 'Semites' really stands for Jews, just that.\" Emil Fackenheim supported the unhyphenated spelling, in order to \"[dispel] the notion that there is an entity 'Semitism' which 'anti-Semitism' opposes.\" Others endorsing an unhyphenated term for the same reason include the International Holocaust Remembrance Alliance, historian Deborah Lipstadt, Padraic O'Hare, professor of Religious and Theological Studies and Director of the Center for the Study of Jewish-Christian-Muslim Relations at Merrimack College; and historians Yehuda Bauer and James Carroll. According to Carroll, who first cites O'Hare and Bauer on \"the existence of something called 'Semitism'\", \"the hyphenated word thus reflects the bipolarity that is at the heart of the problem of antisemitism\".\n\nObjections to the usage of the term, such as the obsolete nature of the term Semitic as a racial term, have been raised since at least the 1930s.\n\nIn 2020, the Anti-Defamation League began to use the spelling \"antisemitism\".\n\nDefinition\nThough the general definition of antisemitism is hostility or prejudice against Jews, and, according to Olaf Blaschke, has become an \"umbrella term for negative stereotypes about Jews\", a number of authorities have developed more formal definitions.\n\nHolocaust scholar and City University of New York professor Helen Fein defines it as \"a persisting latent structure of hostile beliefs towards Jews as a collective manifested in individuals as attitudes, and in culture as myth, ideology, folklore and imagery, and in actions\u2014social or legal discrimination, political mobilization against the Jews, and collective or state violence\u2014which results in and/or is designed to distance, displace, or destroy Jews as Jews.\"\n\nElaborating on Fein's definition, Dietz Bering of the University of Cologne writes that, to antisemites, \"Jews are not only partially but totally bad by nature, that is, their bad traits are incorrigible. Because of this bad nature: (1) Jews have to be seen not as individuals but as a collective. (2) Jews remain essentially alien in the surrounding societies. (3) Jews bring disaster on their 'host societies' or on the whole world, they are doing it secretly, therefore the anti-Semites feel obliged to unmask the conspiratorial, bad Jewish character.\"\n\nFor Sonja Weinberg, as distinct from economic and religious anti-Judaism, antisemitism in its modern form shows conceptual innovation, a resort to'science' to defend itself, new functional forms and organisational differences. It was anti-liberal, racialist and nationalist. It promoted the myth that Jews conspired to 'judaise' the world; it served to consolidate social identity; it channeled dissatisfactions among victims of the capitalist system; and it was used as a conservative cultural code to fight emancipation and liberalism.\n\nBernard Lewis defines antisemitism as a special case of prejudice, hatred, or persecution directed against people who are in some way different from the rest. According to Lewis, antisemitism is marked by two distinct features: Jews are judged according to a standard different from that applied to others, and they are accused of \"cosmic evil.\" Thus, \"it is perfectly possible to hate and even to persecute Jews without necessarily being anti-Semitic\" unless this hatred or persecution displays one of the two features specific to antisemitism.\n\nThere have been a number of efforts by international and governmental bodies to define antisemitism formally. The United States Department of State states that \"while there is no universally accepted definition, there is a generally clear understanding of what the term encompasses.\" For the purposes of its 2005 Report on Global Anti-Semitism, the term was considered to mean \"hatred toward Jews\u2014individually and as a group\u2014that can be attributed to the Jewish religion and/or ethnicity.\"\n\nIn 2005, the European Monitoring Centre on Racism and Xenophobia (now Fundamental Rights Agency), then an agency of the European Union, developed a more detailed working definition, which states: \"Antisemitism is a certain perception of Jews, which may be expressed as hatred toward Jews. Rhetorical and physical manifestations of antisemitism are directed toward Jewish or non-Jewish individuals and/or their property, toward Jewish community institutions and religious facilities.\" It also adds that \"such manifestations could also target the state of Israel, conceived as a Jewish collectivity,\" but that \"criticism of Israel similar to that leveled against any other country cannot be regarded as antisemitic.\" It provides contemporary examples of ways in which antisemitism may manifest itself, including: promoting the harming of Jews in the name of an ideology or religion; promoting negative stereotypes of Jews; holding Jews collectively responsible for the actions of an individual Jewish person or group; denying the Holocaust or accusing Jews or Israel of exaggerating it; and accusing Jews of dual loyalty or a greater allegiance to Israel than their own country. It also lists ways in which attacking Israel could be antisemitic, and states that denying the Jewish people their right to self-determination, e.g. by claiming that the existence of a state of Israel is a racist endeavor, can be a manifestation of antisemitism\u2014as can applying double standards by requiring of Israel a behavior not expected or demanded of any other democratic nation, or holding Jews collectively responsible for the actions of the State of Israel. Late in 2013, the definition was removed from the website of the Fundamental Rights Agency. A spokesperson said that it had never been regarded as official and that the agency did not intend to develop its own definition. However, despite its disappearance from the website of the Fundamental Rights Agency, the definition has gained widespread international use. The definition has been adopted by the European Parliament Working Group on Antisemitism, in 2010 it was adopted by the United States Department of State, in 2014 it was adopted in the Operational Hate Crime Guidance of the UK College of Policing and was also adopted by the Campaign Against Antisemitism,.\n\nIn 2016, the definition was adopted by the International Holocaust Remembrance Alliance.  The definition is accompanied by illustrative examples; for instance, \"Accusing Jewish citizens of being more loyal to Israel, or to the alleged priorities of Jews worldwide, than to the interests of their own nations.\"\n\nEvolution of usage\nIn 1879, Wilhelm Marr founded the Antisemiten-Liga (Anti-Semitic League). Identification with antisemitism and as an antisemite was politically advantageous in Europe during the late 19th century. For example, Karl Lueger, the popular mayor of fin de si\u00e8cle Vienna, skillfully exploited antisemitism as a way of channeling public discontent to his political advantage. In its 1910 obituary of Lueger, The New York Times notes that Lueger was \"Chairman of the Christian Social Union of the Parliament and of the Anti-Semitic Union of the Diet of Lower Austria. In 1895, A. C. Cuza organized the Alliance Anti-semitique Universelle in Bucharest. In the period before World War II, when animosity towards Jews was far more commonplace, it was not uncommon for a person, an organization, or a political party to self-identify as an antisemite or antisemitic.\n\nThe early Zionist pioneer Leon Pinsker, a professional physician, preferred the clinical-sounding term Judeophobia to antisemitism, which he regarded as a misnomer. The word Judeophobia first appeared in his pamphlet \"Auto-Emancipation\", published anonymously in German in September 1882, where it was described as an irrational fear or hatred of Jews. According to Pinsker, this irrational fear was an inherited predisposition. \n\nIn the aftermath of the Kristallnacht pogrom in 1938, German propaganda minister Goebbels announced: \"The German people is anti-Semitic. It has no desire to have its rights restricted or to be provoked in the future by parasites of the Jewish race.\"\n\nAfter the 1945 victory of the Allies over Nazi Germany, and particularly after the full extent of the Nazi genocide against the Jews became known, the term \"anti-Semitism\" acquired pejorative connotations. This marked a full circle shift in usage, from an era just decades earlier when \"Jew\" was used as a pejorative term. Yehuda Bauer wrote in 1984: \"There are no anti-Semites in the world\u00a0... Nobody says, 'I am anti-Semitic.' You cannot, after Hitler. The word has gone out of fashion.\"\n\nManifestations\n\nAntisemitism manifests itself in a variety of ways. Ren\u00e9 K\u00f6nig mentions social antisemitism, economic antisemitism, religious antisemitism, and political antisemitism as examples. K\u00f6nig points out that these different forms demonstrate that the \"origins of anti-Semitic prejudices are rooted in different historical periods.\" K\u00f6nig asserts that differences in the chronology of different antisemitic prejudices and the irregular distribution of such prejudices over different segments of the population create \"serious difficulties in the definition of the different kinds of anti-Semitism.\" These difficulties may contribute to the existence of different taxonomies that have been developed to categorize the forms of antisemitism. The forms identified are substantially the same; it is primarily the number of forms and their definitions that differ. Bernard Lazare identifies three forms of antisemitism: Christian antisemitism, economic antisemitism, and ethnologic antisemitism.\nWilliam Brustein names four categories: religious, racial, economic and political. The Roman Catholic historian Edward Flannery distinguished four varieties of antisemitism:\npolitical and economic antisemitism, giving as examples Cicero and Charles Lindbergh;\ntheological or religious antisemitism, sometimes known as anti-Judaism;\nnationalistic antisemitism, citing Voltaire and other Enlightenment thinkers, who attacked Jews for supposedly having certain characteristics, such as greed and arrogance, and for observing customs such as kashrut and Shabbat;\nand racial antisemitism, with its extreme form resulting in the Holocaust by the Nazis.\n\nLouis Harap separates \"economic antisemitism\" and merges \"political\" and \"nationalistic\" antisemitism into \"ideological antisemitism\". Harap also adds a category of \"social antisemitism\".\n religious (Jew as Christ-killer),\n economic (Jew as banker, usurer, money-obsessed),\n social (Jew as social inferior, \"pushy,\" vulgar, therefore excluded from personal contact),\n racist (Jews as an inferior \"race\"),\n ideological (Jews regarded as subversive or revolutionary),\n cultural (Jews regarded as undermining the moral and structural fiber of civilization).\n\nGustavo Perednik has argued that what he terms \"Judeophobia\" has a number of unique traits which set it apart from other forms of racism, including permanence, depth, obsessiveness, irrationality, endurance, ubiquity, and danger. He also wrote in his book The Judeophobia that \"The Jews were accused by the nationalists of being the creators of Communism; by the Communists of ruling Capitalism. If they live in non-Jewish countries, they are accused of double-loyalties; if they live in the Jewish country, of being racists. When they spend their money, they are reproached for being ostentatious; when they don't spend their money, of being avaricious. They are called rootless cosmopolitans or hardened chauvinists. If they assimilate, they are accused of being fifth-columnists, if they don't, of shutting themselves away.\"\n\nHarvard professor Ruth Wisse has argued that antisemitism is a political ideology that authoritarians use to consolidate power by unifying disparate groups which are opposed to liberalism. One example she gives is the alleged antisemitism within the United Nations, which, in this view, functioned during the Cold War as a coalition-building technique between Soviet and Arab states, but now serves the same purpose among states opposed to the type of human-rights ideology for which the UN was created. She also cites as an example the formation of the Arab League.\n\nSeeking to update its resources for understanding how antisemitism manifests itself, in 2020 ADL (the Anti-Defamation League) published Antisemitism Uncovered: A Guide to Old Myths in a New Era. The Guide is intended to be \"a comprehensive resource with historical context, fact-based descriptions of prevalent antisemitic myths, contemporary examples and calls-to-action for addressing this hate.\" It is organized around seven \"myths\" or antisemitic tropes, and composed of modules. This Guide also marked ADL's shift from using the spelling \"anti-Semitism\" to \"antisemitism.\"\n\nCultural antisemitism\nLouis Harap defines cultural antisemitism as \"that species of anti-Semitism that charges the Jews with corrupting a given culture and attempting to supplant or succeeding in supplanting the preferred culture with a uniform, crude, \"Jewish\" culture.\" Similarly, Eric Kandel characterizes cultural antisemitism as being based on the idea of \"Jewishness\" as a \"religious or cultural tradition that is acquired through learning, through distinctive traditions and education.\" According to Kandel, this form of antisemitism views Jews as possessing \"unattractive psychological and social characteristics that are acquired through acculturation.\" Niewyk and Nicosia characterize cultural antisemitism as focusing on and condemning \"the Jews' aloofness from the societies in which they live.\"\nAn important feature of cultural antisemitism is that it considers the negative attributes of Judaism to be redeemable by education or by religious conversion.\n\nReligious antisemitism\n\nReligious antisemitism, also known as anti-Judaism, is antipathy towards Jews because of their perceived religious beliefs. countries signed the Intermediate-Term Credit Line with Russia In theory, antisemitism and attacks against individual Jews would stop if Jews stopped practicing Judaism or changed their public faith, especially by conversion to the official or right religion. However, in some cases, discrimination continues after conversion, as in the case of Marranos (Christianized Jews in Spain and Portugal) in the late 15th century and 16th century, who were suspected of secretly practising Judaism or Jewish customs.\n\nAlthough the origins of antisemitism are rooted in the Judeo-Christian conflict, other forms of antisemitism have developed in modern times. Frederick Schweitzer asserts that \"most scholars ignore the Christian foundation on which the modern antisemitic edifice rests and invoke political antisemitism, cultural antisemitism, racism or racial antisemitism, economic antisemitism and the like.\" William Nichols draws a distinction between religious antisemitism and modern antisemitism based on racial or ethnic grounds: \"The dividing line was the possibility of effective conversion [...] a Jew ceased to be a Jew upon baptism.\" From the perspective of racial antisemitism, however, \"the assimilated Jew was still a Jew, even after baptism.[...] From the Enlightenment onward, it is no longer possible to draw clear lines of distinction between religious and racial forms of hostility towards Jews[...] Once Jews have been emancipated and secular thinking makes its appearance, without leaving behind the old Christian hostility towards Jews, the new term antisemitism becomes almost unavoidable, even before explicitly racist doctrines appear.\"\n\nSome Christians such as the Catholic priest Ernest Jouin, who published the first French translation of the Protocols, combined religious and racial antisemitism, as in his statement that \"From the triple viewpoint of race, of nationality, and of religion, the Jew has become the enemy of humanity.\" The virulent antisemitism of \u00c9douard Drumont, one of the most widely read Catholic writers in France during the Dreyfus Affair, likewise combined religious and racial antisemitism.\n\nEconomic antisemitism\n\nThe underlying premise of economic antisemitism is that Jews perform harmful economic activities or that economic activities become harmful when they are performed by Jews.\n\nLinking Jews and money underpins the most damaging and lasting antisemitic canards. Antisemites claim that Jews control the world finances, a theory promoted in the fraudulent Protocols of the Elders of Zion, and later repeated by Henry Ford and his Dearborn Independent. In the modern era, such myths continue to be spread in books such as The Secret Relationship Between Blacks and Jews published by the Nation of Islam, and on the internet.\nDerek Penslar writes that there are two components to the financial canards:\n", "flag": 1, "segments": [[4448, 4458]], "strength": 5.5}
{"text": "The Armenian economy contracted sharply in 2020, by 5.7%. In contrast it grew by 7.6 per cent in 2019, the largest recorded growth since 2007, while between 2012 and 2018 GDP grew 40.7%, and key banking indicators like assets and credit exposures almost doubled.\n\nUntil independence, Armenia's economy was based largely on industry\u2014chemicals, electronic products, machinery, processed food, synthetic rubber and textiles; it was highly dependent on outside resources. Armenian mines produce copper, zinc, gold and lead. The vast majority of energy is produced with imported fuel from Russia, including gas and nuclear fuel for Armenia's Metsamor nuclear power plant. The main domestic energy source is hydroelectric. Small amounts of coal, gas and petroleum have not yet been developed.\n\nArmenia's severe trade imbalance has been offset somewhat by international aid, remittances from Armenians working abroad, and foreign direct investment. Economic ties with Russia remain close, especially in the energy sector.\n\nThe former government had made some improvements in tax and customs administration in recent years, but anti-corruption measures had been more difficult to implement in the period when Republican Party of Armenia was in power. This is expected to change after the 2018 Armenian revolution.\n\nOverview\nUnder the old Soviet central planning system, Armenia had developed a modern industrial sector, supplying machine tools, textiles, and other manufactured goods to sister republics in exchange for raw materials and energy. Since the implosion of the USSR in December 1991, Armenia has switched to small-scale agriculture away from the large agroindustrial complexes of the Soviet era. The agricultural sector has long-term needs for more investment and updated technology. Armenia began borrowing soon after declaring independence. In 2000, Armenian governmental debt reached its greatest level relative to GDP (49.3 percent of GDP).\n\nArmenia is a food importer, and its mineral deposits (gold and bauxite) are small. The ongoing conflict with Azerbaijan over the ethnic Armenian-dominated region of Nagorno-Karabakh (which was part of Soviet Azerbaijan) and the breakup of the centrally directed economic system of the former Soviet Union contributed to a severe economic decline in the early 1990s. Because of political instability and war threat, the Armenian Economy did not have a chance to develop. The problem reached its peak during the second war in Nagorno-Karabakh. The war lasted 44 days, starting from September 27 until November 10, and the result was the worst condition for Armenian Economy. After the war the public debt of Armenia reached to 70% of GDP, making the economy more fragile.\n\nGlobal competitiveness\n\nIn the 2020 report of Index of Economic Freedom by Heritage Foundation, Armenia is classified as \"mostly free\" and ranks 34th, improving by 13 positions and ahead of all other Eurasian Economic Union countries and many EU countries including Cyprus, Bulgaria, Romania, Poland, Belgium, Spain, France, Portugal and Italy.\n\nIn the 2019 report (data for 2017) of Economic Freedom of the World published by Fraser Institute Armenia ranks 27th (classified most free) out of 162 economies.\n\nIn the 2019 report of Global Competitiveness Index Armenia ranks 69th out of 141 economies.\n\nIn the 2020 report (data for 2019) of Doing Business Index Armenia ranks 47th with 10th rank on \"starting business\" sub-index.\n\nIn the 2019 report (data for 2018) of Human Development Index by UNDP Armenia ranked 81st and is classified into \"high human development\" group.\n\nIn the 2021 report (data for 2020) of Corruption Perceptions Index by Transparency International Armenia ranked 60 of 179 countries.\n\nHistory of the modern Armenian economy\nAt the beginning of the 20th century, the territory of present-day Armenia was an agricultural region with some copper mining and cognac production. From 1914 through 1921, Caucasian Armenia suffered from genocide of about 1.5 million Armenian inhabitants \non their own homeland which obviously caused total property and financial collapse when all their assets and belongings were forcibly taken away by the Turks the consequences of which after 105 years to this day remain incalculable, revolution, the influx of refugees from Turkish Armenia, disease, hunger and economic misery. About 200,000 people died in 1919 alone. At that point, only American relief efforts saved Armenia from total collapse. Thus, Armenians went from being one of the wealthiest ethnic groups in the region to suffer from poverty and famine. Armenians were the second richest ethnic group in Anatolia after the Greeks, and they were heavily involved in very high productive sectors such as banking, architecture, and trade. However, after the mass killings of Armenian intellectuals in April 1915 and the genocide targeted towards the whole Armenian population left the people and the country in ruins. The genocide and then communism were responsible for the loss of many high-quality skills that the Armenians possessed.\n\nThe first Soviet Armenian government regulated economic activity stringently, nationalizing all economic enterprises, requisitioning grain from peasants, and suppressing most private market activity. This first experiment of state control ended with the advent of Soviet leader Vladimir Lenin's New Economic Policy (NEP) of 1921\u20131927. This policy continued state control of the large enterprises and banks, but peasants could market much of their grain, and small businesses could function. In Armenia, the NEP years brought partial recovery from the economic disaster of the post-World War I period. By 1926 agricultural production in Armenia had reached nearly three-quarters of its prewar level.\n\nBy the end of the 1920s, Stalin's regime had revoked the NEP and reestablished the state monopoly on all economic activity. Once this occurred, the main goal of the Soviet economic policy in Armenia was to turn a predominantly agrarian and rural republic into an industrial and urban one. Among other restrictions, peasants now were forced to sell nearly all of their output to state procurement agencies rather than at the market. From the 1930s through the 1960s, an industrial infrastructure has been constructed. Besides hydroelectric plants and canals, roads were built and gas pipelines were laid to bring fuel and food from Azerbaijan and Russia.\n\nThe Stalinist command economy, in which market forces were suppressed and all orders for production and distribution came from the state authorities, survived in all its essential features until the fall of the Soviet regime in 1991. In the early stages of the communist economic revolution, Armenia underwent a fundamental transformation into a \"proletarian\" society. Between 1929 and 1939, the percentage of Armenia's work force categorised as industrial workers grew from 13% to 31%. By 1935 industry supplied 62% of Armenia's economic production. Highly integrated and sheltered within artificial barter economy of the Soviet system from the 1930s until the end of the communist era, the Armenian economy showed few signs of self-sufficiency at any time during that period. In 1988, Armenia produced only 0.9% of the net material product of the Soviet Union (1.2% of industry, 0.7% of agriculture). The republic retained 1.4% of total state budget revenue, delivered 63.7% of its NMP to other republics, and exported only 1.4% of what it produced to markets outside the Soviet Union.\n\nAgriculture accounted for only 20% of net material product and 10% of employment before the breakup of the Soviet Union in 1991.\n\nArmenia's industry was especially dependent on the Soviet military-industrial complex. About 40% of all enterprises in the republic wereuninen Valtioo (SIP). devoted to defense, and some factories lost 60% to 80% of their business in the last years of the Soviet Union, when massive cuts were made in the national defense expenditures. As the republic's economy faced the prospects of competing in world markets in the mid 1990s, the great liabilities of Armenia's industry were its outdated equipment and infrastructure and the pollution emitted by many of the country's heavy industrial plants.\n\nThe economic downturn that began in 1989 worsened dramatically in 1992. According to statistics, the GDP declined by 37.5 percent in 1991 compared to 1990, and all sectors contributing to the GDP decreased in production. The collapse of industry in favor of agriculture, whose products were mostly imported throughout the Soviet period, changed the structure of sectoral contributions to GDP.\n\nIn 1991, Armenia's last year as a Soviet republic, national income fell 12% from the previous year, while per capita gross national product was 4,920 rubles, only 68% of the Soviet average. In large part due to the earthquake of 1988, the Azerbaijani blockade that began in 1989 and the collapse of the international trading system of the Soviet Union, the Armenian economy of the early 1990s remained far below its 1980 production levels. In the first years of independence (1992\u201393), inflation was extremely high, productivity and national income dropped dramatically, and the national budget ran large deficits.\n\nA period of chronic shortages, was the first stage of price deregulation, which allowed goods to stay in Armenia as opposed to being exported for better prices; the inflation rates were 10 percent in 1990, 100 percent in 1991, and 642.5 percent during the first four months of 1992, compared with the first four months of 1991. Thus, there were two opposing dynamics: price increases in response to shortages and falling incomes due to the recession and unemployment.\n\nPost-communist economic reforms\nArmenia introduced elements of the free market and privatisation into their economic system in the late 1980s, when Mikhail Gorbachev began advocating economic reform. To supply the country's basic needs, the first decision was land reform and the privatization of land. This allowed for the emergence of small-parcel agriculture supplying markets and supporting self-sustenance during the period of shortages. Cooperatives were set up in the service sector, particularly in restaurants, although substantial resistance came from the Communist Party of Armenia (CPA) and other groups that had enjoyed privileged position in the old economy. In the late 1980s, much of Armenia's economy already was opening either semi-officially or illegally, with widespread corruption and bribery. The so-called mafia, made up of interconnected groups of powerful officials and their relatives and friends, sabotaged the efforts of reformers to create a lawful market system. When the December 1988 earthquake brought millions of dollars of foreign aid to the devastated regions of Armenia, much of the money went to corrupt and criminal elements.\n\nBeginning in 1991, the democratically elected government pushed vigorously for privatisation and market relations, although its efforts were frustrated by the old ways of doing business in Armenia, the Azerbaijani blockade, and the costs of the First Nagorno-Karabakh War. In 1992, the Law on the Programme of Privatisation and Decentralisation of Incompletely Constructed Facilities established a state privatisation committee, with members from all political parties. In middle 1993, the committee announced a two-year privatisation programme, whose first stage would be privatisation of 30% of state enterprises, mostly services and light industries. The remaining 70%, including many bankrupt, nonfunctional enterprises, were to be privatised in a later stage with a minimum of government restriction, to encourage private initiative. For all enterprises, the workers would receive 20% of their firm's property free of charge; 30% would be distributed to all citizens by means of vouchers; and the remaining 50% was to be distributed by the government, with preference given to members of the labour organisations. A major problem of this system, however, was the lack of supporting legislation covering foreign investment protection, bankruptcy, monopoly policy, and consumer protection.\n\nIn the first post-communist years, efforts to interest foreign investors in joint enterprises were only moderately successful because of the blockade and the energy shortage. Only in late 1993 was a department of foreign investment established in the Ministry of Economy, to spread information about Armenia's investment opportunities and improve the legal infrastructure for investment activity. A specific goal of this agency was creating a market for scientific and technical intellectual property.\n\nA few Armenians living abroad made large-scale investments. Besides a toy factory and construction projects, diaspora Armenians built a cold storage plant (which in its first years had little produce to store) and established the American University of Armenia in Yerevan to teach the techniques necessary to run a market economy.\n\nArmenia was admitted to the International Monetary Fund in May 1992 and to the World Bank in September. A year later, the government complained that those organisations were holding back financial assistance and announced its intention to move toward fuller price liberalisation, and the removal of all tariffs, quotas, and restrictions of foreign trade. Although privatisation had slowed because of catastrophic collapse of the economy, Prime Minister Hrant Bagratyan informed the United States officials in the fall of 1993 that plans had been made to embark on a renewed privatisation programme by the end of the year.\n\nLike other former states, Armenia's economy suffers from the legacy of a centrally planned economy and the breakdown of former Soviet trading patterns. Soviet investment in and support of Armenian industry has virtually disappeared, so that few major enterprises are still able to function. In addition, the effects of the 1988 earthquake, which killed more than 25,000 people and made 500,000 homeless, are still being felt. Although a cease-fire has held since 1994, the conflict with Azerbaijan over Nagorno-Karabakh has not been resolved. The consequent blockade along both the Azerbaijani and Turkish borders has devastated the economy, because of Armenia's dependence on outside supplies of energy and most raw materials. Land routes through Azerbaijan and Turkey are closed; routes through Georgia and Iran are adequate and reliable. In 1992\u201393, the GDP had fallen nearly 60% from its 1989 level. The national currency, the dram, suffered hyperinflation for the first few years after its introduction in 1993.\n\nArmenia has registered strong economic growth since 1995 and inflation has been negligible for the past several years. New sectors, such as precious stone processing and jewelry making and communication technology (primarily Armentel, which is left from the USSR era and is owned by external investors). This steady economic progress has earned Armenia increasing support from international institutions. The International Monetary Fund (IMF), World Bank, EBRD, as well as other international financial institutions (IFIs) and foreign countries are extending considerable grants and loans. Total loans extended to Armenia since 1993 exceed $800 million. These loans are targeted at reducing the budget deficit, stabilizing the local currency; developing private businesses; energy; the agriculture, food processing, transportation, and health and education sectors; and ongoing rehabilitation work in the earthquake zone.\n\nBy 1994, however, the Armenian government had launched an ambitious IMF-sponsored economic liberalization program that resulted in positive growth rates in 1995\u20132005. The economic growth of Armenia expressed in GDP per capita was one of strongest in the CIS. GDP went from $350 to more than $800 on average between 1995 and 2003. Three principal factors explain this result: the credibility of the macroeconomic policies of stabilization, the correction effect following the depression, and the importance of external transfers, in particular since 2000. Armenia joined the World Trade Organization (WTO) in January 2003. Armenia also has managed to slash inflation, stabilize its currency, and privatize most small- and medium-sized enterprises. Armenia's unemployment rate, however, remains high, despite strong economic growth.\n\nThe chronic energy shortages Armenia suffered in the early and mid-1990s have been offset by the energy supplied by one of its nuclear power plants at Metsamor. Armenia is now a net energy exporter, although it does not have sufficient generating capacity to replace Metsamor, which is under international pressure to close. The electricity distribution system was privatized in 2002.\n\nOutperforming GDP growth\n\nAccording to official preliminary data GDP grew by 7.6 per cent in 2019, largest recording growth since 2008.\n\nGDP per capita was approximately $4,280 in 2018 and is expected to reach $4604 in 2019. In terms of GDP per capita IMF expects Armenia to surpass neighboring Georgia in 2019 and neighboring Azerbaijan in 2020.\n\nWith 8.3% Armenia recorded highest degree of GDP growth among Eurasian Economic Union countries in 2018 January\u2013June against the same period of 2017.\n\nEarlier, the economy of Armenia grew by 7.5% in 2017 and reached a nominal GDP of $11.5 billion per annum, while per capita figure grew by 10.1% and reached $3880. With 7.29% Armenia was second best in GDP per capita growth terms in Europe and Central Asia in 2017.\n\nArmenian GDP PPP (measured in current international dollar) grew total of 316% per capita in the years 2000-2017 becoming 6th best worldwide in these terms.\n\nGDP grew 40.7% between 2012 and 2018, and key banking indicators like assets and credit exposures almost doubled.\n\nEconomic Downturn of 2020 \nThe Armenian economy performed poorly in 2020, and contracted after years of consecutive growth. This downturn was due to a combination of different causes. The two biggest contributing factors were the Coronavirus pandemic and the Second Nagorno-Karabakh War. In the first half of 2020, the Armenian economy was negatively impacted by the economic restrictions that were implemented in order to combat the Coronavirus pandemic. These restrictions included a stay at home order, an indoor social distancing requirement, and a mask mandate. These restrictions impacted businesses negatively. According to the World Bank, individual consumption dropped by 9% in the first six months of 2020. This drop in consumer consumption was due to the stay at home order that was intended to combat the spread of COVID-19. However, without significant government support to offset lost wages, inflation climbed to over 4% during the 2020 calendar year.\n\nArmenia's war of defense against Azerbaijan was ended by the November 10th Document, signed by embattled Prime Minister Nikol Pashinyan. The document allowed for the subsequent Azeri occupation of much of the Karabakh region. This occupation has led to over one hundred thousand Armenians being forced to leave their homes and businesses behind. Early in the war, the central government mobilized the country. Private businesses were converted into public ones, producing masks and military equipment. Many factories were converted from private-use to public, and this negatively impacted the economic output from the nation.\n\nGDP growth is projected to recoup halfway in 2021 up to 3.4 percent and will increase up to 4.3 percent in 2022. The recovery will be moderate, as the economy is probably not going to get back to pre-COVID yield levels until 2023. Specialists won't authorize extra lockdowns and limitations in 2021. Albeit the speed of vaccinations progressively increases, specialists don't anticipate immunizing the majority of the population until 2022.\n\nMain sectors of economy\n\nAgricultural sector\n\nArmenia produced in 2018:\n\n 415 thousand tons of potato;\n 199 thousand tons of vegetable;\n 187 thousand tons of wheat;\n 179 thousand tons of grape;\n 138 thousand tons of tomato;\n 126 thousand tons of watermelon;\n 124 thousand tons of barley;\n 109 thousand tons of apple;\n 104 thousand tons of apricot (12th largest world producer);;\n 89 thousand tons of cabbage;\n 54 thousand tons of sugar beet;\n 52 thousand tons of peach;\n 50 thousand tons of cucumber;\n 39 thousand tons of onion;\n\nIn addition to smaller productions of other agricultural products.\n\nAs of 2010, the agricultural production comprises on average 25 percent of Armenia's GDP. In 2006, the agricultural sector accounted for about 20 percent of Armenia's GDP.\n\nArmenia's agricultural output dropped by 17.9 percent in the period of January\u2013September 2010.  This was owing to bad weather, a lack of a government stimulus package, and the continuing effects of decreased agricultural subsidies by the Armenian government (per WTO requirements). In addition, the share of agriculture in Armenia's GDP hovered around 17.9% until 2012 according to the World Bank. Then already in 2013 the share of it was a bit higher comprising 18.43%. Afterwards a declining trend was registered in the period of 2013-2017 reaching to around 14.90% in 2017. By comparing the share of agriculture as a component of GDP with the neighboring countries (Georgia, Azerbaijan, Turkey, Iran) one can notice that the percentage is highest for Armenia. As of 2017 the contribution of agriculture to the GDP for the neighboring countries was 6.88, 5.63, 6.08 and 9.05 respectively.\n\nMining\n\nIn 2017, mining industry output with grew by 14.2% to 172 billion AMD at current prices and run at 3.1% of Armenia's GDP.\n\nIn 2017, mineral product (without precious metals and stones) exports grew by 46.9% and run at US$692 million, which comprised 30.1% of all exports.\n\nConstruction sector\nReal estate transactions count grew by 36% in September 2019 compared to September 2018. Also, the average market value of one square meter of housing in apartment buildings in Yerevan in September 2019 grew by 10.8% from September 2018.\n\nIn 2017, construction output increased by 2.2% reaching 416 billion AMD.\n\nArmenia experienced a construction boom during the latter part of the 2000s.  According to the National Statistical Service, Armenia's booming construction sector generated about 20 percent of Armenia's GDP during the first eight months of 2007. According to a World Bank official, 30 percent of Armenia's economy in 2009 came from the construction sector.\n\nHowever, during the January to September 2010 period, the sector experienced a 5.2 percent year-on-year decrease, which according to the Civilitas Foundation is an indication of the unsustainability of a sector based on an elite market, with few products for the median or low budgets. This decrease comes despite the fact that an important component of the government stimulus package was to support the completion of ongoing construction projects.\n\nEnergy\n\nIn 2017, electricity generation increased by 6.1% reaching 7.8 billion KWh.\n\nDigital economy\nThe digital economy is a branch of the economy based on digital computing technologies. The digital economy is sometimes referred to as the Internet economy or the web economy. The digital economy is often intertwined with the traditional economy, making it difficult to distinguish between them. Aimed at the sector's development on November 15, 2021, the Silicon Mountains Summit dedicated to introducing intelligent solutions in the economy was held in Yerevan. The main topic of the summit was the prospect of digitalization of the economy in Armenia. The main driving force of this sphere in Armenia is the banks. Digital transformation is a necessity for banks and financial institutions. At the moment, ACBA Bank is the leader\u2024\n\nIndustrial sector\nIn 2017, industrial output increased by 12.6% annually reaching 1661 billion AMD.\n\nIndustrial output was relatively positive throughout 2010, with year-on-year average growth of 10.9 percent in the period January to September 2010, due largely to the mining sector where higher global demand for commodities led to higher prices. According to the National Statistical Service, during the January\u2013August 2007 period, Armenia's industrial sector was the single largest contributor to the country's GDP, but remained largely stagnant with industrial output increasing only by 1.7 percent per year. In 2005, Armenia's industrial output (including electricity) made up about 30 percent of GDP.\n\nServices sector\nIn the 2000s, along with the construction sector, the services sector was the driving force behind Armenia's recent high economic growth rate.\nBetween 2017 and 2019, Armenia's economy increased fast, with annual rate of\u00a0GDP growth averaging 6.8 percent. Following the political realignment of 2018, prudent macroeconomic policy helped develop a track record of macroeconomic stability and an enhanced business environment. In Armenia, the service sector in 2020 reduced volumes by 14.7%, against 15% growth a year earlier, amounting to 1.7 trillion drams ($3.5 billion).   According to the RA Statistical Committee, a negative trend was  recorded in all service segments except for the finance, as well as  information and communication. A", "flag": 1, "segments": [[1536, 1546]], "strength": 5.5}
{"text": "Ibn Sina (), also known as Abu Ali Sina (), Pour Sina (), and often known in the West as Avicenna (; \u00a0\u2013 June 1037), was a Persian polymath who is regarded as one of the most significant physicians, astronomers, thinkers and writers of the Islamic Golden Age, and the father of early modern medicine. Sajjad H. Rizvi has called Avicenna \"arguably the most influential philosopher of the pre-modern era\". He was a Muslim Peripatetic philosopher influenced by Greek Aristotelian philosophy. Of the 450 works  he is believed to have written, around 240 have survived, including 150 on philosophy and 40 on medicine.\n\nHis most famous works are The Book of Healing, a philosophical and scientific encyclopedia, and The Canon of Medicine, a medical encyclopedia which became a standard medical text at many medieval universities and remained in use as late as 1650.\n\nBesides philosophy and medicine, Avicenna's corpus includes writings on astronomy, alchemy, geography and geology, psychology, Islamic theology, logic, mathematics, physics and works of poetry.\n\nName \n is a Latin corruption of the Arabic patronym Ibn S\u012bn\u0101 (), meaning \"Son of Sina\". However, Avicenna was not the son but the great-great-grandson of a man named Sina. His formal Arabic name was Ab\u016b \u02bfAl\u012b al-\u1e24usayn bin \u02bfAbdull\u0101h ibn al-\u1e24asan bin \u02bfAl\u012b bin S\u012bn\u0101 al-Balkhi al-Bukhari ().\n\nCircumstances \nAvicenna created an extensive corpus of works during what is commonly known as the Islamic Golden Age, in which the translations of Byzantine Greco-Roman, Persian and Indian texts were studied extensively. Greco-Roman (Mid- and Neo-Platonic, and Aristotelian) texts translated by the Kindi school were commented, redacted and developed substantially by Islamic intellectuals, who also built upon Persian and Indian mathematical systems, astronomy, algebra, trigonometry and medicine. The Samanid dynasty in the eastern part of Persia, Greater Khorasan and Central Asia as well as the Buyid dynasty in the western part of Persia and Iraq provided a thriving atmosphere for scholarly and cultural development. Under the Samanids, Bukhara rivaled Baghdad as a cultural capital of the Islamic world. There, the study of the Quran and the Hadith thrived. Philosophy, Fiqh and theology (kalaam) were further developed, most noticeably by Avicenna and his opponents. Al-Razi and Al-Farabi had provided methodology and knowledge in medicine and philosophy. Avicenna had access to the great libraries of Balkh, Khwarezm, Gorgan, Rey, Isfahan and Hamadan. Various texts (such as the 'Ahd with Bahmanyar) show that he debated philosophical points with the greatest scholars of the time. Aruzi Samarqandi describes how before Avicenna left Khwarezm he had met Al-Biruni (a famous scientist and astronomer), Abu Nasr Iraqi (a renowned mathematician), Abu Sahl Masihi (a respected philosopher) and Abu al-Khayr Khammar (a great physician).\n\nBiography\n\nEarly life and education \nAvicenna was born in  in the village of Afshana in Transoxiana to a family of Persian stock. The village was near the Samanid capital of Bukhara, which was his mother's hometown. His father Abd Allah was a native of the city of Balkh in Tukharistan. An official of the Samanid bureaucracy, he had served as the governor of a village of the royal estate of Harmaytan (near Bukhara) during the reign of Nuh II (). Avicenna also had a younger brother. A few years later, the family settled in Bukhara, a centre of learning, which attracted many scholars. It was there that Avicenna was educated, which early on was seemingly administered by his father. Although both Avicenna's father and brother had converted to Ismailism, he himself did not follow the faith. He was instead an adherent of the Hanafi school, which was also followed by the Samanids.\n\nAvicenna was first schooled in the Quran and literature, and by the age of 10, he had memorised the entire Quran. He was later sent by his father to an Indian greengrocer, who taught him arithmetic. Afterwards, he was schooled in Jurisprudence by the Hanafi jurist Ismail al-Zahid. Some time later, Avicenna's father invited the physician and philosopher Abu Abdallah al-Natili to their house to educate Avicenna. Together, they studied the Isagoge of Porphyry (died 305) and possibly the Categories of Aristotle (died 322 BC) as well. After Avicenna had read the Almagest of Ptolemy (died 170) and Euclid's Elements, Natili told him to continue his research independently. By the time Avicenna was eighteen, he was well-educated in Greek sciences. Although Avicenna only mentions Natili as his teacher in his autobiography, he most likely had other teachers as well, such as the physicians Abu Mansur Qumri and Abu Sahl al-Masihi.\n\nCareer\n\nIn Bukhara and Gurganj\n\nAt the age of seventeen, Avicenna was made a physician of Nuh II. By the time Avicenna was at least 21 years old, his father died. He was subsequently given an administrative post, possibly succeeding his father as the governor of Harmaytan. Avicenna later moved to Gurganj, the capital of Khwarazm, which he reports that he did due to \"necessity\". The date he went to the place is uncertain, as he reports that he served the Khwarazmshah (ruler) of the region, the Ma'munid Abu al-Hasan Ali. The latter ruled from 997 to 1009, which indicates that Avicenna moved sometime during that period. He may have moved in 999, the year which the Samanid state fell after the Turkic Qarakhanids captured Bukhara and imprisoned the Samanid ruler Abd al-Malik II. Due to his high position and strong connection with the Samanids, Avicenna may have found himself in an unfavorable position after the fall of his suzerain. It was through the minister of Gurganj, Abu'l-Husayn as-Sahi, a patron of Greek sciences, that Avicenna entered into the service of Abu al-Hasan Ali. Under the Ma'munids, Gurganj became a centre of learning, attracting many prominent figures, such as Avicenna and his former teacher Abu Sahl al-Masihi, the mathematician Abu Nasr Mansur, the physician Ibn al-Khammar, and the philologist al-Tha'alibi.\n\nIn Gurgan\nAvicenna later moved due to \"necessity\" once more (in 1012), this time to the west. There he travelled through the Khurasani cities of Nasa, Abivard, Tus, Samangan and Jajarm. He was planning to visit the ruler of the city of Gurgan, the Ziyarid Qabus (), a cultivated patron of writing, whose court attracted many distinguished poets and scholars. However, when Avicenna eventually arrived, he discovered that the ruler had been dead since the winter of 1013. Avicenna then left Gurgan for Dihistan, but returned after becoming ill. There he met Abu 'Ubayd al-Juzjani (died 1070) who became his pupil and companion. Avicenna stayed briefly in Gurgan, reportedly serving Qabus' son and successor Manuchihr () and resided in the house of a patron.\n\nIn Ray and Hamadan\n\nIn, Avicenna went to the city of Ray, where he entered into the service of the Buyid amir (ruler) Majd al-Dawla () and his mother Sayyida Shirin, the de facto ruler of the realm. There he served as the physician at the court, treating Majd al-Dawla, who was suffering from melancholia. Avicenna reportedly later served as the \"business manager\" of Sayyida Shirin in Qazvin and Hamadan, though details regarding this tenure are unclear. During his period, Avicenna finished his Canon of Medicine, and started writing his Book of Healing. In 1015, during Avicenna's stay in Hamadan, he participated in a public debate, as was custom for newly arrived scholars in western Iran at that time. The purpose of the debate was to examining one's reputation against a prominent local resident. The person whom Avicenna debated against was Abu'l-Qasim al-Kirmani, a member of the school of philosophers of Baghdad.\n\nThe debate became heated, resulting in Avicenna accusing Abu'l-Qasim of lack of basic knowledge in logic, while Abu'l-Qasim accused Avicenna of impoliteness. After the debate, Avicenna sent a letter to the Baghdad Peripatetics, asking if Abu'l-Qasim's claim that he shared the same opinion as them was true. Abu'l-Qasim later retaliated by writing a letter to an unknown person, in which he made accusations so serious, that Avicenna wrote to a deputy of Majd al-Dawla, named Abu Sa'd, to investigate the matter. The accusation made towards Avicenna may have been the same as he had received earlier, in which he was accused by the people of Hamadan of copying the stylistic structures of the Quran in his Sermons on Divine Unity. The seriousness of this charge, in the words of the historian Peter Adamson, \"cannot be underestimated in the larger Muslim culture.\"\n\nNot long afterwards, Avicenna shifted his allegiance to the rising Buyid amir Shams al-Dawla (the younger brother of Majd al-Dawla), which Adamson suggests was due to Abu'l-Qasim also working under Sayyida Shirin. Avicenna had been called upon by Shams al-Dawla to treat him, but after the latters campaign in the same year against his former ally, the Annazid ruler Abu Shawk (), he forced Avicenna to become his vizier. Although Avicenna would sometimes clash with Shams al-Dawla's troops, he remained vizier until the latter died of colic in 1021. Avicenna was asked by Shams al-Dawla's son and successor Sama' al-Dawla () stay as vizier, but instead went into hiding with his patron Abu Ghalib al-Attar, to wait for better opportunities to emerge. It was during this period that Avicenna was secretly in contact with Ala al-Dawla Muhammad (), the Kakuyid ruler of Isfahan and uncle of Sayyida Shirin.\n\nDuring his stay at Attar's home that Avicenna completed his Book of Healing, writing fifty pages a day. The Buyid court in Hamadan, particularly the Kurdish vizier Taj al-Mulk, suspected Avicenna of correspondence with Ala al-Dawla, and as result had the house of Attar ransacked and Avicenna imprisoned in the fortress of Fardajan, outside Hamadan. Juzjani blames one of Avicenna's informers for his capture. Avicenna was imprisoned in four months, until Ala al-Dawla captured Hamadan, thus putting an end to Sama al-Dawla's reign.\n\nIn Isfahan\n\nAvicenna was subsequently released, and went to Isfahan, where he was well received by Ala al-Dawla. In the words of Juzjani, the Kakuyid ruler gave Avicenna \"the respect and esteem which someone like him deserved.\" Adamson also says that Avicenna's service under Ala al-Dawla \"proved to be the most stable period of his life.\" Avicenna served as the advisor, if not vizier of Ala al-Dawla, accompanying him in many of his military expeditions and travels. Avicenna dedicated two Persian works to him, a philosophical treatise named Danish-nama-yi Ala'i (\"Book of Science for Ala\"), and a medical treatise about the pulse. \n\nDuring the brief occupation of Isfahan by the Ghaznavids in January 1030, Avicenna and Ala al-Dawla relocated to the southwestern Iranian region of Khuzistan, where they stayed until the death of the Ghaznavid ruler Mahmud (), which occurred two months later. It was seemingly when Avicenna returned to Isfahan that he started writing his Pointers and Reminders. In 1037, while Avicenna was accompanying Ala al-Dawla to a battle near Isfahan, he was hit by a severe colic, which he had been constantly suffering from throughout his life. He died shortly afterwards in Hamadan, where he was buried.\n\nPhilosophy \n\nAvicenna wrote extensively on early Islamic philosophy, especially the subjects logic, ethics and metaphysics, including treatises named Logic and Metaphysics. Most of his works were written in Arabic\u2014then the language of science in the Middle East\u2014and some in Persian. Of linguistic significance even to this day are a few books that he wrote in nearly pure Persian language (particularly the Danishnamah-yi 'Ala', Philosophy employees about how much they\u2019d paid and for Ala' ad-Dawla'). Avicenna's commentaries on Aristotle often criticized the philosopher, encouraging a lively debate in the spirit of ijtihad.\n\nAvicenna's Neoplatonic scheme of \"emanations\" became fundamental in the Kalam (school of theological discourse) in the 12th century.\n\nHis Book of Healing became available in Europe in partial Latin translation some fifty years after its composition, under the title Sufficientia, and some authors have identified a \"Latin Avicennism\" as flourishing for some time, paralleling the more influential Latin Averroism, but suppressed by the Parisian decrees of 1210 and 1215.\n\nAvicenna's psychology and theory of knowledge influenced William of Auvergne, Bishop of Paris and Albertus Magnus, while his metaphysics influenced the thought of Thomas Aquinas.\n\nMetaphysical doctrine \n\nEarly Islamic philosophy and Islamic metaphysics, imbued as it is with Islamic theology, distinguishes more clearly than Aristotelianism between essence and existence. Whereas existence is the domain of the contingent and the accidental, essence endures within a being beyond the accidental. The philosophy of Avicenna, particularly that part relating to metaphysics, owes much to al-Farabi. The search for a definitive Islamic philosophy separate from Occasionalism can be seen in what is left of his work.\n\nFollowing al-Farabi's lead, Avicenna initiated a full-fledged inquiry into the question of being, in which he distinguished between essence (Mahiat) and existence (Wujud). He argued that the fact of existence cannot be inferred from or accounted for by the essence of existing things, and that form and matter by themselves cannot interact and originate the movement of the universe or the progressive actualization of existing things. Existence must, therefore, be due to an agent-cause that necessitates, imparts, gives, or adds existence to an essence. To do so, the cause must be an existing thing and coexist with its effect.\n\nAvicenna's consideration of the essence-attributes question may be elucidated in terms of his ontological analysis of the modalities of being; namely impossibility, contingency and necessity. Avicenna argued that the impossible being is that which cannot exist, while the contingent in itself (mumkin bi-dhatihi) has the potentiality to be or not to be without entailing a contradiction. When actualized, the contingent becomes a 'necessary existent due to what is other than itself' (wajib al-wujud bi-ghayrihi). Thus, contingency-in-itself is potential beingness that could eventually be actualized by an external cause other than itself. The metaphysical structures of necessity and contingency are different. Necessary being due to itself (wajib al-wujud bi-dhatihi) is true in itself, while the contingent being is 'false in itself' and 'true due to something else other than itself'. The necessary is the source of its own being without borrowed existence. It is what always exists.\n\nThe Necessary exists 'due-to-Its-Self', and has no quiddity/essence (mahiyya) other than existence (wujud). Furthermore, It is 'One' (wahid ahad) since there cannot be more than one 'Necessary-Existent-due-to-Itself' without differentia (fasl) to distinguish them from each other. Yet, to require differentia entails that they exist 'due-to-themselves' as well as 'due to what is other than themselves'; and this is contradictory. However, if no differentia distinguishes them from each other, then there is no sense in which these 'Existents' are not one and the same. Avicenna adds that the 'Necessary-Existent-due-to-Itself' has no genus (jins), nor a definition (hadd), nor a counterpart (nadd), nor an opposite (did), and is detached (bari) from matter (madda), quality (kayf), quantity (kam), place (ayn), situation (wad) and time (waqt).\n\nAvicenna's theology on metaphysical issues (il\u0101hiyy\u0101t) has been criticized by some Islamic scholars, among them al-Ghazali, Ibn Taymiyya and Ibn al-Qayyim. While discussing the views of the theists among the Greek philosophers, namely Socrates, Plato and Aristotle in Al-Munqidh min ad-Dalal (\"Deliverance from Error\"), al-Ghazali noted that the Greek philosophers \"must be taxed with unbelief, as must their partisans among the Muslim philosophers, such as Avicenna and al-Farabi and their likes.\" He added that \"None, however, of the Muslim philosophers engaged so much in transmitting Aristotle's lore as did the two men just mentioned. [...] The sum of what we regard as the authentic philosophy of Aristotle, as transmitted by al-Farabi and Avicenna, can be reduced to three parts: a part which must be branded as unbelief; a part which must be stigmatized as innovation; and a part which need not be repudiated at all.\"\n\nArgument for God's existence \n\nAvicenna made an argument for the existence of God which would be known as the \"Proof of the Truthful\" (Arabic: burhan al-siddiqin). Avicenna argued that there must be a \"necessary existent\" (Arabic: wajib al-wujud), an entity that cannot not exist and through a series of arguments, he identified it with the Islamic conception of God. Present-day historian of philosophy Peter Adamson called this argument one of the most influential medieval arguments for God's existence, and Avicenna's biggest contribution to the history of philosophy.\n\nAl-Biruni correspondence \nCorrespondence between Avicenna (with his student Ahmad ibn 'Ali al-Ma'sumi) and Al-Biruni has survived in which they debated Aristotelian natural philosophy and the Peripatetic school. Abu Rayhan began by asking Avicenna eighteen questions, ten of which were criticisms of Aristotle's On the Heavens.\n\nTheology \nAvicenna was a devout Muslim and sought to reconcile rational philosophy with Islamic theology. His aim was to prove the existence of God and His creation of the world scientifically and through reason and logic. Avicenna's views on Islamic theology (and philosophy) were enormously influential, forming part of the core of the curriculum at Islamic religious schools until the 19th century. Avicenna wrote a number of short treatises dealing with Islamic theology. These included treatises on the prophets (whom he viewed as \"inspired philosophers\"), and also on various scientific and philosophical interpretations of the Quran, such as how Quranic cosmology corresponds to his own philosophical system. In general these treatises linked his philosophical writings to Islamic religious ideas; for example, the body's afterlife.\n\nThere are occasional brief hints and allusions in his longer works, however, that Avicenna considered philosophy as the only sensible way to distinguish real prophecy from illusion. He did not state this more clearly because of the political implications of such a theory, if prophecy could be questioned, and also because most of the time he was writing shorter works which concentrated on explaining his theories on philosophy and theology clearly, without digressing to consider epistemological matters which could only be properly considered by other philosophers.\n\nLater interpretations of Avicenna's philosophy split into three different schools; those (such as al-Tusi) who continued to apply his philosophy as a system to interpret later political events and scientific advances; those (such as al-Razi) who considered Avicenna's theological works in isolation from his wider philosophical concerns; and those (such as al-Ghazali) who selectively used parts of his philosophy to support their own attempts to gain greater spiritual insights through a variety of mystical means. It was the theological interpretation championed by those such as al-Razi which eventually came to predominate in the madrasahs.\n\nAvicenna memorized the Quran by the age of ten, and as an adult, he wrote five treatises commenting on suras from the Quran. One of these texts included the Proof of Prophecies, in which he comments on several Quranic verses and holds the Quran in high esteem. Avicenna argued that the Islamic prophets should be considered higher than philosophers.\n\nAvicenna is generally understood to have been aligned with the Sunni Hanafi school of thought. Avicenna studied Hanafi law, many of his notable teachers were Hanafi jurists, and he served under the Hanafi court of Ali ibn Mamun. Avicenna said at an early age that he remained \"unconvinced\" by Ismaili missionary attempts to convert him. Medieval historian \u1e92ah\u012br al-d\u012bn al-Bayhaq\u012b (d. 1169) also believed Avicenna to be a follower of the Brethren of Purity.\n\nThought experiments \n\nWhile he was imprisoned in the castle of Fardajan near Hamadhan, Avicenna wrote his famous \"floating man\"\u2014literally falling man\u2014a thought experiment to demonstrate human self-awareness and the substantiality and immateriality of the soul. Avicenna believed his \"Floating Man\" thought experiment demonstrated that the soul is a substance, and claimed humans cannot doubt their own consciousness, even in a situation that prevents all sensory data input. The thought experiment told its readers to imagine themselves created all at once while suspended in the air, isolated from all sensations, which includes no sensory contact with even their own bodies. He argued that, in this scenario, one would still have self-consciousness. Because it is conceivable that a person, suspended in air while cut off from sense experience, would still be", "flag": 1, "segments": [[2907, 2917]], "strength": 5.5}
{"text": "The Ashes is a Test cricket series played between England and Australia. The term originated in a satirical obituary published in a British newspaper, The Sporting Times, immediately after Australia's 1882 victory at The Oval, its first Test win on English soil. The obituary stated that English cricket had died, and \"the body will be cremated and the ashes taken to Australia\". The mythical ashes immediately became associated with the 1882\u201383 series played in Australia, before which the English captain Ivo Bligh had vowed to \"regain those ashes\". The English media therefore dubbed the tour the quest to regain the Ashes.\n\nAfter England had won two of the three Tests on the tour, a small urn was presented to Bligh by a group of Melbourne women including Florence Morphy, whom Bligh married within a year. The contents of the urn are reputed to be the ashes of a wooden bail, and were humorously described as \"the ashes of Australian cricket\". It is not clear whether that \"tiny silver urn\" is the same as the small terracotta urn given to the MCC by Bligh's widow after his death in 1927.\n\nThe urn has never been the official trophy of the Ashes series, having been a personal gift to Bligh. However, replicas of the urn are often held aloft by victorious teams as a symbol of their victory in an Ashes series. Since the 1998\u201399 Ashes series, a Waterford Crystal representation of the Ashes urn (called the Ashes Trophy) has been presented to the winners of an Ashes series as the official trophy of that series. Irrespective of which side holds the tournament, the urn remains in the MCC Museum at Lord's; it has however been taken to Australia to be put on touring display on two occasions: as part of the Australian Bicentenary celebrations in 1988 and to accompany the Ashes series in 2006\u201307.\n\nAn Ashes series traditionally consists of five Tests, hosted in turn by England and Australia at least once every two years. The Ashes are regarded as being held by the team that most recently won the series. If the series is drawn, the team that currently holds the Ashes retains the trophy. \n\nThere have been 72 Ashes series: Australia have won 34, England have won 32 and six series have been drawn.\n\n1882 origins\n\nThe first Test match between England and Australia was played in Melbourne, Australia, in 1877, though the Ashes legend started later, after the ninth Test, played in 1882. On their tour of England that year the Australians played just one Test, at the Oval in London. It was a low-scoring affair on a difficult wicket. Australia made a mere 63 runs in their first innings, and England, led by A. N. Hornby, took a 38-run lead with a total of 101. In their second innings, Australia, boosted by a spectacular 55 runs off 60 deliveries from Hugh Massie, managed 122, which left England only 85 runs to win. The Australians were greatly demoralised by the manner of their second-innings collapse, but fast bowler Fred Spofforth, spurred on by the gamesmanship of his opponents, in particular W. G. Grace, refused to give in. \"This thing can be done,\" he declared. Spofforth went on to devastate the English batting, taking his final four wickets for only two runs to leave England just eight runs short of victory.\n\nWhen Ted Peate, England's last batsman, came to the crease, his side needed just ten runs to win, but Peate managed only two before he was bowled by Harry Boyle. An astonished Oval crowd fell silent, struggling to believe that England could possibly have lost on home soil. When it finally sank in, the crowd swarmed onto the field, cheering loudly and chairing Boyle and Spofforth to the pavilion.\n\nWhen Peate returned to the pavilion he was reprimanded by his captain for not allowing his partner, Charles Studd (one of the best batsmen in England, having already hit two centuries that season against the colonists), to get the runs. Peate humorously replied, \"I had no confidence in Mr Studd, sir, so thought I had better do my best.\"\n\nThe momentous defeat was widely recorded in the British press, which praised the Australians for their plentiful \"pluck\" and berated the Englishmen for their lack thereof. A celebrated poem appeared in Punch on Saturday, 9 September. The first verse, quoted most frequently, reads:\n\nWell done, Cornstalks! Whipt us\nFair and square,\nWas it luck that tript us?\nWas it scare?\nKangaroo Land's 'Demon', or our own\nWant of 'devil', coolness, nerve, backbone?\n\nOn 31 August, in the Charles Alcock-edited magazine Cricket: A Weekly Record of The Game, there appeared a mock obituary:\n\nOn 2 September a more celebrated mock obituary, written by Reginald Shirley Brooks, appeared in The Sporting Times. It read:\n\nIvo Bligh promised that on 1882\u201383 tour of Australia, he would, as England's captain, \"recover those Ashes\". He spoke of them several times over the course of the tour, and the Australian media quickly caught on. The three-match series resulted in a two-one win to England, notwithstanding a fourth match, won by the Australians, whose status remains a matter of ardent dispute.\n\nIn the 20 years following Bligh's campaign the term \"the Ashes\" largely disappeared from public use. There is no indication that this was the accepted name for the series, at least not in England. The term became popular again in Australia first, when George Giffen, in his memoirs (With Bat and Ball, 1899), used the term as if it were well known.\n\nThe true and global revitalisation of interest in the concept dates from 1903, when Pelham Warner took a team to Australia with the promise that he would regain \"the ashes\". As had been the case on Bligh's tour 20 years before, the Australian media latched fervently onto the term and, this time, it stuck. Having fulfilled his promise, Warner published a book entitled How We Recovered the Ashes. Although the origins of the term are not referred to in the text, the title served (along with the general hype created in Australia) to revive public interest in the legend. The first mention of \"the Ashes\" in Wisden Cricketers' Almanack occurs in 1905, while Wisden'''s first account of the legend is in the 1922 edition.\n\nUrn\n\nIt took many years before the contests between England and Australia were consistently called \"The Ashes\", and so there was no concept of either a trophy or a physical representation of the ashes. As late as 1925, the following verse appeared in The Cricketers Annual:\n\nSo here's to Chapman, Hendren and Hobbs,\nGilligan, Woolley and Hearne\nMay they bring back to the Motherland,\nThe ashes which have no urn!\n\nNevertheless, several attempts had been made to embody the Ashes in a physical memorial. Examples include one presented to Warner in 1904, another to Australian captain M. A. Noble in 1909, and another to Australian captain W. M. Woodfull in 1934.\n\nThe oldest, and the one to enjoy enduring fame, was the one presented to Bligh, later Lord Darnley, during the 1882\u201383 tour. The precise nature of the origin of this urn is matter of dispute. Based on a statement by Darnley in 1894, it was believed that a group of Victorian ladies, including Darnley's later wife Florence Morphy, made the presentation after the victory in the Third Test in 1883. More recent researchers, in particular Ronald Willis and Joy Munns have studied the tour in detail and concluded that the presentation was made after a private cricket match played over Christmas 1882 when the English team were guests of Sir William Clarke, at his property \"Rupertswood\", in Sunbury, Victoria. This was before the matches had started. The prime evidence for this theory was provided by a descendant of Clarke.\n\nIn August 1926 Ivo Bligh (now Lord Darnley) displayed the Ashes urn at the Morning Post Decorative Art Exhibition held in the Central Hall, Westminster. He made the following statement about how he was given the urn:\n\nA more detailed account of how the Ashes were given to Ivo Bligh was outlined by his wife, the Countess of Darnley, in 1930 during a speech at a cricket luncheon. Her speech was reported by the Times as follows:\n\nThere is another statement which is not totally clear made by Lord Darnley in 1921 about the timing of the presentation of the urn. He was interviewed in his home at Cobham Hall by Montague Grover and the report of this interview was as follows:\n\nHe made a similar statement in 1926. The report of this statement in the Brisbane Courier was as follows:\n\nThe contents of the urn are also problematic; they were variously reported to be the remains of a stump, bail or the outer casing of a ball, but in 1998 Darnley's 82-year-old daughter-in-law said they were the remains of her mother-in-law's veil, casting a further layer of doubt on the matter. However, during the tour of Australia in 2006/7, the MCC official accompanying the urn said the veil legend had been discounted, and it was now \"95% certain\" that the urn contains the ashes of a cricket bail. Speaking on Channel Nine TV on 25 November 2006, he said x-rays of the urn had shown the pedestal and handles were cracked, and repair work had to be carried out. The urn is made of terracotta and is about  tall and may originally have been a perfume jar.\n\nA label containing a six-line verse is pasted on the urn. This is the fourth verse of a song-lyric published in the Melbourne Punch on 1 February 1883:\n\nWhen Ivo goes back with the urn, the urn;\nStudds, Steel, Read and Tylecote return, return;\nThe welkin will ring loud,\nThe great crowd will feel proud,\nSeeing Barlow and Bates with the urn, the urn;\nAnd the rest coming home with the urn.\n\nIn February 1883, just before the disputed Fourth Test, a velvet bag made by Mrs Ann Fletcher, the daughter of Joseph Hines Clarke and Marion Wright, both of Dublin, was given to Bligh to contain the urn. During Darnley's lifetime there was little public knowledge of the urn, and no record of a published photograph exists before 1921. The Illustrated London News published this photo in January 1921 (shown above). When Darnley died in 1927 his widow presented the urn to the Marylebone Cricket Club and that was the key event in establishing the urn as the physical embodiment of the legendary ashes. MCC first displayed the urn in the Long Room at Lord's and since 1953 in the MCC Cricket Museum at the ground. MCC's wish for it to be seen by as wide a range of cricket enthusiasts as possible has led to its being mistaken for an official trophy. It is in fact a private memento, and for this reason it is never awarded to either England or Australia, but is kept permanently in the MCC Cricket Museum where it can be seen together with the specially made red and gold velvet bag and the scorecard of the 1882 match.\n\nBecause the urn itself is so delicate, it has been allowed to travel to Australia only twice. The first occasion was in 1988 for a museum tour as part of the Australian Bicentenary celebrations; the second was for the 2006/7 Ashes series. The urn arrived on 17 October 2006, going on display at the Museum of Sydney. It then toured to other states, with the final appearance at the Tasmanian Museum and Art Gallery on 21 January 2007.\n\nIn the 1990s, given Australia's long dominance of the Ashes and the popular acceptance of the Darnley urn as \"the Ashes\", the idea was mooted that the victorious team should be awarded the urn as a trophy and allowed to retain it until the next series. As its condition is fragile and it is a prized exhibit at the MCC Cricket Museum, the MCC would not agree. Furthermore, in 2002, Bligh's great-great-grandson Lord Clifton, the heir-apparent to the Earldom of Darnley, argued that the Ashes urn should not be returned to Australia because it belonged to his family and was given to the MCC only for safe keeping.\n\nAs a compromise, the MCC commissioned a larger replica of the urn in Waterford Crystal, known as the Ashes Trophy, to award to the winning team of each series starting with the 1998\u201399 Ashes. This did little to diminish the status of the Darnley urn as the most important icon in cricket, the symbol of this old and keenly fought contest.\n\nSeries and matches\n\nQuest to \"recover those ashes\"\n\nLater in 1882, following the famous Australian victory at trilogy was a book that nobody else could have imagined The Oval, Bligh led an England team to Australia, as he said, to \"recover those ashes\". Publicity surrounding the series was intense, and it was at some time during this series that the Ashes urn was crafted. Australia won the First Test by nine wickets, but in the next two England were victorious. At the end of the Third Test, England were generally considered to have \"won back the Ashes\" 2\u20131. A fourth match was played, against a \"United Australian XI\", which was arguably stronger than the Australian sides that had competed in the previous three matches; this game, however, is not generally considered part of the 1882\u201383 series. It is counted as a Test, but as a standalone. This match ended in a victory for Australia.\n\n1884 to 1896\nAfter Bligh's victory, there was an extended period of English dominance. The tours generally had fewer Tests in the 1880s and 1890s than people have grown accustomed to in more recent years, the first five-Test series taking place only in 1894\u201395. England lost only four Ashes Tests in the 1880s out of 23 played, and they won all the seven series contested.\n\nThere was more chopping and changing in the teams, given that there was no official board of selectors for each country (in 1887\u201388, two separate English teams were on tour in Australia) and popularity with the fans varied. The 1890s games were more closely fought, Australia taking its first series win since 1882 with a 2\u20131 victory in 1891\u201392. But England dominated, winning the next three series to 1896 despite continuing player disputes.\n\nThe 1894\u201395 series began in sensational fashion when England won the First Test at Sydney by just 10 runs having followed on. Australia had scored a massive 586 (Syd Gregory 201, George Giffen 161) and then dismissed England for 325. But England responded with 437 and then dramatically dismissed Australia for 166 with Bobby Peel taking 6 for 67. At the close of the second last day's play, Australia were 113\u20132, needing only 64 more runs. But heavy rain fell overnight and next morning the two slow left-arm bowlers, Peel and Johnny Briggs, were all but unplayable. England went on to win the series 3\u20132 after it had been all square before the Final Test, which England won by 6 wickets. The English heroes were Peel, with 27 wickets in the series at an average of 26.70, and Tom Richardson, with 32 at 26.53.\n\nIn 1896, England under the captaincy of W. G. Grace won the series 2\u20131, and this marked the end of England's longest period of Ashes dominance.\n\n1897 to 1902\nAustralia resoundingly won the 1897\u201398 series by 4\u20131 under the captaincy of Harry Trott. His successor Joe Darling won the next three series in 1899, 1901\u201302 and the classic 1902 series, which became one of the most famous in the history of Test cricket.\n\nFive matches were played in 1902 but the first two were drawn after being hit by bad weather. In the First Test (the first played at Edgbaston), after scoring 376 England bowled out Australia for 36 (Wilfred Rhodes 7/17) and reduced them to 46\u20132 when they followed on. Australia won the Third and Fourth Tests at Bramall Lane and Old Trafford respectively. At Old Trafford, Australia won by just 3 runs after Victor Trumper had scored 104 on a \"bad wicket\", reaching his hundred before lunch on the first day. England won the last Test at The Oval by one wicket. Chasing 263 to win, they slumped to 48\u20135 before Jessop's 104 gave them a chance. He reached his hundred in just 75 minutes. The last-wicket pair of George Hirst and Rhodes were required to score 15 runs for victory. When Rhodes joined him, Hirst reportedly said: \"We'll get them in singles, Wilfred.\" In fact, they scored thirteen singles and a two.\n\nThe period of Darling's captaincy saw the emergence of outstanding Australian players such as Trumper, Warwick Armstrong, James Kelly, Monty Noble, Clem Hill, Hugh Trumble and Ernie Jones.\n\nReviving the legend\nAfter what the MCC saw as the problems of the earlier professional and amateur series they decided to take control of organising tours themselves, and this led to the first MCC tour of Australia in 1903\u201304. England won it against the odds, and Plum Warner, the England captain, wrote up his version of the tour in his book How We Recovered The Ashes. The title of this book revived the Ashes legend and it was after this that England v Australia series were customarily referred to as \"The Ashes\".\n\n1905 to 1912\nEngland and Australia were evenly matched until the outbreak of the First World War in 1914. Five more series took place between 1905 and 1912. In 1905, England's captain Stanley Jackson not only won the series 2\u20130, but also won the toss in all five matches and headed both the batting and the bowling averages. Monty Noble led Australia to victory in both 1907\u201308 and 1909. Then England won in 1911\u201312 by four matches to one. Jack Hobbs establishing himself as England's first-choice opening batsman with three centuries, while Frank Foster (32 wickets at 21.62) and Sydney Barnes (34 wickets at 22.88) formed a formidable bowling partnership.\n\nEngland retained the Ashes when it won the 1912 Triangular Tournament, which also featured South Africa. The Australian touring party had been severely weakened by a dispute between the board and players that caused Clem Hill, Victor Trumper, Warwick Armstrong, Tibby Cotter, Sammy Carter and Vernon Ransford to be omitted.\n\n1920 to 1933\nAfter the war, Australia took firm control of both the Ashes and world cricket. For the first time, the tactic of using two express bowlers in tandem paid off as Jack Gregory and Ted McDonald crippled the English batting on a regular basis. Australia recorded overwhelming victories both in England and on home soil. It won the first eight matches in succession including a 5\u20130 whitewash in 1920\u20131921 at the hands of Warwick Armstrong's team.\n\nThe ruthless and belligerent Armstrong led his team back to England in 1921 where his men lost only two games late in the tour to narrowly miss out of being the first team to complete a tour of England without defeat.\n\nEngland won only one Test out of 15 from the end of the war until 1925.\n\nIn a rain-hit series in 1926, England managed to eke out a 1\u20130 victory with a win in the final Test at The Oval. Because the series was at stake, the match was to be \"timeless\", i.e., played to a finish. Australia had a narrow first innings lead of 22. Jack Hobbs and Herbert Sutcliffe took the score to 49\u20130 at the end of the second day, a lead of 27. Heavy rain fell overnight, and next day the pitch soon developed into a traditional sticky wicket. England seemed doomed to be bowled out cheaply and to lose the match. In spite of the very difficult batting conditions, however, Hobbs and Sutcliffe took their partnership to 172 before Hobbs was out for exactly 100. Sutcliffe went on to make 161 and England won the game comfortably. Australian captain Herbie Collins was stripped of all captaincy positions down to club level, and some accused him of throwing the match.\n\nAustralia's ageing post-war team broke up after 1926, with Collins, Charlie Macartney and Warren Bardsley all departing, and Gregory breaking down at the start of the 1928\u201329 series.\n\nDespite the debut of Donald Bradman, the inexperienced Australians, led by Jack Ryder, were heavily defeated, losing 4\u20131. England had a very strong batting side, with Wally Hammond contributing 905 runs at an average of 113.12, and Hobbs, Sutcliffe and Patsy Hendren all scoring heavily; the bowling was more than adequate, without being outstanding.\n\nIn 1930, Bill Woodfull led an extremely inexperienced team to England.\n\nBradman fulfilled his promise in the 1930 series when he scored 974 runs at 139.14, which remains a world record Test series aggregate. A modest Bradman can be heard in a 1930 recording saying \"I have always endeavoured to do my best for the side, and the few centuries that have come my way have been achieved in the hope of winning matches. My one idea when going into bat was to make runs for Australia.\" In the Headingley Test, he made 334, reaching 309* at the end of the first day, including a century before lunch. Bradman himself thought that his 254 in the preceding match, at Lord's, was a better innings. England managed to stay in contention until the deciding final Test at The Oval, but yet another double hundred by Bradman, and 7/92 by Percy Hornibrook in England's second innings, enabled Australia to win by an innings and take the series 2\u20131. Clarrie Grimmett's 29 wickets at 31.89 for Australia in this high-scoring series were also important.\n\nAustralia had one of the strongest batting line-ups ever in the early 1930s, with Bradman, Archie Jackson, Stan McCabe, Bill Woodfull and Bill Ponsford. It was the prospect of bowling at this line-up that caused England's 1932\u201333 captain Douglas Jardine to adopt the tactic of fast leg theory, better known as Bodyline.\n\nJardine instructed his fast bowlers, most notably Harold Larwood and Bill Voce, to bowl at the bodies of the Australian batsmen, with the goal of forcing them to defend their bodies with their bats, thus providing easy catches to a stacked leg-side field. Jardine insisted that the tactic was legitimate and called it \"leg theory\" but it was widely disparaged by its opponents, who dubbed it \"Bodyline\" (from \"on the line of the body\"). Although England decisively won the Ashes 4\u20131, Bodyline caused such a furore in Australia that diplomats had to intervene to prevent serious harm to Anglo-Australian relations, and the MCC eventually changed the Laws of cricket to curtail the number of leg side fielders.\n\nJardine's comment was: \"I've not travelled 6,000 miles to make friends. I'm here to win the Ashes\".\n\nSome of the Australians wanted to use Bodyline in retaliation, but Woodfull flatly refused. He famously", "flag": 1, "segments": [[2797, 2807]], "strength": 5.5}
{"text": "Augustin-Jean Fresnel ( ;  ; or  ; ; 10 May 1788\u00a0\u2013 14 July 1827) was a French civil engineer and physicist whose research in optics led to the almost unanimous acceptance of the wave theory of light, excluding any remnant of Newton's corpuscular theory, from the late 1830s until the end of the 19th century. He is perhaps better known for inventing the catadioptric (reflective/refractive) Fresnel lens and for pioneering the use of \"stepped\" lenses to extend the visibility of lighthouses, saving countless lives at sea. The simpler dioptric (purely refractive) stepped lens, first proposed by Count Buffon and independently reinvented by Fresnel, is used in screen magnifiers and in condenser lenses for overhead projectors.\n\nBy expressing Huygens's principle of secondary waves and Young's principle of interference in quantitative terms, and supposing that simple colors consist of sinusoidal waves, Fresnel gave the first satisfactory explanation of diffraction by straight edges, including the first satisfactory wave-based explanation of rectilinear propagation. Part of his argument was a proof that the addition of sinusoidal functions of the same frequency but different phases is analogous to the addition of forces with different directions. By further supposing that light waves are purely transverse, Fresnel explained the nature of polarization, the mechanism of chromatic polarization, and the transmission and reflection coefficients at the interface between two transparent isotropic media. Then, by generalizing the direction-speed-polarization relation for calcite, he accounted for the directions and polarizations of the refracted rays in doubly-refractive crystals of the biaxial class (those for which Huygens's secondary wavefronts are not axisymmetric). The period between the first publication of his pure-transverse-wave hypothesis, and the submission of his first correct solution to the biaxial problem, was less than a year.\n\nLater, he coined the terms linear polarization, circular polarization, and elliptical polarization, explained how optical rotation could be understood as a difference in propagation speeds for the two directions of circular polarization, and (by allowing the reflection coefficient to be complex) accounted for the change in polarization due to total internal reflection, as exploited in the Fresnel rhomb. Defenders of the established corpuscular theory could not match his quantitative explanations of so many phenomena on so few assumptions.\n\nFresnel had a lifelong battle with tuberculosis, to which he succumbed at the age of 39.  Although he did not become a public celebrity in his lifetime, he lived just long enough to receive due recognition from his peers, including (on his deathbed) the Rumford Medal of the Royal Society of London, and his name is ubiquitous in the modern terminology of optics and waves. After the wave theory of light was subsumed by Maxwell's electromagnetic theory in the 1860s, some attention was diverted from the magnitude of Fresnel's contribution. In the period between Fresnel's unification of physical optics and Maxwell's wider unification, a contemporary authority, Humphrey Lloyd, described Fresnel's transverse-wave theory as \"the noblest fabric which has ever adorned the domain of physical science, Newton's system of the universe alone excepted.\"\n\nEarly life\n\nFamily \n\nAugustin-Jean Fresnel (also called Augustin Jean or simply Augustin), born in Broglie, Normandy, on 10 May 1788, was the second of four sons of the architect Jacques Fresnel (1755\u20131805) and his wife Augustine, n\u00e9e M\u00e9rim\u00e9e (1755\u20131833). In 1790, following the Revolution, Broglie became part of the d\u00e9partement of Eure. The family moved twice \u2013 in 1789/90 to Cherbourg, and in 1794 to Jacques's home town of Mathieu, where Madame Fresnel would spend 25 years as a widow, outliving two of her sons.\n\nThe first son, Louis (1786\u20131809), was admitted to the \u00c9cole Polytechnique, became a lieutenant in the artillery, and was killed in action at Jaca, Spain, the day before his 23rd birthday. The third, L\u00e9onor (1790\u20131869), followed Augustin into civil engineering, succeeded him as secretary of the Lighthouse Commission, and helped to edit his collected works. The fourth, Fulgence Fresnel (1795\u20131855), became a noted linguist, diplomat, and orientalist, and occasionally assisted Augustin with negotiations.  Fulgence died in Bagdad in 1855 having led a mission to explore Babylon.  L\u00e9onor apparently was the only one of the four who married.\n\nTheir mother's younger brother, Jean Fran\u00e7ois \"L\u00e9onor\" M\u00e9rim\u00e9e (1757\u20131836), father of the writer Prosper M\u00e9rim\u00e9e (1803\u20131870), was a paint\u00a0artist who turned his attention to the chemistry of painting. He became the Permanent Secretary of the \u00c9cole des Beaux-Arts and (until 1814) a professor at the \u00c9cole Polytechnique, and was the initial point of contact between Augustin and the leading optical physicists of the day.\n\nEducation \n\nThe Fresnel brothers were initially home-schooled by their mother. The sickly Augustin was considered the slow one, not inclined to memorization; but the popular story that he hardly began to read until the age of eight is disputed. At the age of nine or ten he was undistinguished except for his ability to turn tree-branches into toy bows and guns that worked far too well, earning himself the title l'homme de g\u00e9nie (the man of genius) from his accomplices, and a united crackdown from their elders.\n\nIn 1801, Augustin was sent to the \u00c9cole Centrale at Caen, as company for Louis. But Augustin lifted his performance: in late 1804 he was accepted into the \u00c9cole Polytechnique, being placed 17th in the entrance examination. As the detailed records of the \u00c9cole Polytechnique begin in 1808, we know little of Augustin's time there, except that he made few if any friends and \u2013 in spite of continuing poor health \u2013 excelled in drawing and geometry: in his first year he took a prize for his solution to a geometry problem posed by Adrien-Marie Legendre. Graduating in 1806, he then enrolled at the \u00c9cole Nationale des Ponts et Chauss\u00e9es (National School of Bridges and Roads, also known as \"ENPC\" or \"\u00c9cole des Ponts\"), from which he graduated in 1809, entering the service of the Corps des Ponts et Chauss\u00e9es as an ing\u00e9nieur ordinaire aspirant (ordinary engineer in training). Directly or indirectly, he was to remain in the employment of the \"Corps des Ponts\" for the rest of his life.\n\nReligious formation \n\nAugustin Fresnel's parents were Roman Catholics of the Jansenist sect, characterized by an extreme Augustinian view of original sin. Religion took first place in the boys' home-schooling. In\u00a01802, Mme\u00a0Fresnel reportedly said:\n\nAugustin remained a Jansenist. He indeed regarded his intellectual talents as gifts from God, and considered it his duty to use them for the benefit of others. Plagued by poor health, and determined to do his duty before death thwarted him, he shunned pleasures and worked to the point of exhaustion. According to his fellow engineer Alphonse Duleau, who helped to nurse him through his final illness, Fresnel saw the study of nature as part of the study of the power and goodness of God. He placed virtue above science and genius. Yet in his last days he needed \"strength of soul,\" not against death alone, but against \"the interruption of discoveries\u2026 of which he hoped to derive useful applications.\"\n\nJansenism is considered heretical by the Roman Catholic Church, and this may be part of the explanation why Fresnel, in spite of his scientific achievements and his royalist credentials, never gained a permanent academic teaching post; his only teaching appointment was at the Ath\u00e9n\u00e9e in the winter of 1819\u201320. Be that as it may, the brief article on Fresnel in the old Catholic Encyclopedia does not mention his Jansenism, but describes him as \"a deeply religious man and remarkable for his keen sense of duty.\"\n\nEngineering assignments \n\nFresnel was initially posted to the western d\u00e9partement of Vend\u00e9e. There, in 1811, he anticipated what became known as the Solvay process for producing soda\u00a0ash, except that recycling of the ammonia was not considered. That difference may explain why leading chemists, who learned of his discovery through his uncle L\u00e9onor, eventually thought it uneconomic.\n\nAbout 1812, Fresnel was sent to Nyons, in the southern d\u00e9partement of Dr\u00f4me, to assist with the imperial highway that was to connect Spain and Italy. It is from Nyons that we have the first evidence of his interest in optics. On 15 May 1814, while work was slack due to Napoleon's defeat, Fresnel wrote a \"P.S.\" to his brother L\u00e9onor, saying in part:\n\nAs late as 28 December he was still waiting for information, but he had received Biot's memoir by 10 February 1815. (The Institut de France had taken over the functions of the French Acad\u00e9mie des Sciences and other acad\u00e9mies in 1795. In\u00a01816 the Acad\u00e9mie des Sciences regained its name and autonomy, but remained part of the institute.)\n\nIn March 1815, perceiving Napoleon's return from Elba as \"an attack on civilization\", Fresnel departed without leave, hastened to Toulouse and offered his services to the royalist resistance, but soon found himself on the sick list. Returning to Nyons in defeat, he was threatened and had his windows broken. During the Hundred Days he was placed on suspension, which he was eventually allowed to spend at his mother's house in Mathieu. There he used his enforced leisure to begin his optical experiments.\n\nContributions to physical optics\n\nHistorical context: From Newton to Biot \n\nThe appreciation of Fresnel's reconstruction of physical optics might be assisted by an overview of the fragmented state in which he found the subject. In this subsection, optical phenomena that were unexplained or whose explanations were disputed are named in bold\u00a0type.\n\nThe corpuscular theory of light, favored by Isaac Newton and accepted by nearly all of Fresnel's seniors, easily explained rectilinear propagation: the corpuscles obviously moved very fast, so that their paths were very nearly straight. The wave theory, as developed by Christiaan Huygens in his Treatise on Light (1690), explained rectilinear propagation on the assumption that each point crossed by a traveling wavefront becomes the source of a secondary wavefront. Given the initial position of a traveling wavefront, any later position (according to Huygens) was the common tangent surface (envelope) of the secondary wavefronts emitted from the earlier position. As the extent of the common tangent was limited by the extent of the initial wavefront, the repeated application of Huygens's construction to a plane wavefront of limited extent (in a uniform medium) gave a straight, parallel beam. While this construction indeed predicted rectilinear propagation, it was difficult to reconcile with the common observation that wavefronts on the surface of water can bend around obstructions, and with the similar behavior of sound waves \u2013 causing Newton to maintain, to the end of his life, that if light consisted of waves it would \"bend and spread every way\" into the shadows.\n\nHuygens's theory neatly explained the law of ordinary reflection and the law of ordinary refraction (\"Snell's law\"), provided that the secondary waves traveled slower in denser media (those of higher refractive index). The corpuscular theory, with the hypothesis that the corpuscles were subject to forces acting perpendicular to surfaces, explained the same laws equally well, albeit with the implication that light traveled faster in denser media; that implication was wrong, but could not be directly disproven with the technology of Newton's time or even Fresnel's time.\n\nSimilarly inconclusive was stellar aberration\u2014that is, the apparent change in the position of a star due to the velocity of the earth across the line of sight (not to be confused with stellar parallax, which is due to the displacement of the earth across the line of sight). Identified by James Bradley in 1728, stellar aberration was widely taken as confirmation of the corpuscular theory. But it was equally compatible with the wave theory, as Euler noted in 1746 \u2013 tacitly assuming that the aether (the supposed wave-bearing medium) near the earth was not disturbed by the motion of the earth.\n\nThe outstanding strength of Huygens's theory was his explanation of the birefringence (double refraction) of \"Iceland crystal\" (transparent calcite), on the assumption that the secondary waves are spherical for the ordinary refraction (which satisfies Snell's law) and spheroidal for the extraordinary refraction (which does not). In general, Huygens's common-tangent construction implies that rays are paths of least time between successive positions of the wavefront, in accordance with Fermat's principle. In the special case of isotropic media, the secondary wavefronts must be spherical, and Huygens's construction then implies that the rays are perpendicular to the wavefront; indeed, the law of ordinary refraction can be separately derived from that premise, as Ignace-Gaston Pardies did before Huygens.\n\nAlthough Newton rejected the wave theory, he noticed its potential to explain colors, including the colors of \"thin plates\" (e.g., \"Newton's rings\", and the colors of skylight reflected in soap bubbles), on the assumption that light consists of periodic waves, with the lowest frequencies (longest wavelengths) at the red end of the spectrum, and the highest frequencies (shortest wavelengths) at the violet end. In\u00a01672 he published a heavy hint to that effect, but contemporary supporters of the wave theory failed to act on it: Robert Hooke treated light as a periodic sequence of pulses but did not use frequency as the criterion of color, while Huygens treated the waves as individual pulses without any periodicity; and Pardies died young in 1673. Newton himself tried to explain colors of thin plates using the corpuscular theory, by supposing that his corpuscles had the wavelike property of alternating between \"fits of easy transmission\" and \"fits of easy reflection\", the distance between like \"fits\" depending on the color and the medium and, awkwardly, on the angle of refraction or reflection into that medium. More awkwardly still, this theory required thin plates to reflect only at the back surface, although thick plates manifestly reflected also at the front surface. It was not until 1801 that Thomas Young, in the Bakerian Lecture for that year, cited Newton's hint, and accounted for the colors of a thin plate as the combined effect of the front and back reflections, which reinforce or cancel each other according to the wavelength and the thickness. Young similarly explained the colors of \"striated surfaces\" (e.g., gratings) as the wavelength-dependent reinforcement or cancellation of reflections from adjacent lines. He described this reinforcement or cancellation as interference.\n\nNeither Newton nor Huygens satisfactorily explained diffraction\u2014the blurring and fringing of shadows where, according to rectilinear propagation, they ought to be sharp. Newton, who called diffraction \"inflexion\", supposed that rays of light passing close to obstacles were bent (\"inflected\"); but his explanation was only qualitative. Huygens's common-tangent construction, without modifications, could not accommodate diffraction at all. Two such modifications were proposed by Young in the same 1801 Bakerian Lecture: first, that the secondary waves near the edge of an obstacle could diverge into the shadow, but only weakly, due to limited reinforcement from other secondary waves; and second, that diffraction by an edge was caused by interference between two rays: one reflected off the edge, and the other inflected while passing near the edge. The latter ray would be undeviated if sufficiently far from the edge, but Young did not elaborate on that case. These were the earliest suggestions that the degree of diffraction depends on wavelength. Later, in the 1803 Bakerian Lecture, Young ceased to regard inflection as a separate phenomenon, and produced evidence that diffraction fringes inside the shadow of a narrow obstacle were due to interference: when the light from one side was blocked, the internal fringes disappeared. But Young was alone in such efforts until Fresnel entered the field.\n\nHuygens, in his investigation of double refraction, noticed something that he could not explain: when light passes through two similarly oriented calcite crystals at normal incidence, the ordinary ray emerging from the first crystal suffers only the ordinary refraction in the second, while the extraordinary ray emerging from the first suffers only the extraordinary refraction in the second; but when the second crystal is rotated 90\u00b0 about the incident rays, the roles are interchanged, so that the ordinary ray emerging from the first crystal suffers only the extraordinary refraction in the second, and vice versa. This discovery gave Newton another reason to reject the wave theory: rays of light evidently had \"sides\". Corpuscles could have sides (or poles, as they would later be called); but waves of light could not, because (so it seemed) any such waves would need to be longitudinal (with vibrations in the direction of propagation). Newton offered an alternative \"Rule\" for the extraordinary refraction, which rode on his authority through the 18th century, although he made \"no known attempt to deduce it from any principles of optics, corpuscular or otherwise.\"\n\nIn 1808, the extraordinary refraction of calcite was investigated experimentally, with unprecedented accuracy, by \u00c9tienne-Louis Malus, and found to be consistent with Huygens's spheroid construction, not Newton's \" spoke on the condition that the player hadn\u2019Rule\". Malus, encouraged by Pierre-Simon Laplace, then sought to explain this law in corpuscular terms: from the known relation between the incident and refracted ray directions, Malus derived the corpuscular velocity (as a function of direction) that would satisfy Maupertuis's \"least action\" principle. But, as Young pointed out, the existence of such a velocity law was guaranteed by Huygens's spheroid, because Huygens's construction leads to Fermat's principle, which becomes Maupertuis's principle if the ray speed is replaced by the reciprocal of the particle speed! The corpuscularists had not found a force law that would yield the alleged velocity law, except by a circular argument in which a force acting at the surface of the crystal inexplicably depended on the direction of the (possibly subsequent) velocity within the crystal. Worse, it was doubtful that any such force would satisfy the conditions of Maupertuis's principle. In contrast, Young proceeded to show that \"a\u00a0medium more easily compressible in one direction than in any direction perpendicular to it, as if it consisted of an infinite number of parallel plates connected by a substance somewhat less elastic\" admits spheroidal longitudinal wavefronts, as Huygens supposed.\n\nBut Malus, in the midst of his experiments on double refraction, noticed something else: when a ray of light is reflected off a non-metallic surface at the appropriate angle, it behaves like one of the two rays emerging from a calcite crystal. It was Malus who coined the term polarization to describe this behavior, although the polarizing angle became known as Brewster's angle after its dependence on the refractive index was determined experimentally by David Brewster in 1815. Malus also introduced the term plane of polarization. In the case of polarization by reflection, his \"plane of polarization\" was the plane of the incident and reflected rays; in modern terms, this is the plane normal to the electric vibration. In\u00a01809, Malus further discovered that the intensity of light passing through two polarizers is proportional to the squared cosine of the angle between their planes of polarization (Malus's law), whether the polarizers work by reflection or double refraction, and that all birefringent crystals produce both extraordinary refraction and polarization. As the corpuscularists started trying to explain these things in terms of polar \"molecules\" of light, the wave-theorists had no working hypothesis on the nature of polarization, prompting Young to remark that Malus's observations \"present greater difficulties to the advocates of the undulatory theory than any other facts with which we are acquainted.\"\n\nMalus died in February 1812, at the age of 36, shortly after receiving the Rumford Medal for his work on polarization.\n\nIn August 1811, Fran\u00e7ois Arago reported that if a thin plate of mica was viewed against a white polarized backlight through a calcite crystal, the two images of the mica were of complementary colors (the overlap having the same color as the background). The light emerging from the mica was \"depolarized\" in the sense that there was no orientation of the calcite that made one image disappear; yet it was not ordinary (\"unpolarized\") light, for which the two images would be of the same color. Rotating the calcite around the line of sight changed the colors, though they remained complementary. Rotating the mica changed the saturation (not the hue) of the colors. This phenomenon became known as chromatic polarization. Replacing the mica with a much thicker plate of quartz, with its faces perpendicular to the optic axis (the axis of Huygens's spheroid or Malus's velocity function), produced a similar effect, except that rotating the quartz made no difference. Arago tried to explain his observations in corpuscular terms.\n\nIn 1812, as Arago pursued further qualitative experiments and other commitments, Jean-Baptiste Biot reworked the same ground using a gypsum lamina in place of the mica, and found empirical formulae for the intensities of the ordinary and extraordinary images. The formulae contained two coefficients, supposedly representing colors of rays \"affected\" and \"unaffected\" by the plate \u2013 the \"affected\" rays being of the same color mix as those reflected by amorphous thin plates of proportional, but lesser, thickness.\n\nArago protested, declaring that he had made some of the same discoveries but had not had time to write them up. In fact the overlap between Arago's work and Biot's was minimal, Arago's being only qualitative and wider in scope (attempting to include polarization by reflection). But the dispute triggered a notorious falling-out between the two men.\n\nLater that year, Biot tried to explain the observations as an oscillation of the alignment of the \"affected\" corpuscles at a frequency proportional to that of Newton's \"fits\", due to forces depending on the alignment. This theory became known as mobile polarization. To reconcile his results with a sinusoidal oscillation, Biot had to suppose that the corpuscles emerged with one of two permitted orientations, namely the extremes of the oscillation, with probabilities depending on the phase of the oscillation. Corpuscular optics was becoming expensive on assumptions. But in 1813, Biot reported that the case of quartz was simpler: the observable phenomenon (now called optical rotation or optical activity or sometimes rotary polarization) was a gradual rotation of the polarization direction with distance, and could be explained by a corresponding", "flag": 1, "segments": [[3845, 3855]], "strength": 5.5}
{"text": "Adelaide ( ) is the capital city of South Australia, the state's largest city and the fifth-most populous city of Australia. \"Adelaide\" may refer to either Greater Adelaide (including the Adelaide Hills) or the Adelaide city centre. The demonym  is used to denote the city and the residents of Adelaide. Adelaide city centre was originally inhabited by a group of Kaurna people and known as Tarndanyangga (\"place of the red kangaroo\") \u2013 now the dual name of Victoria Square in the middle of the city \u2013 or Tarndanya.\n\nAdelaide is situated on the Adelaide Plains north of the Fleurieu Peninsula, between the Gulf St Vincent in the west and the Mount Lofty Ranges in the east. Its metropolitan area extends  from the coast to the foothills of the Mount Lofty Ranges, and stretches  from Gawler in the north to Sellicks Beach in the south.\n\nNamed in honour of Queen Adelaide, the city was founded in 1836 as the planned capital for the only freely-settled British province in Australia. Colonel William Light, one of Adelaide's founding fathers, designed the city centre and chose its location close to the River Torrens. Light's design, now listed as national heritage, set out the city centre in a grid layout known as \"Light's Vision\", interspaced by wide boulevards and large public squares, and entirely surrounded by parklands.\n\nEarly colonial Adelaide was shaped by the diversity and wealth of its free settlers, in contrast to the convict history of other Australian cities. Until the post-war era, it was Australia's third most populated city. It has been noted for its leading examples of religious freedom and progressive political reforms, and became known as the \"City of Churches\" due to its diversity of faiths. Today, Adelaide is known by its many festivals and sporting events, its food and wine, its coastline and hills, and its large defence and manufacturing sectors. Adelaide's quality of life has ranked consistently highly in various measures through the 21st century, at one stage being named Australia's most liveable city.\n\nAs South Australia's government and commercial centre, Adelaide is the site of many governmental and financial institutions. Most of these are concentrated in the city centre along the cultural boulevards of North Terrace and King William Street.\n\nHistory\n\nBefore European settlement \n\nBefore its proclamation as a British settlement in 1836, the area around Adelaide was inhabited by the Indigenous Kaurna people, one of many Aboriginal nations in South Australia. The city and parklands area was known as Tarntanya, Tandanya (now the short name of Tandanya National Aboriginal Cultural Institute), Tarndanya, or Tarndanyangga (now the dual name for Victoria Square) in the Kaurna language. The surrounding area was an open grassy plain with patches of trees and shrub which had been managed by hundreds of generations. Kaurna country encompassed the plains which stretched north and south of Tarntanya as well as the wooded foothills of the Mt Lofty Ranges. The River Torrens was known as the Karrawirra Pari (Red Gum forest river). About 300 Kaurna populated the Adelaide area, and were referred to by the settlers as the Cowandilla.\n\nWithin a few decades of European settlement of South Australia, Kaurna culture was almost completely destroyed; the last speaker of Kaurna language died in 1929. Extensive documentation by early missionaries and other researchers has enabled a modern revival of both, which has included a commitment by local and state governments to rename or include Kaurna names for many local places.\n\n19th century \n\nSouth Australia was officially established as a British Province in England in February 1836. The first governor \nproclaimed the commencement of colonial government in South Australia on 28 December 1836, near The Old Gum Tree in what is now the suburb of Glenelg North. The event is commemorated in South Australia as Proclamation Day. The site of the colony's capital was surveyed and laid out by Colonel William Light, the first Surveyor-General of South Australia, with his own original, unique, topographically sensitive design.\nClaims of the design being by the architect George Strickland Kingston have been thoroughly debunked. The city was named after Queen Adelaide.\n\nAdelaide was established as a planned colony of free immigrants, promising civil liberties and freedom from religious persecution, based upon the ideas of Edward Gibbon Wakefield. Wakefield had read accounts of Australian settlement while in prison in London for attempting to abduct an heiress, and realised that the eastern colonies suffered from a lack of available labour, due to the practice of giving land grants to all arrivals. Wakefield's idea was for the Government to survey and sell the land at a rate that would maintain land values high enough to be unaffordable for labourers and journeymen. Funds raised from the sale of land were to be used to bring out working-class emigrants, who would have to work hard for the monied settlers to ever afford their own land. As a result of this policy, Adelaide does not share the convict settlement history of other Australian cities like Sydney, Brisbane and Hobart.\n\nAs it was believed that in a colony of free settlers there would be little crime, no provision was made for a gaol in Colonel Light's 1837 plan. But by mid-1837 the South Australian Register was warning of escaped convicts from New South Wales and tenders for a temporary gaol were sought. Following a burglary, a murder, and two attempted murders in Adelaide during March 1838, Governor Hindmarsh created the South Australian Police Force (now the South Australia Police) in April 1838 under 21-year-old Henry Inman. The first sheriff, Samuel Smart, was wounded during a robbery, and on 2 May 1838 one of the offenders, Michael Magee, became the first person to be hanged in South Australia. William Baker Ashton was appointed governor of the temporary gaol in 1839, and in 1840 George Strickland Kingston was commissioned to design Adelaide's new gaol. Construction of Adelaide Gaol commenced in 1841.\n\nAdelaide's early history was marked by economic uncertainty and questionable leadership. The first governor of South Australia, John Hindmarsh, clashed frequently with others, in particular the Resident Commissioner, James Hurtle Fisher. The rural area surrounding Adelaide was surveyed by Light in preparation to sell a total of over  of land. Adelaide's early economy started to get on its feet in 1838 with the arrival of livestock from Victoria, New South Wales and Tasmania. Wool production provided an early basis for the South Australian economy. By 1860, wheat farms had been established from Encounter Bay in the south to Clare in the north.\n\nGeorge Gawler took over from Hindmarsh in late 1838 and, despite being under orders from the Select Committee on South Australia in Britain not to undertake any public works, promptly oversaw construction of a governor's house, the Adelaide Gaol, police barracks, a hospital, a customs house and a wharf at Port Adelaide. Gawler was recalled and replaced by George Edward Grey in 1841. Grey slashed public expenditure against heavy opposition, although its impact was negligible at this point: silver was discovered in Glen Osmond that year, agriculture was well underway, and other mines sprung up all over the state, aiding Adelaide's commercial development. The city exported meat, wool, wine, fruit and wheat by the time Grey left in 1845, contrasting with a low point in 1842 when one-third of Adelaide houses were abandoned.\n\nTrade links with the rest of the Australian states were established after the Murray River was successfully navigated the economic downturn from happening in the near future or in 1853 by Francis Cadell, an Adelaide resident. South Australia became a self-governing colony in 1856 with the ratification of a new constitution by the British parliament. Secret ballots were introduced, and a bicameral parliament was elected on 9 March 1857, by which time 109,917 people lived in the province.\n\nIn 1860, the Thorndon Park reservoir was opened, finally providing an alternative water source to the now turbid River Torrens. Gas street lighting was implemented in 1867, the University of Adelaide was founded in 1874, the South Australian Art Gallery opened in 1881 and the Happy Valley Reservoir opened in 1896. In the 1890s Australia was affected by a severe economic depression, ending a hectic era of land booms and tumultuous expansionism. Financial institutions in Melbourne and banks in Sydney closed. The national fertility rate fell and immigration was reduced to a trickle. The value of South Australia's exports nearly halved. Drought and poor harvests from 1884 compounded the problems, with some families leaving for Western Australia. Adelaide was not as badly hit as the larger gold-rush cities of Sydney and Melbourne, and silver and lead discoveries at Broken Hill provided some relief. Only one year of deficit was recorded, but the price paid was retrenchments and lean public spending. Wine and copper were the only industries not to suffer a downturn.\n\n20th century \n\nAdelaide was Australia's third largest city for most of the 20th century. Electric street lighting was introduced in 1900 and electric trams were transporting passengers in 1909. 28,000 men were sent to fight in World War I. Historian F. W. Crowley examined the reports of visitors in the early 20th century, noting that \"many visitors to Adelaide admired the foresighted planning of its founders\", as well as pondering the riches of the young city. Adelaide enjoyed a postwar boom, entering a time of relative prosperity. Its population grew, and it became the third most populous metropolitan area in the country, after Sydney and Melbourne. Its prosperity was short-lived, with the return of droughts and the Great Depression of the 1930s. It later returned to fortune under strong government leadership. Secondary industries helped reduce the state's dependence on primary industries. World War II brought industrial stimulus and diversification to Adelaide under the Playford Government, which advocated Adelaide as a safe place for manufacturing due to its less vulnerable location. Shipbuilding was expanded at the nearby port of Whyalla.\n\nThe South Australian Government in this period built on former wartime manufacturing industries but neglected cultural facilities which meant South Australia's economy lagged behind. International manufacturers like General Motors Holden and Chrysler made use of these factories around the Adelaide area in suburbs like Elizabeth, completing its transformation from an agricultural service centre to a 20th-century motor city. The Mannum\u2013Adelaide pipeline brought River Murray water to Adelaide in 1955 and an airport opened at West Beach in 1955. Flinders University and the Flinders Medical Centre were established in the 1960s at Bedford Park, south of the city. Today, Flinders Medical Centre is one of the largest teaching hospitals in South Australia. In the post-war years around the early 1960s, Adelaide was surpassed by Brisbane as Australia's third largest city.\n\nThe Dunstan Governments of the 1970s saw something of an Adelaide 'cultural revival', establishing a wide array of social reforms. The city became noted for its progressivism as South Australia became the first Australian state or territory to decriminalise homosexuality between consenting adults in 1975. It also became a centre for the arts, building upon the biennial \"Adelaide Festival of Arts\" that commenced in 1960. Adelaide hosted the Formula One Australian Grand Prix between 1985 and 1995 on a street circuit in the city's east parklands; it moved to Melbourne in 1996. The State Bank collapsed in 1991 during an economic recession; the effects lasted until 2004, when Standard & Poor's reinstated South Australia's AAA credit rating. From 1999 until 2020, the Adelaide 500 Supercars race has made use of sections of the former Formula One circuit. Adelaide's tallest building, completed in 2020, is called the Adelaidean and is located at 11 Frome Street.\n\n21st century \nIn the early years of the 21st century, a significant increase in the state government's spending on Adelaide's infrastructure occurred. The Rann government invested A$535\u00a0million in a major upgrade of the Adelaide Oval to enable Australian Football League to be played in the city centre and more than A$2 billion to build a new Royal Adelaide Hospital on land adjacent to the Adelaide Railway Station. The Glenelg tramline was extended through the city to Hindmarsh down to East Terrace and the suburban railway line extended south to Seaford.\n\nFollowing a period of stagnation in the 1990s and 2000s, Adelaide began several major developments and redevelopments. The Adelaide Convention Centre was redeveloped and expanded at a cost of A$350\u00a0million beginning in 2012. Three historic buildings were adapted for modern use: the Torrens Building in Victoria Square as the Adelaide campus for Carnegie Mellon University, University College London, and Torrens University; the Stock Exchange building as the Science Exchange of the Royal Institution Australia; and the Glenside Psychiatric Hospital as the Adelaide Studios of the SA Film Corporation. The government also invested more than A$2\u00a0billion to build a desalination plant, powered by renewable energy, as an 'insurance policy' against droughts affecting Adelaide's water supply. The Adelaide Festival, Fringe, and Womadelaide became annual events.\n\nThe COVID-19 Pandemic  had an impact the economy and resident life of the city. Comparing to other major cities in Australia, Adelaide is less affected. The city only went to fully lockdown twice since the beginning of the pandemic, once in November 2020 (4 days) and another once in July 2021 (7 days), despite being the nearest city to Melbourne (262 days of lockdown) with 1 million or more population.\n\nGeography \n\nAdelaide is north of the Fleurieu Peninsula, on the Adelaide Plains between the Gulf St Vincent and the low-lying Mount Lofty Ranges. The city stretches  from the coast to the foothills, and  from Gawler at its northern extent to Sellicks Beach in the south. According to the Regional Development Australia, an Australian government planning initiative, the \"Adelaide Metropolitan Region\" has a total land area of, while a more expansive definition by the Australian Bureau of Statistics defines a \"Greater Adelaide\" statistical area totalling. The city sits at an average elevation of  above sea level. Mount Lofty, east of the Adelaide metropolitan region in the Adelaide Hills at an elevation of, is the tallest point of the city and in the state south of Burra.\n\nMuch of Adelaide was bushland before British settlement, with some variation \u2013 sandhills, swamps and marshlands were prevalent around the coast. The loss of the sandhills to urban development had a particularly destructive effect on the coastline due to erosion. Where practical, the government has implemented programs to rebuild and vegetate sandhills at several of Adelaide's beachside suburbs. Much of the original vegetation has been cleared with what is left to be found in reserves such as the Cleland National Park and Belair National Park. A number of creeks and rivers flow through the Adelaide region. The largest are the Torrens and Onkaparinga catchments. Adelaide relies on its many reservoirs for water supply with the Happy Valley Reservoir supplying around 40% and the much larger Mount Bold Reservoir 10% of Adelaide's domestic requirements respectively.\n\nGeology\nAdelaide and its surrounding area is one of the most seismically active regions in Australia. On 1 March 1954 at 3:40 am Adelaide experienced its largest recorded earthquake to date, with the epicentre 12\u00a0km from the city centre at Darlington, and a reported magnitude of 5.6. There have been smaller earthquakes in 2010, 2011, 2014, 2017, and 2018.\n\nThe uplands of the Adelaide Hills, part of the southern Mount Lofty Ranges to the east of Adelaide, are defined on their western side by a number of arcuate faults (the Para, Eden, Clarendon and Willunga Faults), and consist of rocks such as siltstone, dolomite and quartzite, dating from the Neoproterozoic to the middle Cambrian, laid down in the Adelaide Rift Complex, the oldest part of the Adelaide Superbasin.\n\nMost of the Adelaide metropolitan area lies in the downthrown St Vincent Basin and its embayments, including the Adelaide Plains Sub-basin, and the Golden Grove, Noarlunga and Willunga Embayments. These basins contain deposits of Tertiary marine and non-marine sands and limestones, which form important aquifers.  These deposits are overlain by  Quaternary alluvial fans and piedmont slope deposits, derived from erosion of the uplands, consisting of sands, clays and gravels, interfingering to the west with transgressive Pleistocene to  Holocene marine sands and coastal sediments of the shoreline of Gulf St Vincent.\n\nUrban layout \n\nAdelaide is a planned city, designed by the first Surveyor-General of South Australia, Colonel William Light. His plan, sometimes referred to as \"Light's Vision\" (also the name of a statue of him on Montefiore Hill), arranged Adelaide in a grid, with five squares in the Adelaide city centre and a ring of parks, known as the Adelaide Parklands, surrounding it. Light's selection of the location for the city was initially unpopular with the early settlers, as well as South Australia's first governor, John Hindmarsh, due to its distance from the harbour at Port Adelaide, and the lack of fresh water there. Light successfully persisted with his choice of location against this initial opposition. Recent evidence suggests that Light worked closely with George Kingston as well as a team of men to set out Adelaide, using various templates for city plans going back to Ancient Greece, including Italian Renaissance designs and the similar layouts of the American cities Philadelphia and Savannah\u2013which, like Adelaide, follow the same layout of a central city square, four complementing city squares surrounding it and a parklands area that surrounds the city centre.\n\nThe benefits of Light's design are numerous: Adelaide has had wide multi-lane roads from its beginning, an easily navigable cardinal direction grid layout and an expansive green ring around the city centre. There are two sets of ring roads in Adelaide that have resulted from the original design. The inner ring route (A21) borders the parklands, and the outer route (A3/A13/A16/A17) completely bypasses the inner city via (in clockwise order) Grand Junction Road, Hampstead Road, Ascot Avenue, Portrush Road, Cross Road and South Road.\n\nSuburban expansion has to some extent outgrown Light's original plan. Numerous former outlying villages and \"country towns\", as well as the satellite city of Elizabeth, have been enveloped by its suburban sprawl. Expanding developments in the Adelaide Hills region led to the construction of the South Eastern Freeway to cope with growth, which has subsequently led to new developments and further improvements to that transport corridor. Similarly, the booming development in Adelaide's South led to the construction of the Southern Expressway.\n\nNew roads are not the only transport infrastructure developed to cope with the urban growth. The O-Bahn Busway is an example of a unique solution to Tea Tree Gully's transport woes in the 1980s. The development of the nearby suburb of Golden Grove in the late 1980s is an example of well-thought-out urban planning.\n\nIn the 1960s, a Metropolitan Adelaide Transport Study Plan was proposed to cater for the future growth of the city. The plan involved the construction of freeways, expressways and the upgrade of certain aspects of the public transport system. The then premier Steele Hall approved many parts of the plan and the government went as far as purchasing land for the project. The later Labor government elected under Don Dunstan shelved the plan, but allowed the purchased land to remain vacant, should the future need for freeways arise. In 1980, the Liberal party won government and premier David Tonkin committed his government to selling off the land acquired for the MATS plan, ensuring that even when needs changed, the construction of most MATS-proposed freeways would be impractical. Some parts of this land have been used for transport, (e.g. the O-Bahn Busway and Southern Expressway), while most has been progressively subdivided for residential use.\n\nIn 2008, the SA Government announced plans for a network of transport-oriented developments across the Adelaide metropolitan area and purchased a 10 hectare industrial site at Bowden for $52.5 million as the first of these developments. The site covers 102,478 square metres, or about 10 hectares, and is bounded by Park Terrace to the south, the Adelaide to Outer Harbour railway line to the west, Drayton Street to the north and Sixth and Seventh Streets to the east.\n\nHousing \n\nHistorically, Adelaide's suburban residential areas have been characterised by single-storey detached houses built on  blocks. A relative lack of suitable, locally-available timber for construction purposes led to the early development of a brick-making industry, as well as the use of stone, for houses and other buildings. By 1891 68% of houses were built of stone, 15% of timber, and 10% of brick, with brick also being widely used in stone houses for quoins, door and window surrounds, and chimneys and fireplaces.\n\nThere is a wide variety in the styles of these houses. Until the 1960s most of the more substantial houses were built of red brick, though many front walls were of ornamental stone. Then cream bricks became fashionable, and in the 1970s, deep red and brown bricks became popular. Until the 1970s, roofs tended to be clad with (painted) corrugated iron or tiles (cement or clay, usually red \"terracotta\"). Since then, Colorbond corrugated steel has dominated. Most roofs are pitched; flat roofs are not common. Up to the 1970s, most houses were of \"double brick\" construction on concrete footings, with timber floors laid on joists supported by \"dwarf walls\". Later houses have mainly been of \"brick veneer\" construction \u2013 structural timber or, more recently, lightweight steel frame on a concrete slab foundation, lined with Gyprock, and with an outer skin of brickwork, to cope with Adelaide's reactive soils, particularly Keswick Clay, black earth and some red-brown earth soils. The use of precast concrete panels for floor and wall construction has also increased. In addition to this, a significant factor in Adelaide's suburban history is the role of the South Australian Housing Trust.\n\nClimate \n\nAdelaide has a Mediterranean climate (K\u00f6ppen climate classification: Csa). The city has hot, dry summers and cool winters with moderate rainfall. Most precipitation falls in the winter months, leading to the suggestion that the climate be classified as a \"cold monsoon\". Rainfall is unreliable, light and infrequent throughout summer, although heavy falls can occur. In contrast, the winter has fairly reliable rainfall with June being the wettest month of the year, averaging around 80\u00a0mm. Frosts are occasional, with the most notable occurrences in 1908 and 1982. Hail is also common in winter. Adelaide is a windy city with significant wind chill in winter, which makes the temperature seem colder than it actually is. Snowfall in the metropolitan area is extremely uncommon, although light and sporadic falls in the nearby hills and at Mount Lofty occur during winter. Dewpoints in the summer typically range from. There are usually several days in summer where the temperature reaches  or above; the frequency of these temperatures has been increasing in recent years. Temperature extremes range from -0.4\u00a0\u00b0C (31.4\u00a0\u00b0F), 8 June 1982 to 47.7\u00a0\u00b0C (117.9\u00a0\u00b0F), 24 January 2019.\n\nThe average sea temperature ranges from  in August to  in February.\n\nLiveability \n\nAdelaide was consistently ranked in the world's 10 most liveable cities through the 2010s by The", "flag": 1, "segments": [[1592, 1602]], "strength": 5.5}
{"text": "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. Leading AI textbooks define the field as the study of \"intelligent agents\": any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n\nSome popular accounts use the term \"artificial intelligence\" to describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\", however, this definition is rejected by major AI researchers.\n\nAI applications include advanced web search engines (e.g., Google), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Tesla), automated decision-making and competing at the highest level in strategic game systems (such as chess and Go).\nAs machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect.  For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n\nArtificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success and renewed funding. AI research has tried and discarded many different approaches since its founding, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior. In the first decades of the 21st century, highly mathematical statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.\n\nThe various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and the ability to move and manipulate objects. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals. To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques\u2014including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, probability and economics. AI also draws upon computer science, psychology, linguistics, philosophy, and many other fields.\n\nThe field was founded on the assumption that human intelligence \"can be so precisely described that a machine can be made to simulate it\".\nThis raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction, and philosophy since antiquity.\nScience fiction and futurology have also suggested that, with its enormous potential and power, AI may become an existential risk to humanity.\n\nHistory \n\nArtificial beings with intelligence appeared as storytelling devices in antiquity,\nand have been common in fiction, as in Mary Shelley's Frankenstein or Karel \u010capek's R.U.R. These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.\n\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable act of mathematical deduction. This insight that digital computers can simulate any process of formal reasoning is known as the Church\u2013Turing thesis.\n\nThe Church-Turing thesis, along with concurrent discoveries in neurobiology, information theory and cybernetics, led researchers to consider the possibility of building an electronic brain.\nThe first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete \"artificial neurons\".\n\nWhen access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to step-by-step symbol manipulation, known as Symbolic AI or GOFAI. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.\n\nThe field of AI research was born at a workshop at Dartmouth College in 1956.\nThe attendees became the founders and leaders of AI research.\nThey and their students produced programs that the press described as \"astonishing\":\ncomputers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.\nBy the middle of the 1960s, research in the U. nest boxes by a small baby penguin. TheS. was heavily funded by the Department of Defense\nand laboratories had been established around the world.\n\nResearchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.\nHerbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".\nMarvin Minsky agreed, writing, \"within a generation\u00a0... the problem of creating 'artificial intelligence' will substantially be solved\".\n\nThey failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill\nand ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an \"AI winter\", a period when obtaining funding for AI projects was difficult.\n\nIn the early 1980s, AI research was revived by the commercial success of expert systems,\na form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research.\nHowever, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.\n\nMany researchers began to doubt that the symbolic approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches to specific AI problems. Robotics researchers, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move, survive, and learn their environment.\nInterest in neural networks and \"connectionism\" was revived by Geoffrey Hinton, David Rumelhart and others in the middle of the 1980s.\nSoft computing tools were developed in the 80s, such as neural networks, fuzzy systems, Grey system theory, evolutionary computation and many tools drawn from statistics or mathematical optimization.\n\nAI gradually restored its reputation in the late 1990s and early 21st century by finding specific solutions to specific problems. The narrow focus allowed researchers to produce verifiable results, exploit more  mathematical methods, and collaborate with other fields (such as statistics, economics and mathematics).\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".\n\nFaster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.\nAccording to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects. He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets. In a 2017 survey, one in five companies reported they had \"incorporated AI in some offerings or processes\". The amount of research into AI (measured by total publications) increased by 50% in the years 2015\u20132019.\n\nNumerous academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Much of current research involves statistical AI, which is overwhelmingly used to solve specific problems, even highly successful techniques such as deep learning. This concern has led to the subfield artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.\n\nGoals \nThe general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.\n\nReasoning, problem solving \n\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.\nBy the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.\n\nMany of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a \"combinatorial explosion\": they became exponentially slower as the problems grew larger.\nEven humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.\n\nKnowledge representation \n\nKnowledge representation and knowledge engineering\nallow AI programs to answer questions intelligently and make deductions about real world facts.\n\nA representation of \"what exists\" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them.\nThe most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge and act as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). A truly intelligent program would also need access to commonsense knowledge; the set of facts that an average person knows. The semantics of an ontology is typically represented in a description logic, such as the Web Ontology Language.\n\nAI research has developed tools to represent specific domains, such as: objects, properties, categories and relations between objects;\nsituations, events, states and time;\ncauses and effects;\nknowledge about knowledge (what we know about what other people know);.\ndefault reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);\n\nas well as other domains. Among the most difficult problems in AI are: the breadth of commonsense knowledge (the number of atomic facts that the average person knows is enormous);\nand the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).\n\nFormal knowledge representations are used in content-based indexing and retrieval,\nscene interpretation,\nclinical decision support,\nknowledge discovery (mining \"interesting\" and actionable inferences from large databases),\nand other areas.\n\nPlanning \n\nAn intelligent agent that can plan makes a representation of the state of the world, makes predictions about how their actions will change it and makes choices that maximize the utility (or \"value\") of the available choices.\nIn classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions.\nHowever, if the agent is not the only actor, then it requires that the agent reason under uncertainty, and continuously re-assess its environment and adapt.\nMulti-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.\n\nLearning \n\nMachine learning (ML), a fundamental concept of AI research since the field's inception,\nis the study of computer algorithms that improve automatically through experience.\n\nUnsupervised learning finds patterns in a stream of input. Supervised learning requires a human to label the input data first, and comes in two main varieties: classification and numerical regression. Classification is used to determine what category something belongs in\u2014the program sees a number of examples of things from several categories and will learn to classify new inputs. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. Both classifiers and regression learners can be viewed as \"function approximators\" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, \"spam\" or \"not spam\".\nIn reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent classifies its responses to form a strategy for operating in its problem space.\nTransfer learning is when knowledge gained from one problem is applied to a new problem.\n\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n\nNatural language processing \n\nNatural language processing (NLP)\nallows machines to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of NLP include information retrieval, question answering and machine translation.\n\nSymbolic AI used formal syntax to translate the deep structure of sentences into logic. This failed to produce useful applications, due to the intractability of logic and the breadth of commonsense knowledge. Modern statistical techniques include co-occurrence frequencies (how often one word appears near another), \"Keyword spotting\" (searching for a particular word to retrieve information), transformer-based deep learning (which finds patterns in text), and others. They have achieved acceptable accuracy at the page or paragraph level, and, by 2019, could generate coherent text.\n\nPerception \n\nMachine perception\nis the ability to use input from sensors (such as cameras, microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition,\nfacial recognition, and object recognition.\nComputer vision is the ability to analyze visual input.\n\nMotion and manipulation \n\nAI is heavily used in robotics.\nLocalization is how a robot knows its location and maps its environment. When given a small, static, and visible environment, this is easy; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge.\nMotion planning is the process of breaking down a movement task into \"primitives\" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. Robots can learn from experience how to move efficiently despite the presence of friction and gear slippage.\n\nSocial intelligence \n\nAffective computing is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human feeling, emotion and mood. \nFor example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.\nHowever, this tends to give na\u00efve users an unrealistic conception of how intelligent existing computer agents actually are.\nModerate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.\n\nGeneral intelligence \n\nA machine with general intelligence can solve a wide variety of problems with a breadth and versatility similar to human intelligence. There are several competing ideas about how to develop artificial general intelligence. Hans Moravec and Marvin Minsky argue that work in different individual domains can be incorporated into an advanced multi-agent system or cognitive architecture with general intelligence.\nPedro Domingos hopes that there is a conceptually straightforward, but mathematically difficult, \"master algorithm\" that could lead to AGI.\nOthers believe that anthropomorphic features like an artificial brain\nor simulated child development\nwill someday reach a critical point where general intelligence emerges.\n\nTools\n\nSearch and optimization \n\nMany problems in AI can be solved theoretically by intelligently searching through many possible solutions:\nReasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule.\nPlanning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.\nRobotics algorithms for moving limbs and grasping objects use local searches in configuration space.\n\nSimple exhaustive searches\nare rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use \"heuristics\" or \"rules of thumb\" that prioritize choices in favor of those more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies, heuristics can also serve to eliminate some choices unlikely to lead to a goal (called \"pruning the search tree\"). Heuristics supply the program with a \"best guess\" for the path on which the solution lies.\nHeuristics limit the search for solutions into a smaller sample size.\n\nA very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are simulated annealing, beam search and random optimization.\nEvolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Classic evolutionary algorithms include genetic algorithms, gene expression programming, and genetic programming.\nAlternatively, distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).\n\nLogic \n\nLogic\nis used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the satplan algorithm uses logic for planning\nand inductive logic programming is a method for learning.\n\nSeveral different forms of logic are used in AI research. Propositional logic involves truth functions such as \"or\" and \"not\". First-order logic\nadds quantifiers and predicates, and can express facts about objects, their properties, and their relations with each other. Fuzzy logic assigns a \"degree of truth\" (between 0 and 1) to vague statements such as \"Alice is old\" (or rich, or tall, or hungry), that are too linguistically imprecise to be completely true or false.\nDefault logics, non-monotonic logics and circumscription are forms of logic designed to help with default reasoning and the qualification problem.\nSeveral extensions of logic have been designed to handle specific domains of knowledge, such as: description logics;\nsituation calculus, event calculus and fluent calculus (for representing events and time);\ncausal calculus;\nbelief calculus (belief revision); and modal logics.\nLogics to model contradictory or inconsistent statements arising in multi-agent systems have also been designed, such as paraconsistent logics.\n\nProbabilistic methods for uncertain reasoning \n\nMany problems in AI (in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from probability theory and economics.\nBayesian networks\nare a very general tool that can be used for various problems: reasoning (using the Bayesian inference algorithm),\nlearning (using the expectation-maximization algorithm),\nplanning (using decision networks) and perception (using dynamic Bayesian networks).\nProbabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\n\nA key concept from the science of economics is \"utility\": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,\nand information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\n\nClassifiers and statistical learning methods \n\nThe simplest AI applications can be divided into two types: classifiers (\"if shiny then diamond\") and controllers (\"if diamond then pick up\"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. Classifiers are functions that use pattern matching to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class is a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.\n\nA classifier can be trained in various ways; there are many statistical and machine learning approaches.\nThe decision tree is the simplest and most widely used symbolic machine learning algorithm.\nK-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s.\nKernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.\nNeural networks are also used for classification.\n\nClassifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, distribution of samples across classes, the dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as \"naive Bayes\" on most practical data sets.\n\nArtificial neural networks \n\nNeural networks\nwere inspired by the architecture of neurons in the human brain. A simple \"neuron\" N accepts input from other neurons, each of which, when activated (or \"fired\"), casts a weighted \"vote\" for or against whether neuron N should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed \"fire together, wire together\") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes.\n\nModern neural networks model complex relationships between inputs and outputs or and find patterns in data. They can learn continuous functions and even", "flag": 1, "segments": [[962, 972]], "strength": 5.5}
{"text": "Aphrodite ( ; ;,, ) is an ancient Greek goddess associated with love, lust, beauty, pleasure, passion and procreation. She was syncretized with the Roman goddess. Aphrodite's major symbols include myrtles, roses, doves, sparrows, and swans. The cult of Aphrodite was largely derived from that of the Phoenician goddess Astarte, a cognate of the East Semitic goddess Ishtar, whose cult was based on the Sumerian cult of Inanna. Aphrodite's main cult centers were Cythera, Cyprus, Corinth, and Athens. Her main festival was the Aphrodisia, which was celebrated annually in midsummer. In Laconia, Aphrodite was worshipped as a warrior goddess. She was also the patron goddess of prostitutes, an association which led early scholars to propose the concept of \"sacred prostitution\" in Greco-Roman culture, an idea which is now generally seen as erroneous.\n\nIn Hesiod's Theogony, Aphrodite is born off the coast of Cythera from the foam (, ) produced by Uranus's genitals, which his son Cronus had severed and thrown into the sea. In Homer's Iliad, however, she is the daughter of Zeus and Dione. Plato, in his Symposium 180e, asserts that these two origins actually belong to separate entities: Aphrodite Ourania (a transcendent, \"Heavenly\" Aphrodite) and Aphrodite Pandemos (Aphrodite common to \"all the people\"). Aphrodite had many other epithets, each emphasizing a different aspect of the same goddess, or used by a different local cult. Thus she was also known as Cytherea (Lady of Cythera) and Cypris (Lady of Cyprus), because both locations claimed to be the place of her birth.\n\nIn Greek mythology, Aphrodite was married to Hephaestus, the god of fire, blacksmiths and metalworking. Aphrodite was frequently unfaithful to him and had many lovers; in the Odyssey, she is caught in the act of adultery with Ares, the god of war. In the First Homeric Hymn to Aphrodite, she seduces the mortal shepherd Anchises. Aphrodite was also the surrogate mother and lover of the mortal shepherd Adonis, who was killed by a wild boar. Along with Athena and Hera, Aphrodite was one of the three goddesses whose feud resulted in the beginning of the Trojan War and she plays a major role throughout the Iliad. Aphrodite has been featured in Western art as a symbol of female beauty and has appeared in numerous works of Western literature. She is a major deity in modern Neopagan religions, including the Church of Aphrodite, Wicca, and Hellenismos.\n\nEtymology \nHesiod derives Aphrodite from  () \"sea-foam\", interpreting the name as \"risen from the foam\", but most modern scholars regard this as a spurious folk etymology. Early modern scholars of classical mythology attempted to argue that Aphrodite's name was of Greek or Indo-European origin, but these efforts have now been mostly abandoned. Aphrodite's name is generally accepted to be of non-Greek, probably Semitic, origin, but its exact derivation cannot be determined.\n\nScholars in the late nineteenth and early twentieth centuries, accepting Hesiod's \"foam\" etymology as genuine, analyzed the second part of Aphrodite's name as *-od\u00edt\u0113 \"wanderer\" or *-d\u00edt\u0113 \"bright\". More recently, Michael Janda, also accepting Hesiod's etymology, has argued in favor of the latter of these interpretations and claims the story of a birth from the foam as an Indo-European mytheme. Similarly, Krzysztof Tomasz Witczak proposes an Indo-European compound  \"very\" and  \"to shine\", also referring to Eos, and Daniel K\u00f6lligan has interpreted her name as \"shining up from the mist/foam\". Other scholars have argued that these hypotheses are unlikely since Aphrodite's attributes are entirely different from those of both Eos and the Vedic deity Ushas.\n\nA number of improbable non-Greek etymologies have also been suggested. One Semitic etymology compares Aphrodite to the Assyrian bar\u012br\u012btu, the name of a female demon that appears in Middle Babylonian and Late Babylonian texts. Hammarstr\u00f6m looks to Etruscan, comparing (e)pr\u03b8ni \"lord\", an Etruscan honorific loaned into Greek as \u03c0\u03c1\u03cd\u03c4\u03b1\u03bd\u03b9\u03c2. This would make the theonym in origin an honorific, \"the lady\". Most scholars reject this etymology as implausible, especially since Aphrodite actually appears in Etruscan in the borrowed form Apru (from Greek, clipped form of Aphrodite). The medieval Etymologicum Magnum (c. 1150) offers a highly contrived etymology, deriving Aphrodite from the compound habrod\u00edaitos (), \"she who lives delicately\", from habr\u00f3s and d\u00edaita. The alteration from b to ph is explained as a \"familiar\" characteristic of Greek \"obvious from the Macedonians\".\n\nOrigins\n\nNear Eastern love goddess\n\nThe cult of Aphrodite in Greece was imported from, or at least influenced by, the cult of Astarte in Phoenicia, which, in turn, was influenced by the cult of the Mesopotamian goddess known as \"Ishtar\" to the East Semitic peoples and as \"Inanna\" to the Sumerians. Pausanias states that the first to establish a cult of Aphrodite were the Assyrians, followed by the Paphians of Cyprus and then the Phoenicians at Ascalon. The Phoenicians, in turn, taught her worship to the people of Cythera.\n\nAphrodite took on Inanna-Ishtar's associations with sexuality and procreation. Furthermore, she was known as Ourania (\u039f\u1f50\u03c1\u03b1\u03bd\u03af\u03b1), which means \"heavenly\", a title corresponding to Inanna's role as the Queen of Heaven. Early artistic and literary portrayals of Aphrodite are extremely similar on Inanna-Ishtar. Like Inanna-Ishtar, Aphrodite was also a warrior goddess; the second-century AD Greek geographer Pausanias records that, in Sparta, Aphrodite was worshipped as Aphrodite Areia, which means \"warlike\". He also mentions that Aphrodite's most ancient cult statues in Sparta and on Cythera showed her bearing arms. Modern scholars note that Aphrodite's warrior-goddess aspects appear in the oldest strata of her worship and see it as an indication of her Near Eastern origins.\n\nNineteenth century classical scholars had a general aversion to the idea that ancient Greek religion was at all influenced by the cultures of the Near East, but, even Friedrich Gottlieb Welcker, who argued that Near Eastern influence on Greek culture was largely confined to material culture, admitted that Aphrodite was clearly of Phoenician origin. The significant influence of Near Eastern culture on early Greek religion in general, and on the cult of Aphrodite in particular, is now widely recognized as dating to a period of orientalization during the eighth century BC, when archaic Greece was on the fringes of the Neo-Assyrian Empire.\n\nIndo-European dawn goddess\nSome early comparative mythologists opposed to the idea of a Near Eastern origin argued that Aphrodite originated as an aspect of the Greek dawn goddess Eos and that she was therefore ultimately derived from the Proto-Indo-European dawn goddess *Ha\u00e9us\u014ds (properly Greek Eos, Latin Aurora, Sanskrit Ushas). Most modern scholars have now rejected the notion of a purely Indo-European Aphrodite, but it is possible that Aphrodite, originally a Semitic deity, may have been influenced by the Indo-European dawn goddess. Both Aphrodite and Eos were known for their erotic beauty and aggressive sexuality and both had relationships with mortal lovers. Both goddesses were associated with the colors red, white, and gold. Michael Janda etymologizes Aphrodite's name as an epithet of Eos meaning \"she who rises from the foam [of the ocean]\" and points to Hesiod's Theogony account of Aphrodite's birth as an archaic reflex of Indo-European myth. Aphrodite rising out of the waters after Cronus defeats Uranus as a mytheme would then be directly cognate to the Rigvedic myth of Indra defeating Vrtra, liberating Ushas. Another key similarity between Aphrodite and the Indo-European dawn goddess is her close kinship to the Greek sky deity, since both of the main claimants to her paternity (Zeus and Uranus) are sky deities.\n\nForms and epithets\n\nAphrodite's most common cultic epithet was Ourania, meaning \"heavenly\", but this epithet almost never occurs in literary texts, indicating a purely cultic significance. Another common name for Aphrodite was Pandemos (\"For All the Folk\"). In her role as Aphrodite Pandemos, Aphrodite was associated with Peith\u014d (), meaning \"persuasion\", and could be prayed to for aid in seduction. The character of Pausanias in Plato's Symposium, takes differing cult-practices associated with different epithets of the goddess to claim that Ourania and Pandemos are, in fact, separate goddesses. He asserts that Aphrodite Ourania is the celestial Aphrodite, born from the sea foam after Cronus castrated Uranus, and the older of the two goddesses. According to the Symposium, Aphrodite Ourania is the inspiration of male homosexual desire, specifically the ephebic eros, and pederasty. Aphrodite Pandemos, by contrast, is the younger of the two goddesses: the common Aphrodite, born from the union of Zeus and Dione, and the inspiration of heterosexual desire and sexual promiscuity, the \"lesser\" of the two loves. Paphian (\u03a0\u03b1\u03c6\u03af\u03b1), was one of her epithets, after the Paphos in Cyprus where she had emerged from the sea at her birth.\n\nAmong the Neoplatonists and, later, their Christian interpreters, Ourania is associated with spiritual love, and Pandemos with physical love (desire). A representation of Ourania with her foot resting on a tortoise came to be seen as emblematic of discretion in conjugal love; it was the subject of a chryselephantine sculpture by Phidias for Elis, known only from a parenthetical comment by the geographer Pausanias.\n\nOne of Aphrodite's most common literary epithets is Philommeid\u1e17s (), which means \"smile-loving\", but is sometimes mistranslated as \"laughter-loving\". This epithet occurs throughout both of the Homeric epics and the First Homeric Hymn to Aphrodite. Hesiod references it once in his Theogony in the context of Aphrodite's birth, but interprets it as \"genital-loving\" rather than \"smile-loving\". Monica Cyrino notes that the epithet may relate to the fact that, in many artistic depictions of Aphrodite, she is shown smiling. Other common literary epithets are Cypris and Cythereia, which derive from her associations with the islands of Cyprus and Cythera respectively.\n\nOn Cyprus, Aphrodite was sometimes called Eleemon (\"the merciful\"). In Athens, she was known as Aphrodite en kopois (\"Aphrodite of the Gardens\"). At Cape Colias, a town along the Attic coast, she was venerated as Genetyllis \"Mother\". The Spartans worshipped her as Potnia \"Mistress\", Enoplios \"Armed\", Morpho \"Shapely\", Ambologera \"She who Postpones Old Age\". Across the Greek world, she was known under epithets such as Melainis \"Black One\", Skotia \"Dark One\", Androphonos \"Killer of Men\", Anosia \"Unholy\", and Tymborychos \"Gravedigger\", all of which indicate her darker, more violent nature.\n\nA male version of Aphrodite known as Aphroditus was worshipped in the city the federal government\u2019s plans for the country of Amathus on Cyprus. Aphroditus was depicted with the figure and dress of a woman, but had a beard, and was shown lifting his dress to reveal an erect phallus. This gesture was believed to be an apotropaic symbol, and was thought to convey good fortune upon the viewer. Eventually, the popularity of Aphroditus waned as the mainstream, fully feminine version of Aphrodite became more popular, but traces of his cult are preserved in the later legends of Hermaphroditus.\n\nWorship\n\nClassical period\n\nAphrodite's main festival, the Aphrodisia, was celebrated across Greece, but particularly in Athens and Corinth. In Athens, the Aphrodisia was celebrated on the fourth day of the month of Hekatombaion in honor of Aphrodite's role in the unification of Attica. During this festival, the priests of Aphrodite would purify the temple of Aphrodite Pandemos on the southwestern slope of the Acropolis with the blood of a sacrificed dove. Next, the altars would be anointed and the cult statues of Aphrodite Pandemos and Peitho would be escorted in a majestic procession to a place where they would be ritually bathed. Aphrodite was also honored in Athens as part of the Arrhephoria festival. The fourth day of every month was sacred to Aphrodite.\n\nPausanias records that, in Sparta, Aphrodite was worshipped as Aphrodite Areia, which means \"warlike\". This epithet stresses Aphrodite's connections to Ares, with whom she had extramarital relations. Pausanias also records that, in Sparta and on Cythera, a number of extremely ancient cult statues of Aphrodite portrayed her bearing arms. Other cult statues showed her bound in chains.\n\nAphrodite was the patron goddess of prostitutes of all varieties, ranging from pornai (cheap street prostitutes typically owned as slaves by wealthy pimps) to hetairai (expensive, well-educated hired companions, who were usually self-employed and sometimes provided sex to their customers). The city of Corinth was renowned throughout the ancient world for its many hetairai, who had a widespread reputation for being among the most skilled, but also the most expensive, prostitutes in the Greek world. Corinth also had a major temple to Aphrodite located on the Acrocorinth and was one of the main centers of her cult. Records of numerous dedications to Aphrodite made by successful courtesans have survived in poems and in pottery inscriptions. References to Aphrodite in association with prostitution are found in Corinth as well as on the islands of Cyprus, Cythera, and Sicily. Aphrodite's Mesopotamian precursor Inanna-Ishtar was also closely associated with prostitution.\n\nScholars in the nineteenth and twentieth centuries believed that the cult of Aphrodite may have involved ritual prostitution, an assumption based on ambiguous passages in certain ancient texts, particularly a fragment of a skolion by the Boeotian poet Pindar, which mentions prostitutes in Corinth in association with Aphrodite. Modern scholars now dismiss the notion of ritual prostitution in Greece as a \"historiographic myth\" with no factual basis.\n\nHellenistic and Roman periods\n\nDuring the Hellenistic period, the Greeks identified Aphrodite with the ancient Egyptian goddesses Hathor and Isis. Aphrodite was the patron goddess of the Lagid queens and Queen Arsinoe II was identified as her mortal incarnation. Aphrodite was worshipped in Alexandria and had numerous temples in and around the city. Arsinoe II introduced the cult of Adonis to Alexandria and many of the women there partook in it. The Tessarakonteres, a gigantic catamaran galley designed by Archimedes for Ptolemy IV Philopator, had a circular temple to Aphrodite on it with a marble statue of the goddess herself. In the second century BC, Ptolemy VIII Physcon and his wives Cleopatra II and Cleopatra III dedicated a temple to Aphrodite Hathor at Philae. Statuettes of Aphrodite for personal devotion became common in Egypt starting in the early Ptolemaic times and extending until long after Egypt became a Roman province.\n\nThe ancient Romans identified Aphrodite with their goddess Venus, who was originally a goddess of agricultural fertility, vegetation, and springtime. According to the Roman historian Livy, Aphrodite and Venus were officially identified in the third century BC when the cult of Venus Erycina was introduced to Rome from the Greek sanctuary of Aphrodite on Mount Eryx in Sicily. After this point, Romans adopted Aphrodite's iconography and myths and applied them to Venus. Because Aphrodite was the mother of the Trojan hero Aeneas in Greek mythology and Roman tradition claimed Aeneas as the founder of Rome, Venus became venerated as Venus Genetrix, the mother of the entire Roman nation. Julius Caesar claimed to be directly descended from Aeneas's son Iulus and became a strong proponent of the cult of Venus. This precedent was later followed by his nephew Augustus and the later emperors claiming succession from him.\n\nThis syncretism greatly impacted Greek worship of Aphrodite. During the Roman era, the cults of Aphrodite in many Greek cities began to emphasize her relationship with Troy and Aeneas. They also began to adopt distinctively Roman elements, portraying Aphrodite as more maternal, more militaristic, and more concerned with administrative bureaucracy. She was claimed as a divine guardian by many political magistrates. Appearances of Aphrodite in Greek literature also vastly proliferated, usually showing Aphrodite in a characteristically Roman manner.\n\nMythology\n\nBirth \n\nAphrodite is usually said to have been born near her chief center of worship, Paphos, on the island of Cyprus, which is why she is sometimes called \"Cyprian\", especially in the poetic works of Sappho. The Sanctuary of Aphrodite Paphia, marking her birthplace, was a place of pilgrimage in the ancient world for centuries. Other versions of her myth have her born near the island of Cythera, hence another of her names, \"Cytherea\". Cythera was a stopping place for trade and culture between Crete and the Peloponesus, so these stories may preserve traces of the migration of Aphrodite's cult from the Middle East to mainland Greece.\n\nAccording to the version of her birth recounted by Hesiod in his Theogony, Cronus severed Uranus' genitals and threw them behind him into the sea. The foam from his genitals gave rise to Aphrodite (hence her name, which Hesiod interprets as \"foam-arisen\"), while the Giants, the Erinyes (furies), and the Meliae emerged from the drops of his blood. Hesiod states that the genitals \"were carried over the sea a long time, and white foam arose from the immortal flesh; with it a girl grew.\" Hesiod's account of Aphrodite's birth following Uranus's castration is probably derived from The Song of Kumarbi, an ancient Hittite epic poem in which the god Kumarbi overthrows his father Anu, the god of the sky, and bites off his genitals, causing him to become pregnant and give birth to Anu's children, which include Ishtar and her brother Teshub, the Hittite storm god.\n\nIn the Iliad, Aphrodite is described as the daughter of Zeus and Dione. Dione's name appears to be a feminine cognate to Dios and Dion, which are oblique forms of the name Zeus. Zeus and Dione shared a cult at Dodona in northwestern Greece. In Theogony, Hesiod describes Dione as an Oceanid.\n\nMarriage\n\nAphrodite is consistently portrayed as a nubile, infinitely desirable adult, having had no childhood. She is often depicted nude. In the Iliad, Aphrodite is the apparently unmarried consort of Ares, the god of war, and the wife of Hephaestus is a different goddess named Charis. Likewise, in Hesiod's Theogony, Aphrodite is unmarried and the wife of Hephaestus is Aglaea, the youngest of the three Charites.\n\nIn Book Eight of the Odyssey, however, the blind singer Demodocus describes Aphrodite as the wife of Hephaestus and tells how she committed adultery with Ares during the Trojan War. The sun-god Helios saw Aphrodite and Ares having sex in Hephaestus's bed and warned Hephaestus, who fashioned a net of gold. The next time Ares and Aphrodite had sex together, the net trapped them both. Hephaestus brought all the gods into the bedchamber to laugh at the captured adulterers, but Apollo, Hermes, and Poseidon had sympathy for Ares and Poseidon agreed to pay Hephaestus for Ares's release. Humiliated, Aphrodite returned to Cyprus, where she was attended by the Charites. This narrative probably originated as a Greek folk tale, originally independent of the Odyssey.\n\nLater stories were invented to explain Aphrodite's marriage to Hephaestus. In the most famous story, Zeus hastily married Aphrodite to Hephaestus in order to prevent the other gods from fighting over her. In another version of the myth, Hephaestus gave his mother Hera a golden throne, but when she sat on it, she became trapped and he refused to let her go until she agreed to give him Aphrodite's hand in marriage. Hephaestus was overjoyed to be married to the goddess of beauty, and forged her beautiful jewelry, including a strophion () known as the  (), a saltire-shaped undergarment (usually translated as \"girdle\"), which accentuated her breasts and made her even more irresistible to men. Such strophia were commonly used in depictions of the Near Eastern goddesses Ishtar and Atargatis.\n\nAttendants\nAphrodite is almost always accompanied by Eros, the god of lust and sexual desire. In his Theogony, Hesiod describes Eros as one of the four original primeval forces born at the beginning of time, but, after the birth of Aphrodite from the sea foam, he is joined by Himeros and, together, they become Aphrodite's constant companions. In early Greek art, Eros and Himeros are both shown as idealized handsome youths with wings. The Greek lyric poets regarded the power of Eros and Himeros as dangerous, compulsive, and impossible for anyone to resist. In modern times, Eros is often seen as Aphrodite's son, but this is actually a comparatively late innovation. A scholion on Theocritus's Idylls remarks that the sixth-century BC poet Sappho had described Eros as the son of Aph", "flag": 1, "segments": [[2684, 2694]], "strength": 5.5}
{"text": "Aleister Crowley (; born Edward Alexander Crowley; 12 October 1875 \u2013 1 December 1947) was an English occultist, ceremonial magician, poet, painter, novelist, and mountaineer. He founded the religion of Thelema, identifying himself as the prophet entrusted with guiding humanity into the \u00c6on of Horus in the early 20th century. A prolific writer, he published widely over the course of his life.\n\nBorn to a wealthy family in Royal Leamington Spa, Warwickshire, Crowley rejected his parents' fundamentalist Christian Plymouth Brethren faith to pursue an interest in Western esotericism. He was educated at Trinity College at the University of Cambridge, where he focused his attentions on mountaineering and poetry, resulting in several publications. Some biographers allege that here he was recruited into a British intelligence agency, further suggesting that he remained a spy throughout his life. In 1898, he joined the esoteric Hermetic Order of the Golden Dawn, where he was trained in ceremonial magic by Samuel Liddell MacGregor Mathers and Allan Bennett. Moving to Boleskine House by Loch Ness in Scotland, he went mountaineering in Mexico with Oscar Eckenstein, before studying Hindu and Buddhist practices in India. He married Rose Edith Kelly and in 1904 they honeymooned in Cairo, Egypt, where Crowley claimed to have been contacted by a supernatural entity named Aiwass, who provided him with The Book of the Law, a sacred text that served as the basis for Thelema. Announcing the start of the \u00c6on of Horus, The Book declared that its followers should \"Do what thou wilt\" and seek to align themselves with their True Will through the practice of magick.\n\nAfter an unsuccessful attempt to climb Kanchenjunga and a visit to India and China, Crowley returned to Britain, where he attracted attention as a prolific author of poetry, novels, and occult literature. In 1907, he and George Cecil Jones co-founded an esoteric order, the A\u2234A\u2234, through which they propagated Thelema. After spending time in Algeria, in 1912 he was initiated into another esoteric order, the German-based Ordo Templi Orientis (O.T.O.), rising to become the leader of its British branch, which he reformulated in accordance with his Thelemite beliefs. Through the O.T.O., Thelemite groups were established in Britain, Australia, and North America. Crowley spent the First World War in the United States, where he took up painting and campaigned for the German war effort against Britain, later revealing that he had infiltrated the pro-German movement to assist the British intelligence services. In 1920, he established the Abbey of Thelema, a religious commune in Cefal\u00f9, Sicily where he lived with various followers. His libertine lifestyle led to denunciations in the British press, and the Italian government evicted him in 1923. He divided the following two decades between France, Germany, and England, and continued to promote Thelema until his death.\n\nCrowley gained widespread notoriety during his lifetime, being a recreational drug user, bisexual, and an individualist social critic. Crowley has remained a highly influential figure over Western esotericism and the counterculture of the 1960s, and continues to be considered a prophet in Thelema. He is the subject of various biographies and academic studies.\n\nEarly life\n\nYouth: 1875\u20131894\n\nCrowley was born Edward Alexander Crowley at 30 Clarendon Square in Royal Leamington Spa, Warwickshire, on 12 October 1875. His father, Edward Crowley (1829\u20131887), was trained as an engineer, but his share in a lucrative family brewing business, Crowley's Alton Ales, had allowed him to retire before his son was born. His mother, Emily Bertha Bishop (1848\u20131917), came from a Devonshire-Somerset family and had a strained relationship with her son; she described him as \"the Beast\", a name that he revelled in. The couple had been married at London's Kensington Registry Office in November 1874, and were evangelical Christians. Crowley's father had been born a Quaker, but had converted to the Exclusive Brethren, a faction of a Christian fundamentalist group known as the Plymouth Brethren; Emily likewise converted upon marriage. Crowley's father was particularly devout, spending his time as a travelling preacher for the sect and reading a chapter from the Bible to his wife and son after breakfast every day. Following the death of their baby daughter in 1880, in 1881 the Crowleys moved to Redhill, Surrey. At the age of 8, Crowley was sent to H.T. Habershon's evangelical Christian boarding school in Hastings, and then to Ebor preparatory school in Cambridge, run by the Reverend Henry d'Arcy Champney, whom Crowley considered a sadist.\n\nIn March 1887, when Crowley was 11, his father died of tongue cancer. Crowley described this as a turning point in his life, and he always maintained an admiration of his father, describing him as \"my hero and my friend\". Inheriting a third of his father's wealth, he began misbehaving at school and was harshly punished by Champney; Crowley's family removed him from the school when he developed albuminuria. He then attended Malvern College and Tonbridge School, both of which he despised and left after a few terms. He became increasingly sceptical regarding Christianity, pointing out inconsistencies in the Bible to his religious teachers, and went against the Christian morality of his upbringing by smoking, masturbating, and having sex with prostitutes from whom he contracted gonorrhea. Sent to live with a Brethren tutor in Eastbourne, he undertook chemistry courses at Eastbourne College. Crowley developed interests in chess, poetry, and mountain climbing, and in 1894 climbed Beachy Head before visiting the Alps and joining the Scottish Mountaineering Club. The following year he returned to the Bernese Alps, climbing the Eiger, Trift, Jungfrau, M\u00f6nch, and Wetterhorn.\n\nCambridge University: 1895\u20131898\nHaving adopted the name of Aleister over Edward, in October 1895 Crowley began a three-year course at Trinity College, Cambridge, where he was entered for the Moral Science Tripos studying philosophy. With approval from his personal tutor, he changed to English literature, which was not then part of the curriculum offered. Crowley spent much of his time at university engaged in his pastimes, becoming president of the chess club and practising the game for two hours a day; he briefly considered a professional career as a chess player. Crowley also embraced his love of literature and poetry, particularly the works of Richard Francis Burton and Percy Bysshe Shelley. Many of his own poems appeared in student publications such as The Granta, Cambridge Magazine, and Cantab. He continued his mountaineering, going on holiday to the Alps to climb every year from 1894 to 1898, often with his friend Oscar Eckenstein, and in 1897 he made the first ascent of the M\u00f6nch without a guide. These feats led to his recognition in the Alpine mountaineering community.\n\nCrowley had his first significant mystical experience while on holiday in Stockholm in December 1896. Several biographers, including Lawrence Sutin, Richard Kaczynski, and Tobias Churton, believed that this was the result of Crowley's first same-sex sexual experience so much is made to give one a picture of, which enabled him to recognize his bisexuality. At Cambridge, Crowley maintained a vigorous sex life with women\u2014largely with female prostitutes, from one of whom he caught syphilis\u2014but eventually he took part in same-sex activities, despite their illegality. In October 1897, Crowley met Herbert Charles Pollitt, president of the Cambridge University Footlights Dramatic Club, and the two entered into a relationship. They broke apart because Pollitt did not share Crowley's increasing interest in Western esotericism, a break-up that Crowley would regret for many years.\n\nIn 1897, Crowley travelled to Saint Petersburg in Russia, later saying that he was trying to learn Russian as he was considering a future diplomatic career there. In October 1897, a brief illness triggered considerations of mortality and \"the futility of all human endeavour\", and Crowley abandoned all thoughts of a diplomatic career in favour of pursuing an interest in the occult. \n\nIn March 1898, he obtained A.E. Waite's The Book of Black Magic and of Pacts, and then Karl von Eckartshausen's The Cloud Upon the Sanctuary, furthering his occult interests. That same year, Crowley privately published 100 copies of his poem Aceldama: A Place to Bury Strangers In, but it was not a particular success. Aceldama was issued by Leonard Smithers.\nThat same year, Crowley published a string of other poems, including White Stains, a Decadent collection of erotic poetry that was printed abroad lest its publication be prohibited by the British authorities. In July 1898, he left Cambridge, not having taken any degree at all despite a \"first class\" showing in his 1897 exams and consistent \"second class honours\" results before that.\n\nThe Golden Dawn: 1898\u201399\n\nIn August 1898, Crowley was in Zermatt, Switzerland, where he met the chemist Julian L. Baker, and the two began discussing their common interest in alchemy. Back in London, Baker introduced Crowley to George Cecil Jones, Baker's brother-in-law and a fellow member of the occult society known as the Hermetic Order of the Golden Dawn, which had been founded in 1888. Crowley was initiated into the Outer Order of the Golden Dawn on 18 November 1898 by the group's leader, Samuel Liddell MacGregor Mathers. The ceremony took place in the Golden Dawn's Isis-Urania Temple held at London's Mark Masons Hall, where Crowley took the magical motto and name \"Frater Perdurabo\", which he interpreted as \"I shall endure to the end\".\n\nCrowley moved into his own luxury flat at 67\u201369 Chancery Lane and soon invited a senior Golden Dawn member, Allan Bennett, to live with him as his personal magical tutor. Bennett taught Crowley more about ceremonial magic and the ritual use of drugs, and together they performed the rituals of the Goetia, until Bennett left for South Asia to study Buddhism. In November 1899, Crowley purchased Boleskine House in Foyers on the shore of Loch Ness in Scotland. He developed a love of Scottish culture, describing himself as the \"Laird of Boleskine\", and took to wearing traditional highland dress, even during visits to London. He continued writing poetry, publishing Jezebel and Other Tragic Poems, Tales of Archais, Songs of the Spirit, Appeal to the American Republic, and Jephthah in 1898\u201399; most gained mixed reviews from literary critics, although Jephthah was considered a particular critical success.\n\nCrowley soon progressed through the lower grades of the Golden Dawn, and was ready to enter the group's inner Second Order. He was unpopular in the group; his bisexuality and libertine lifestyle had gained him a bad reputation, and he had developed feuds with some of the members, including W. B. Yeats. When the Golden Dawn's London lodge refused to initiate Crowley into the Second Order, he visited Mathers in Paris, who personally admitted him into the Adeptus Minor Grade. A schism had developed between Mathers and the London members of the Golden Dawn, who were unhappy with his autocratic rule. Acting under Mathers' orders, Crowley\u2014with the help of his mistress and fellow initiate Elaine Simpson\u2014attempted to seize the Vault of the Adepts, a temple space at 36 Blythe Road in West Kensington, from the London lodge members. When the case was taken to court, the judge ruled in favour of the London lodge, as they had paid for the space's rent, leaving both Crowley and Mathers isolated from the group.\n\nMexico, India, Paris, and marriage: 1900\u20131903\nIn 1900, Crowley travelled to Mexico via the United States, settling in Mexico City and starting a relationship with a local woman. Developing a love of the country, he continued experimenting with ceremonial magic, working with John Dee's Enochian invocations. He later claimed to have been initiated into Freemasonry while there, and he wrote a play based on Richard Wagner's Tannh\u00e4user as well as a series of poems, published as Oracles (1905). Eckenstein joined him later in 1900, and together they climbed several mountains, including Iztaccihuatl, Popocatepetl, and Colima, the latter of which they had to abandon owing to a volcanic eruption. Leaving Mexico, Crowley headed to San Francisco before sailing for Hawaii aboard the Nippon Maru. On the ship, he had a brief affair with a married woman named Mary Alice Rogers; saying he had fallen in love with her, he wrote a series of poems about the romance, published as Alice: An Adultery (1903).\n\nBriefly stopping in Japan and Hong Kong, Crowley reached Ceylon, where he met with Allan Bennett, who was there studying Shaivism. The pair spent some time in Kandy before Bennett decided to become a Buddhist monk in the Theravada tradition, travelling to Burma to do so. Crowley decided to tour India, devoting himself to the Hindu practice of R\u0101ja yoga, from which he claimed to have achieved the spiritual state of dhyana. He spent much of this time studying at the Meenakshi Temple in Madura. At this time he also wrote poetry which was published as The Sword of Song (1904). He contracted malaria, and had to recuperate from the disease in Calcutta and Rangoon. In 1902, he was joined in India by Eckenstein and several other mountaineers: Guy Knowles, H. Pfannl, V. Wesseley, and Jules Jacot-Guillarmod. Together, the Eckenstein-Crowley expedition attempted K2, which had never been climbed. On the journey, Crowley was afflicted with influenza, malaria, and snow blindness, and other expedition members were also struck with illness. They reached an altitude of  before turning back.\n\nHaving arrived in Paris in November 1902, he socialized with friend and future brother-in-law, the painter Gerald Kelly, and through him became a fixture of the Parisian arts scene. Whilst there, Crowley wrote a series of poems on the work of an acquaintance, the sculptor Auguste Rodin. These poems were later published as Rodin in Rime (1907). One of those frequenting this milieu was W. Somerset Maugham, who after briefly meeting Crowley later used him as a model for the character of Oliver Haddo in his novel The Magician (1908). He returned to Boleskine in April 1903. In August, Crowley wed Gerald's sister Rose Edith Kelly in a \"marriage of convenience\" to prevent her from entering an arranged marriage; the marriage appalled the Kelly family and damaged his friendship with Gerald. Heading on a honeymoon to Paris, Cairo, and then Ceylon, Crowley fell in love with Rose and worked to prove his affections. While on his honeymoon, he wrote her a series of love poems, published as Rosa Mundi and other Love Songs (1906), as well as authoring the religious satire Why Jesus Wept (1904).\n\nDeveloping Thelema\n\nEgypt and The Book of the Law: 1904\n\nIn February 1904, Crowley and Rose arrived in Cairo. Claiming to be a prince and princess, they rented an apartment in which Crowley set up a temple room and began invoking ancient Egyptian deities, while studying Islamic mysticism and Arabic. According to Crowley's later account, Rose regularly became delirious and informed him \"they are waiting for you.\" On 18 March, she explained that \"they\" were the god Horus, and on 20 March proclaimed that \"the Equinox of the Gods has come\". She led him to a nearby museum, where she showed him a seventh-century BCE mortuary stele known as the Stele of Ankh-ef-en-Khonsu; Crowley thought it important that the exhibit's number was 666, the Number of the Beast in Christian belief, and in later years termed the artefact the \"Stele of Revealing.\"\n\nAccording to Crowley's later statements, on 8 April he heard a disembodied voice claiming to be that of Aiwass, the messenger of Horus, or Hoor-Paar-Kraat. Crowley said that he wrote down everything the voice told him over the course of the next three days, and titled it Liber AL vel Legis or The Book of the Law. The book proclaimed that humanity was entering a new Aeon, and that Crowley would serve as its prophet. It stated that a supreme moral law was to be introduced in this Aeon, \"Do what thou wilt shall be the whole of the Law,\" and that people should learn to live in tune with their Will. This book, and the philosophy that it espoused, became the cornerstone of Crowley's religion, Thelema. Crowley said that at the time he had been unsure what to do with The Book of the Law. Often resenting it, he said that he ignored the instructions which the text commanded him to perform, which included taking the Stele of Revealing from the museum, fortifying his own island, and translating the book into all the world's languages. According to his account, he instead sent typescripts of the work to several occultists he knew, putting the manuscript away and ignoring it.\n\nKanchenjunga and China: 1905\u201306\nReturning to Boleskine, Crowley came to believe that Mathers had begun using magic against him, and the relationship between the two broke down. On 28 July 1905, Rose gave birth to Crowley's first child, a daughter named Lilith, with Crowley writing the pornographic Snowdrops from a Curate's Garden to entertain his recuperating wife. He also founded a publishing company through which to publish his poetry, naming it the Society for the Propagation of Religious Truth in parody of the Society for Promoting Christian Knowledge. Among its first publications were Crowley's Collected Works, edited by Ivor Back, an old friend of Crowley's who was both a practicing surgeon and an enthusiast of literature. His poetry often received strong reviews (either positive or negative), but never sold well. In an attempt to gain more publicity, he issued a reward of \u00a3100 for the best essay on his work. The winner of this was J. F. C. Fuller, a British Army officer and military historian, whose essay, The Star in the West (1907), heralded Crowley's poetry as some of the greatest ever written.\n\nCrowley decided to climb Kanchenjunga in the Himalayas of Nepal, widely recognized as the world's most treacherous mountain. The collaboration between Jacot-Guillarmod, Charles Adolphe Reymond, Alexis Pache, and Alcesti C. Rigo de Righi, the expedition was marred by much argument between Crowley and the others, who thought that he was reckless. They eventually mutinied against Crowley's control, with the other climbers heading back down the mountain as nightfall approached despite Crowley's warnings that it was too dangerous. Subsequently, Pache and several porters were killed in an accident, something for which Crowley was widely blamed by the mountaineering community.\n\nSpending time in Moharbhanj, where he took part in big-game hunting and wrote the homoerotic work The Scented Garden, Crowley met up with Rose and Lilith in Calcutta before being forced to leave India after non-lethally shooting two men who tried to mug him. Briefly visiting Bennett in Burma, Crowley and his family decided to tour Southern China, hiring porters and a nanny for the purpose. Crowley smoked opium throughout the journey, which took the family from Tengyueh through to Yungchang, Tali, Yunnanfu, and then Hanoi. On the way, he spent much time on spiritual and magical work, reciting the \"Bornless Ritual\", an invocation to his Holy Guardian Angel, on a daily basis.\n\nWhile Rose and Lilith returned to Europe, Crowley headed to Shanghai to meet old friend Elaine Simpson, who was fascinated by The Book of the Law; together they performed rituals in an attempt to contact Aiwass. Crowley then sailed to Japan and Canada, before continuing to New York City, where he unsuccessfully solicited support for a second expedition up Kanchenjunga. Upon arrival in Britain, Crowley learned that his daughter Lilith had died of typhoid in Rangoon, something he later blamed on Rose's increasing alcoholism. Under emotional distress, his health began to suffer, and he underwent a series of surgical operations. He began short-lived romances with actress Vera \"Lola\" Neville (n\u00e9e Snepp) and author Ada Leverson, while Rose gave birth to Crowley's second daughter, Lola Zaza, in February 1907.\n\nThe A\u2234A\u2234 and The Holy Books of Thelema: 1907\u20131909\nWith his old mentor George Cecil Jones, Crowley continued performing the Abramelin rituals at the Ashdown Park Hotel in Coulsdon, Surrey. Crowley claimed that in doing so he attained samadhi, or union with Godhead, thereby marking a turning point in his life. Making heavy use of hashish during these rituals, he wrote an essay on \"The Psychology of Hashish\" (1909) in which he championed the drug as an aid to mysticism. He also claimed to have been contacted once again by Aiwass in late October and November 1907, adding that Aiwass dictated two further texts to him, \"Liber VII\" and \"Liber Cordis Cincti Serpente\", both of which were later classified in the corpus of The Holy Books of Thelema. Crowley wrote down more Thelemic Holy Books during the last two months of the year, including \"Liber LXVI\", \"Liber Arcanorum\", \"Liber Porta Lucis, Sub Figura X\", \"Liber Tau\", \"Liber Trigrammaton\" and \"Liber DCCCXIII vel Ararita\", which he again claimed to have received from a preternatural source. Crowley stated that in June 1909, when the manuscript of The Book of the Law was rediscovered at Boleskine, he developed the opinion that Thelema represented objective truth.\n\nCrowley's inheritance was running out. Trying to earn money, he was hired by George Montagu Bennett, the Earl of Tankerville, to help protect him from witchcraft; recognizing Bennett's paranoia as being based in his cocaine addiction, Crowley took him on holiday to France and Morocco to recuperate. In 1907, he also began taking in paying students, whom he instructed in occult and magical practice. Victor Neuburg, whom Crowley met in February 1907, became his sexual partner and closest disciple; in 1908 the pair toured northern Spain before heading to Tangier, Morocco. The following year Neuburg stayed at Boleskine, where he and Crowley engaged in sadomasochism. Crowley continued to write prolifically, producing such works of poetry as Ambergris, Clouds Without Water, and Konx Om Pax, as well as his first attempt at an autobiography, The World's Tragedy. Recognizing the popularity of short horror stories, Crowley wrote his own, some of which were published, and he also published several articles in Vanity Fair, a magazine edited by his friend Frank Harris. He also wrote Liber 777, a book of magical and Qabalistic correspondences that borrowed from Mathers and Bennett.\n\nIn November 1907, Crowley and Jones decided to found an occult order to act as a successor to", "flag": 1, "segments": [[1545, 1555]], "strength": 5.5}
{"text": "The afterlife (also referred to as life after death or the world to come) is a purported existence in which the essential part of an individual's identity or their stream of consciousness continues to live after the death of their physical body. According to various ideas about the afterlife, the essential aspect of the individual that lives on after death may be some partial element, or the entire soul or spirit of an individual, which carries with it and may confer personal identity or, on the contrary nirvana. Belief in an afterlife is in contrast to the belief in oblivion after death.\n\nIn some views, this continued existence takes place in a spiritual realm, and in other popular views, the individual may be reborn into this world and begin the life cycle over again, likely with no memory of what they have done in the past. In this latter view, such rebirths and deaths may take place over and over again continuously until the individual gains entry to a spiritual realm or otherworld. Major views on the afterlife derive from religion, esotericism and metaphysics.\n\nSome belief systems, such as those in the Abrahamic tradition, hold that the dead go to a specific plane of existence after death, as determined by God, or other divine judgment, based on their actions or beliefs during life. In contrast, in systems of reincarnation, such as those in the Indian religions, the nature of the continued existence is determined directly by the actions of the individual in the ended life.\n\nDifferent metaphysical models\nTheists generally believe some afterlife awaits people when they die. Members of some generally non-theistic religions tend to believe in an afterlife but without reference to a deity. The Sadducees were an ancient Jewish sect that generally believed that there was a God but no existence after death.\n\nMany religions, whether they believe in the soul's existence in another world like Christianity, Islam, and many pagan belief systems, or reincarnation like many forms of Hinduism and Buddhism, believe that one's status in the afterlife is a consequence of one's conduct during life.\n\nReincarnation\n\nReincarnation is the philosophical or religious concept that an aspect of a living being starts a new life in a different physical body or form after each death. This concept is also known as rebirth or transmigration and is part of the Sa\u1e43s\u0101ra doctrine of cyclic existence. It is a central tenet of all major Indian religions, namely Buddhism, Hinduism, Jainism, and Sikhism. The idea of reincarnation is found in many ancient cultures, and a belief in rebirth/metempsychosis was held by historic Greek figures, such as Pythagoras, Socrates, and Plato. It is also a common belief of various ancient and modern religions such as Spiritism, Theosophy, and Eckankar. It is found as well in many tribal societies around the world, in places such as Australia, East Asia, Siberia, and South America.\n\nAlthough the majority of denominations within the Abrahamic religions of Judaism, Christianity, and Islam do not believe that individuals reincarnate, particular groups within these religions do refer to reincarnation; these groups include the mainstream historical and contemporary followers of Kabbalah, the Cathars, Alawites, the Druze, and the Rosicrucians. The historical relations between these sects and the beliefs about reincarnation that were characteristic of Neoplatonism, Orphism, Hermeticism, Manicheanism, and Gnosticism of the Roman era as well as the Indian religions have been the subject of recent scholarly research. Unity Church and its founder Charles Fillmore teach reincarnation.\n\nRosicrucians speak of a life review period occurring immediately after death and before entering the afterlife's planes of existence (before the silver cord is broken), followed by a judgment, more akin to a final review or end report over one's life.\n\nHeaven and Hell\n\nHeaven, the heavens, Seven Heavens, pure lands, Tian, Jannah, Valhalla, or the Summerland, is a common religious, cosmological, or transcendent place where beings such as gods, angels, jinn, saints, or venerated ancestors are said to originate, be enthroned, or live. According to the beliefs of some religions, heavenly beings can descend to earth or incarnate, and earthly beings can ascend to heaven in the afterlife, or in exceptional cases, enter heaven alive.\n\nHeaven is often described as a \"higher place\", the holiest place, a paradise, in contrast to hell or the underworld or the \"low places\", and universally or conditionally accessible by earthly beings according to various standards of divinity, goodness, piety, faith or other virtues or right beliefs or simply the will of God. Some believe in the possibility of a heaven on Earth in a world to come.\n\nIn Hinduism, heaven is considered as Svarga loka. There are seven positive regions the soul can go to after death and seven negative regions. After completing its stay in the respective region, the soul is subjected to rebirth in different living forms according to its karma. This cycle can be broken after a soul achieves Moksha or Nirvana. Any place of existence, either of humans, souls or deities, outside the tangible world (heaven, hell, or other) is referred to as otherworld.\n\nHell, in many religious and folkloric traditions, is a place of torment and punishment in the afterlife. Religions with a linear divine history often depict hell as an eternal destination, while religions with a cyclic history often depict a hell as an intermediary period between incarnations. Typically, these traditions locate hell in another dimension or under the earth's surface and often include entrances to hell from the land of the living. Other afterlife destinations include purgatory and limbo.\n\nTraditions that do not conceive of the afterlife as a place of punishment or reward merely describe hell as an abode of the dead, the grave, a neutral place (for example, Sheol or Hades) located under the surface of earth.\n\nAncient religions\n\nAncient Egyptian religion\n\nThe afterlife played an important role in Ancient Egyptian religion, and its belief system is one of the earliest known in recorded history. When the body died, parts of its soul known as ka (body double) and the ba (personality) would go to the Kingdom of the Dead. While the soul dwelt in the Fields of Aaru, Osiris demanded work as restitution for the protection he provided. Statues were placed in the tombs to serve as substitutes for the deceased.\n\nArriving at one's reward in afterlife was a demanding ordeal, requiring a sin-free heart and the ability to recite the spells, passwords, and formulae of the Book of the Dead. In the Hall of Two Truths, the deceased's heart was weighed against the Shu feather of truth and justice taken from the headdress of the goddess Ma'at. If the heart was lighter than the feather, they could pass on, but if it were heavier they would be devoured by the demon Ammit.\n\nEgyptians also believed that being mummified and put in a sarcophagus (an ancient Egyptian \"coffin\" carved with complex symbols and designs, as well as pictures and hieroglyphs) was the only way to have an afterlife. What are referred to as the Coffin Texts, are inscribed on a coffin and serve as a guide for the challenges in the afterlife. The Coffin texts are more or less a duplication of the Pyramid Texts, which would serve as a guide for Egyptian pharaohs or queens in the afterlife. Only if the corpse had been properly embalmed and entombed in a mastaba, could the dead live again in the Fields of Yalu and accompany the Sun on its daily ride. Due to the dangers the afterlife posed, the Book of the Dead was placed in the tomb with the body as well as food, jewelry, and 'curses'. They also used the \"opening of the mouth\".\n\nAncient Egyptian civilization was based on religion. The belief in the rebirth after death became the driving force behind  funeral practices. Death was simply a temporary interruption, rather than complete cessation of life. Eternal life could be ensured by means like piety to the gods, preservation of the physical form through mummification, and the provision of statuary and other funerary equipment. Each human consisted of the physical body, the ka, the ba, and the akh. The Name and Shadow were also living entities. To enjoy the afterlife, all these elements had to be sustained and protected from harm.\n\nOn 30 March 2010, a spokesman for the Egyptian Culture Ministry claimed it had unearthed a large red granite door in Luxor with inscriptions by User, a powerful adviser to the 18th Dynasty Queen Hatshepsut who ruled between 1479 BC and 1458 BC, the longest of any woman. It believes the false door is a 'door to the Afterlife'. According to the archaeologists, the door was reused in a structure in Roman Egypt.\n\nAncient Greek and Roman religions\n\nThe Greek god Hades is known in Greek mythology as the king of the underworld, a place where souls live after death. The Greek god Hermes, the messenger of the gods, would take the dead soul of a person to the underworld (sometimes called Hades or the House of Hades). Hermes would leave the soul on the banks of the River Styx, the river between life and death.\n\nCharon, also known as the ferry-man, would take the soul across the river to Hades, if the soul had gold: Upon burial, the family of the dead soul would put coins under the deceased's tongue. Once crossed, the soul would be judged by Aeacus, Rhadamanthus and King Minos. The soul would be sent to Elysium, Tartarus, or Asphodel Fields. The Elysian Fields were for the ones that lived pure lives. It consisted of green fields, valleys and mountains, everyone there was peaceful and contented, and the Sun always shone there. Tartarus was for the people that blasphemed against the gods, or were simply rebellious and consciously evil.\n\nThe Asphodel Fields were for a varied selection of human souls including those whose sins equalled their goodness, those who were indecisive in their lives, and those who were not judged. Those who had sinned went to the deepest pit, Tartarus. In Tartarus, the soul would be punished by being burned in lava, or stretched on racks. Some heroes of Greek legend are allowed to visit the underworld. The Romans had a similar belief system about the afterlife, with Hades becoming known as Pluto. In the ancient Greek myth about the Labours of Heracles, the hero Heracles had to travel to the underworld to capture Cerberus, the three-headed guard dog, as one of his tasks.\n\nIn Dream of Scipio, Cicero describes what seems to be an out of body experience, of the soul traveling high above the Earth, looking down at the small planet, from far away.\n\nIn Book VI of Virgil's Aeneid, the hero, Aeneas, travels to the underworld to see his father. By the River Styx, he sees the souls of those not given a proper burial, forced to wait by the river until someone buries them. While down there, along with the dead, he is shown the place where the wrongly convicted reside, the fields of sorrow where those who committed suicide and now regret it reside, including Aeneas' former lover, the warriors and shades, Tartarus (where the titans and powerful non-mortal enemies of the Olympians reside) where he can hear the groans of the imprisoned, the palace of Pluto, and the fields of Elysium where the descendants of the divine and bravest heroes reside. He sees the river of forgetfulness, Lethe, which the dead must drink to forget their life and begin anew. Lastly, his father shows him all of the future heroes of Rome who will live if Aeneas fulfills his destiny in founding the city.\n\nNorse religion\n\nThe Poetic and Prose Eddas, the oldest sources for information on the Norse concept of the afterlife, vary in their description of the several realms that are described as falling under this topic. The most well-known are:\n Valhalla: (lit. \"Hall of the Slain\" i.e. \"the Chosen Ones\") Half the warriors who die in battle join the god Odin who rules over a majestic hall called Valhalla in Asgard.\n F\u00f3lkvangr: (lit. \"Field of the Host\") The other half join the goddess Freyja in a great meadow known as F\u00f3lkvangr.\n Hel: (lit. \"The Covered Hall\")\n Niflhel: (lit. \"The Dark\" or \"Misty Hel\")\n\nAbrahamic religions\n\nJudaism\n\nSheol\nSheol, in the Hebrew Bible, is a place of darkness (Job x. 21, 22) to which all the dead go, both the righteous and the unrighteous, regardless of the moral choices made in life, (Gen. xxxvii. 36; Ezek. xxxii.; Isa. xiv.; Job xxx. 23), a place of stillness, (Ps. lxxxviii. 13, xciv. 17; Eccl. ix. 10), at the longest possible distance from heaven (Job xi. 8; Amos ix. 2; Ps. cxxxix. 8).\n\nThe inhabitants of Sheol are the \"shades\" (rephaim), entities without personality or strength. Under some circumstances they are thought to be able to be contacted by the living, as the Witch of Endor contacts the shade of Samuel for Saul, but such practices are forbidden (Deuteronomy 18:10).\n\nWhile the Hebrew Bible appears to describe Sheol as the permanent place of the dead, in the Second Temple period (roughly 500 BC \u2013 70 AD) a more diverse set of ideas developed. In some texts, Sheol is considered to be the home of both the righteous and the wicked, separated into respective compartments; in others, it was considered a place of punishment, meant for the wicked dead alone. When the Hebrew scriptures were translated into Greek in ancient Alexandria around 200 BC, the word \"Hades\" (the Greek underworld) was substituted for Sheol. This is reflected in the New Testament where Hades is both the underworld of the dead and the personification of the evil it represents.\n\nWorld to Come\nThe Talmud offers a number of thoughts relating to the afterlife. After death, the soul is brought for judgment. Those who have led pristine lives enter immediately into the Olam Haba or world to come. Most do not enter the world to come immediately, but experience a period of reflection of their earthly actions and  are made aware of what they have done wrong. Some view this period as being a \"re-schooling\", with the soul gaining wisdom as one's errors are reviewed. Others view this period to include spiritual discomfort for past wrongs. At the end of this period, not longer than one year, the soul then takes its place in the world to come. Although discomforts are made part of certain Jewish conceptions of the afterlife, the concept of eternal damnation is not a tenet of the Jewish afterlife. According to the Talmud, extinction of the soul is reserved for a far smaller group of malicious and evil leaders, either whose very evil deeds go way beyond norms, or who lead large groups of people to utmost evil. This is also part of Maimonides' 13 principles of faith.\n\nMaimonides describes the Olam Haba in spiritual terms, relegating the prophesied physical resurrection to the status of a future miracle, unrelated to the afterlife or the Messianic era. According to Maimonides, an afterlife continues for the soul of every human being, a soul now separated from the body in which it was \"housed\" during its earthly existence.\n\nThe Zohar describes Gehenna not as a place of punishment for the wicked but as a place of spiritual purification for souls.\n\nReincarnation in Jewish tradition\nAlthough there is no reference to reincarnation in the Talmud or any prior writings, according to rabbis such as Avraham Arieh Trugman, reincarnation is recognized as being part and parcel of Jewish tradition. Trugman explains that it is through oral tradition that the meanings of the Torah, its commandments and stories, are known and understood. The classic work of Jewish mysticism, the Zohar, is quoted liberally in all Jewish learning; in the Zohar the idea of reincarnation is mentioned repeatedly. Trugman states that in the last five centuries the concept of reincarnation, which until then had been a much hidden tradition within Judaism, was given open exposure.\n\nShraga Simmons commented that within the Bible itself, the idea [of reincarnation] is intimated in Deut. 25:5\u201310, Deut. 33:6 and Isaiah 22:14, 65:6.\n\nYirmiyahu Ullman wrote that reincarnation is an \"ancient, mainstream belief in Judaism\". The Zohar makes frequent and lengthy references to reincarnation. Onkelos, a righteous convert and authoritative commentator of the same period, explained the verse, \"Let Reuben live and not die\u00a0...\" (Deuteronomy 33:6) to mean that Reuben should merit the World to Come directly, and not have to die again as a result of being reincarnated. Torah scholar, commentator and kabbalist, Nachmanides (Ramban 1195\u20131270), attributed Job's suffering to reincarnation, as hinted in Job's saying \"God does all these things twice or three times with a man, to bring back his soul from the pit to... the light of the living' (Job 33:29, 30).\"\n\nReincarnation, called gilgul, became popular in folk belief, and is found in much Yiddish literature among Ashkenazi Jews. Among a few kabbalists, it was posited that some human souls could end up being reincarnated into non-human bodies. These ideas were found in a number of Kabbalistic works from the 13th century, and also among many mystics in the late 16th century. Martin Buber's early collection of stories of the Baal Shem Tov's life includes several that refer to people reincarnating in successive lives.\n\nAmong well known (generally non-kabbalist or anti-kabbalist) rabbis who rejected the idea of reincarnation are Saadia Gaon, David Kimhi, Hasdai Crescas, Yedayah Bedershi (early 14th century), Joseph Albo, Abraham ibn Daud, the Rosh and Leon de Modena. Saadia Gaon, in Emunoth ve-Deoth (Hebrew: \"beliefs and opinions\") concludes Section VI with a refutation of the doctrine of metempsychosis (reincarnation). While rebutting reincarnation, Saadia Gaon further states that Jews who hold to reincarnation have adopted non-Jewish beliefs. By no means do all Jews today believe in reincarnation, but belief in reincarnation is not uncommon among many Jews, including Orthodox.\n\nOther well-known rabbis who are reincarnationists include Yonassan Gershom, Abraham Isaac Kook, Talmud scholar Adin Steinsaltz, DovBer Pinson, David M. Wexelman, Zalman Schachter, and many others. Reincarnation is cited by authoritative biblical commentators, including Ramban (Nachmanides), Menachem Recanti and Rabbenu Bachya.\n\nAmong the many volumes of Yitzchak Luria, most of which come down from the pen of his primary disciple, Chaim Vital, are insights explaining issues related to reincarnation. His Shaar HaGilgulim, \"The Gates of Reincarnation\", is a book devoted exclusively to the subject of reincarnation in Judaism.\n\nRabbi Naftali Silberberg of The Rohr Jewish Learning Institute notes that \"Many ideas that originate in other religions and belief systems have been popularized in the media and are taken for granted by unassuming Jews.\"\n\nChristianity\n\nMainstream Christianity professes belief in the Nicene Creed, and English versions of the Nicene Creed in current use include the phrase: \"We look for the resurrection of the dead, and the life of the world to come.\"\n\nWhen questioned by the Sadducees about the resurrection of the dead (in a context relating to who one's spouse would be if one had been married several times in life), Jesus said that marriage will be irrelevant after the resurrection as the resurrected will be like the angels in heaven.\n\nJesus also maintained that the time would come when the dead would hear the Smartphone apps, in particular, are making an voice of the Son of God, and all who were in the tombs would come out; those who have heard His \"[commandments] and believes in the one who sent [Him]\" to the resurrection of life, but those who do not to the resurrection of condemnation.\n\nThe Book of Enoch describes Sheol as divided into four compartments for four types of the dead: the faithful saints who await resurrection in Paradise, the merely virtuous who await their reward, the wicked who await punishment, and the wicked who have already been punished and will not be resurrected on Judgment Day. The Book of Enoch is considered apocryphal by most denominations of Christianity and all denominations of Judaism.\n\nThe book of 2 Maccabees gives a clear account of the dead awaiting a future resurrection and judgment in addition to prayers and offerings for the dead to remove the burden of sin.\n\nThe author of Luke recounts the story of Lazarus and the rich man, which shows people in Hades awaiting the resurrection either in comfort or torment. The author of the Book of Revelation writes about God and the angels versus Satan and demons in an epic battle at the end of times when all souls are judged. There is mention of ghostly bodies of past prophets, and the transfiguration.\n\nThe non-canonical Acts of Paul and Thecla speak of the efficacy of prayer for the dead so that they might be \"translated to a state of happiness\".\n\nHippolytus of Rome pictures the underworld (Hades) as a place where the righteous dead, awaiting in the bosom of Abraham their resurrection, rejoice at their future prospect, while the unrighteous are tormented at the sight of the \"lake of unquenchable fire\" into which they are destined to be cast.\n\nGregory of Nyssa discusses the long-before believed possibility of purification of souls after death.\n\nPope Gregory I repeats the concept, articulated over a century earlier by Gregory of Nyssa that the saved suffer purification after death, in connection with which he wrote of \"purgatorial flames\".\n\nThe noun \"purgatorium\" (Latin: place of cleansing) is used for the first time to describe a state of painful purification of the saved after life. The same word in adjectival form (purgatorius -a -um, cleansing), which appears also in non-religious writing, was already used by Christians such as Augustine of Hippo and Pope Gregory I to refer to an after-death cleansing.\n\nDuring the Age of Enlightenment, theologians and philosophers presented various philosophies and beliefs. A notable example is Emanuel Swedenborg who wrote some 18 theological works which describe in detail the nature of the afterlife according to his claimed spiritual experiences, the most famous of which is Heaven and Hell. His report of life there covers a wide range of topics, such as marriage in heaven (where all angels are married), children in heaven (where they are raised by angel parents), time and space in heaven (there are none), the after-", "flag": 1, "segments": [[4376, 4386]], "strength": 5.5}
{"text": "Athena or Athene, often given the epithet Pallas, is an ancient Greek goddess associated with wisdom, handicraft, and warfare who was later syncretized with the Roman goddess Minerva. Athena was regarded as the patron and protectress of various cities across Greece, particularly the city of Athens, from which she most likely received her name. The Parthenon on the Acropolis of Athens is dedicated to her. Her major symbols include owls, olive trees, snakes, and the Gorgoneion. In art, she is generally depicted wearing a helmet and holding a spear.\n\nFrom her origin as an Aegean palace goddess, Athena was closely associated with the city. She was known as Polias and Poliouchos (both derived from polis, meaning \"city-state\"), and her temples were usually located atop the fortified acropolis in the central part of the city. The Parthenon on the Athenian Acropolis is dedicated to her, along with numerous other temples and monuments. As the patron of craft and weaving, Athena was known as Ergane. She was also a warrior goddess, and was believed to lead soldiers into battle as Athena Promachos. Her main festival in Athens was the Panathenaia, which was celebrated during the month of Hekatombaion in midsummer and was the most important festival on the Athenian calendar.\n\nIn Greek mythology, Athena was believed to have been born from the forehead of her father Zeus. In some versions of the story, Athena has no mother and is born from Zeus' forehead by parthenogenesis. In others, such as Hesiod's Theogony, Zeus swallows his consort Metis, who was pregnant with Athena; in this version, Athena is first born within Zeus and then escapes from his body through his forehead. In the founding myth of Athens, Athena bested Poseidon in a competition over patronage of the city by creating the first olive tree. She was known as Athena Parthenos \"Athena the Virgin,\" but in one archaic Attic myth, the god Hephaestus tried and failed to rape her, resulting in Gaia giving birth to Erichthonius, an important Athenian founding hero. Athena was the patron goddess of heroic endeavor; she was believed to have aided the heroes Perseus, Heracles, Bellerophon, and Jason. Along with Aphrodite and Hera, Athena was one of the three goddesses whose feud resulted in the beginning of the Trojan War.\n\nShe plays an active role in the Iliad, in which she assists the Achaeans and, in the Odyssey, she is the divine counselor to Odysseus. In the later writings of the Roman poet Ovid, Athena was said to have competed against the mortal Arachne in a weaving competition, afterward transforming Arachne into the first spider; Ovid also describes how she transformed Medusa into a Gorgon after witnessing her being raped by Poseidon in her temple. Since the Renaissance, Athena has become an international symbol of wisdom, the arts, and classical learning. Western artists and allegorists have often used Athena as a symbol of freedom and democracy.\n\nEtymology\n\nAthena is associated with the city of Athens. The name of the city in ancient Greek is  (), a plural toponym, designating the place where\u2014according to myth\u2014she presided over the Athenai, a sisterhood devoted to her worship. In ancient times, scholars argued whether Athena was named after Athens or Athens after Athena. Now scholars generally agree that the goddess takes her name from the city; the ending -ene is common in names of locations, but rare for personal names. Testimonies from different cities in ancient Greece attest that similar city goddesses were worshipped in other cities and, like Athena, took their names from the cities where they were worshipped. For example, in Mycenae there was a goddess called Mykene, whose sisterhood was known as Mykenai, whereas at Thebes an analogous deity was called Thebe, and the city was known under the plural form Thebai (or Thebes, in English, where the's' is the plural formation). The name Athenai is likely of Pre-Greek origin because it contains the presumably Pre-Greek morpheme *-\u0101n-.\n\nIn his dialogue Cratylus, the ancient Greek philosopher Plato (428\u2013347 BC) gives some rather imaginative etymologies of Athena's name, based on the theories of the ancient Athenians and his own etymological speculations:\n\nThus, Plato believed that Athena's name was derived from Greek, \u2014which the later Greeks rationalised as from the deity's (, ) mind (, ). The second-century AD orator Aelius Aristides attempted to derive natural symbols from the etymological roots of Athena's names to be aether, air, earth, and moon.\n\nOrigins\n\nAthena was originally the Aegean goddess of the palace, who presided over household crafts and protected the king. A single Mycenaean Greek inscription   appears at Knossos in the Linear B tablets from the Late Minoan II-era \"Room of the Chariot Tablets\"; these comprise the earliest Linear B archive anywhere. Although Athana potnia is often translated as \"Mistress Athena\", it could also mean \"the Potnia of Athana\", or the Lady of Athens. However, any connection to the city of Athens in the Knossos inscription is uncertain. A sign series  appears in the still undeciphered corpus of Linear A tablets, written in the unclassified Minoan language. This could be connected with the Linear B Mycenaean expressions  and  or  (Diwia, \"of Zeus\" or, possibly, related to a homonymous goddess), resulting in a translation \"Athena of Zeus\" or \"divine Athena\". Similarly, in the Greek mythology and epic tradition, Athena figures as a daughter of Zeus (; cfr. Dyeus). However, the inscription quoted seems to be very similar to \"\", quoted as SY Za 1 by Jan Best. Best translates the initial, which is recurrent in line beginnings, as \"I have given\".\n\nA Mycenean fresco depicts two women extending their hands towards a central figure, who is covered by an enormous figure-eight shield; this may depict the warrior-goddess with her palladion, or her pallad by young women in what appears in the films asion in an aniconic representation. In the \"Procession Fresco\" at Knossos, which was reconstructed by the Mycenaeans, two rows of figures carrying vessels seem to meet in front of a central figure, which is probably the Minoan precursor to Athena. The early twentieth-century scholar Martin Persson Nilsson argued that the Minoan snake goddess figurines are early representations of Athena.\n\nNilsson and others have claimed that, in early times, Athena was either an owl herself or a bird goddess in general. In the third book of the Odyssey, she takes the form of a sea-eagle. Proponents of this view argue that she dropped her prophylactic owl-mask before she lost her wings. \"Athena, by the time she appears in art,\" Jane Ellen Harrison remarks, \"has completely shed her animal form, has reduced the shapes she once wore of snake and bird to attributes, but occasionally in black-figure vase-paintings she still appears with wings.\"\n\nIt is generally agreed that the cult of Athena preserves some aspects of the Proto-Indo-European transfunctional goddess. The cult of Athena may have also been influenced by those of Near Eastern warrior goddesses such as the East Semitic Ishtar and the Ugaritic Anat, both of whom were often portrayed bearing arms. Classical scholar Charles Penglase notes that Athena resembles Inanna in her role as a \"terrifying warrior goddess\" and that both goddesses were closely linked with creation. Athena's birth from the head of Zeus may be derived from the earlier Sumerian myth of Inanna's descent into and return from the Underworld.\n\nPlato notes that the citizens of Sais in Egypt worshipped a goddess known as Neith, whom he identifies with Athena. Neith was the ancient Egyptian goddess of war and hunting, who was also associated with weaving; her worship began during the Egyptian Pre-Dynastic period. In Greek mythology, Athena was reported to have visited mythological sites in North Africa, including Libya's Triton River and the Phlegraean plain. Based on these similarities, the Sinologist Martin Bernal created the \"Black Athena\" hypothesis, which claimed that Neith was brought to Greece from Egypt, along with \"an enormous number of features of civilization and culture in the third and second millennia\". The \"Black Athena\" hypothesis stirred up widespread controversy near the end of the twentieth century, but it has now been widely rejected by modern scholars.\n\nCult and patronages\n\nPanhellenic and Athenian cult\n\nIn her aspect of Athena Polias, Athena was venerated as the goddess of the city and the protectress of the citadel. In Athens, the Plynteria, or \"Feast of the Bath\", was observed every year at the end of the month of Thargelion. The festival lasted for five days. During this period, the priestesses of Athena, or plyntr\u00eddes, performed a cleansing ritual within the Erechtheion, a sanctuary devoted to Athena and Poseidon. Here Athena's statue was undressed, her clothes washed, and body purified. Athena was worshipped at festivals such as Chalceia as Athena Ergane, the patroness of various crafts, especially weaving. She was also the patron of metalworkers and was believed to aid in the forging of armor and weapons. During the late fifth century BC, the role of goddess of philosophy became a major aspect of Athena's cult.\n\nAs Athena Promachos, she was believed to lead soldiers into battle. Athena represented the disciplined, strategic side of war, in contrast to her brother Ares, the patron of violence, bloodlust, and slaughter\u2014\"the raw force of war\". Athena was believed to only support those fighting for a just cause and was thought to view war primarily as a means to resolve conflict. The Greeks regarded Athena with much higher esteem than Ares. Athena was especially worshipped in this role during the festivals of the Panathenaea and Pamboeotia, both of which prominently featured displays of athletic and military prowess. As the patroness of heroes and warriors, Athena was believed to favor those who used cunning and intelligence rather than brute strength.\n\nIn her aspect as a warrior maiden, Athena was known as Parthenos ( \"virgin\"), because, like her fellow goddesses Artemis and Hestia, she was believed to remain perpetually a virgin. Athena's most famous temple, the Parthenon on the Athenian Acropolis, takes its name from this title. According to Karl Ker\u00e9nyi, a scholar of Greek mythology, the name Parthenos is not merely an observation of Athena's virginity, but also a recognition of her role as enforcer of rules of sexual modesty and ritual mystery. Even beyond recognition, the Athenians allotted the goddess value based on this pureness of virginity, which they upheld as a rudiment of female behavior. Ker\u00e9nyi's study and theory of Athena explains her virginal epithet as a result of her relationship to her father Zeus and a vital, cohesive piece of her character throughout the ages. This role is expressed in a number of stories about Athena. Marinus of Neapolis reports that when Christians removed the statue of the goddess from the Parthenon, a beautiful woman appeared in a dream to Proclus, a devotee of Athena, and announced that the \"Athenian Lady\" wished to dwell with him.\n\nRegional cults\n\nAthena was not only the patron goddess of Athens, but also other cities, including Argos, Sparta, Gortyn, Lindos, and Larisa. The various cults of Athena were all branches of her panhellenic cult and often proctored various initiation rites of Grecian youth, such as the passage into citizenship by young men or the passage of young women into marriage. These cults were portals of a uniform socialization, even beyond mainland Greece. Athena was frequently equated with Aphaea, a local goddess of the island of Aegina, originally from Crete and also associated with Artemis and the nymph Britomartis. In Arcadia, she was assimilated with the ancient goddess Alea and worshiped as Athena Alea. Sanctuaries dedicated to Athena Alea were located in the Laconian towns of Mantineia and Tegea. The temple of Athena Alea in Tegea was an important religious center of ancient Greece. The geographer Pausanias was informed that the temenos had been founded by Aleus.\n\nAthena had a major temple on the Spartan Acropolis, where she was venerated as Poliouchos and Khalk\u00edoikos (\"of the Brazen House\", often latinized as Chalcioecus). This epithet may refer to the fact that cult statue held there may have been made of bronze, that the walls of the temple itself may have been made of bronze, or that Athena was the patron of metal-workers. Bells made of terracotta and bronze were used in Sparta as part of Athena's cult. An Ionic-style temple to Athena Polias was built at Priene in the fourth century BC. It was designed by Pytheos of Priene, the same architect who designed the Mausoleum at Halicarnassus. The temple was dedicated by Alexander the Great and an inscription from the temple declaring his dedication is now held in the British Museum.\n\nEpithets and attributes\n\nAthena was known as Atrytone ( \"the Unwearying\"), Parthenos ( \"Virgin\"), and Promachos ( \"she who fights in front\"). The epithet Polias (\u03a0\u03bf\u03bb\u03b9\u03ac\u03c2 \"of the city\"), refers to Athena's role as protectress of the city. The epithet Ergane (\u0395\u03c1\u03b3\u03ac\u03bd\u03b7 \"the Industrious\") pointed her out as the patron of craftsmen and artisans. Burkert notes that the Athenians sometimes simply called Athena \"the Goddess\", h\u0113 the\u00f3s (\u1f21 \u03b8\u03b5\u03cc\u03c2), certainly an ancient title. After serving as the judge at the trial of Orestes in which he was acquitted of having murdered his mother Clytemnestra, Athena won the epithet Areia (\u0391\u03c1\u03b5\u03af\u03b1). Some have described Athena, along with the goddesses Hestia and Artemis as being asexual, this is mainly supported by the fact that in the Homeric Hymns, 5, To Aphrodite, where Aphrodite is described as having \"no power\" over the three goddesses.  \n\nAthena was sometimes given the epithet Hippia (\u1f3d\u03c0\u03c0\u03b9\u03b1 \"of the horses\", \"equestrian\"), referring to her invention of the bit, bridle, chariot, and wagon. The Greek geographer Pausanias mentions in his Guide to Greece that the temple of Athena Chalinitis (\"the bridler\") in Corinth was located near the tomb of Medea's children. Other epithets include Ageleia, Itonia and Aethyia, under which she was worshiped in Megara. The word a\u00edthyia () signifies a \"diver\", also some diving bird species (possibly the shearwater) and figuratively, a \"ship\", so the name must reference Athena teaching the art of shipbuilding or navigation. In a temple at Phrixa in Elis, reportedly built by Clymenus, she was known as Cydonia (\u039a\u03c5\u03b4\u03c9\u03bd\u03af\u03b1). Pausanias wrote that at Buporthmus there was a sanctuary of Athena Promachorma (\u03a0\u03c1\u03bf\u03bc\u03b1\u03c7\u03cc\u03c1\u03bc\u03b1), meaning protector of the anchorage.\n\nThe Greek biographer Plutarch (AD 46\u2013120) refers to an instance during the Parthenon's construction of her being called Athena Hygieia (\u1f59\u03b3\u03af\u03b5\u03b9\u03b1, i.\u00a0e. personified \"Health\") after inspiring a physician to a successful course of treatment.\n\nIn Homer's epic works, Athena's most common epithet is Glaukopis (), which usually is translated as, \"bright-eyed\" or \"with gleaming eyes\". The word is a combination of glauk\u00f3s (, meaning \"gleaming, silvery\", and later, \"bluish-green\" or \"gray\") and \u1e53ps (, \"eye, face\"). The word gla\u00fax (, \"little owl\") is from the same root, presumably according to some, because of the bird's own distinctive eyes. Athena was clearly associated with the owl from very early on; in archaic images, she is frequently depicted with an owl perched on her hand. Through its association with Athena, the owl evolved into the national mascot of the Athenians and eventually became a symbol of wisdom.\n\nIn the Iliad (4.514), the Odyssey (3.378), the Homeric Hymns, and in Hesiod's Theogony, Athena is also given the curious epithet Tritogeneia (\u03a4\u03c1\u03b9\u03c4\u03bf\u03b3\u03ad\u03bd\u03b5\u03b9\u03b1), whose significance remains unclear. It could mean various things, including \"Triton-born\", perhaps indicating that the homonymous sea-deity was her parent according to some early myths. One myth relates the foster father relationship of this Triton towards the half-orphan Athena, whom he raised alongside his own daughter Pallas. Ker\u00e9nyi suggests that \"Tritogeneia did not mean that she came into the world on any particular river or lake, but that she was born of the water itself; for the name Triton seems to be associated with water generally.\" In Ovid's Metamorphoses, Athena is occasionally referred to as \"Tritonia\".\n\nAnother possible meaning may be \"triple-born\" or \"third-born\", which may refer to a triad or to her status as the third daughter of Zeus or the fact she was born from Metis, Zeus, and herself; various legends list her as being the first child after Artemis and Apollo, though other legends identify her as Zeus' first child. Several scholars have suggested a connection to the Rigvedic god Trita, who was sometimes grouped in a body of three mythological poets. Michael Janda has connected the myth of Trita to the scene in the Iliad in which the \"three brothers\" Zeus, Poseidon, and Hades divide the world between them, receiving the \"broad sky\", the sea, and the underworld respectively. Janda further connects the myth of Athena being born of the head (i.\u00a0e. the uppermost part) of Zeus, understanding Trito- (which perhaps originally meant \"the third\") as another word for \"the sky\". In Janda's analysis of Indo-European mythology, this heavenly sphere is also associated with the mythological body of water surrounding the inhabited world (cfr. Triton's mother, Amphitrite).\n\nYet another possible meaning is mentioned in Diogenes Laertius' biography of Democritus, that Athena was called \"Tritogeneia\" because three things, on which all mortal life depends, come from her.\n\nMythology\n\nBirth\n\nShe was the daughter of Zeus, produced without a mother, so that she emerged full-grown from his forehead. There was an alternative story that Zeus swallowed Metis, the goddess of counsel, while she was pregnant with Athena, so that Athena finally emerged from Zeus. Being the favourite child of Zeus, she had great power.\nIn the classical Olympian pantheon, Athena was regarded as the favorite daughter of Zeus, born fully armed from his forehead. The story of her birth comes in several versions. The earliest mention is in Book V of the Iliad, when Ares accuses Zeus of being biased in favor of Athena because \"autos egeinao\" (literally \"you fathered her\", but probably intended as \"you gave birth to her\").\nShe was essentially urban and civilized, the antithesis in many respects of Artemis, goddess of the outdoors. Athena was probably a pre-Hellenic goddess and was later taken over by the Greeks.\nIn the version recounted by Hesiod in his Theogony, Zeus married the goddess Metis, who is described as the \"wisest among gods and mortal men\", and engaged in sexual intercourse with her. After learning that Metis was pregnant, however, he became afraid that the unborn offspring would try to overthrow him, because Gaia and Ouranos had prophesied that Metis would bear children wiser than their father. In order to prevent this, Zeus tricked Metis into letting him swallow her, but it was too late because Metis had already conceived. A later account of the story from the Bibliotheca of Pseudo-Apollodorus, written in the second century AD, makes Metis Zeus's unwilling sexual partner, rather than his wife. According to this version of the story, Metis transformed into many different shapes in effort to escape Zeus, but Zeus successfully raped her and swallowed her.\n\nAfter swallowing Metis, Zeus took six more wives in succession until he married his seventh and present wife, Hera. Then Zeus experienced an enormous headache. He was in such pain that he ordered someone (either Prometheus, Hephaestus, Hermes, Ares, or Palaemon, depending on the sources examined) to cleave his head open with the labrys, the double-headed Minoan axe. Athena leaped from Zeus's head, fully grown and armed. The \"First Homeric Hymn to Athena\" states in lines 9\u201316 that the gods were awestruck by Athena's appearance and even Helios, the god of the sun, stopped his chariot in the sky. Pindar, in his \"Seventh Olympian Ode\", states that she \"cried aloud with a mighty shout\" and that \"the Sky and mother Earth shuddered before her.\"\n\nHesiod states that Hera was so annoyed at Zeus for having given birth to a child on his own that she conceived and bore Hephaestus by herself, but in Imagines 2. 27 (trans. Fairbanks), the third-century AD Greek rhetorician Philostratus the Elder writes that Hera \"rejoices\" at Athena's birth \"as though Athena were her daughter also.\" The second-century AD Christian apologist Justin Martyr takes issue with those pagans who erect at springs images of Kore, whom he interprets as Athena: \"They said that Athena was the daughter of Zeus not from intercourse, but when the god had in mind the making of a world through a word (logos) his first thought was Athena.\" According to a version of the story in a scholium on the Iliad (found nowhere else), when Zeus swallowed Metis, she was pregnant with Athena by the Cyclops Brontes. The Etymologicum Magnum instead deems Athena the daughter of the Daktyl Itonos. Fragments attributed by the Christian Eusebius of Caesarea to the semi-legendary Phoenician historian Sanchuniathon, which Eusebius thought had been written before the Trojan war, make Athena instead the daughter of Cronus, a king of Byblos who visited \"the inhabitable world\" and bequeathed Attica to Athena.\n\nPallas Athena\n\nAthena's epithet Pallas is derived either from", "flag": 1, "segments": [[1345, 1355]], "strength": 5.5}
{"text": "Alternate history (also alternative history, althist, AH) is a genre of speculative fiction of stories in which one or more historical events occur and are resolved differently than in real life. As conjecture based upon historical fact, alternative history stories propose What if? scenarios about crucial events in human history, and present outcomes very different from the historical record. Alternate history also is a subgenre of literary fiction, science fiction, and historical fiction; as literature, alternate history uses the tropes of the genre to answer the What if? speculations of the story.\n\nSince the 1950s, as a subgenre of science fiction, alternative history stories feature the tropes of time travel between histories, and the psychic awareness of the existence of an alternative universe, by the inhabitants of a given universe; and time travel that divides history into various timestreams. In the Spanish, French, German, and Portuguese, Italian,  Catalan, and Galician languages, the terms Uchronie, ucronia,  ucron\u00eda, and Uchronie identify the alternate history genre, from which derives the English term Uchronia, composed of the Greek prefix  (\"not\", \"not any\", and \"no\") and the Greek word  () \"time\", to describe a story that occurs \"[in] no time\"; analogous to a story that occurs in utopia, \"[in] no place\". The term Uchronia also is the name of the list of alternate-history books, uchronia.net. Moreover, Allohistory (other history) is another term for the genre of alternative history.\n\nDefinition\nAlternative history is a genre of fiction wherein the author speculates upon how the course of history might have been altered if a particular historical event had an outcome different from the real life outcome. An alternate history requires three conditions: (i) A point of divergence from the historical record, before the time in which the author is writing; (ii) A change that would alter known history; and (iii) An examination of the ramifications of that alteration to history. Occasionally, some types of genre fiction are misidentified as alternative history, specifically science fiction stories set in a time that was the future for the writer, but now is the past for the reader, such as the novels 2001: A Space Odyssey (1968), by Arthur C. Clarke and Nineteen Eighty-Four (1949), by George Orwell, because the authors did not alter the history of the past when they wrote the stories.\n\nMoreover, the genre of the Secret History of an event, which can be either fictional or non-fictional, documents events that might have occurred in history, but which had no effect upon the recorded historical outcome. Alternative history also is thematically related to, but distinct from, Counterfactual History, which is a form of historiography that attempts to answer the What if? speculations that arise from counterfactual conditions in order to understand what did happen. As a method of historical research, counterfactual history explores historical events with an extrapolated timeline in which key historical events either did not occur or had an outcome different from the historical record.\n\nHistory of literature\n\nAntiquity and medieval\n\nThe earliest example of alternate (or counterfactual) history is found in Livy's Ab Urbe Condita Libri (book IX, sections 17\u201319). Livy contemplated an alternative 4th century BC in which Alexander the Great had survived to attack Europe as he had planned; asking, \"What would have been the results for Rome if she had been engaged in a war with Alexander?\" Livy concluded that the Romans would likely have defeated Alexander. An even earlier possibility is Herodotus's Histories, which contains speculative material.\n\nAnother example of counterfactual history was posited by cardinal and Doctor of the Church Peter Damian in the 11th century. In his famous work De Divina Omnipotentia, a long letter in which he discusses God's omnipotence, he treats questions related to the limits of divine power, including the question of whether God can change the past, for example, bringing about that Rome was never founded:I see I must respond finally to what  many people, on the basis of your holiness\u2019s [own] judgment, raise as an objection on the topic of this dispute. For they say: If, as you assert, God is omnipotent in all things, can he manage this, that things that have been made were not  made? He can certainly destroy all things that have been made, so that they do not exist now. But it cannot be seen how he can bring it about that things that have been made were not made. To be sure, it can come about that from now on and hereafter Rome does not exist; for it can be destroyed. But no opinion can grasp how it can come about that it was not founded long ago...One early work of fiction detailing an alternate history is Joanot Martorell's 1490 epic romance Tirant lo Blanch, which was written when the loss of Constantinople to the Turks was still a recent and traumatic memory for Christian Europe. It tells the story of the knight Tirant the White from Brittany who travels to the embattled remnants of the Byzantine Empire. He becomes a Megaduke and commander of its armies and manages to fight off the invading Ottoman armies of. He saves the city from Islamic conquest, and even chases the Turks deeper into lands they had previously conquered.\n\n19th century\nOne of the earliest works of alternate history published in large quantities for the reception of a large audience may be Louis Geoffroy's Histoire de la Monarchie universelle: Napol\u00e9on et la conqu\u00eate du monde (1812\u20131832) (History of the Universal Monarchy: Napoleon and the Conquest of the World) (1836), which imagines Napoleon's First French Empire emerging victorious in the French invasion of Russia in 1812 and in an invasion of England in 1814, later unifying the world under Bonaparte's rule.\n\nIn the English language, the first known complete alternate history is Nathaniel Hawthorne's short story \"P.'s Correspondence\", published in 1845. It recounts the tale of a man who is considered \"a madman\" due to his perceptions of a different 1845, a reality in which long-dead famous people, such as the poets Robert Burns, Lord Byron, Percy Bysshe Shelley and John Keats, the actor Edmund Kean, the British politician George Canning, and Napoleon Bonaparte, are still alive.\n\nThe first novel-length alternate history in English would seem to be Castello Holford's Aristopia (1895). While not as nationalistic as Louis Geoffroy's Napol\u00e9on et la conqu\u00eate du monde, 1812\u20131823, Aristopia is another attempt to portray a Utopian society. In Aristopia, the earliest settlers in Virginia discover a reef made of solid gold and are able to build a Utopian society in North America.\n\nEarly 20th century and the era of the pulps\nIn 1905, H. G. Wells published A Modern Utopia. As explicitly noted in the book itself, Wells's main aim in writing it was to set out his social and political ideas, the plot serving mainly as a vehicle to expound them. This book introduced the idea of a person being transported from a point in our familiar world to the precise geographical equivalent point in an alternate world in which history had gone differently. The protagonists undergo various adventures in the alternate world, and then are finally transported back to our world, again to the precise geographical equivalent point. Since then, that has become a staple of the alternate history genre.    \n\nA number of alternate history stories and novels appeared in the late 19th and early 20th centuries (see, for example, Joseph Edgar Chamberlin's The Ifs of History [1907] and Charles Petrie's If: A Jacobite Fantasy [1926]). In 1931, British historian Sir John Squire collected a series of essays from some of the leading historians of the period for his anthology If It Had Happened Otherwise. In that work, scholars from major universities, as well as important non-academic authors, turned their attention to such questions as \"If the Moors in Spain Had Won\" and \"If Louis XVI Had Had an Atom of Firmness\". The essays range from serious scholarly efforts to Hendrik Willem van Loon's fanciful and satiric portrayal of an independent 20th-century New Amsterdam, a Dutch city-state on the island of Manhattan. Among the authors included were Hilaire Belloc, Andr\u00e9 Maurois, and Winston Churchill.\n\nOne of the entries in Squire's volume was Churchill's \"If Lee Had Not Won the Battle of Gettysburg\", written from the viewpoint of a historian in a world in which the Confederacy had won the American Civil War. The entry considers what would have happened if the North had been victorious (in other words, a character from an alternate world imagines a world more like the real one we live in, although it is not identical in every detail). Speculative work that narrates from the point of view of an alternate history is variously known as \"recursive alternate history\", a \"double-blind what-if\", or an \"alternate-alternate history\". Churchill's essay was one of the influences behind Ward Moore's alternate history novel Bring the Jubilee in which General Robert E. Lee won the Battle of Gettysburg and paved the way for the eventual victory of the Confederacy in the American Civil War (named the \"War of Southron Independence\" in this timeline). The protagonist, the autodidact Hodgins Backmaker, travels back to the aforementioned battle and inadvertently changes history, which results in the emergence of our own timeline and the consequent victory of the Union instead.\n\nThe American humorist author James Thurber parodied alternate history stories about the American Civil War in his 1930 story \"If Grant Had Been Drinking at Appomattox\", which he accompanied with this very brief introduction: \"Scribner's magazine is publishing a series of three articles: 'If Booth Had Missed Lincoln', 'If Lee Had Won the Battle of Gettysburg', and 'If Napoleon Had Escaped to America'. This is the fourth\".\n\nAnother example of alternate history from this period (and arguably the first that explicitly posited cross-time travel from one universe to another as anything more than a visionary experience) is H.G. Wells' Men Like Gods (1923) in which the London-based journalist Mr. Barnstable, along with two cars and their passengers, is mysteriously teleported into \"another world\", which the \"Earthlings\" call Utopia. Being far more advanced than Earth, Utopia is some 3000 years ahead of humanity in its development. Wells describes a multiverse of alternative worlds, complete with the paratime travel machines that would later become popular with American pulp writers. However, since his hero experiences only a single alternate world, the story is not very different from conventional alternate history.\n\nIn the 1930s, alternate history moved into a new arena. The December 1933 issue of Astounding published Nat Schachner's \"Ancestral Voices\", which was quickly followed by Murray Leinster's \"Sidewise in Time\". While earlier alternate histories examined reasonably-straightforward divergences, Leinster attempted something completely different. In his \"World gone mad\", pieces of Earth traded places with their analogs from different timelines. The story follows Professor Minott and his students from a fictitious Robinson College as they wander through analogues of worlds that followed a different history.\n\nA somewhat similar approach was taken by Robert A. Heinlein in his 1941 novelette Elsewhen in which a professor trains his mind to move his body across timelines. He then hypnotizes his students so that they can explore more of them. Eventually, each settles into the reality that is most suitable for him or her. Some of the worlds they visit are mundane, some are very odd, and others follow science fiction or fantasy conventions.\n\nWorld War II produced alternate history for propaganda: both British and American authors wrote works depicting Nazi invasions of their respective countries as cautionary tales.\n\nTime travel to create historical divergences\nThe period around World War II also saw the publication of the time travel novel Lest Darkness Fall by L. Sprague de Camp in which an American academic travels to Italy at the time of the Byzantine invasion of the Ostrogoths. De Camp's time traveler, Martin Padway, is depicted as making permanent historical changes and implicitly forming a new time branch, thereby making the work an alternate history.\n\nIn William Tenn's short story Brooklyn Project (1948), a tyrannical US Government brushes aside the warnings of scientists about the dangers of time travel and goes on with a planned experiment - with the result that minor changes to the prehistoric past cause Humanity to never have existed, its place taken by tentacled underwater intelligent creatures - who also have a tyrannical government which also insists on experimenting with time-travel.\n\nTime travel as the cause of a point of divergence (POD), which can denote either the bifurcation of a historical timeline or a simple replacement of the future that existed before the time-travelling event, has continued to be a popular theme. In Ward Moore's Bring the Jubilee, the protagonist lives in an alternate history in which the Confederacy has won the American Civil War. He travels backward through time and brings about a Union victory at the Battle of Gettysburg.\n\nWhen a story's assumptions about the nature of time travel lead to the complete replacement of the visited time's future, rather than just the creation of an additional time line, the device of a \"time patrol\" is often used where related to Christmas. Each year around 1:00 guardians move through time to preserve the \"correct\" history.\n\nA more recent example is Making History by Stephen Fry in which a time machine is used to alter history so that Adolf Hitler was never born. That ironically results in a more competent leader of Nazi Germany and results in the country's ascendancy and longevity in the altered timeline.\n\nCross-time stories\n\nH.G. Wells' \"cross-time\" or \"many universes\" variant (see above) was fully developed by Murray Leinster in his 1934 short story \"Sidewise in Time\", in which sections of the Earth's surface begin changing places with their counterparts in alternate timelines.\n\nFredric Brown employed this subgenre to satirize the science fiction pulps and their adolescent readers\u2014and fears of foreign invasion\u2014in the classic What Mad Universe (1949). In Clifford D. Simak's Ring Around the Sun (1953), the hero ends up in an alternate earth of thick forests in which humanity never developed but a band of mutants is establishing a colony; the story line appears to frame the author's anxieties regarding McCarthyism and the Cold War.\n\nQuantum theory of many worlds\nWhile many justifications for alternate histories involve a multiverse, the \"many world\" theory would naturally involve many worlds, in fact a continually exploding array of universes. In quantum theory, new worlds would proliferate with every quantum event, and even if the writer uses human decisions, every decision that could be made differently would result in a different timeline. A writer's fictional multiverse may, in fact, preclude some decisions as humanly impossible, as when, in Night Watch, Terry Pratchett depicts a character informing Vimes that while anything that can happen, has happened, nevertheless there is no history whatsoever in which Vimes has ever murdered his wife. When the writer explicitly maintains that all possible decisions are made in all possible ways, one possible conclusion is that the characters were neither brave, nor clever, nor skilled, but simply lucky enough to happen on the universe in which they did not choose the cowardly route, take the stupid action, fumble the crucial activity, etc.; few writers focus on this idea, although it has been explored in stories such as Larry Niven's story All the Myriad Ways, where the reality of all possible universes leads to an epidemic of suicide and crime because people conclude their choices have no moral import.\n\nIn any case, even if it is true that every possible outcome occurs in some world, it can still be argued that traits such as bravery and intelligence might still affect the relative frequency of worlds in which better or worse outcomes occurred (even if the total number of worlds with each type of outcome is infinite, it is still possible to assign a different measure to different infinite sets). The physicist David Deutsch, a strong advocate of the many-worlds interpretation of quantum mechanics, has argued along these lines, saying that \"By making good choices, doing the right thing, we thicken the stack of universes in which versions of us live reasonable lives. When you succeed, all the copies of you who made the same decision succeed too. What you do for the better increases the portion of the multiverse where good things happen.\" This view is perhaps somewhat too abstract to be explored directly in science fiction stories, but a few writers have tried, such as Greg Egan in his short story The Infinite Assassin, where an agent is trying to contain reality-scrambling \"whirlpools\" that form around users of a certain drug, and the agent is constantly trying to maximize the consistency of behavior among his alternate selves, attempting to compensate for events and thoughts he experiences, he guesses are of low measure relative to those experienced by most of his other selves.\n\nMany writers\u2014perhaps the majority\u2014avoid the discussion entirely. In one novel of this type, H. Beam Piper's Lord Kalvan of Otherwhen, a Pennsylvania State Police officer, who knows how to make gunpowder, is transported from our world to an alternate universe where the recipe for gunpowder is a tightly held secret and saves a country that is about to be conquered by its neighbors. The paratime patrol members are warned against going into the timelines immediately surrounding it, where the country will be overrun, but the book never depicts the slaughter of the innocent thus entailed, remaining solely in the timeline where the country is saved.\n\nThe cross-time theme was further developed in the 1960s by Keith Laumer in the first three volumes of his Imperium sequence, which would be completed in Zone Yellow (1990). Piper's politically more sophisticated variant was adopted and adapted by Michael Kurland and Jack Chalker in the 1980s; Chalker's G.O.D. Inc trilogy (1987\u201389), featuring paratime detectives Sam and Brandy Horowitz, marks the first attempt at merging the paratime thriller with the police procedural. Kurland's Perchance (1988), the first volume of the never-completed \"Chronicles of Elsewhen\", presents a multiverse of secretive cross-time societies that utilize a variety of means for cross-time travel, ranging from high-tech capsules to mutant powers. Harry Turtledove has launched the Crosstime Traffic series for teenagers featuring a variant of H. Beam Piper's paratime trading empire.\n\nRival paratime worlds\nThe concept of a cross-time version of a world war, involving rival paratime empires, was developed in Fritz Leiber's Change War series, starting with the Hugo Award winning The Big Time (1958); followed by Richard C. Meredith's Timeliner trilogy in the 1970s, Michael McCollum's A Greater Infinity (1982) and John Barnes' Timeline Wars trilogy in the 1990s.\n\nSuch \"paratime\" stories may include speculation that the laws of nature can vary from one universe to the next, providing a science fictional explanation\u2014or veneer\u2014for what is normally fantasy. Aaron Allston's Doc Sidhe and Sidhe Devil take place between our world, the \"grim world\" and an alternate \"fair world\" where the Sidhe retreated to. Although technology is clearly present in both worlds, and the \"fair world\" parallels our history, about fifty years out of step, there is functional magic in the fair world. Even with such explanation, the more explicitly the alternate world resembles a normal fantasy world, the more likely the story is to be labelled fantasy, as in Poul Anderson's \"House Rule\" and \"Loser's Night\". In both science fiction and fantasy, whether a given parallel universe is an alternate history may not be clear. The writer might allude to a POD only to explain the existence and make no use of the concept, or may present the universe without explanation of its existence.\n\nMajor writers explore alternate histories\nIsaac Asimov's short story \"What If\u2014\" (1952) is about a couple who can explore alternate realities by means of a television-like device. This idea can also be found in Asimov's novel The End of Eternity (1955), in which the \"Eternals\" can change the realities of the world, without people being aware of it.  Poul Anderson's Time Patrol stories feature conflicts between forces intent on changing history and the Patrol who work to preserve it.  One story, Delenda Est, describes a world in which Carthage triumphed over the Roman Republic.  The Big Time, by Fritz Leiber, describes a Change War ranging across all of history.\n\nKeith Laumer's Worlds of the Imperium is one of the earliest alternate history novels; it was published by Fantastic Stories of the Imagination in 1961, in magazine form, and reprinted by Ace Books in 1962 as one half of an Ace Double. Besides our world, Laumer describes a world ruled by an Imperial aristocracy formed by the merger of European empires, in which the American Revolution never happened, and a third world in post-war chaos ruled by the protagonist's doppelganger.\n\nPhilip K. Dick's novel, The Man in the High Castle (1962), is an alternate history in which Nazi Germany and Imperial Japan won World War II. This book contains an example of \"alternate-alternate\" history, in that one of its characters authored a book depicting a reality in which the Allies won the war, itself divergent from real-world history in several aspects. The several characters live within a divided United States, in which the Empire of Japan takes the Pacific states, governing them as a puppet, Nazi Germany takes the East Coast of the United States and parts of the Midwest, with the remnants of the old United States' government as the Neutral Zone, a buffer state between the two superpowers. The book has inspired an Amazon series of the same name.\n\nVladimir Nabokov's novel, Ada or Ardor: A Family Chronicle (1969), is a story of incest that takes place within an alternate North America settled in part by Czarist Russia and that borrows from Dick's idea of \"alternate-alternate\" history (the world of Nabokov's hero is wracked by rumors of a \"counter-earth\" that apparently is ours). Some critics believe that the references to a counter-earth suggest that the world portrayed in Ada is a delusion in the mind of the hero (another favorite theme of Dick's novels). Strikingly, the characters in Ada seem to acknowledge their own world as the copy or negative version, calling it \"Anti-Terra\", while its mythical twin is the real \"Terra\". Like history, science has followed a divergent path on Anti-Terra: it boasts all the same technology as our world, but all based on water instead of electricity; e.g., when a character in Ada makes a long-distance call, all the toilets in the house flush at once to provide hydraulic power.\n\nGuido Morselli described the defeat of Italy (and subsequently France) in World War I in his novel, Past Conditional (1975; ), wherein the static Alpine front line which divided Italy from Austria during that war collapses when the Germans and the Austrians forsake trench warfare and adopt blitzkrieg twenty years in advance.\n\nKingsley Amis set his novel, The Alteration (1976), in the 20th century, but major events in the Reformation did not take place, and Protestantism is limited", "flag": 1, "segments": [[2862, 2872]], "strength": 5.5}
{"text": "In atomic theory and quantum mechanics, an atomic orbital is a mathematical function describing the location and wave-like behavior of an electron in an atom. This function can be used to calculate the probability of finding any electron of an atom ins you is patience. It might seem like cooking any specific region around the atom's nucleus. The term atomic orbital may also refer to the physical region or space where the electron can be calculated to be present, as predicted by the particular mathematical form of the orbital.\n\nEach orbital in an atom is characterized by a set of values of the three quantum numbers,, and, which respectively correspond to the electron's energy, angular momentum, and an angular momentum vector component (the magnetic quantum number). Alternative to the magnetic quantum number, the orbitals are often labeled by the associated harmonic polynomials (e.g. xy, x2\u2212y2). Each such orbital can be occupied by a maximum of two electrons, each with its own projection of spin. The simple names s orbital, p orbital, d orbital, and f orbital refer to orbitals with angular momentum quantum number  and  respectively. These names, together with the value of\u00a0, are used to describe the electron configurations of atoms. They are derived from the description by early spectroscopists of certain series of alkali metal spectroscopic lines as sharp, principal, diffuse, and fundamental. Orbitals for  > 3 continue alphabetically (g, h, i, k,...), omitting\u00a0j because some languages do not distinguish between the letters \"i\" and \"j\".\n\nAtomic orbitals are the basic building blocks of the atomic orbital model (alternatively known as the electron cloud or wave mechanics model), a modern framework for visualizing the submicroscopic behavior of electrons in matter. In this model the electron cloud of a multi-electron atom may be seen as being built up (in approximation) in an electron configuration that is a product of simpler hydrogen-like atomic orbitals. The repeating periodicity of the blocks of 2, 6, 10, and 14 elements within sections of the periodic table arises naturally from the total number of electrons that occupy a complete set of s, p, d, and f atomic orbitals, respectively, although for higher values of the quantum number, particularly when the atom in question bears a positive charge, the energies of certain sub-shells become very similar and so the order in which they are said to be populated by electrons (e.g. Cr = [Ar]4s13d5 and Cr2+ = [Ar]3d4) can only be rationalized somewhat arbitrarily.\n\nElectron properties \nWith the development of quantum mechanics and experimental findings (such as the two slit diffraction of electrons), it was found that the orbiting electrons around a nucleus could not be fully described as particles, but needed to be explained by the wave-particle duality. In this sense, the electrons have the following properties:\n\nWave-like properties:\n The electrons do not orbit the nucleus in the manner of a planet orbiting the sun, but instead exist as  standing waves. Thus the lowest possible energy an electron can take is similar to the  fundamental frequency of a wave on a string. Higher energy states are similar to harmonics of that fundamental frequency.\n The electrons are never in a single point location, although the probability of interacting with the electron at a single point can be found from the wave function of the electron.  The charge on the electron acts like it is smeared out in space in a continuous distribution, proportional at any point to the squared magnitude of the electron's wave function.\n\nParticle-like properties:\n The number of electrons orbiting the nucleus can only be an integer.\n Electrons jump between orbitals like particles. For example, if a single photon strikes the electrons, only a single electron changes states in response to the photon.\n The electrons retain particle-like properties such as: each wave state has the same electrical charge as its electron particle. Each wave state has a single discrete spin (spin up or spin down) depending on its superposition.\n\nThus, electrons cannot be described simply as solid particles. An analogy might be that of a large and often oddly shaped \"atmosphere\" (the electron), distributed around a relatively tiny planet (the atomic nucleus). Atomic orbitals exactly describe the shape of this \"atmosphere\" only when a single electron is present in an atom. When more electrons are added to a single atom, the additional electrons tend to more evenly fill in a volume of space around the nucleus so that the resulting collection (sometimes termed the atom's \"electron cloud\") tends toward a generally spherical zone of probability describing the electron's location, because of the uncertainty principle.\n\nFormal quantum mechanical definition \nAtomic orbitals may be defined more precisely in formal quantum mechanical language.  They are approximate solutions to the Schrodinger equation for the electrons bound to the atom by the electric field of the atom's nucleus. Specifically, in quantum mechanics, the state of an atom, i.e., an eigenstate of the atomic Hamiltonian, is approximated by an expansion (see configuration interaction expansion and basis set) into linear combinations of anti-symmetrized products (Slater determinants) of one-electron functions. The spatial components of these one-electron functions are called atomic orbitals. (When one considers also their spin component, one speaks of atomic spin orbitals.) A state is actually a function of the coordinates of all the electrons, so that their motion is correlated, but this is often approximated by this independent-particle model of products of single electron wave functions. (The London dispersion force, for example, depends on the correlations of the motion of the electrons.)\n\nIn atomic physics, the atomic spectral lines correspond to transitions (quantum leaps) between quantum states of an atom. These states are labeled by a set of quantum numbers summarized in the term symbol and usually associated with particular electron configurations, i.e., by occupation schemes of atomic orbitals (for example, 1s2\u00a02s2\u00a02p6 for the ground state of neon-term symbol: 1S0).\n\nThis notation means that the corresponding Slater determinants have a clear higher weight in the configuration interaction expansion. The atomic orbital concept is therefore a key concept for visualizing the excitation process associated with a given transition. For example, one can say for a given transition that it corresponds to the excitation of an electron from an occupied orbital to a given unoccupied orbital. Nevertheless, one has to keep in mind that electrons are fermions ruled by the Pauli exclusion principle and must be distinguished from each other. Moreover, it sometimes happens that the configuration interaction expansion converges very slowly and that one cannot speak about simple one-determinant wave function at all. This is the case when electron correlation is large.\n\nFundamentally, an atomic orbital is a one-electron wave function, even though most electrons do not exist in one-electron atoms, and so the one-electron view is an approximation. When thinking about orbitals, we are often given an orbital visualization heavily influenced by the Hartree\u2013Fock approximation, which is one way to reduce the complexities of molecular orbital theory.\n\nTypes of orbitals \n\nAtomic orbitals can be the hydrogen-like \"orbitals\" which are exact solutions to the Schr\u00f6dinger equation for a hydrogen-like \"atom\" (i.e., an atom with one electron). Alternatively, atomic orbitals refer to functions that depend on the coordinates of one electron (i.e., orbitals) but are used as starting points for approximating wave functions that depend on the simultaneous coordinates of all the electrons in an atom or molecule. The coordinate systems chosen for atomic orbitals are usually spherical coordinates  in atoms and Cartesian  in polyatomic molecules. The advantage of spherical coordinates (for atoms) is that an orbital wave function is a product of three factors each dependent on a single coordinate:. The angular factors of atomic orbitals  generate s, p, d, etc. functions as real combinations of spherical harmonics  (where  and  are quantum numbers). There are typically three mathematical forms for the radial functions\u00a0 which can be chosen as a starting point for the calculation of the properties of atoms and molecules with many electrons:\n\n The hydrogen-like atomic orbitals are derived from the exact solutions of the Schr\u00f6dinger Equation for one electron and a nucleus, for a hydrogen-like atom. The part of the function that depends on the distance r from the nucleus has nodes (radial nodes) and decays as.\n The Slater-type orbital (STO) is a form without radial nodes but decays from the nucleus as does the hydrogen-like orbital.\n The form of the Gaussian type orbital (Gaussians) has no radial nodes and decays as.\n\nAlthough hydrogen-like orbitals are still used as pedagogical tools, the advent of computers has made STOs preferable for atoms and diatomic molecules since combinations of STOs can replace the nodes in hydrogen-like atomic orbital. Gaussians are typically used in molecules with three or more atoms. Although not as accurate by themselves as STOs, combinations of many Gaussians can attain the accuracy of hydrogen-like orbitals.\n\nHistory \n\nThe term \"orbital\" was coined by Robert Mulliken in 1932 as an abbreviation for one-electron orbital wave function. However, the idea that electrons might revolve around a compact nucleus with definite angular momentum was convincingly argued at least 19 years earlier by Niels Bohr, and the Japanese physicist Hantaro Nagaoka published an orbit-based hypothesis for electronic behavior as early as 1904. Explaining the behavior of these electron \"orbits\" was one of the driving forces behind the development of quantum mechanics.\n\nEarly models \nWith J. J. Thomson's discovery of the electron in 1897, it became clear that atoms were not the smallest building blocks of nature, but were rather composite particles. The newly discovered structure within atoms tempted many to imagine how the atom's constituent parts might interact with each other. Thomson theorized that multiple electrons revolved in orbit-like rings within a positively charged jelly-like substance, and between the electron's discovery and 1909, this \"plum pudding model\" was the most widely accepted explanation of atomic structure.\n\nShortly after Thomson's discovery, Hantaro Nagaoka predicted a different model for electronic structure. Unlike the plum pudding model, the positive charge in Nagaoka's \"Saturnian Model\" was concentrated into a central core, pulling the electrons into circular orbits reminiscent of Saturn's rings. Few people took notice of Nagaoka's work at the time, and Nagaoka himself recognized a fundamental defect in the theory even at its conception, namely that a classical charged object cannot sustain orbital motion because it is accelerating and therefore loses energy due to electromagnetic radiation. Nevertheless, the Saturnian model turned out to have more in common with modern theory than any of its contemporaries.\n\nBohr atom \nIn 1909, Ernest Rutherford discovered that the bulk of the atomic mass was tightly condensed into a nucleus, which was also found to be positively charged. It became clear from his analysis in 1911 that the plum pudding model could not explain atomic structure. In 1913, Rutherford's post-doctoral student, Niels Bohr, proposed a new model of the atom, wherein electrons orbited the nucleus with classical periods, but were only permitted to have discrete values of angular momentum, quantized in units h/2\u03c0. This constraint automatically permitted only certain values of electron energies. The Bohr model of the atom fixed the problem of energy loss from radiation from a ground state (by declaring that there was no state below this), and more importantly explained the origin of spectral lines.\n\nAfter Bohr's use of Einstein's explanation of the photoelectric effect to relate energy levels in atoms with the wavelength of emitted light, the connection between the structure of electrons in atoms and the emission and absorption spectra of atoms became an increasingly useful tool in the understanding of electrons in atoms. The most prominent feature of emission and absorption spectra (known experimentally since the middle of the 19th century), was that these atomic spectra contained discrete lines. The significance of the Bohr model was that it related the lines in emission and absorption spectra to the energy differences between the orbits that electrons could take around an atom. This was, however, not achieved by Bohr through giving the electrons some kind of wave-like properties, since the idea that electrons could behave as matter waves was not suggested until eleven years later. Still, the Bohr model's use of quantized angular momenta and therefore quantized energy levels was a significant step towards the understanding of electrons in atoms, and also a significant step towards the development of quantum mechanics in suggesting that quantized restraints must account for all discontinuous energy levels and spectra in atoms.\n\nWith de Broglie's suggestion of the existence of electron matter waves in 1924, and for a short time before the full 1926 Schr\u00f6dinger equation treatment of hydrogen-like atoms, a Bohr electron \"wavelength\" could be seen to be a function of its momentum, and thus a Bohr orbiting electron was seen to orbit in a circle at a multiple of its half-wavelength. The Bohr model for a short time could be seen as a classical model with an additional constraint provided by the 'wavelength' argument. However, this period was immediately superseded by the full three-dimensional wave mechanics of 1926. In our current understanding of physics, the Bohr model is called a semi-classical model because of its quantization of angular momentum, not primarily because of its relationship with electron wavelength, which appeared in hindsight a dozen years after the Bohr model was proposed.\n\nThe Bohr model was able to explain the emission and absorption spectra of hydrogen. The energies of electrons in the n\u00a0=\u00a01, 2, 3, etc. states in the Bohr model match those of current physics. However, this did not explain similarities between different atoms, as expressed by the periodic table, such as the fact that helium (two electrons), neon (10 electrons), and argon (18 electrons) exhibit similar chemical inertness. Modern quantum mechanics explains this in terms of electron shells and subshells which can each hold a number of electrons determined by the Pauli exclusion principle. Thus the n\u00a0=\u00a01 state can hold one or two electrons, while the n = 2 state can hold up to eight electrons in 2s and 2p subshells. In helium, all n\u00a0=\u00a01 states are fully occupied; the same is true for n\u00a0=\u00a01 and n\u00a0=\u00a02 in neon. In argon, the 3s and 3p subshells are similarly fully occupied by eight electrons; quantum mechanics also allows a 3d subshell but this is at higher energy than the 3s and 3p in argon (contrary to the situation in the hydrogen atom) and remains empty.\n\nModern conceptions and connections to the Heisenberg uncertainty principle \nImmediately after Heisenberg discovered his uncertainty principle, Bohr noted that the existence of any sort of wave packet implies uncertainty in the wave frequency and wavelength, since a spread of frequencies is needed to create the packet itself. In quantum mechanics, where all particle momenta are associated with waves, it is the formation of such a wave packet which localizes the wave, and thus the particle, in space. In states where a quantum mechanical particle is bound, it must be localized as a wave packet, and the existence of the packet and its minimum size implies a spread and minimal value in particle wavelength, and thus also momentum and energy. In quantum mechanics, as a particle is localized to a smaller region in space, the associated compressed wave packet requires a larger and larger range of momenta, and thus larger kinetic energy. Thus the binding energy to contain or trap a particle in a smaller region of space increases without bound as the region of space grows smaller. Particles cannot be restricted to a geometric point in space, since this would require an infinite particle momentum.\n\nIn chemistry, Schr\u00f6dinger, Pauling, Mulliken and others noted that the consequence of Heisenberg's relation was that the electron, as a wave packet, could not be considered to have an exact location in its orbital. Max Born suggested that the electron's position needed to be described by a probability distribution which was connected with finding the electron at some point in the wave-function which described its associated wave packet. The new quantum mechanics did not give exact results, but only the probabilities for the occurrence of a variety of possible such results. Heisenberg held that the path of a moving particle has no meaning if we cannot observe it, as we cannot with electrons in an atom.\n\nIn the quantum picture of Heisenberg, Schr\u00f6dinger and others, the Bohr atom number\u00a0n for each orbital became known as an n-sphere in a three-dimensional atom and was pictured as the most probable energy of the probability cloud of the electron's wave packet which surrounded the atom.\n\nOrbital names\n\nOrbital notation and subshells\nOrbitals have been given names, which are usually given in the form:\n\nwhere X is the energy level corresponding to the principal quantum number ; type is a lower-case letter denoting the shape or subshell of the orbital, corresponding to the angular momentum quantum number\u00a0. \n\nFor example, the orbital 1s (pronounced as the individual numbers and letters: \"'one' 'ess'\") is the lowest energy level () and has an angular quantum number of, denoted as s. Orbitals with  are denoted as p, d and f respectively.\n\nThe set of orbitals for a given n and  is called a subshell, denoted \n. \nThe exponent y shows the number of electrons in the subshell. For example, the notation 2p4 indicates that the 2p subshell of an atom contains 4 electrons. This subshell has 3 orbitals, each with n = 2 and  = 1.\n\nX-ray notation\n\nThere is also another, less common system still used in X-ray science known as X-ray notation, which is a continuation of the notations used before orbital theory was well understood. In this system, the principal quantum number is given a letter associated with it. For, the letters associated with those numbers are K, L, M, N, O,... respectively.\n\nHydrogen-like orbitals \n\nThe simplest atomic orbitals are those that are calculated for systems with a single electron, such as the hydrogen atom. An atom of any other element ionized down to a single electron is very similar to hydrogen, and the orbitals take the same form. In the Schr\u00f6dinger equation for this system of one negative and one positive particle, the atomic orbitals are the eigenstates of the Hamiltonian operator for the energy. They can be obtained analytically, meaning that the resulting orbitals are products of a polynomial series, and exponential and trigonometric functions. (see hydrogen atom).\n\nFor atoms with two or more electrons, the governing equations can only be solved with the use of methods of iterative approximation. Orbitals of multi-electron atoms are qualitatively similar to those of hydrogen, and in the simplest models, they are taken to have the same form. For more rigorous and precise analysis, numerical approximations must be used.\n\nA given (hydrogen-like) atomic orbital is identified by unique values of three quantum numbers:,, and. The rules restricting the values of the quantum numbers, and their energies (see below), explain the electron configuration of the atoms and the periodic table.\n\nThe stationary states (quantum states) of the hydrogen-like atoms are its atomic orbitals. However, in general, an electron's behavior is not fully described by a single orbital. Electron states are best represented by time-depending \"mixtures\" (linear combinations) of multiple orbitals. See Linear combination of atomic orbitals molecular orbital method.\n\nThe quantum number  first appeared in the Bohr model where it determines the radius of each circular electron orbit. In modern quantum mechanics however,  determines the mean distance of the electron from the nucleus; all electrons with the same value of n lie at the same average distance. For this reason, orbitals with the same value of n are said to comprise a \"shell\". Orbitals with the same value of n and also the same value of\u00a0 are even more closely related, and are said to comprise a \"subshell\".\n\nQuantum numbers \n\nBecause of the quantum mechanical nature of the electrons around a nucleus, atomic orbitals can be uniquely defined by a set of integers known as quantum numbers. These quantum numbers only occur in certain combinations of values, and their physical interpretation changes depending on whether real or complex versions of the atomic orbitals are employed.\n\nComplex orbitals \n\nIn physics, the most common orbital descriptions are based on the solutions to the hydrogen atom, where orbitals are given by the product between a radial function and a pure spherical harmonic. The quantum numbers, together with the rules governing their possible values, are as follows:\n\nThe principal quantum number  describes the energy of the electron and is always a positive integer. In fact, it can be any positive integer, but for reasons discussed below, large numbers are seldom encountered. Each atom has, in general, many orbitals associated with each value of n; these orbitals together are sometimes called electron shells.\n\nThe azimuthal quantum number  describes the orbital angular momentum of each electron and is a non-negative integer. Within a shell where  is some integer,  ranges across all (integer) values satisfying the relation. For instance, the \u00a0shell has only orbitals with, and the \u00a0shell has only orbitals with, and. The set of orbitals associated with a particular value of\u00a0 are sometimes collectively called a subshell.\n\nThe magnetic quantum number,, describes the magnetic moment of an electron in an arbitrary direction, and is also always an integer. Within a subshell where  is some integer,  ranges thus:.\n\nThe above results may be summarized in the following table. Each cell represents a subshell, and lists the values of  available in that subshell. Empty cells represent subshells that do not exist.\n\nSubshells are usually identified by their - and -values.  is represented by its numerical value, but  is represented by a letter as follows: 0 is represented by's', 1 by 'p', 2 by 'd', 3 by 'f', and 4 by 'g'. For instance, one may speak of the subshell with  and  as a '2s subshell'.\n\nEach electron also has a spin quantum number, s, which describes the spin of each electron (spin up or spin down). The number s can be + or \u2212.\n\nThe Pauli exclusion principle states that no two electrons in an atom can have the same values of all four quantum numbers. If there are two electrons in an orbital with given values for three quantum numbers, (,, ), these two electrons must differ in their spin.\n\nThe above conventions imply a preferred axis (for example, the z direction in Cartesian coordinates), and they also imply a preferred direction along this preferred axis. Otherwise there would be no sense in distinguishing  from. As such, the model is most useful when applied to physical systems that share these symmetries. The Stern\u2013Gerlach experiment \u2014 where an atom is exposed to a magnetic field \u2014 provides one such example.\n\nReal orbitals \n\nIn addition to the complex orbitals described above, it is common, especially in the chemistry literature, to utilize real atomic orbitals. These real orbitals arise from simple linear combinations of the complex orbitals. Using the Condon-Shortley phase convention, the real atomic orbitals are related to the complex", "flag": 1, "segments": [[46, 56]], "strength": 5.5}
{"text": "Alan Mathison Turing  (; 23 June 1912\u00a0\u2013 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science and artificial intelligence.\n\nBorn in Maida Vale, London, Turing was raised in southern England. He graduated at King's College, Cambridge, with a degree in mathematics. Whilst he was a fellow at Cambridge, he published a proof demonstrating that some purely mathematical yes\u2013no questions can never be answered by computation and defined a Turing machine, and went on to prove the halting problem for Turing machines is undecidable. In 1938, he obtained his PhD from the Department of Mathematics at Princeton University. During the Second World War, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. For a time he led Hut 8, the section that was responsible for German naval cryptanalysis. Here, he devised a number of techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bombe method, an electromechanical machine that could find settings for the Enigma machine. Turing played a crucial role in cracking intercepted coded messages that enabled the Allies to defeat the Axis powers in many crucial engagements, including the Battle of the Atlantic.\n\nAfter the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine (ACE), one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory, at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. He wrote a paper on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov\u2013Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised in his home country during his lifetime because much of his work was covered by the Official Secrets Act.\n\nTuring was prosecuted in 1952 for homosexual acts. He accepted hormone treatment with DES, so-called chemical castration, as an alternative to prison. In 2009, following an Internet campaign, British Prime Minister Gordon Brown made an official public apology on behalf of the British government for \"the appalling way he was treated\". Queen Elizabeth II granted Turing a posthumous pardon in 2013. The \"Alan Turing law\" is now an informal term for a 2017 law in the United Kingdom that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts. \n\nTuring died in 1954, 16 days before his 42nd birthday, from cyanide poisoning. An inquest determined his death as a suicide, but it has been noted that the known evidence is also consistent with accidental poisoning.\n\nTuring has an extensive legacy with statues of him and many things named after him, including an annual award for computer science innovations. He appears on the current Bank of England \u00a350 note, which was released to coincide with his birthday. A 2019 BBC series, as voted by the audience, named him the greatest person of the 20th century.\n\nEarly life and education\n\nFamily\nTuring was born in Maida Vale, London, while his father, Julius Mathison Turing (1873\u20131947), was on leave from his position with the Indian Civil Service (ICS) at Chatrapur, then in the Madras Presidency and presently in Odisha state, in India. Turing's father was the son of a clergyman, the Rev.\u00a0John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius's wife, was Ethel Sara Turing (; 1881\u20131976), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare.\n\nJulius's work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John (the father of Sir John Dermot Turing, 12th Baronet of the Turing baronets).\n\nTuring's father's civil service commission was still active and during Turing's childhood years, his parents travelled between Hastings in the United Kingdom and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2012, the centenary of Turing's birth.\n\nVery early in life, Turing showed signs of the genius that he was later to display prominently. His parents purchased a house in Guildford in 1927, and Turing lived there during school holidays. The location is also marked with a blue plaque.\n\nSchool\nTuring's parents enrolled him at St Michael's, a primary school at 20 Charles Road, St Leonards-on-Sea, from the age of six to nine. The headmistress recognised his talent, noting that she has \"...had clever boys and hardworking boys, but Alan is a genius.\"\n\nBetween January 1922 and 1926, Turing was educated at Hazelhurst Preparatory School, an independent school in the village of Frant in Sussex (now East Sussex). In 1926, at the age of 13, he went on to Sherborne School, a boarding independent school in the market town of Sherborne in Dorset, where he boarded at Westcott House. The first day of term coincided with the 1926 General Strike, in Britain, but Turing was so determined to attend, that he rode his bicycle unaccompanied  from Southampton to Sherborne, stopping overnight at an inn.\n\nTuring's natural inclination towards mathematics and science did not earn him respect from some of the teachers at Sherborne, whose definition of education placed more emphasis on the classics. His headmaster wrote to his parents: \"I hope he will not fall between two stools. If he is to stay at public school, he must aim at becoming educated. If he is to be solely a Scientific Specialist, he is wasting his time at a public school\". Despite this, Turing continued to show remarkable ability in the studies he loved, solving advanced problems in 1927 without having studied even elementary calculus. In 1928, aged 16, Turing encountered Albert Einstein's work; not only did he grasp it, but it is possible that he managed to deduce Einstein's questioning of Newton's laws of motion from a text in which this was never made explicit.\n\nChristopher Morcom\nAt Sherborne, Turing formed a significant friendship with fellow pupil Christopher Collan Morcom (13 July 1911 \u2013 13 February 1930), who has been described as Turing's \"first love\". Their relationship provided inspiration in Turing's of Rezaian and another reporter, Izz future endeavours, but it was cut short by Morcom's death, in February 1930, from complications of bovine tuberculosis, contracted after drinking infected cow's milk some years previously.\n\nThe event caused Turing great sorrow. He coped with his grief by working that much harder on the topics of science and mathematics that he had shared with Morcom. In a letter to Morcom's mother, Frances Isobel Morcom (n\u00e9e Swan), Turing wrote:\n\nTuring's relationship with Morcom's mother continued long after Morcom's death, with her sending gifts to Turing, and him sending letters, typically on Morcom's birthday. A day before the third anniversary of Morcom's death (13 February 1933), he wrote to Mrs. Morcom: \n\nSome have speculated that Morcom's death was the cause of Turing's atheism and materialism. Apparently, at this point in his life he still believed in such concepts as a spirit, independent of the body and surviving death. In a later letter, also written to Morcom's mother, Turing wrote:\n\nUniversity and work on computability\nAfter Sherborne, Turing studied as an undergraduate from 1931 to 1934 at King's College, Cambridge, where he was awarded first-class honours in mathematics. In 1935, at the age of 22, he was elected a Fellow of King's College on the strength of a dissertation in which he proved the central limit theorem. Unknown to the committee, the theorem had already been proven, in 1922, by Jarl Waldemar Lindeberg.\n\nIn 1936, Turing published his paper \"On Computable Numbers, with an Application to the Entscheidungsproblem\". It was published in the Proceedings of the London Mathematical Society journal in two parts, the first on 30 November and the second on 23 December. In this paper, Turing reformulated Kurt G\u00f6del's 1931 results on the limits of proof and computation, replacing G\u00f6del's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. The Entscheidungsproblem (decision problem) was originally posed by German mathematician David Hilbert in 1928. Turing proved that his \"universal computing machine\" would be capable of performing any conceivable mathematical computation if it were representable as an algorithm. He went on to prove that there was no solution to the decision problem by first showing that the halting problem for Turing machines is undecidable: it is not possible to decide algorithmically whether a Turing machine will ever halt.  This paper has been called \"easily the most influential math paper in history\".\n\nAlthough Turing's proof was published shortly after Alonzo Church's equivalent proof using his lambda calculus, Turing's approach is considerably more accessible and intuitive than Church's. It also included a notion of a 'Universal Machine' (now known as a universal Turing machine), with the idea that such a machine could perform the tasks of any other computation machine (as indeed could Church's lambda calculus). According to the Church\u2013Turing thesis, Turing machines and the lambda calculus are capable of computing anything that is computable. John von Neumann acknowledged that the central concept of the modern computer was due to Turing's paper. To this day, Turing machines are a central object of study in theory of computation.\n\nFrom September 1936 to July 1938, Turing spent most of his time studying under Church at Princeton University, in the second year as a Jane Eliza Procter Visiting Fellow. In addition to his purely mathematical work, he studied cryptology and also built three of four stages of an electro-mechanical binary multiplier. In June 1938, he obtained his PhD from the Department of Mathematics at Princeton; his dissertation, Systems of Logic Based on Ordinals, introduced the concept of ordinal logic and the notion of relative computing, in which Turing machines are augmented with so-called oracles, allowing the study of problems that cannot be solved by Turing machines. John von Neumann wanted to hire him as his postdoctoral assistant, but he went back to the United Kingdom.\n\nCareer and research\nWhen Turing returned to Cambridge, he attended lectures given in 1939 by Ludwig Wittgenstein about the foundations of mathematics. The lectures have been reconstructed verbatim, including interjections from Turing and other students, from students' notes. Turing and Wittgenstein argued and disagreed, with Turing defending formalism and Wittgenstein propounding his view that mathematics does not discover any absolute truths, but rather invents them.\n\nCryptanalysis\nDuring the Second World War, Turing was a leading participant in the breaking of German ciphers at Bletchley Park. The historian and wartime codebreaker Asa Briggs has said, \"You needed exceptional talent, you needed genius at Bletchley and Turing's was that genius.\"\n\nFrom September 1938, Turing worked part-time with the Government Code and Cypher School (GC&CS), the British codebreaking organisation. He concentrated on cryptanalysis of the Enigma cipher machine used by Nazi Germany, together with Dilly Knox, a senior GC&CS codebreaker. Soon after the July 1939 meeting near Warsaw at which the Polish Cipher Bureau gave the British and French details of the wiring of Enigma machine's rotors and their method of decrypting Enigma machine's messages, Turing and Knox developed a broader solution. The Polish method relied on an insecure indicator procedure that the Germans were likely to change, which they in fact did in May 1940. Turing's approach was more general, using crib-based decryption for which he produced the functional specification of the bombe (an improvement on the Polish Bomba).\n\nOn 4 September 1939, the day after the UK declared war on Germany, Turing reported to Bletchley Park, the wartime station of GC&CS. Like all others who came to Bletchley, he was required to sign the Official Secrets Act, in which he agreed not to disclose anything about his work at Bletchley, with severe legal penalties for violating the Act.\n\nSpecifying the bombe was the first of five major cryptanalytical advances that Turing made during the war. The others were: deducing the indicator procedure used by the German navy; developing a statistical procedure dubbed Banburismus for making much more efficient use of the bombes; developing a procedure dubbed Turingery for working out the cam settings of the wheels of the Lorenz SZ 40/42 (Tunny) cipher machine and, towards the end of the war, the development of a portable secure voice scrambler at Hanslope Park that was codenamed Delilah.\n\nBy using statistical techniques to optimise the trial of different possibilities in the code breaking process, Turing made an innovative contribution to the subject. He wrote two papers discussing mathematical approaches, titled The Applications of Probability to Cryptography and Paper on Statistics of Repetitions, which were of such value to GC&CS and its successor GCHQ that they were not released to the UK National Archives until April 2012, shortly before the centenary of his birth. A GCHQ mathematician, \"who identified himself only as Richard,\" said at the time that the fact that the contents had been restricted under the Official Secrets Act for some 70 years demonstrated their importance, and their relevance to post-war cryptanalysis: \n\nTuring had a reputation for eccentricity at Bletchley Park. He was known to his colleagues as \"Prof\" and his treatise on Enigma was known as the \"Prof's Book\". According to historian Ronald Lewin, Jack Good, a cryptanalyst who worked with Turing, said of his colleague:\n\nPeter Hilton recounted his experience working with Turing in Hut 8 in his \"Reminiscences of Bletchley Park\" from A Century of Mathematics in America:\n\nHilton echoed similar thoughts in the Nova PBS documentary Decoding Nazi Secrets.\n\nWhile working at Bletchley, Turing, who was a talented long-distance runner, occasionally ran the  to London when he was needed for meetings, and he was capable of world-class marathon standards. Turing tried out for the 1948 British Olympic team, but he was hampered by an injury. His tryout time for the marathon was only 11 minutes slower than British silver medallist Thomas Richards' Olympic race time of 2 hours 35 minutes. He was Walton Athletic Club's best runner, a fact discovered when he passed the group while running alone. When asked why he ran so hard in training he replied:\n\nDue to the problems of counterfactual history, it is hard to estimate the precise effect Ultra intelligence had on the war. However, official war historian Harry Hinsley estimated that this work shortened the war in Europe by more than two years and saved over 14\u00a0million lives.\n\nAt the end of the war, a memo was sent to all those who had worked at Bletchley Park, reminding them that the code of silence dictated by the Official Secrets Act did not end with the war but would continue indefinitely. Thus, even though Turing was appointed an Officer of the Order of the British Empire (OBE) in 1946 by King George VI for his wartime services, his work remained secret for many years.\n\nBombe\n\nWithin weeks of arriving at Bletchley Park, Turing had specified an electromechanical machine called the bombe, which could break Enigma more effectively than the Polish bomba kryptologiczna, from which its name was derived. The bombe, with an enhancement suggested by mathematician Gordon Welchman, became one of the primary tools, and the major automated one, used to attack Enigma-enciphered messages.\n\nThe bombe searched for possible correct settings used for an Enigma message (i.e., rotor order, rotor settings and plugboard settings) using a suitable crib: a fragment of probable plaintext. For each possible setting of the rotors (which had on the order of 1019 states, or 1022 states for the four-rotor U-boat variant), the bombe performed a chain of logical deductions based on the crib, implemented electromechanically.\n\nThe bombe detected when a contradiction had occurred and ruled out that setting, moving on to the next. Most of the possible settings would cause contradictions and be discarded, leaving only a few to be investigated in detail. A contradiction would occur when an enciphered letter would be turned back into the same plaintext letter, which was impossible with the Enigma. The first bombe was installed on 18 March 1940.\n\nBy late 1941, Turing and his fellow cryptanalysts Gordon Welchman, Hugh Alexander and Stuart Milner-Barry were frustrated. Building on the work of the Poles, they had set up a good working system for decrypting Enigma signals, but their limited staff and bombes meant they could not translate all the signals. In the summer, they had considerable success, and shipping losses had fallen to under 100,000 tons a month; however, they badly needed more resources to keep abreast of German adjustments. They had tried to get more people and fund more bombes through the proper channels, but had failed.\n\nOn 28 October they wrote directly to Winston Churchill explaining their difficulties, with Turing as the first named. They emphasised how small their need was compared with the vast expenditure of men and money by the forces and compared with the level of assistance they could offer to the forces. As Andrew Hodges, biographer of Turing, later wrote, \"This letter had an electric effect.\" Churchill wrote a memo to General Ismay, which read: \"ACTION THIS DAY. Make sure they have all they want on extreme priority and report to me that this has been done.\" On 18 November, the chief of the secret service reported that every possible measure was being taken. The cryptographers at Bletchley Park did not know of the Prime Minister's response, but as Milner-Barry recalled, \"All that we did notice was that almost from that day the rough ways began miraculously to be made smooth.\" More than two hundred bombes were in operation by the end of the war.\n\nHut 8 and the naval Enigma\nTuring decided to tackle the particularly difficult problem of German naval Enigma \"because no one else was doing anything about it and I could have it to myself\". In December 1939, Turing solved the essential part of the naval indicator system, which was more complex than the indicator systems used by the other services.\n\nThat same night, he also conceived of the idea of Banburismus, a sequential statistical technique (what Abraham Wald later called sequential analysis) to assist in breaking the naval Enigma, \"though I was not sure that it would work in practice, and was not, in fact, sure until some days had actually broken.\" For this, he invented a measure of weight of evidence that he called the ban. Banburismus could rule out certain sequences of the Enigma rotors, substantially reducing the time needed to test settings on the bombes. Later this sequential process of accumulating sufficient weight of evidence using decibans (one tenth of a ban) was used in Cryptanalysis of the Lorenz cipher.\n\nTuring travelled to the United States in November 1942 and worked with US Navy cryptanalysts on the naval Enigma and bombe construction in Washington; he also visited their Computing Machine Laboratory in Dayton, Ohio.\n\nTuring's reaction to the American bombe design was far from enthusiastic:\n\nDuring this trip, he also assisted at Bell Labs with the development of secure speech devices. He returned to Bletchley Park in March 1943. During his absence, Hugh Alexander had officially assumed the position of head of Hut 8, although Alexander had been de facto head for some time (Turing having little interest in the day-to-day running of the section). Turing became a general consultant for cryptanalysis at Bletchley Park.\n\nAlexander wrote of Turing's contribution:\n\nTuringery\nIn July 1942, Turing devised a technique termed Turingery (or jokingly Turingismus) for use against the Lorenz cipher messages produced by the Germans' new Geheimschreiber (secret writer) machine. This was a teleprinter rotor cipher attachment codenamed Tunny at Bletchley Park. Turingery was a method of wheel-breaking, i.e., a procedure for working out the cam settings of Tunny's wheels. He also introduced the Tunny team to Tommy Flowers who, under the guidance of Max Newman, went on to build the Colossus computer, the world's first programmable digital electronic computer, which replaced a simpler prior machine (the Heath Robinson), and whose superior speed allowed the statistical decryption techniques to be applied usefully to the messages. Some have mistakenly said that Turing was a key figure in the design of the Colossus computer. Turingery and the statistical approach of Banburismus undoubtedly fed into the thinking about cryptanalysis of the Lorenz cipher, but he was not directly involved in the Colossus development.\n\nDelilah\nFollowing his work at Bell Labs in the US, Turing pursued the idea of electronic enciphering of speech in the telephone system. In the latter part of the war, he moved to work for the Secret Service's Radio Security Service (later HMGCC) at Hanslope Park. At the park, he further developed his knowledge of electronics with the assistance of engineer Donald Bayley. Together they undertook the design and construction of a portable secure voice communications machine codenamed Delilah. The machine was intended for different applications, but it lacked the capability for use with long-distance radio transmissions. In any case, Delilah was completed too late to be used during the war. Though the system worked fully, with Turing demonstrating it to officials by encrypting and decrypting a recording of a Winston Churchill speech, Delilah was not adopted for use. Turing also consulted with Bell Labs on the development of SIGSALY, a secure voice system that was used in the later years of the war.\n\nEarly computers and the Turing test\n\nBetween 1945 and 1947, Turing lived in Hampton, London, while he worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory (NPL). He presented a paper on 19 February 1946, which was the first detailed design of a stored-program computer. Von Neumann's incomplete First Draft of a Report on the EDVAC had predated Turing's paper, but it was much less detailed and, according to John R. Womersley, Superintendent of the NPL Mathematics Division, it \"contains a number of ideas which are Dr. Turing's own\".\n\nAlthough ACE was a feasible design, the effect of the Official Secrets Act surrounding the wartime work at Bletchley Park made it impossible", "flag": 1, "segments": [[1533, 1543]], "strength": 5.5}
{"text": "Anglicanism is a Western Christian tradition that has developed from the practices, liturgy, and identity of the Church of England following the English Reformation, in the context of the Protestant Reformation in Europe. It is one of the largest branches of Christianity, with around 110 million adherents worldwide.\n\nAdherents of Anglicanism are called Anglicans; they are also called Episcopalians in some countries. The majority of Anglicans are members of national or regional ecclesiastical provinces of the international Anglican Communion, which forms the third-largest Christian communion in the world, after the Roman Catholic Church and the Eastern Orthodox Church. These provinces are in full communion with the See of Canterbury and thus with the British Monarch\u2019s personal choice of the Archbishop of Canterbury, whom the communion refers to as its primus inter pares (Latin, 'first among equals'). The Archbishop calls the decennial Lambeth Conference, chairs the meeting of primates, and is the president of the Anglican Consultative Council. Some churches that are not part of the Anglican Communion or recognised by it also call themselves Anglican, including those that are within the Continuing Anglican movement and Anglican realignment.\n\nAnglicans base their Christian faith on the Bible, traditions of the apostolic Church, apostolic succession (\"historic episcopate\"), and the writings of the Church Fathers. Anglicanism forms one of the branches of Western Christianity, having definitively declared its independence from the Holy See at the time of the Elizabethan Religious Settlement. Many of the new Anglican formularies of the mid-16th century corresponded closely to those of contemporary Protestantism. These reforms in the Church of England were understood by one of those most responsible for them, Thomas Cranmer, the Archbishop of Canterbury, and others as navigating a middle way between two of the emerging Protestant traditions, namely Lutheranism and Calvinism.\n\nIn the first half of the 17th century, the Church of England and its associated Church of Ireland were presented by some Anglican divines as comprising a distinct Christian tradition, with theologies, structures, and forms of worship representing a different kind of middle way, or via media, between Protestantism and Catholicism \u2013 a perspective that came to be highly influential in later theories of Anglican identity and expressed in the description of Anglicanism as \"catholic and reformed\". The degree of distinction between Protestant and Catholic tendencies within the Anglican tradition is routinely a matter of debate both within specific Anglican churches and throughout the Anglican Communion. Unique to Anglicanism is the Book of Common Prayer, the collection of services in one Book used for centuries. The Book is acknowledged as a principal tie that binds the Anglican Communion together as a liturgical rather than a confessional tradition or one possessing a magisterium as in the Roman Catholic Church.\n\nAfter the American Revolution, Anglican congregations in the United States and British North America (which would later form the basis for the modern country of Canada) were each reconstituted into autonomous churches with their own bishops and self-governing structures; these were known as the American Episcopal Church and the Church of England in the Dominion of Canada. Through the expansion of the British Empire and the activity of Christian missions, this model was adopted as the model for many newly formed churches, especially in Africa, Australasia, and Asia-Pacific. In the 19th century, the term Anglicanism was coined to describe the common religious tradition of these churches; as also that of the Scottish Episcopal Church, which, though originating earlier within the Church of Scotland, had come to be recognised as sharing this common identity.\n\nTerminology\n\nThe word Anglican originates in, a phrase from the Magna Carta dated 15 June 1215, meaning \"the Anglican Church shall be free\". Adherents of Anglicanism are called Anglicans. As an adjective, \"Anglican\" is used to describe the people, institutions, and churches, as well as the liturgical traditions and theological concepts developed by the Church of England.\n\nAs a noun, an Anglican is a member of a church in the Anglican Communion. The word is also used by followers of separated groups which have left the communion or have been founded separately from it, although this is considered as a misuse by the Anglican Communion. The word Anglicanism came into being in the 19th century. The word originally referred only to the teachings and rites of Christians throughout the world in communion with the see of Canterbury, but has come to sometimes be extended to any church following those traditions rather than actual membership in the modern Anglican Communion.\n\nAlthough the term Anglican is found referring to the Church of England as far back as the 16th century, its use did not become general until the latter half of the 19th century. In British parliamentary legislation referring to the English Established Church, there is no need for a description; it is simply the Church of England, though the word \"Protestant\" is used in many legal acts specifying the succession to the Crown and qualifications for office. When the Union with Ireland Act created the United Church of England and Ireland, it is specified that it shall be one \"Protestant Episcopal Church\", thereby distinguishing its form of church government from the Presbyterian polity that prevails in the Church of Scotland.\n\nThe word Episcopal is preferred in the title of the Episcopal Church (the province of the Anglican Communion covering the United States) and the Scottish Episcopal Church, though the full name of the former is The Protestant Episcopal Church of the United States of America. Elsewhere, however, the term \"Anglican Church\" came to be preferred as it distinguished these churches from others that maintain an episcopal polity.\n\nDefinition\nAnglicanism, in its structures, theology, and forms of worship, is commonly understood as a distinct Christian tradition representing a middle ground between what are perceived to be the extremes of the claims of 16th-century Roman Catholicism and the Lutheran and Reformed varieties of Protestantism of that era. As such, it is often referred to as being a via media (or \"middle way\") between these traditions.\n\nThe faith of Anglicans is founded in the Scriptures and the Gospels, the traditions of the Apostolic Church, the historical episcopate, the first four ecumenical councils, and the early Church Fathers (among these councils, especially the premier four ones, and among these Fathers, especially those active during the five initial centuries of Christianity, according to the quinquasaecularist principle proposed by the English bishop Lancelot Andrewes and the Lutheran dissident Georg Calixtus). Anglicans understand the Old and New Testaments as \"containing all things necessary for salvation\" and as being the rule and ultimate standard of faith. Reason and tradition are seen as valuable means to interpret scripture (a position first formulated in detail by Richard Hooker), but there is no full mutual agreement among Anglicans about exactly how scripture, reason, and tradition interact (or ought to interact) with each other. Anglicans understand the Apostles' Creed as the baptismal symbol and the Nicene Creed as the sufficient statement of the Christian faith.\n\nAnglicans believe the catholic and apostolic faith is revealed in Holy Scripture and the Catholic creeds and interpret these in light of the Christian tradition of the historic church, scholarship, reason, and experience.\n\nAnglicans celebrate the traditional sacraments, with special emphasis being given to the Eucharist, also called Holy Communion, the Lord's Supper or the Mass. The Eucharist is central to worship for most Anglicans as a communal offering of prayer and praise in which the life, death, and resurrection of Jesus Christ are proclaimed through prayer, reading of the Bible, singing, giving God thanks over the bread and wine for the innumerable benefits obtained through the passion of Christ, the breaking of the bread, the blessing of the cup, and the partaking of the body and blood of Christ as instituted at the Last Supper, however one wished to define the Presence. The consecrated bread and wine, which are the true body and blood of Christ after a spiritual manner, are outward symbols of an inner grace given by Christ, which to the repentant conveys forgiveness and cleaning from sin. While many Anglicans celebrate the Eucharist in similar ways to the predominant western Catholic tradition, a considerable degree of liturgical freedom is permitted, and worship styles range from the simple to elaborate.\n\nUnique to Anglicanism is the Book of Common Prayer (BCP), the collection of services that worshippers in most Anglican churches have used for centuries. It was called common prayer originally because it was intended for use in all Church of England churches, which had previously followed differing local liturgies. The term was kept when the church became international, because all Anglicans used to share in its use around the world.\n\nIn 1549, the first Book of Common Prayer was compiled by Thomas Cranmer, who was then Archbishop of Canterbury. While it has since undergone many revisions and Anglican churches in different countries have developed other service books, the Prayer Book is still acknowledged as one of the ties that bind Anglicans together.\n\nIdentity\n\nEarly history\n\nThe founding of Christianity in Britain is commonly attributed to Joseph of Arimathea, according to Anglican legend, and is commemorated in Glastonbury Abbey. Many of the early Church Fathers wrote of the presence of Christianity in Roman Britain, with Tertullian stating \"those parts of Britain into which the Roman arms had never penetrated were become subject to Christ\". Saint Alban, who was executed in AD 209, is the first Christian martyr in the British Isles. For this reason he is venerated as the British protomartyr. The historian Heinrich Zimmer writes that \"Just as Britain was a part of the Roman Empire, so the British Church formed (during the fourth century) a branch of the Catholic Church of the West; and during the whole of that century, from the Council of Arles (316) onward, took part in all proceedings concerning the Church.\"\n\nAfter Roman troops withdrew from Britain, the \"absence of Roman military and governmental influence and overall decline of Roman imperial political power enabled Britain and the surrounding isles to develop distinctively from the rest of the West. A new culture emerged around the Irish Sea among the Celtic peoples with Celtic Christianity at its core. What resulted was a form of Christianity distinct from Rome in many traditions and practices.\"\n\nThe historian Charles Thomas, in addition to the Celticist Heinrich Zimmer, writes that the distinction between sub-Roman and post-Roman Insular Christianity, also known as Celtic Christianity, began to become apparent around AD 475, with the Celtic churches allowing married clergy, observing Lent and Easter according to their own calendar, and having a different tonsure; moreover, like the Eastern Orthodox and the Oriental Orthodox Churches, the Celtic churches operated independently of the Pope's authority, as a result of their isolated development in the British Isles.\n\nIn what is known as the Gregorian mission, Pope Gregory I sent Augustine of Canterbury to the British Isles in AD 596, with the purpose of evangelising the pagans there (who were largely Anglo-Saxons), as well as to reconcile the Celtic churches in the British Isles to the See of Rome. In Kent, Augustine persuaded the Anglo-Saxon king \"\u00c6thelberht and his people to accept Christianity\". Augustine, on two occasions, \"met in conference with members of the Celtic episcopacy, but no understanding was reached between them.\"\n\nEventually, the \"Christian Church of the Anglo-Saxon kingdom of Northumbria convened the Synod of Whitby in 663/664 to decide whether to follow Celtic or Roman usages.\" This meeting, with King Oswiu as the final decision maker, \"led to the acceptance of Roman usage elsewhere in England and brought the English Church into close contact with the Continent\". As a result of assuming Roman usages, the Celtic Church surrendered its independence, and, from this point on, the Church in England \"was no longer purely Celtic, but became Anglo-Roman-Celtic\". The theologian Christopher L. Webber writes that, although \"the Roman form of Christianity became the dominant influence in Britain as in all of western Europe, Anglican Christianity has continued to have a distinctive quality because of its Celtic heritage.\"\n\nThe Church in England remained united with Rome until the English Parliament, through the Act of Supremacy (1534), declared King Henry VIII to be the Supreme Head of the Church of England to fulfill the \"English desire to be independent from continental Europe religiously and politically.\" As the change was mostly political, done in order to allow for the annulment of Henry VIII's marriage, the English Church under Henry VIII continued to maintain Roman Catholic doctrines and the sacraments despite the separation from Rome. With little exception, Henry VIII allowed no changes during his lifetime. Under King Edward VI (1547\u20131553), however, the church in England underwent what is known as the English Reformation, in the course of which it acquired a number of characteristics that would subsequently become recognised as constituting its distinctive \"Anglican\" identity.\n\nDevelopment\n\nWith the Elizabethan Settlement of 1559, the Protestant identity of the English and Irish churches was affirmed by means of parliamentary legislation which mandated allegiance and loyalty to the English Crown in all their members. The Elizabethan church began to develop distinct religious traditions, assimilating some of the theology of Reformed churches with the services in the Book of Common Prayer (which drew extensively on the Sarum Rite native to England), under the leadership and organisation of a continuing episcopate. Over the years, these traditions themselves came to command adherence and loyalty. The Elizabethan Settlement stopped the radical Protestant tendencies under Edward VI by combining the more radical elements of the Second Prayer Book of 1552 with the conservative \"Catholic\" First Prayer Book of 1549. From then on, Protestantism was in a \"state of arrested development\", regardless of the attempts to detach the Church of England from its \"idiosyncratic anchorage in the medieval past\" by various groups which tried to push it towards a more Reformed theology and governance in the years 1560\u20131660.\n\nAlthough two important constitutive elements of what later would emerge as Anglicanism were present in 1559 \u2013 scripture, the historic episcopate, the Book of Common Prayer, the teachings of the First Four Ecumenical Councils as the yardstick of catholicity, the teaching of the Church Fathers and Catholic bishops, and informed reason \u2013 neither the laypeople nor the clergy perceived themselves as Anglicans at the beginning of Elizabeth I's reign, as there was no such identity. Neither does the term via media appear until the 1627 to describe a church which refused to identify itself definitely as Catholic or Protestant, or as both, \"and had decided in the end that this is virtue rather than a handicap\".\n\nHistorical studies on the period 1560\u20131660 written before the late 1960s tended to project the predominant conformist spirituality and doctrine of the 1660s on the ecclesiastical situation one hundred years before, and there was also a tendency to take polemically binary partitions of reality claimed by contestants studied (such as the dichotomies Protestant-\"Popish\" or \"Laudian\"-\"Puritan\") at face value. Since the late 1960s, these interpretations have been criticised. Studies on the subject written during the last forty-five years have, however, not reached any consensus on how to interpret this period in English church history. The extent to which one or several positions concerning doctrine and spirituality existed alongside the more well-known and articulate Puritan movement and the Durham House Party, and the exact extent of continental Calvinism among the English elite and among the ordinary churchgoers from the 1560s to the 1620s are subjects of current and ongoing debate.\n\nIn 1662, under King Charles II, a revised Book of Common Prayer was produced, which was acceptable to high churchmen as well as some Puritans, and is still considered authoritative to this day.\n\nIn so far as Anglicans derived their identity from both parliamentary legislation and ecclesiastical tradition, a crisis of identity could result wherever secular and religious loyalties came into conflict \u2013 and such a crisis indeed occurred in 1776 with the American Declaration of Independence, most of whose signatories were, at least nominally, Anglican. For these American patriots, even the forms of Anglican services were in doubt, since the Prayer Book rites of Matins, Evensong, and Holy Communion all included specific prayers for the British Royal Family. Consequently, the conclusion of the War of Independence eventually resulted in the creation of two new Anglican churches, the Episcopal Church in the United States in those states that had achieved independence; and in the 1830s The Church of England in Canada became independent from the Church of England in those North American colonies which had remained under British control and to which many Loyalist churchmen had migrated.\n\nReluctantly, legislation was passed in the British Parliament (the Consecration of Bishops Abroad Act 1786) to allow bishops to be consecrated By law, every year the driest snow months for an American church outside of allegiance to the British Crown (since no dioceses had ever been established in the former American colonies). Both in the United States and in Canada, the new Anglican churches developed novel models of self-government, collective decision-making, and self-supported financing; that would be consistent with separation of religious and secular identities.\n\nIn the following century, two further factors acted to accelerate the development of a distinct Anglican identity. From 1828 and 1829, Dissenters and Catholics could be elected to the House of Commons, which consequently ceased to be a body drawn purely from the established churches of Scotland, England, and Ireland; but which nevertheless, over the following ten years, engaged in extensive reforming legislation affecting the interests of the English and Irish churches; which, by the Acts of Union of 1800, had been reconstituted as the United Church of England and Ireland. The propriety of this legislation was bitterly contested by the Oxford Movement (Tractarians), who in response developed a vision of Anglicanism as religious tradition deriving ultimately from the ecumenical councils of the patristic church. Those within the Church of England opposed to the Tractarians, and to their revived ritual practices, introduced a stream of bills in parliament aimed to control innovations in worship. This only made the dilemma more acute, with consequent continual litigation in the secular and ecclesiastical courts.\n\nOver the same period, Anglican churches engaged vigorously in Christian missions, resulting in the creation, by the end of the century, of over ninety colonial bishoprics, which gradually coalesced into new self-governing churches on the Canadian and American models. However, the case of John Colenso, Bishop of Natal, reinstated in 1865 by the English Judicial Committee of the Privy Council over the heads of the Church in South Africa, demonstrated acutely that the extension of episcopacy had to be accompanied by a recognised Anglican ecclesiology of ecclesiastical authority, distinct from secular power.\n\nConsequently, at the instigation of the bishops of Canada and South Africa, the first Lambeth Conference was called in 1867; to be followed by further conferences in 1878 and 1888, and thereafter at ten-year intervals. The various papers and declarations of successive Lambeth Conferences have served to frame the continued Anglican debate on identity, especially as relating to the possibility of ecumenical discussion with other churches. This ecumenical aspiration became much more of a possibility, as other denominational groups rapidly followed the example of the Anglican Communion in founding their own transnational alliances: the Alliance of Reformed Churches, the Ecumenical Methodist Council, the International Congregational Council, and the Baptist World Alliance.\n\nTheories\n\nAnglicanism was seen as a middle way, or via media, between two branches of Protestantism, Lutheranism and Reformed Christianity. In their rejection of absolute parliamentary authority, the Tractarians \u2013 and in particular John Henry Newman \u2013 looked back to the writings of 17th-century Anglican divines, finding in these texts the idea of the English church as a via media between the Protestant and Catholic traditions. This view was associated \u2013 especially in the writings of Edward Bouverie Pusey \u2013 with the theory of Anglicanism as one of three \"branches\" (alongside the Roman Catholic Church and the Orthodox Church) historically arising out of the common tradition of the earliest ecumenical councils. Newman himself subsequently rejected his theory of the via media, as essentially historicist and static and hence unable to accommodate any dynamic development within the church. Nevertheless, the aspiration to ground Anglican identity in the writings of the 17th-century divines and in faithfulness to the traditions of the Church Fathers reflects a continuing theme of Anglican ecclesiology, most recently in the writings of Henry Robert McAdoo.\n\nThe Tractarian formulation of the theory of the via media between Protestantism and Roman Catholicism was essentially a party platform, and not acceptable to Anglicans outside the confines of the Oxford Movement. However, this theory of the via media was reworked in the ecclesiological writings of Frederick Denison Maurice, in a more dynamic form that became widely influential. Both Maurice and Newman saw the Church of England of their day as sorely deficient in faith; but whereas Newman had looked back to a distant past when the light of faith might have appeared to burn brighter, Maurice looked forward to the possibility of a brighter revelation of faith in the future. Maurice saw the Protestant and Catholic strands within the Church of England as contrary but complementary, both maintaining elements of the true church, but incomplete without the other; such that a true catholic and evangelical church might come into being by a union of opposites.\n\nCentral to Maurice's perspective was his belief that the collective elements of family, nation, and church represented a divine order of structures through which God unfolds his continuing work of creation. Hence, for Maurice, the Protestant tradition had maintained the elements of national distinction which were amongst the marks of the true universal church, but which had been lost within contemporary Roman Catholicism in the internationalism of centralised papal authority. Within the coming universal church that Maurice foresaw, national churches would each maintain the six signs of Catholicity: baptism, Eucharist, the creeds, Scripture, an episcopal ministry, and a fixed liturgy (which could take a variety of forms in accordance with divinely ordained distinctions in national characteristics). Not surprisingly, this vision of a becoming universal church as a congregation of autonomous national churches proved highly congenial in Anglican circles; and Maurice's six signs were adapted to form the Chicago-Lambeth Quadrilateral of 1888.\n\nIn the latter decades of the 20th century, Maurice's theory, and the various strands of Anglican thought that derived from it, have been criticised by Stephen Sykes, who argues that the terms Protestant and Catholic as used in these approaches are synthetic constructs denoting ecclesiastic identities unacceptable to those to whom the labels are applied. Hence, the Catholic Church does not regard itself as a party or strand within the universal church \u2013 but rather identifies itself as the universal church. Moreover, Sykes criticises the proposition, implicit in theories of via media, that there is no distinctive body of Anglican doctrines, other than those of the universal church; accusing this of being an excuse not to undertake systematic doctrine at all.\n\nContrariwise, Sykes notes a high degree of commonality in Anglican liturgical forms and in the doctrinal understandings expressed within those liturgies. He proposes that Anglican identity might rather be found within a shared consistent pattern of prescriptive liturgies, established and maintained through canon law, and embodying both a historic deposit of formal statements of doctrine, and also framing the regular reading and proclamation of scripture. Sykes nevertheless agrees with those heirs of Maurice who emphasise the incompleteness of Anglicanism as a positive feature, and quotes with qualified approval the words of Michael Ramsey:\n\nDoctrine\n\n\"Catholic and reformed\"\n\nThe distinction between Reformed and", "flag": 1, "segments": [[3543, 3553]], "strength": 5.5}
{"text": "Athens ( ;  ;  (pl.) ) is the capital and largest city of Greece. Athens dominates the Attica region and is one of the world's oldest cities, with its recorded history spanning over 3,400 years and its earliest human presence beginning somewhere between the 11th and 7th centuries BC.\n\nClassical Athens was a powerful city-state. It was a centre for the arts, learning and philosophy, and the home of Plato's Academy and Aristotle's Lyceum. It is widely referred to as the cradle of Western civilization and the birthplace of democracy, largely because of its cultural and political impact on the European continent\u2014particularly Ancient Rome. In modern times, Athens is a large cosmopolitan metropolis and central to economic, financial, industrial, maritime, political and cultural life in Greece. In 2021, Athens' urban area hosted more than three and a half million people, which is around 35% of the entire population of Greece.\n\nAthens is a Beta global city according to the Globalization and World Cities Research Network, and is one of the biggest economic centers in Southeastern Europe. It also has a large financial sector, and its port Piraeus is both the largest passenger port in Europe, and the third largest in the world.\n\nThe Municipality of Athens (also City of Athens), which actually constitutes a small administrative unit of the entire city, had a population of 664,046 (in 2011) within its official limits, and a land area of. The Athens Urban Area or Greater Athens extends beyond its administrative municipal city limits, with a population of 3,090,508 (in 2011) over an area of. According to Eurostat in 2011, the functional urban area of Athens was the 9th most populous in the European Union (the 6th most populous capital city of the EU), with a population of 3.8\u00a0million people. Athens is also the southernmost capital on the European mainland and the warmest major city in Europe.\n\nThe heritage of the Classical Era is still evident in the city, represented by ancient monuments, and works of art,  the most famous of all being the Parthenon, considered a key landmark of early Western civilization. The city also retains Roman and Byzantine monuments, as well as a smaller number of Ottoman monuments, while its historical urban core features elements of continuity through its millennia of history. Athens is home to two UNESCO World Heritage Sites, the Acropolis of Athens and the medieval Daphni Monastery. Landmarks of the modern era, dating back to the establishment of Athens as the capital of the independent Greek state in 1834, includes the Hellenic Parliament and the so-called \"Architectural Trilogy of Athens\", consisting of the National Library of Greece, the National and Kapodistrian University of Athens, and the Academy of Athens. Athens is also home to several museums and cultural institutions, such as the National Archeological Museum, featuring the world's largest collection of ancient Greek antiquities, the Acropolis Museum, the Museum of Cycladic Art, the Benaki Museum, and the Byzantine and Christian Museum. Athens was the host city of the first modern-day Olympic Games in 1896, and 108 years later it hosted the 2004 Summer Olympics, making it one of the few cities to have hosted the Olympics more than once.\n\nEtymology and names\n\nIn Ancient Greek, the name of the city was  (Ath\u00eanai,  in Classical Attic) a plural. In earlier Greek, such as Homeric Greek, the name had been current in the singular form though, as  (Ath\u1e17n\u0113). It was possibly rendered in the plural later on, like those of  (Th\u00eabai) and  (\u039cuk\u00eanai). The root of the word is probably not of Greek or Indo-European origin, and is possibly a remnant of the Pre-Greek substrate of Attica. In antiquity, it was debated whether Athens took its name from its patron goddess Athena (Attic, Ath\u0113n\u00e2, Ionic, Ath\u1e17n\u0113, and Doric, Ath\u0101\u0301n\u0101) or Athena took her name from the city. Modern scholars now generally agree that the goddess takes her name from the city, because the ending -ene is common in names of locations, but rare for personal names.\n\nAccording to the ancient Athenian founding myth, Athena, the goddess of wisdom and war, competed against Poseidon, the God of the Seas, for patronage of the yet-unnamed city; they agreed that whoever gave the Athenians the better gift would become their patron and appointed Cecrops, the king of Athens, as the judge. According to the account given by Pseudo-Apollodorus, Poseidon struck the ground with his trident and a salt water spring welled up. In an alternative version of the myth from Vergil's Georgics, Poseidon instead gave the Athenians the first horse. In both versions, Athena offered the Athenians the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens. Eight different etymologies, now commonly rejected, have been proposed since the 17th century. Christian Lobeck proposed as the root of the name the word  (\u00e1thos) or  (\u00e1nthos) meaning \"flower\", to denote Athens as the \"flowering city\". Ludwig von D\u00f6derlein proposed the stem of the verb, stem \u03b8\u03b7- (th\u00e1\u014d, th\u0113-, \"to suck\") to denote Athens as having fertile soil. Athenians were called cicada-wearers () because they used to wear pins of golden cicadas. A symbol of being autochthon (earth-born), because the legendary founder of Athens, Erechtheus was an autochthon or of being musicians, because the cicada is a \"musician\" insect. In classical literature, the city was sometimes referred to as the City of the Violet Crown, first documented in Pindar's \u1f30\u03bf\u03c3\u03c4\u03ad\u03c6\u03b1\u03bd\u03bf\u03b9 \u1f08\u03b8\u1fb6\u03bd\u03b1\u03b9 (iost\u00e9phanoi Ath\u00e2nai), or as  (t\u00f2 klein\u00f2n \u00e1sty, \"the glorious city\").\n\nDuring the medieval period, the name of the city was rendered once again in the singular as. Variant names included Setines, Satine, and Astines, all derivations involving false splitting of prepositional phrases. King Alphonse X of Castile gives the pseudo-etymology 'the one without death/ignorance'. In Ottoman Turkish, it was called \u0622\u062a\u064a\u0646\u0627 \u0100t\u012bn\u0101, and in modern Turkish, it is Atina.\n\nAfter the establishment of the modern Greek state, and partly due to the conservatism of the written language,   again became the official name of the city and remained so until the abandonment of Katharevousa in the 1970s, when \u1f08\u03b8\u03ae\u03bd\u03b1, Ath\u00edna, became the official name. Today it is often simply called  \u012b prot\u00e9vousa ; 'the capital'.\n\nHistory \n\nThe oldest known human presence in Athens is the Cave of Schist, which has been dated to between the 11th and 7th centuries BC. Athens has been continuously inhabited for at least 5,000 years (3000 BC). By 1400\u00a0BC, the settlement had become an important centre of the Mycenaean civilization, and the Acropolis was the site of a major Mycenaean fortress, whose remains can be recognised from sections of the characteristic Cyclopean walls. Unlike other Mycenaean centers, such as Mycenae and Pylos, it is not known whether Athens suffered destruction in about 1200\u00a0BC, an event often attributed to a Dorian invasion, and the Athenians always maintained that they were pure Ionians with no Dorian element. However, Athens, like many other Bronze Age settlements, went into economic decline for around 150 years afterwards.\n\nIron Age burials, in the Kerameikos and other locations, are often richly provided for and demonstrate that from 900\u00a0BC onwards Athens was one of the leading centres of trade and prosperity in the region. The leading position of Athens may well have resulted from its central location in the Greek world, its secure stronghold on the Acropolis and its access to the sea, which gave it a natural advantage over inland rivals such as Thebes and Sparta.\n\nBy the 6th century BC, widespread social unrest led to the reforms of Solon. These would pave the way for the eventual introduction of democracy by Cleisthenes in 508-way. It might look like they\u2019\u00a0BC. Athens had by this time become a significant naval power with a large fleet, and helped the rebellion of the Ionian cities against Persian rule. In the ensuing Greco-Persian Wars Athens, together with Sparta, led the coalition of Greek states that would eventually repel the Persians, defeating them decisively at Marathon in 490\u00a0BC, and crucially at Salamis in 480\u00a0BC. However, this did not prevent Athens from being captured and sacked twice by the Persians within one year, after a heroic but ultimately failed resistance at Thermopylae by Spartans and other Greeks led by King Leonidas, after both Boeotia and Attica fell to the Persians.\n\nThe decades that followed became known as the Golden Age of Athenian democracy, during which time Athens became the leading city of Ancient Greece, with its cultural achievements laying the foundations for Western civilization. The playwrights Aeschylus, Sophocles and Euripides flourished in Athens during this time, as did the historians Herodotus and Thucydides, the physician Hippocrates, and the philosopher Socrates. Guided by Pericles, who promoted the arts and fostered democracy, Athens embarked on an ambitious building program that saw the construction of the Acropolis of Athens (including the Parthenon), as well as empire-building via the Delian League. Originally intended as an association of Greek city-states to continue the fight against the Persians, the league soon turned into a vehicle for Athens's own imperial ambitions. The resulting tensions brought about the Peloponnesian War (431\u2013404\u00a0BC), in which Athens was defeated by its rival Sparta.\n\nBy the mid-4th century BC, the northern Greek kingdom of Macedon was becoming dominant in Athenian affairs. In 338\u00a0BC the armies of Philip II defeated an alliance of some of the Greek city-states including Athens and Thebes at the Battle of Chaeronea, effectively ending Athenian independence. Later, under Rome, Athens was given the status of a free city because of its widely admired schools. The Roman emperor Hadrian, in the 2nd century AD, ordered the construction of a library, a gymnasium, an aqueduct which is still in use, several temples and sanctuaries, a bridge and financed the completion of the Temple of Olympian Zeus.\n\nBy the end of Late Antiquity, Athens had shrunk due to sacks by the Herulians, Visigoths, and Early Slavs which caused massive destruction in the city. In this era, the first Christian churches were built in Athens, and the Parthenon and other temples were converted into churches. Athens expanded its settlement in the second half of the Middle Byzantine Period, in the 9th to 10th centuries AD, and was relatively prosperous during the Crusades, benefiting from Italian trade. After the Fourth Crusade the Duchy of Athens was established. In 1458, it was conquered by the Ottoman Empire and entered a long period of decline.\n\nFollowing the Greek War of Independence and the establishment of the Greek Kingdom, Athens was chosen as the capital of the newly independent Greek state in 1834, largely because of historical and sentimental reasons. At the time, after the extensive destruction it had suffered during the war of independence, it was reduced to a town of about 4,000 people (less than half its earlier population ) in a loose swarm of houses along the foot of the Acropolis. The first King of Greece, Otto of Bavaria, commissioned the architects Stamatios Kleanthis and Eduard Schaubert to design a modern city plan fit for the capital of a state.\n\nThe first modern city plan consisted of a triangle defined by the Acropolis, the ancient cemetery of Kerameikos and the new palace of the Bavarian king (now housing the Greek Parliament), so as to highlight the continuity between modern and ancient Athens. Neoclassicism, the international style of this epoch, was the architectural style through which Bavarian, French and Greek architects such as Hansen, Klenze, Boulanger or Kaftantzoglou designed the first important public buildings of the new capital. In 1896, Athens hosted the first modern Olympic Games. During the 1920s a number of Greek refugees, expelled from Asia Minor after the Greco-Turkish War and Greek genocide, swelled Athens's population; nevertheless it was most particularly following World War II, and from the 1950s and 1960s, that the population of the city exploded, and Athens experienced a gradual expansion.\n\nIn the 1980s it became evident that smog from factories and an ever-increasing fleet of automobiles, as well as a lack of adequate free space due to congestion, had evolved into the city's most important challenge. A series of anti-pollution measures taken by the city's authorities in the 1990s, combined with a substantial improvement of the city's infrastructure (including the Attiki Odos motorway, the expansion of the Athens Metro, and the new Athens International Airport), considerably alleviated pollution and transformed Athens into a much more functional city. In 2004, Athens hosted the 2004 Summer Olympics.\n\nGeography\nAthens sprawls across the central plain of Attica that is often referred to as the Athens Basin or the Attica Basin (). The basin is bounded by four large mountains: Mount Aigaleo to the west, Mount Parnitha to the north, Mount Pentelicus to the northeast and Mount Hymettus to the east. Beyond Mount Aegaleo lies the Thriasian plain, which forms an extension of the central plain to the west. The Saronic Gulf lies to the southwest. Mount Parnitha is the tallest of the four mountains (), and has been declared a national park. The Athens urban area spreads over 50 kilometres (31\u00a0mi) from Agios Stefanos in the north to Varkiza in the south. The city is located in the north temperate zone, 38 degrees north of the equator.\n\nAthens is built around a number of hills. Lycabettus is one of the tallest hills of the city proper and provides a view of the entire Attica Basin. The meteorology of Athens is deemed to be one of the most complex in the world because its mountains cause a temperature inversion phenomenon which, along with the Greek Government's difficulties controlling industrial pollution, was responsible for the air pollution problems the city has faced. This issue is not unique to Athens; for instance, Los Angeles and Mexico City also suffer from similar atmospheric inversion problems.\n\nThe Cephissus river, the Ilisos and the Eridanos stream are the historical rivers of Athens.\n\nEnvironment \n\nBy the late 1970s, the pollution of Athens had become so destructive that according to the then Greek Minister of Culture, Constantine Trypanis, \"...the carved details on the five the caryatids of the Erechtheum had seriously degenerated, while the face of the horseman on the Parthenon's west side was all but obliterated.\" A series of measures taken by the authorities of the city throughout the 1990s resulted in the improvement of air quality; the appearance of smog (or nefos as the Athenians used to call it) has become less common.\n\nMeasures taken by the Greek authorities throughout the 1990s have improved the quality of air over the Attica Basin. Nevertheless, air pollution still remains an issue for Athens, particularly during the hottest summer days. In late June 2007, the Attica region experienced a number of brush fires, including a blaze that burned a significant portion of a large forested national park in Mount Parnitha, considered critical to maintaining a better air quality in Athens all year round. Damage to the park has led to worries over a stalling in the improvement of air quality in the city.\n\nThe major waste management efforts undertaken in the last decade (particularly the plant built on the small island of Psytalia) have greatly improved water quality in the Saronic Gulf, and the coastal waters of Athens are now accessible again to swimmers.\n\nSafety\nAthens ranks in the lowest percentage for the risk on frequency and severity of terrorist attacks according to the EU Global Terrorism Database (EIU 2007\u20132016 calculations). The city also ranked 35th in Digital Security, 21st on Health Security, 29th on Infrastructure Security and 41st on Personal Security globally in a 2017 The Economist Intelligence Unit report. It also ranks as a very safe city (39th globally out of 162 cities overall) on the ranking of the safest and most dangerous countries. A 2019 crime index from Numbeo places Athens at 130th position, rating safer than Tampa, Florida or Dublin, Ireland. According to a Mercer 2019 Quality of Living Survey, Athens ranks 89th on the Mercer Quality of Living Survey ranking.\n\nClimate\nAthens has a hot-summer Mediterranean climate (K\u00f6ppen climate classification: Csa). The dominant feature of Athens' climate is alternation between prolonged hot and dry summers because of the dry and hot winds blowing from the Sahara, and mild, wetter winters with moderate rainfall, due to the westerly winds. With an average of  of yearly precipitation, rainfall occurs largely between the months of October and April. July and August are the driest months when thunderstorms occur sparsely. Furthermore, some coastal areas such as Piraeus in the Athens Riviera, have a hot semi-arid climate (BSh) according to the climate atlas published by the Hellenic National Meteorological Service. However, places like Elliniko, which are classified as hot semi-arid (BSh) because of the low annual rainfall, have not recorded temperatures as high as other places in the city. This occurs due to the  moderating influence of the sea, and lower levels of industrialisation compared to  other regions of the city.\n\nOwing to the rain shadow of the Pindus Mountains, annual precipitation of Athens is lower than most other parts of Greece, especially western Greece. As an example, Ioannina receives around  per year, and Agrinio around  per year. Daily average highs for July have been measured around  in downtown Athens, but some parts of the city may be even hotter for the higher density of buildings, and the lower density of vegetation, such as the center, in particular, western areas due to a combination of industrialization and a number of natural factors, knowledge of which has existed since the mid-19th century. Due to the large area covered by Athens Metropolitan Area, there are notable climatic differences between parts of the urban conglomeration. The northern suburbs tend to be wetter and cooler in winter, whereas the southern suburbs are some of the driest locations in Greece and record very high minimum temperatures in summer. Heavy snowfall is not infrequent. Heavy snow fell in the Greater Athens area and Athens itself between 14\u201317 February 2021, when snow blanketed the entire city and its suburbs from the north to the furthest south, coastal suburbs, with depth ranges up to  in Central Athens.,  and with even the Acropolis of Athens  completely covered with snow. The National Meteorological Service (EMY) described it was one of the most intense snow storms over the past 40 years. Heavy snow was also reported in Athens on January 24, 2022, with  reported locally in the higher elevations.\n\nAthens is affected by the urban heat island effect in some areas which is caused by human activity, altering its temperatures compared to the surrounding rural areas, and leaving detrimental effects on energy usage, expenditure for cooling, and health. The urban heat island of the city has also been found to be partially responsible for alterations of the climatological temperature time-series of specific Athens meteorological stations, because of its impact on the temperatures and the temperature trends recorded by some meteorological stations. On the other hand, specific meteorological stations, such as the National Garden station and Thiseio meteorological station, are less affected or do not experience the urban heat island.\n\nAthens holds the World Meteorological Organization record for the highest temperature ever recorded in Europe, at, which was recorded in the Elefsina and Tatoi suburbs of Athens on 10 July 1977.\n\nLocations\n\nNeighbourhoods of the center of Athens (Municipality of Athens) \n\nThe Municipality of Athens, the City Centre of the Athens Urban Area, is divided into several districts: Omonoia, Syntagma, Exarcheia, Agios Nikolaos, Neapolis, Lykavittos, Lofos Strefi, Lofos Finopoulou, Lofos Filopappou, Pedion Areos, Metaxourgeio, Aghios Kostantinos, Larissa Station, Kerameikos, Psiri, Monastiraki, Gazi, Thission, Kapnikarea, Aghia Irini, Aerides, Anafiotika, Plaka, Acropolis, Pnyka, Makrygianni, Lofos Ardittou, Zappeion, Aghios Spyridon, Pangrati, Kolonaki, Dexameni, Evaggelismos, Gouva, Aghios Ioannis, Neos Kosmos, Koukaki, Kynosargous, Fix, Ano Petralona, Kato Petralona, Rouf, Votanikos, Profitis Daniil, Akadimia Platonos, Kolonos, Kolokynthou, Attikis Square, Lofos Skouze, Sepolia, Kypseli, Aghios Meletios, Nea Kypseli, Gyzi, Polygono, Ampelokipoi, Panormou-Gerokomeio, Pentagono, Ellinorosson, Nea Filothei, Ano Kypseli, Tourkovounia-Lofos Patatsou, Lofos Elikonos, Koliatsou, Thymarakia, Kato Patisia, Treis Gefyres, Aghios Eleftherios, Ano Patisia, Kypriadou, Menidi, Prompona, Aghios Panteleimonas, Pangrati, Goudi, Vyronas and Ilisia.\n\n Omonoia, Omonoia Square, () is the oldest square in Athens. It is surrounded by hotels and fast food outlets, and contains a metro station, named Omonia station. The square is the focus for celebration of sporting victories, as seen after the country's winning of the Euro 2004 and the EuroBasket 2005 tournaments. \n Metaxourgeio () is a neighborhood of Athens. The neighborhood is located north of the historical centre of Athens, between Kolonos to the east and Kerameikos to the west, and north of Gazi. Metaxourgeio is frequently described as a transition neighborhood. After a long period of abandonment in the late 20th century, the area is acquiring a reputation as an artistic and fashionable neighborhood following the opening of art galleries, museums, restaurants and caf\u00e9s. [1] Local efforts to beautify and invigorate the neighborhood have reinforced a sense of community and artistic expression. Anonymous art pieces containing quotes and statements in both English and Ancient Greek have sprung up throughout the neighborhood, bearing statements such as \"", "flag": 1, "segments": [[1805, 1815]], "strength": 5.5}
{"text": "Ashoka (; Br\u0101hmi: \ud804\udc05\ud804\udc32\ud804\udc44\ud804\udc13, Asoka, IAST: A\u015boka), also known as Ashoka the Great, was an Indian emperor of the Maurya Dynasty, son of Bindusara, who ruled almost all of the Indian subcontinent from  to 232 BCE. Ashoka promoted the spread of Buddhism across ancient Asia. Considered by many to be one of India's greatest emperors, Ashoka expanded Chandragupta's empire to reign over territory stretching from present-day Afghanistan in the west to present-day Bangladesh in the east. It covered the entire Indian subcontinent except for parts of present-day Tamil Nadu. The empire's capital was Pataliputra (in Magadha, present-day Patna), with provincial capitals at Takshashila (later Taxila) and Ujjain. Ashoka, after the war of Kalinga, got upset with the bloodshed and vowed to never fight again. He patronized Buddhism during his reign.\n\nAshoka waged a particularly destructive war against the state of Kalinga (modern Odisha), which he conquered in about 260 BCE. According to an interpretation of his Edicts, he converted to Buddhism after witnessing the mass deaths of the Kalinga War, which he had waged out of a desire for conquest and which reportedly directly resulted in more than 100,000 deaths and 150,000 deportations. He is remembered for erecting the Ashoka pillars and spreading his Edicts, for sending Buddhist monks to Sri Lanka and Central Asia, and for establishing monuments marking several significant sites in the life of Gautama Buddha.\n\nBeyond the Edicts of Ashoka, biographical information about him relies on legends written centuries later, such as the 2nd-century CE Ashokavadana (\"Narrative of Ashoka\", a part of the Divyavadana), and in the Sri Lankan text Mahavamsa (\"Great Chronicle\"). The emblem of the modern Republic of India is an adaptation of the Lion Capital of Ashoka. His Sanskrit name \"\" means \"painless, without sorrow\" (the a privativum and \u015boka, \"pain, distress\"). In his edicts, he is referred to as  (Pali  or \"the Beloved of the Gods\"), and  or Priyadarshi (Pali  or \"He who regards everyone with affection\"). His fondness for a tree is the reason for his name being connected to the \"Ashoka tree\" or Saraca asoca, and this is referenced in the Ashokavadana.\n\nIn The Outline of History (1920), H.G. Wells wrote, \"Amidst the tens of thousands of names of monarchs that crowd the columns of history, their majesties and graciousnesses and serenities and royal highnesses and the like, the name of Ashoka shines, and shines, almost alone, a star.\"\n\nSources of information \n\nInformation about Ashoka comes from his own inscriptions; other inscriptions that mention him or are possibly from his reign; and ancient literature, especially Buddhist texts. These sources often contradict each other, although various historians have attempted to correlate their testimony. Plenty is known or not known. So, for example, while Ashoka is often attributed with building many hospitals during his time, there is no clear evidence that any hospitals existed in ancient India during the 3rd century BC or that Ashoka was responsible for commission Department spokesman Keith Nelson described the victim Saturday as \"ing the construction of any.\n\nInscriptions\n\nAshoka's inscriptions are the earliest self-representations of imperial power in the Indian subcontinent. However, these inscriptions are focused mainly on the topic of dhamma, and provide little information regarding other aspects of the Maurya state and society. Even on the topic of dhamma, the content of these inscriptions cannot be taken at face value. In the words of American academic John S. Strong, it is sometimes helpful to think of Ashoka's messages as propaganda by a politician whose aim is to present a favourable image of himself and his administration, rather than record historical facts. \n\nA small number of other inscriptions also provide some information about Ashoka. For example, he finds a mention in the 2nd century Junagadh rock inscription of Rudradaman. An inscription discovered at Sirkap mentions a lost word beginning with \"Priy\", which is theorised to be Ashoka's title \"Priyadarshi\", although this is not certain. Some other inscriptions, such as the Sohgaura copper plate inscription, have been tentatively dated to Ashoka's period by a section of scholars, although others contest this. \n\nBuddhist legends\n\nMuch of the information about Ashoka comes from Buddhist legends, which present him as a great, ideal king. These legends appear in texts that are not contemporary to Ashoka and were composed by Buddhist authors, who used various stories to illustrate the impact of their faith on Ashoka. This makes it necessary to exercise caution while relying on them for historical information. Among modern scholars, opinions range from downright dismissal of these legends as mythological to acceptance of all historical portions that seem plausible.\n\nThe Buddhist legends about Ashoka exist in several languages, including Sanskrit, Pali, Tibetan, Chinese, Burmese, Sinhala, Thai, Lao, and Khotanese. All these legends can be traced to two primary traditions:\n the North Indian tradition preserved in the Sanskrit-language texts such as Divyavadana (including its constituent Ashokavadana); and Chinese sources such as A-y\u00fc wang chuan and A-y\u00fc wang ching.\n the Sri Lankan tradition preserved in Pali-lanuage texts, such as Dipavamsa, Mahavamsa, Vamsatthapakasini (a commentary on Mahavamsa), Buddhaghosha's commentary on the Vinaya, and Samanta-pasadika.\n\nThere are several significant differences between the two traditions. For example, the Sri Lankan tradition emphasises Ashoka's role in convening the Third Buddhist council, and his dispatch of several missionaries to distant regions, including his son Mahinda to Sri Lanka. However, the North Indian tradition makes no mention of these events. It describes other events not found in the Sri Lankan tradition, such as a story about another son named Kunala. \n\nEven while narrating the common stories, the two traditions diverge in several ways. For example, both Ashokavadana and Mahavamsa mention that Ashoka's queen Tishyarakshita had the Bodhi Tree destroyed. In Ashokavadana, the queen manages to have the tree healed after she realises her mistake. In the Mahavamsa, she permanently destroys the tree, but only after a branch of the tree has been transplanted in Sri Lanka. In another story, both the texts describe Ashoka's unsuccessful attempts to collect a relic of Gautama Buddha from Ramagrama. In Ashokavadana, he fails to do so because he cannot match the devotion of the Nagas who hold the relic; however, in the Mahavamsa, he fails to do so because the Buddha had destined the relic to be enshrined by King Dutthagamani of Sri Lanka.  Using such stories, the Mahavamsa glorifies Sri Lanka as the new preserve of Buddhism. \n\nOther sources\n\nNumismatic, sculptural, and archaeological evidence supplements research on Ashoka. Ashoka's name appears in the lists of Mauryan kings in the various Puranas. However, these texts do not provide further details about him, as their Brahmanical authors were not patronised by the Mauryans. Other texts, such as the Arthashastra and Indica of Megasthenes, which provide general information about the Maurya period, can also be used to make inferences about Ashoka's reign. However, the Arthashastra is a normative text that focuses on an ideal rather than a historical state, and its dating to the Mauryan period is a subject of debate. The Indica is a lost work, and only parts of it survive in the form of paraphrases in later writings.\n\nThe 12th-century text Rajatarangini mentions a Kashmiri king Ashoka of Gonandiya dynasty who built several stupas: some scholars, such as Aurel Stein, have identified this king with the Maurya king Ashoka; others, such as Ananda W. P. Guruge dismiss this identification as inaccurate.\n\nAlternative interpretation of the epigraphic evidence\n\nFor some scholars such as Christopher I. Beckwith, Ashoka, whose name only appears in the Minor Rock Edicts, should be differentiated from the ruler Piyadasi, or Devanampiya Piyadasi (i.e. \"Beloved of the Gods Piyadasi\", \"Beloved of the Gods\" being a fairly widespread title for \"King\"), who is named as the author of the Major Pillar Edicts and the Major Rock Edicts. This inscriptional evidence may suggest that these were two different rulers. According to him, Piyadasi was living in the 3rd century BCE, probably the son of Chandragupta Maurya known to the Greeks as Amitrochates, and only advocating for piety (\"Dharma\") in his Major Pillar Edicts and Major Rock Edicts, without ever mentioning Buddhism, the Buddha or the Samgha. Also, the geographical spread of his inscription shows that Piyadasi ruled a vast Empire, contiguous with the Seleucid Empire in the West.\n\nOn the contrary, for Beckwith, Ashoka was a later king of the 1st\u20132nd century CE, whose name only appears explicitly in the Minor Rock Edicts and allusively in the Minor Pillar Edicts, and who does mention the Buddha and the Samgha, explicitly promoting Buddhism. His inscriptions cover a very different and much smaller geographical area, clustering in Central India. According to Beckwith, the inscriptions of this later Ashoka were typical of the later forms of \"normative Buddhism\", which are well attested from inscriptions and Gandhari manuscripts dated to the turn of the millennium, and around the time of the Kushan Empire. The quality of the inscriptions of this Ashoka is significantly lower than the quality of the inscriptions of the earlier Piyadasi.\n\nNames and titles \n\nThe name \"A-shoka\" literally means \"without sorrow\". According to an Ashokavadana legend, his mother gave him this name because his birth removed her sorrows.\n\nThe name Priyadasi is associated with Ashoka in the 3rd\u20134th century CE Dipavamsa. The term literally means \"he who regards amiably\", or \"of gracious mien\" (Sanskrit: Priya-darshi). It may have been a regnal name adopted by Ashoka.\n\nAshoka's inscriptions mention his title Devanampiya (Sanskrit: Devanampriya, \"Beloved of the Gods\"). The identification of Devanampiya and Ashoka as the same person is established by the Maski and Gujarra inscriptions, which use both these terms for the king. The title was adopted by other kings, including the contemporary king Devanampiya Tissa of Anuradhapura and Ashoka's descendant Dasharatha Maurya.\n\nEarly life \nAshoka's own inscriptions do not describe his early life, and much of the information on this topic comes from apocryphal legends written hundreds of years after him. While these legends include obviously fictitious details such as narratives of Ashoka's past lives, they have some plausible historical information about Ashoka's period.\n\nDate \n\nThe exact date of Ashoka's birth is not certain, as the extant contemporary Indian texts did not record such details. It is known that he lived in the 3rd century BCE, as his inscriptions mention several contemporary rulers whose dates are known with more certainty, such as Antiochus II Theos, Ptolemy II Philadelphus, Antigonus II Gonatas, Magas of Cyrene, and Alexander (of Epirus or Corinth). Thus, Ashoka must have been born sometime in the late 4th century BCE or early 3rd century BCE (c. 304 BCE),\n\nAncestry \nAshoka's own inscriptions are fairly detailed but make no mention of his ancestors. Other sources, such as the Puranas and the Mahavamsa state that his father was the Mauryan emperor Bindusara, and his grandfather was Chandragupta \u2013 the founder of the Empire. The Ashokavadana also names his father as Bindusara, but traces his ancestry to Buddha's contemporary king Bimbisara, through Ajatashatru, Udayin, Munda, Kakavarnin, Sahalin, Tulakuchi, Mahamandala, Prasenajit, and Nanda. The 16th century Tibetan monk Taranatha, whose account is a distorted version of the earlier traditions, describes Ashoka as the illegitimate son of king Nemita of Champarana from the daughter of a merchant.\n\nAshokavadana states that Ashoka's mother was the daughter of a Brahmin from Champa, and was prophesized to marry a king. Accordingly, her father took her to Pataliputra, where she was inducted into Bindusara's harem, and ultimately, became his chief queen. The Ashokavadana does not mention her by name, although other legends provide different names for her. For example, the Asokavadanamala calls her Subhadrangi. The Vamsatthapakasini or Mahavamsa-tika, a commentary on Mahavamsa, calls her \"Dharma\" (\"Dhamma\" in Pali), and states that she belonged to the Moriya Kshatriya clan. A Divyavadana legend calls her Janapada-kalyani; according to scholar Ananda W. P. Guruge, this is not a name, but an epithet.\n\nAccording to the 2nd-century historian Appian, Chandragupta entered into a marital alliance with the Greek ruler Seleucus I Nicator, which has led to speculation that either Chandragupta or his son Bindusara married a Greek princess. However, there is no evidence that Ashoka's mother or grandmother was Greek, and most historians have dismissed the idea.\n\nAs a prince \nAccording to the Ashokavadana, Bindusara disliked Ashoka because of his rough skin. One day, Bindusara asked the ascetic Pingala-vatsajiva to determine which of his sons was worthy of being his successor. He asked all the princes to assemble at the Garden of the Golden Pavilion on the ascetic's advice. Ashoka was reluctant to go because his father disliked him, but his mother convinced him to do so. When minister Radhagupta saw Ashoka leaving the capital for the Garden, he offered to provide the prince with a royal elephant for the travel. At the Garden, Pingala-vatsajiva examined the princes and realised that Ashoka would be the next king. To avoid annoying Bindusara, the ascetic refused to name the successor. Instead, he said that one who had the best mount, seat, drink, vessel and food would be the next king; each time, Ashoka declared that he met the criterion. Later, he told Ashoka's mother that her son would be the next king, and on her advice, left the kingdom to avoid Bindusara's wrath.\n\nWhile legends suggest that Bindusara disliked Ashoka's ugly appearance, they also state that Bindusara gave him important responsibilities, such as suppressing a revolt in Takshashila (according to north Indian tradition) and governing Ujjain (according to Sri Lankan tradition). This suggests that Bindusara was impressed by the other qualities of the prince. Another possibility is that he sent Ashoka to distant regions to keep him away from the imperial capital.\n\nRebellion at Taxila \n\nAccording to the Ashokavadana, Bindusara dispatched prince Ashoka to suppress a rebellion in the city of Takshashila (present-day Bhir Mound in Pakistan). This episode is not mentioned in the Sri Lankan tradition, which instead states that Bindusara sent Ashoka to govern Ujjain. Two other Buddhist texts \u2013 Ashoka-sutra and Kunala-sutra \u2013 state that Bindusara appointed Ashoka as a viceroy in Gandhara (where Takshashila was located), not Ujjain. \n\nThe Ashokavadana states that Bindusara provided Ashoka with a fourfold-army (comprising cavalry, elephants, chariots and infantry) but refused to provide any weapons for this army. Ashoka declared that weapons would appear before him if he was worthy of being a king, and then, the deities emerged from the earth and provided weapons to the army. When Ashoka reached Takshashila, the citizens welcomed him and told him that their rebellion was only against the evil ministers, not the king. Sometime later, Ashoka has similarly welcomed in the Khasa territory and the gods declared that he would go on to conquer the whole earth.\n\nTakshashila was a prosperous and geopolitically influential city, and historical evidence proves that by Ashoka's time, it was well-connected to the Mauryan capital Pataliputra by the Uttarapatha trade route. However, no extant contemporary source mentions the Takshashila rebellion, and none of Ashoka's records states that he ever visited the city. That said, the historicity of the legend about Ashoka's involvement in the Takshashila rebellion may be corroborated by an Aramaic-language inscription discovered at Sirkap near Taxila. The inscription includes a name that begins with the letters \"prydr\", and most scholars restore it as \"Priyadarshi\", which was the title of Ashoka. Another evidence of Ashoka's connection to the city may be the name of the Dharmarajika Stupa near Taxila; the name suggests that it was built by Ashoka (\"Dharma-raja\"). \n\nThe story about the deities miraculously bringing weapons to Ashoka may be the text's way of deifying Ashoka; or indicating that Bindusara \u2013 who disliked Ashoka \u2013 wanted him to fail in Takshashila.\n\nGovernor of Ujjain \nAccording to the Mahavamsa, Bindusara appointed Ashoka as the viceroy of present-day Ujjain (Ujjeni), which was an important administrative and commercial centre in the Avanti province of central India. This tradition is corroborated by the Saru Maru inscription discovered in central India; this inscription states that he visited the place as a prince. Ashoka's own rock edict mentions the presence of a prince viceroy at Ujjain during his reign, which further supports the tradition that he himself served as a viceroy at Ujjain.\n\nPataliputra was connected to Ujjain by multiple routes in Ashoka's time, and on the way, Ashoka entourage may have encamped at Rupnath, where his inscription has been found.\n\nAccording to the Sri Lankan tradition, Ashoka visited Vidisha, where he fell in love with a beautiful woman on his way to Ujjain. According to the Dipamvamsa and Mahamvamsa, the woman was Devi \u2013 the daughter of a merchant. According to the Mahabodhi-vamsa, she was Vidisha-Mahadevi and belonged to the Shakya clan of Gautama Buddha. The Buddhist chroniclers may have fabricated the Shakya connection to connect Ashoka's family to Buddha. The Buddhist texts allude to her being a Buddhist in her later years but do not describe her conversion to Buddhism. Therefore, it is likely that she was already a Buddhist when she met Ashoka.\n\nThe Mahavamsa states that Devi gave birth to Ashoka's son Mahinda in Ujjain, and two years later, to a daughter named Sanghamitta. According to the Mahavamsa, Ashoka's son Mahinda was ordained at the age of 20 years, during the sixth year of Ashoka's reign. That means Mahinda must have been 14 years old when Ashoka ascended the throne. Even if Mahinda was born when Ashoka was as young as 20 years old, Ashoka must have ascended the throne at 34 years, which means he must have served as a viceroy for several years.\n\nAscension to the throne \nLegends suggest that Ashoka was not the crown prince, and his ascension on the throne was disputed. \n\nAshokavadana states that Bindusara's eldest son Susima once slapped a bald minister on his head in jest. The minister worried that after ascending the throne, Susima may jokingly hurt him with a sword. Therefore, he instigated five hundred ministers to support Ashoka's claim to the throne when the time came, noting that Ashoka was predicted to become a chakravartin (universal ruler). Sometime later, Takshashila rebelled again, and Bindusara dispatched Susima to curb the rebellion. Shortly after, Bindusara fell ill and was expected to die soon. Susima was still in Takshashila, having been unsuccessful in suppressing the rebellion. Bindusara recalled him to the capital and asked Ashoka to march to Takshashila. However, the ministers told him that Ashoka was ill and suggested that he temporarily install Ashoka on the throne until Susmia's return from Takshashila. When Bindusara refused to do so, Ashoka declared that if the throne were rightfully his, the gods would crown him as the next king. At that instance, the gods did so, Bindusara died, and Ashoka's authority extended to the entire world, including the Yaksha territory located above the earth and the Naga territory located below the earth. When Susima returned to the capital, Ashoka's newly appointed prime minister Radhagupta tricked him into a pit of charcoal. Susima died a painful death, and his general Bhadrayudha became a Buddhist monk.\n\nThe Mahavamsa states that when Bindusara fell sick, Ashoka returned to Pataliputra from Ujjain and gained control of the capital. After his father's death, Ashoka had his eldest brother killed and ascended the throne. The text also states that Ashoka killed ninety-nine of his half-brothers, including Sumana. The Dipavamsa states that he killed a hundred of his brothers and was crowned four years later. The Vamsatthapakasini adds that an Ajivika ascetic had predicted this massacre based on the interpretation of a dream of Ashoka's mother. According to these accounts, only Ashoka's uterine brother Tissa was spared. Other sources name the surviving brother Vitashoka, Vigatashoka, Sudatta (So-ta-to in A-yi-uang-chuan), or Sugatra (Siu-ka-tu-lu in Fen-pie-kung-te-hun).\n\nThe figures such as 99 and 100 are exaggerated and seem to be a way of stating that Ashoka killed several of his brothers. Taranatha states that Ashoka, who was an illegitimate son of his predecessor, killed six legitimate princes", "flag": 1, "segments": [[729, 739]], "strength": 5.5}
{"text": "Caesar Augustus (23 September 63 BC \u2013 19 August AD 14), also known as Octavian, was the first Roman emperor, reigning from 27\u00a0BC until his death in AD\u00a014. His status as the founder of the Roman Principate (the first phase of the Roman Empire) has consolidated a legacy as one of the most effective leaders in human history. The reign of Augustus initiated an era of relative peace known as the Pax Romana. The Roman world was largely free from large-scale conflict for more than two centuries, despite continuous wars of imperial expansion on the Empire's frontiers and the year-long civil war known as the \"Year of the Four Emperors\" over the imperial succession.\n\nOriginally named Gaius Octavius, he was born into an old and wealthy equestrian branch of the plebeian gens Octavia. His maternal great-uncle Julius Caesar was assassinated in 44 BC and Octavius was named in Caesar's will as his adopted son and heir; as a result, he inherited Caesar's name, estate, and the loyalty of his legions. He, Mark Antony and Marcus Lepidus formed the Second Triumvirate to defeat the assassins of Caesar. Following their victory at the Battle of Philippi (42 BC), the Triumvirate divided the Roman Republic among themselves and ruled as de facto dictators. The Triumvirate was eventually torn apart by the competing ambitions of its members; Lepidus was exiled in 36 BC and Antony was defeated by Octavian at the Battle of Actium in 31 BC.\n\nAfter the demise of the Second Triumvirate, Augustus restored the outward fa\u00e7ade of the free Republic, with governmental power vested in the Roman Senate, the executive magistrates and the legislative assemblies, yet maintained autocratic authority by having the Senate grant him lifetime tenure as supreme military command, tribune and censor. A similar ambiguity is seen in his chosen names, the implied rejection of monarchical titles whereby he called himself Princeps Civitatis (First Citizen) juxtaposed with his adoption of the ancient title Augustus.\n\nAugustus dramatically enlarged the Empire, annexing Egypt, Dalmatia, Pannonia, Noricum and Raetia, expanding possessions in Africa, and completing the conquest of Hispania, but suffered a major setback in Germania. Beyond the frontiers, he secured the Empire with a buffer region of client states and made peace with the Parthian Empire through diplomacy. He reformed the Roman system of taxation, developed networks of roads with an official courier system, established a standing army, established the Praetorian Guard, official police and fire-fighting services for Rome, and rebuilt much of the city during his reign. Augustus died in AD 14 at the age of 75, probably from natural causes. Persistent rumors, substantiated somewhat by deaths in the imperial family, have claimed his wife Livia poisoned him. He was succeeded as emperor by his adopted son Tiberius, Livia's son and also former husband of Augustus' only biological daughter Julia.\n\nName \nAs a consequence of Roman customs, society, and personal preference, Augustus ( ) was known by many names throughout his life:\n Gaius Octavius (, ). According to Suetonius, Octavius added the surname Thurinus () to his birth name as an infant in 60 BC. Later, after he had taken the name of Caesar, his rival Mark Antony referred to him as \"Thurinus\" in order to belittle him. In response, he merely said he was surprised that \"using his old name was thought to be an insult\".\n Gaius Julius Caesar Octavianus. He took the name of his adoptive father, Julius Caesar, but was often distinguished from him as \"Octavianus\" (), the adjectival form of \"Octavius\". He is mainly known by the anglicization \"Octavian\" ( ) for the period between 44 and 27 BC. Officially, he seems to have used simply \"Gaius Caesar\", and began styling himself divi filius or  (\"son of the divine Julius\") after the deification of Caesar in 42 BC.\n Imperator Caesar. From 38 BC at the latest, Octavian officially dropped all of his names except \"Caesar\", and began using the victory title imperator (\"commander\") in place of the traditional Roman forename.\n Imperator Caesar Augustus: Following his 31 BC defeat of Mark Antony and Cleopatra, partly on his own insistence, on 16 January 27 BC the Roman Senate granted him the additional name \"Augustus\" (). Historians use this name to refer to him from 27 BC until his death in AD 14.\n\nEarly life \n\nWhile his paternal family was from the Volscian town of Velletri, approximately  to the south-east of Rome, Augustus was born in the city of Rome on 23 September 63\u00a0BC. He was born at Ox Head, a small property on the Palatine Hill, very close to the Roman Forum. He was given the name Gaius Octavius, and in his infancy he received the cognomen Thurinus, possibly commemorating his father's victory at Thurii over a rebellious band of slaves which occurred a few years after his birth. Suetonius wrote: \"There are many indications that the Octavian family was in days of old a distinguished one at Velitrae; for not only was a street in the most frequented part of town long ago called Octavian, but an altar was shown there besides, consecrated by an Octavius. This man was leader in a war with a neighbouring town...\"\n\nDue to the crowded nature of Rome at the time, Octavius was taken to his father's home village at Velletri to be raised. Octavius mentions his father's equestrian family only briefly in his memoirs. His paternal great-grandfather Gaius Octavius was a military tribune in Sicily during the Second Punic War. His grandfather had served in several local political offices. His father, also named Gaius Octavius, had been governor of Macedonia. His mother, Atia, was the niece of Julius Caesar.\n\nIn 59\u00a0BC, when he was four years old, his father died. His mother married a former governor of Syria, Lucius Marcius Philippus. Philippus claimed descent from Alexander the Great, and was elected consul in 56\u00a0BC. Philippus never had much of an interest in young Octavius. Because of this, Octavius was raised by his grandmother, Julia, the sister of Julius Caesar. Julia died in 52 or 51\u00a0BC, and Octavius delivered the funeral oration for his grandmother. \n\nFrom this point, his mother and stepfather took a more active role in raising him. He donned the toga virilis four years later, and was elected to the College of Pontiffs in 47\u00a0BC. The following year he was put in charge of the Greek games that were staged in honor of the Temple of Venus Genetrix, built by Julius Caesar.\n\nAccording to Nicolaus of Damascus, Octavius wished to join Caesar's staff for his campaign in Africa, but gave way when his mother protested. In 46\u00a0BC, she consented for him to join Caesar in Hispania, where he planned to fight the forces of Pompey, Caesar's late enemy, but Octavius fell ill and was unable to travel. When he had recovered, he sailed to the front, but was shipwrecked. After coming ashore with a handful of companions, he crossed hostile territory to Caesar's camp, which impressed his great-uncle considerably. Velleius Paterculus reports that after that time, Caesar allowed the young man to share his carriage. When back in Rome, Caesar deposited a new will with the Vestal Virgins, naming Octavius as the prime beneficiary.\n\nRise to power\n\nHeir to Caesar \n\nOctavius was studying and undergoing military training in Apollonia, Illyria, when Julius Caesar was assassinated on the Ides of March (15 March) 44\u00a0BC. He rejected the advice of some army officers to take refuge with the troops in Macedonia and sailed to Italy to ascertain whether he had any potential political fortunes or security. Caesar had no living legitimate children under Roman law, and so had adopted Octavius, his grand-nephew, making him his primary heir. Mark Antony later charged that Octavian had earned his adoption by Caesar through sexual favours, though Suetonius describes Antony's accusation as political slander. This form of slander was popular during this time in the Roman Republic to demean and discredit political opponents by accusing them of having an inappropriate sexual affair. After landing at Lupiae near Brundisium, Octavius learned the contents of Caesar's will, and only then did he decide to become Caesar's political heir as well as heir to two-thirds of his estate.\n\nUpon his adoption, Octavius assumed his great-uncle's name Gaius Julius Caesar. Roman citizens adopted into a new family usually retained their old nomen in cognomen form (e.g., Octavianus for one who had been an Octavius, Aemilianus for one who had been an Aemilius, etc.). However, though some of his contemporaries did, there is no evidence that Octavius ever himself officially used the name Octavianus, as it would have made his modest origins too obvious. Historians usually refer to the new Caesar as Octavian during the time between his adoption and his assumption of the name Augustus in 27\u00a0BC in order to avoid confusing the dead dictator with his heir.\n\nOctavian could not rely on his limited funds to make a successful entry into the upper echelons of the Roman political hierarchy. After a warm welcome by Caesar's soldiers at Brundisium, Octavian demanded a portion of the funds that were allotted by Caesar for the intended war against the Parthian Empire in the Middle East. This amounted to 700\u00a0million sesterces stored at Brundisium, the staging ground in Italy for military operations in the east.\n\nA later senatorial investigation into the disappearance of the public funds took no action against Octavian, since he subsequently used that money to raise troops against the Senate's arch enemy Mark Antony. Octavian made another bold move in 44\u00a0BC when, without official permission, he appropriated the annual tribute that had been sent from Rome's Near Eastern province to Italy.\n\nOctavian began to bolster his personal forces with Caesar's veteran legionaries and with troops designated for the Parthian war, gathering support by emphasizing his status as heir to Caesar. On his march to Rome through Italy, Octavian's presence and newly acquired funds attracted many, winning over Caesar's former veterans stationed in Campania. By June, he had gathered an army of 3,000 loyal veterans, paying each a salary of 500 denarii.\n\nGrowing tensions \n\nArriving in Rome on 6 May 44\u00a0BC, Octavian found consul Mark Antony, Caesar's former colleague, in an uneasy truce with the dictator's assassins. They had been granted a general amnesty on 17 March, yet Antony had succeeded in driving most of them out of Rome with an inflammatory eulogy at Caesar's funeral, mounting public opinion against the assassins.\n\nMark Antony was amassing political support, but Octavian still had opportunity to rival him as the leading member of the faction supporting Caesar. Mark Antony had lost the support of many Romans and supporters of Caesar when he initially opposed the motion to elevate Caesar to divine status. Octavian failed to persuade Antony to relinquish Caesar's money to him. During the summer, he managed to win support from Caesarian sympathizers and also made common with the Optimates, the former enemies of Caesar, who saw him as the lesser evil and hoped to manipulate him. In September, the leading Optimate orator Marcus Tullius Cicero began to attack Antony in a series of speeches portraying him as a threat to the Republican order.\n\nFirst conflict with Antony \nWith opinion in Rome turning against him and his year of consular power nearing its end, Antony attempted to pass laws that would assign him the province of Cisalpine Gaul. Octavian meanwhile built up a private army in Italy by recruiting Caesarian veterans and, on 28 November, he won over two of Antony's legions with the enticing offer of monetary gain.\n\nIn the face of Octavian's large and capable force, Antony saw the danger of staying in Rome and, to the relief of the Senate, he left Rome for Cisalpine Gaul, which was to be handed to him on 1 January. However, the province had earlier been assigned to Decimus Junius Brutus Albinus, one of Caesar's assassins, who now refused to yield to Antony. Antony besieged him at Mutina and rejected the resolutions passed by the Senate to stop the fighting. The Senate had no army to enforce their resolutions. This provided an opportunity for Octavian, who already was known to have armed forces. Cicero also defended Octavian against Antony's taunts about Octavian's lack of noble lineage and aping of Julius Caesar's name, stating \"we have no more brilliant example of traditional piety among our youth.\"\n\nAt the urging of Cicero, the Senate inducted Octavian as senator on 1 January 43\u00a0BC, yet he also was given the power to vote alongside the former consuls. In addition, Octavian was granted propraetor imperium (commanding power) which legalized his command of troops, sending him to relieve the siege along with Hirtius and Pansa (the consuls for 43\u00a0BC).  He assumed the fasces on 7 January, a date that he would later commemorate as the beginning of his public career. Antony's forces were defeated at the battles of Forum Gallorum (14 April) and Mutina (21 April), forcing Antony to retreat to Transalpine Gaul. Both consuls were killed, however, leaving Octavian in sole command of their armies.\n\nThe senate heaped many more rewards on Decimus Brutus than on Octavian for defeating Antony, then attempted to give command of the consular legions to Decimus Brutus. In response, Octavian stayed in the Po Valley and refused to aid any further offensive against Antony. In July, an embassy of centurions sent by Octavian entered Rome and demanded the consulship left vacant by Hirtius and Pansa and also that the decree should be rescinded which declared Antony a public enemy. When this was refused, he marched on the city with eight legions. He encountered no military opposition in Rome, and on 19 August 43\u00a0BC was elected consul with his relative Quintus Pedius as co-consul. Meanwhile, Antony formed an alliance with Marcus Aemilius Lepidus, another leading Caesarian.\n\nSecond Triumvirate\n\nProscriptions \n\nIn a meeting near Bologna in October 43\u00a0BC, Octavian, Antony, and Lepidus formed the Second Triumvirate. Their powers were officialized by the Senate on 27 November. This explicit arrogation of special powers lasting five years was then legalised by law passed by the plebs, unlike the unofficial First Triumvirate formed by Pompey, Julius Caesar, and Marcus Licinius Crassus. The triumvirs then set in motion proscriptions, in which between 130 and 300 senators and 2,000 equites were branded as outlaws and deprived of their property and, for those who failed to escape, their lives. This decree issued by the triumvirate was motivated in part by a need to raise money to pay the salaries of their troops for the upcoming conflict against Caesar's assassins, Marcus Junius Brutus and Gaius Cassius Longinus. Rewards for their arrest gave incentive for Romans to capture those proscribed, while the assets and properties of those arrested were seized by the triumvirs.\n\nContemporary Roman historians provide conflicting reports as to which triumvir was most responsible for the proscriptions and killing.  However, the sources agree that enacting the proscriptions was a means by all three factions to eliminate political enemies. Marcus Velleius Paterculus asserted that Octavian tried to avoid proscribing officials whereas Lepidus and Antony were to blame for initiating them. Cassius Dio defended Octavian as trying to spare as many as possible, whereas Antony and Lepidus, being older and involved in politics longer, had many more enemies to deal with.\n\nThis claim was rejected by Appian, who maintained that Octavian shared an equal interest with Lepidus and Antony in eradicating his enemies. Suetonius said that Octavian was reluctant to proscribe officials, but did pursue his enemies with more vigor than the other triumvirs. Plutarch described the proscriptions as a ruthless and cutthroat swapping of friends and family among Antony, Lepidus, and Octavian. For example, Octavian allowed the proscription of his ally Cicero, Antony the proscription of his maternal uncle Lucius Julius Caesar (the consul of 64 BC), and Lepidus his brother Paullus.\n\nBattle of Philippi and division of territory \n\nOn 1 January 42\u00a0BC, the Senate posthumously recognized Julius Caesar as a divinity of the Roman state, Divus Iulius. Octavian was able to further his cause by emphasizing the fact that he was divi filius, \"Son of the Divine\". Antony and Octavian then sent 28 legions by sea to face the armies of Brutus and Cassius, who had built their base of power in Greece. After two battles at Philippi in Macedonia in October 42, the Caesarian army was victorious and Brutus and Cassius committed suicide. Mark Antony later used the examples of these battles as a means to belittle Octavian, as both battles were decisively won with the use of Antony's forces. In addition to claiming responsibility for both victories, Antony also branded Octavian as a coward for handing over his direct military control to Marcus Vipsanius Agrippa instead.\n\nAfter Philippi, a new territorial arrangement was made among the members of the Second Triumvirate. Gaul and the province of Hispania were placed in the hands of Octavian. Antony traveled east to Egypt where he allied himself with Queen Cleopatra VII, the former lover of Julius Caesar and mother of Caesar's infant son Caesarion. Lepidus was left with the province of Africa, stymied by Antony, who conceded Hispania to Octavian instead.\n\nOctavian was left to decide where in Italy to settle the tens of thousands of veterans of the Macedonian campaign, whom the triumvirs had promised to discharge. The tens of thousands who had fought on the republican side with Brutus and Cassius could easily ally with a political opponent of Octavian if not appeased, and they also required land. There was no more government-controlled land to allot as settlements for their soldiers, so Octavian had to choose one of two options: alienating many Roman citizens by confiscating their land, or alienating many Roman soldiers who could mount a considerable opposition against him in the Roman heartland. Octavian chose the former. There were as many as eighteen Roman towns affected by the new settlements, with entire populations driven out or at least given partial evictions.\n\nRebellion and marriage alliances \n\nThere was widespread dissatisfaction with Octavian over these settlements of his soldiers, and this encouraged many to rally at the side of Lucius Antonius, who was brother of Mark Antony and supported by a majority in the Senate. Meanwhile, Octavian asked for a divorce from Claudia, the daughter of Fulvia (Mark Antony's wife) and her first husband Publius Clodius Pulcher. He returned Claudia to her mother, claiming that their marriage had never been consummated. Fulvia decided to take action. Together with Lucius Antonius, she raised an army in Italy to fight for Antony's rights against Octavian. Lucius and Fulvia took a political and martial gamble in opposing Octavian, however, since the Roman army still depended on the triumvirs for their salaries. Lucius and his allies ended up in a defensive siege at Perusia (modern Perugia), where Octavian forced them into surrender in early 40\u00a0BC.\n\nLucius and his army were spared, due to his kinship with Antony, the strongman of the East, while Fulvia was exiled to Sicyon. Octavian showed no mercy, however, for the mass of allies loyal to Lucius; on 15 March, the anniversary of Julius Caesar's assassination, he had 300 Roman senators and equestrians executed for allying with Lucius. Perusia also was pillaged and burned as a warning for others. This bloody event sullied Octavian's reputation and was criticized by many, such as Augustan poet Sextus Propertius.\n\nSextus Pompeius, the son of Pompey and still a renegade general following Julius Caesar's victory over his father, had established himself in Sicily and Sardinia as part of an agreement reached with the Second Triumvirate in 39\u00a0BC. Both Antony and Octavian were vying for an alliance with Pompeius. Octavian succeeded in a temporary alliance in 40\u00a0BC when he married Scribonia, a sister or daughter of Pompeius's father-in-law Lucius Scribonius Libo. Scribonia gave birth to Octav story of resistance, and those brave pioneers of innovationian's only natural child, Julia, the same day that he divorced her to marry Livia Drusilla, little more than a year after their marriage.\n\nWhile in Egypt, Antony had been engaged in an affair with Cleopatra and had fathered twin children with her. Aware of his deteriorating relationship with Octavian, Antony left Cleopatra; he sailed to Italy in 40\u00a0BC with a large force to oppose Octavian, laying siege to Brundisium. This new conflict proved untenable for both Octavian and Antony, however. Their centurions, who had become important figures politically, refused to fight due to their Caesarian cause, while the legions under their command followed suit. Meanwhile, in Sicyon, Antony's wife Fulvia died of a sudden illness while Antony was en route to meet her. Fulvia's death and the mutiny of their centurions allowed the two remaining triumvirs to effect a reconciliation.\n\nIn the autumn of 40, Octavian and Antony approved the Treaty of Brundisium, by which Lepidus would remain in Africa, Antony in the East, Octavian in the West. The Italian Peninsula was left open to all for the recruitment of soldiers, but in reality, this provision was useless for Antony in the East. To further cement relations of alliance with Mark Antony, Octavian gave his sister, Octavia Minor, in marriage to Antony in late 40\u00a0BC.\n\nWar with Pompeius \n\nSextus Pompeius threatened Octavian in Italy by denying shipments of grain through the Mediterranean Sea to the peninsula. Pompeius's own son was put in charge as naval commander in the effort to cause widespread famine in Italy. Pompeius's control over the sea prompted him to take on the name Neptuni filius, \"son of Neptune\". A temporary peace agreement was reached in 39\u00a0BC with the treaty of Misenum; the blockade on Italy was lifted once Octavian", "flag": 1, "segments": [[4580, 4590]], "strength": 5.5}
{"text": "Allosaurus () is a genus of large carnosaurian theropod dinosaur that lived 155 to 145\u00a0million years ago during the Late Jurassic epoch (Kimmeridgian to late Tithonian). The name \"Allosaurus\" means \"different lizard\" alluding to its unique (at the time of its discovery) concave vertebrae. It is derived from the Greek  () (\"different, other\") and  () (\"lizard / generic reptile\"). The first fossil remains that could definitively be ascribed to this genus were described in 1877 by paleontologist Othniel Charles Marsh. As one of the first well-known theropod dinosaurs, it has long attracted attention outside of paleontological circles.\n\nAllosaurus was a large bipedal predator. Its skull was light, robust and equipped with dozens of sharp, serrated teeth. It averaged  in length for A. fragilis, with the maximum length estimate being 9.7 meters long. Relative to the large and powerful hindlimbs, its three-fingered forelimbs were small, and the body was balanced by a long and heavily muscled tail. It is classified as an allosaurid, a type of carnosaurian theropod dinosaur. \n\nThe genus has a complicated taxonomy, and includes three valid species, the best known of which is A. fragilis. The bulk of Allosaurus remains have come from North America's Morrison Formation, with material also known from Portugal. It was known for over half of the 20th century as Antrodemus, but a study of the copious remains from the Cleveland-Lloyd Dinosaur Quarry brought the name \"Allosaurus\" back to prominence and established it as one of the best-known dinosaurs.\n\nAs the most abundant large predator in the Morrison Formation, Allosaurus be feasible. Yet with this situation in effect there was at the top of the food chain, probably preying on contemporaneous large herbivorous dinosaurs, and perhaps other predators. Potential prey included ornithopods, stegosaurids, and sauropods. Some paleontologists interpret Allosaurus as having had cooperative social behavior, and hunting in packs, while others believe individuals may have been aggressive toward each other, and that congregations of this genus are the result of lone individuals feeding on the same carcasses.\n\nDescription\n\nAllosaurus was a typical large theropod, having a massive skull on a short neck, a long, slightly sloping tail, and reduced forelimbs. Allosaurus fragilis, the best-known species, had an average length of, with the largest definitive Allosaurus specimen (AMNH 680) estimated at  long, with an estimated weight of. In his 1976 monograph on Allosaurus, James H. Madsen mentioned a range of bone sizes which he interpreted to show a maximum length of. As with dinosaurs in general, weight estimates are debatable, and since 1980 have ranged between,, and  for modal adult weight (not maximum). John Foster, a specialist on the Morrison Formation, suggests that  is reasonable for large adults of A. fragilis, but that  is a closer estimate for individuals represented by the average-sized thigh bones he has measured. Using the subadult specimen nicknamed \"Big Al\", since assigned to the species Allosaurus jimmadseni, researchers using computer modelling arrived at a best estimate of  for the individual, but by varying parameters they found a range from approximately  to approximately.\n\nSeveral gigantic specimens have been attributed to Allosaurus, but may in fact belong to other genera. The closely related genus Saurophaganax (OMNH 1708) reached perhaps  in length, and its single species has sometimes been included in the genus Allosaurus as Allosaurus maximus, though recent studies support it as a separate genus. Another potential specimen of Allosaurus, once assigned to the genus Epanterias (AMNH 5767), may have measured  in length. A more recent discovery is a partial skeleton from the Peterson Quarry in Morrison rocks of New Mexico; this large allosaurid may be another individual of Saurophaganax.\n\nDavid K. Smith, examining Allosaurus fossils by quarry, found that the Cleveland-Lloyd Dinosaur Quarry (Utah) specimens are generally smaller than those from Como Bluff (Wyoming) or Brigham Young University's Dry Mesa Quarry (Colorado), but the shapes of the bones themselves did not vary between the sites. A later study by Smith incorporating Garden Park (Colorado) and Dinosaur National Monument (Utah) specimens found no justification for multiple species based on skeletal variation; skull variation was most common and was gradational, suggesting individual variation was responsible. Further work on size-related variation again found no consistent differences, although the Dry Mesa material tended to clump together on the basis of the astragalus, an ankle bone. Kenneth Carpenter, using skull elements from the Cleveland-Lloyd site, found wide variation between individuals, calling into question previous species-level distinctions based on such features as the shape of the horns, and the proposed differentiation of A. jimmadseni based on the shape of the jugal. A study published by Motani et al., in 2020 suggests that Allosaurus was also sexually dimorphic in the width of the femur's head against its length.\n\nSkull\n\nThe skull and teeth of Allosaurus were modestly proportioned for a theropod of its size. Paleontologist Gregory S. Paul gives a length of  for a skull belonging to an individual he estimates at  long. Each premaxilla (the bones that formed the tip of the snout) held five teeth with D-shaped cross-sections, and each maxilla (the main tooth-bearing bones in the upper jaw) had between 14 and 17 teeth; the number of teeth does not exactly correspond to the size of the bone. Each dentary (the tooth-bearing bone of the lower jaw) had between 14 and 17 teeth, with an average count of 16. The teeth became shorter, narrower, and more curved toward the back of the skull. All of the teeth had saw-like edges. They were shed easily, and were replaced continually, making them common fossils. Its skull was light, robust and equipped with dozens of sharp, serrated teeth. Its skull averaged  long but could possibly reach.\n\nThe skull had a pair of horns above and in front of the eyes. These horns were composed of extensions of the lacrimal bones, and varied in shape and size. There were also lower paired ridges running along the top edges of the nasal bones that led into the horns. The horns were probably covered in a keratin sheath and may have had a variety of functions, including acting as sunshades for the eyes, being used for display, and being used in combat against other members of the same species (although they were fragile). There was a ridge along the back of the skull roof for muscle attachment, as is also seen in tyrannosaurids.\n\nInside the lacrimal bones were depressions that may have held glands, such as salt glands. Within the maxillae were sinuses that were better developed than those of more basal theropods such as Ceratosaurus and Marshosaurus; they may have been related to the sense of smell, perhaps holding something like Jacobson's organs. The roof of the braincase was thin, perhaps to improve thermoregulation for the brain. The skull and lower jaws had joints that permitted motion within these units. In the lower jaws, the bones of the front and back halves loosely articulated, permitting the jaws to bow outward and increasing the animal's gape. The braincase and frontals may also have had a joint.\n\nPostcranial skeleton\n\nAllosaurus had nine vertebrae in the neck, 14 in the back, and five in the sacrum supporting the hips. The number of tail vertebrae is unknown and varied with individual size; James Madsen estimated about 50, while Gregory S. Paul considered that to be too many and suggested 45 or less. There were hollow spaces in the neck and anterior back vertebrae. Such spaces, which are also found in modern theropods (that is, the birds), are interpreted as having held air sacs used in respiration. The rib cage was broad, giving it a barrel chest, especially in comparison to less derived theropods like Ceratosaurus. Allosaurus had gastralia (belly ribs), but these are not common findings, and they may have ossified poorly. In one published case, the gastralia show evidence of injury during life. A furcula (wishbone) was also present, but has only been recognized since 1996; in some cases furculae were confused with gastralia. The ilium, the main hip bone, was massive, and the pubic bone had a prominent foot that may have been used for both muscle attachment and as a prop for resting the body on the ground. Madsen noted that in about half of the individuals from the Cleveland-Lloyd Dinosaur Quarry, independent of size, the pubes had not fused to each other at their foot ends. He suggested that this was a sexual characteristic, with females lacking fused bones to make egg-laying easier. This proposal has not attracted further attention, however.\n\nThe forelimbs of Allosaurus were short in comparison to the hindlimbs (only about 35% the length of the hindlimbs in adults) and had three fingers per hand, tipped with large, strongly curved and pointed claws. The arms were powerful, and the forearm was somewhat shorter than the upper arm (1:1.2\u00a0ulna/humerus ratio). The wrist had a version of the semilunate carpal also found in more derived theropods like maniraptorans. Of the three fingers, the innermost (or thumb) was the largest, and diverged from the others. The phalangeal formula is 2-3-4-0-0, meaning that the innermost finger (phalange) has two bones, the next has three, and the third finger has four. The legs were not as long or suited for speed as those of tyrannosaurids, and the claws of the toes were less developed and more hoof-like than those of earlier theropods. Each foot had three weight-bearing toes and an inner dewclaw, which Madsen suggested could have been used for grasping in juveniles. There was also what is interpreted as the splint-like remnant of a fifth (outermost) metatarsal, perhaps used as a lever between the Achilles tendon and foot.\n\nDiscovery and history\n\nEarly discoveries and research\n\nThe discovery and early study of Allosaurus is complicated by the multiplicity of names coined during the Bone Wars of the late 19th century. The first described fossil in this history was a bone obtained secondhand by Ferdinand Vandeveer Hayden in 1869. It came from Middle Park, near Granby, Colorado, probably from Morrison Formation rocks. The locals had identified such bones as \"petrified horse hoofs\". Hayden sent his specimen to Joseph Leidy, who identified it as half of a tail vertebra, and tentatively assigned it to the European dinosaur genus Poekilopleuron as Poicilopleuron  valens. He later decided it deserved its own genus, Antrodemus.\n\nAllosaurus itself is based on YPM 1930, a small collection of fragmentary bones including parts of three vertebrae, a rib fragment, a tooth, a toe bone, and, most useful for later discussions, the shaft of the right humerus (upper arm). Othniel Charles Marsh gave these remains the formal name Allosaurus fragilis in 1877. Allosaurus comes from the Greek /, meaning \"strange\" or \"different\" and /, meaning \"lizard\" or \"reptile\". It was named 'different lizard' because its vertebrae were different from those of other dinosaurs known at the time of its discovery. The species epithet fragilis is Latin for \"fragile\", referring to lightening features in the vertebrae. The bones were collected from the Morrison Formation of Garden Park, north of Ca\u00f1on City. Marsh and Edward Drinker Cope, who were in scientific competition with each other, went on to coin several other genera based on similarly sparse material that would later figure in the taxonomy of Allosaurus. These include Marsh's Creosaurus and Labrosaurus, and Cope's Epanterias.\n\nIn their haste, Cope and Marsh did not always follow up on their discoveries (or, more commonly, those made by their subordinates). For example, after the discovery by Benjamin Mudge of the type specimen of Allosaurus in Colorado, Marsh elected to concentrate work in Wyoming; when work resumed at Garden Park in 1883, M. P. Felch found an almost complete Allosaurus and several partial skeletons. In addition, one of Cope's collectors, H. F. Hubbell, found a specimen in the Como Bluff area of Wyoming in 1879, but apparently did not mention its completeness, and Cope never unpacked it. Upon unpacking in 1903 (several years after Cope had died), it was found to be one of the most complete theropod specimens then known, and in 1908 the skeleton, now cataloged as AMNH 5753, was put on public view. This is the well-known mount poised over a partial Apatosaurus skeleton as if scavenging it, illustrated as such by Charles R. Knight. Although notable as the first free-standing mount of a theropod dinosaur, and often illustrated and photographed, it has never been scientifically described.\n\nThe multiplicity of early names complicated later research, with the situation compounded by the terse descriptions provided by Marsh and Cope. Even at the time, authors such as Samuel Wendell Williston suggested that too many names had been coined. For example, Williston pointed out in 1901 that Marsh had never been able to adequately distinguish Allosaurus from Creosaurus. The most influential early attempt to sort out the convoluted situation was produced by Charles W. Gilmore in 1920. He came to the conclusion that the tail vertebra named Antrodemus by Leidy was indistinguishable from those of Allosaurus, and Antrodemus thus should be the preferred name because, as the older name, it had priority. Antrodemus became the accepted name for this familiar genus for over 50 years, until James Madsen published on the Cleveland-Lloyd specimens and concluded that Allosaurus should be used because Antrodemus was based on material with poor, if any, diagnostic features and locality information (for example, the geological formation that the single bone of Antrodemus came from is unknown). \"Antrodemus\" has been used informally for convenience when distinguishing between the skull Gilmore restored and the composite skull restored by Madsen.\n\nCleveland-Lloyd discoveries\n\nAlthough sporadic work at what became known as the Cleveland-Lloyd Dinosaur Quarry in Emery County, Utah, had taken place as early as 1927, and the fossil site itself described by William L. Stokes in 1945, major operations did not begin there until 1960. Under a cooperative effort involving nearly 40\u00a0institutions, thousands of bones were recovered between 1960 and 1965. The quarry is notable for the predominance of Allosaurus remains, the condition of the specimens, and the lack of scientific resolution on how it came to be. The majority of bones belong to the large theropod Allosaurus fragilis (it is estimated that the remains of at least 46\u00a0A. fragilis have been found there, out of at a minimum 73\u00a0dinosaurs), and the fossils found there are disarticulated and well-mixed. Nearly a dozen scientific papers have been written on the taphonomy of the site, suggesting numerous mutually exclusive explanations for how it may have formed. Suggestions have ranged from animals getting stuck in a bog, to becoming trapped in deep mud, to falling victim to drought-induced mortality around a waterhole, to getting trapped in a spring-fed pond or seep. Regardless of the actual cause, the great quantity of well-preserved Allosaurus remains has allowed this genus to be known in detail, making it among the best-known theropods. Skeletal remains from the quarry pertain to individuals of almost all ages and sizes, from less than  to  long, and the disarticulation is an advantage for describing bones usually found fused. Due to being one of Utah's two fossil quarries where many Allosaurus specimens have been discovered, Allosaurus was designated as the state fossil of Utah in 1988.\n\nRecent work: 1980s\u2013present\nThe period since Madsen's monograph has been marked by a great expansion in studies dealing with topics concerning Allosaurus in life (paleobiological and paleoecological topics). Such studies have covered topics including skeletal variation, growth, skull construction, hunting methods, the brain, and the possibility of gregarious living and parental care. Reanalysis of old material (particularly of large 'allosaur' specimens), new discoveries in Portugal, and several very complete new specimens have also contributed to the growing knowledge base.\n\n\"Big Al\" and \"Big Al II\"\n\nIn 1991,  \"Big Al\" (MOR 693), a 95%\u00a0complete, partially articulated specimen of Allosaurus was discovered. It measured about 8\u00a0meters (about 26\u00a0ft) in length. MOR 693 was excavated near Shell, Wyoming, by a joint Museum of the Rockies and University of Wyoming Geological Museum team. This skeleton was discovered by a Swiss team, led by Kirby Siber. Chure and Loewen in 2020 identified the individual as a representative of the species Allosaurus jimmadseni. In 1996, the same team discovered a second Allosaurus, \"Big Al II\". This specimen, the best preserved skeleton of its kind to date, is also referred to Allosaurus jimmadseni.\n\nThe completeness, preservation, and scientific importance of this skeleton gave \"Big Al\" its name; the individual itself was below the average size for Allosaurus fragilis, and was a subadult estimated at only 87%\u00a0grown. The specimen was described by Breithaupt in 1996. Nineteen of its bones were broken or showed signs of infection, which may have contributed to \"Big Al's\" death. Pathologic bones included five ribs, five vertebrae, and four bones of the feet; several damaged bones showed osteomyelitis, a bone infection. A particular problem for the living animal was infection and trauma to the right foot that probably affected movement and may have also predisposed the other foot to injury because of a change in gait. Al had an infection on the first phalanx on the third toe that was afflicted by an involucrum. The infection was long-lived, perhaps up to six months. Big Al Two is also known to have multiple injuries.\n\nSpecies\n\nSix species of Allosaurus have been named: A. amplus, A. atrox, A. europaeus, the type species A. fragilis, A. jimmadseni and A. lucasi. Among these, Daniel Chure and Mark Loewen in 2020 only recognized the species A. fragilis, A. europaeus, and the newly-named A. jimmadseni as being valid species.\n\nA. fragilis is the type species and was named by Marsh in 1877. It is known from the remains of at least 60 individuals, all found in the Kimmeridgian\u2013Tithonian Upper Jurassic-age Morrison Formation of the United States, spread across the states of Colorado, Montana, New Mexico, Oklahoma, South Dakota, Utah, and Wyoming. Details of the humerus (upper arm) of A. fragilis have been used as diagnostic among Morrison theropods, but A. jimmadseni indicates that this is no longer the case at the species level.\n\nA. jimmadseni has been scientifically described based on two nearly complete skeletons. The first specimen to wear the identification was unearthed in Dinosaur National Monument in northeastern Utah, with the original \"Big Al\" individual subsequently recognized as belonging to the same species. This species differs from A. fragilis in several anatomical details, including a jugal or cheekbone with a straight lower margin. Fossils are confined to the Salt Wash Member of the Morrison Formation, with A. fragilis only found in the higher Brushy Basin Member.\n\nA. fragilis, A. jimmadseni, A. amplus, and A. lucasi are all known from remains discovered in the Kimmeridgian\u2013Tithonian Upper Jurassic-age Morrison Formation of the United States, spread across the states of Colorado, Montana, New Mexico, Oklahoma, South Dakota, Utah and Wyoming. A. fragilis is regarded as the most common, known from the remains of at least 60 individuals. For a while in the late 1980s and early 1990s, it was common to recognize A. fragilis as the short-snouted species, with the long-snouted taxon being A. atrox; however, subsequent analysis of specimens from the Cleveland-Lloyd Dinosaur Quarry, Como Bluff, and Dry Mesa Quarry showed that the differences seen in the Morrison Formation material could be attributed to individual variation. A study of skull elements from the Cleveland-Lloyd site found wide variation between individuals, calling into question previous species-level distinctions based on such features as the shape of the lacrimal horns, and the proposed differentiation of A. jimmadseni based on the shape of the jugal. A. europaeus was found in the Kimmeridgian-age Porto Novo Member of the Lourinh\u00e3 Formation, but may be the same as A. fragilis.\n\nAllosaurus material from Portugal was first reported in 1999 on the basis of MHNUL/AND.001, a partial skeleton including a quadrate, vertebrae, ribs, gastralia, chevrons, part of the hips, and hindlimbs.  This specimen was assigned to A. fragilis, but the subsequent discovery of a partial skull and neck (ML 415) near Lourinh\u00e3, in the Kimmeridgian-age Porto Novo Member of the Lourinh\u00e3 Formation, spurred the naming of the new species A. europaeus by Oct\u00e1vio Mateus and colleagues. The species appeared earlier in the Jurassic than A. fragilis and differs from other species of Allosaurus in cranial details. However, more material may show it to be A. fragilis, as originally described.\n\nThe issue of species and potential synonyms is complicated by the type specimen of Allosaurus fragilis (catalog number YPM\u00a01930) being extremely fragmentary, consisting of a few incomplete vertebrae, limb bone fragments, rib fragments, and a tooth. Because of this, several scientists have interpreted the type specimen as potentially dubious, and thus the genus Allosaurus itself or at least the species A. fragilis would be a nomen dubium (\"dubious name\", based on a specimen too incomplete to compare to other specimens or to classify). To address this situation, Gregory S. Paul and Kenneth Carpenter (2010) submitted a petition to the ICZN to have the name \"A. fragilis\" officially transferred to the more complete specimen USNM4734 (as a neotype).\n\nSynonyms\n\nCreosaurus, Epanterias, and Labrosaurus are regarded as junior synonyms of Allosaurus. Most of the species that are regarded as synonyms of A. fragilis, or that were misassigned to the genus, are obscure and were based on scrappy remains. One exception is Labros", "flag": 1, "segments": [[382, 392]], "strength": 5.5}
{"text": "Ammonia is a compound of nitrogen and hydrogen with the formula NH3. A stable binary hydride, and the simplest pnictogen hydride, ammonia is a colourless gas with a distinct pungent smell. It is a common nitrogenous waste, particularly among aquatic organisms, and it contributes significantly to the nutritional needs of terrestrial organisms by serving as a precursor to 45 percent of the world's food and fertilizers. Ammonia, either directly or indirectly, is also a building block for the synthesis of many pharmaceutical products and is used in many commercial cleaning products. It is mainly collected by downward displacement of both air and water.\n\nAlthough common in natureboth terrestrially and in the outer planets of the Solar Systemand in wide use, ammonia is both caustic and hazardous in its concentrated form. In many countries it is classified as an extremely hazardous substance, and is subject to strict reporting requirements by facilities which produce, store, or use it in significant quantities.\n\nThe global industrial production of ammonia in 2018 was 175 million tonnes, with no significant change relative to the 2013 global industrial production of 175 million tonnes. Industrial ammonia is sold either as ammonia liquor (usually 28% ammonia in water) or as pressurized or refrigerated anhydrous liquid ammonia transported in tank cars or cylinders.\n\nNH3 boils at  at a pressure of one atmosphere, so the liquid must be stored under pressure or at low temperature. Household ammonia or ammonium hydroxide is a solution of NH3 in water. The concentration of such solutions is measured in units of the Baum\u00e9 scale (density), with 26 degrees Baum\u00e9 (about 30% (by weight) ammonia at ) being the typical high-concentration commercial product.\n\nEtymology\nPliny, in Book XXXI of his Natural History, refers to a salt produced in the Roman province of Cyrenaica named hammoniacum, so called because of its proximity to the nearby Temple of Jupiter Amun (Greek \u1f0c\u03bc\u03bc\u03c9\u03bd Ammon). However, the description Pliny gives of the salt does not conform to the properties of ammonium chloride. According to Herbert Hoover's commentary in his English translation of Georgius Agricola's De re metallica, it is likely to have been common sea salt. In any case, that salt ultimately gave ammonia and ammonium compounds their name.\n\nNatural occurrence\nAmmonia is a chemical found in trace quantities in nature, being produced from nitrogenous animal and vegetable matter. Ammonia and ammonium salts are also found in small quantities in rainwater, whereas ammonium chloride (sal ammoniac), and ammonium sulfate are found in volcanic districts; crystals of ammonium bicarbonate have been found in Patagonia guano. The kidneys secrete ammonia to neutralize excess acid. Ammonium salts are found distributed through fertile soil and in seawater.\n\nAmmonia is also found throughout the Solar System on Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto, among other places: on smaller, icy bodies such as Pluto, ammonia can act as a geologically important antifreeze, as a mixture of water and ammonia can have a melting point as low as  if the ammonia concentration is high enough and thus allow such bodies to retain internal oceans and active geology at a far lower temperature than would be possible with water alone. Substances containing ammonia, or those that are similar to it, are called ammoniacal.\n\nProperties\nAmmonia is a colourless gas with a characteristically pungent smell. It is lighter than air, its density being 0.589 times that of air. It is easily liquefied due to the strong hydrogen bonding between molecules; the liquid boils at, and freezes to white crystals at.\n\nSolid The crystal symmetry is cubic, Pearson symbol cP16, space group P213 No.198, lattice constant 0.5125\u00a0nm.\nLiquid Liquid ammonia possesses strong ionising powers reflecting its high \u03b5 of 22. Liquid ammonia has a very high standard enthalpy change of vaporization (23.35\u00a0kJ/mol, cf. water 40.65\u00a0kJ/mol, methane 8.19\u00a0kJ/mol, phosphine 14.6\u00a0kJ/mol) and can therefore be used in laboratories in uninsulated vessels without additional refrigeration. See liquid ammonia as a solvent.\nSolvent properties Ammonia readily dissolves in water. In an aqueous solution, it can be expelled by boiling. The aqueous solution of ammonia is basic. The maximum concentration of ammonia in water (a saturated solution) has a density of 0.880 g/cm3 and is often known as '.880 ammonia'. \nCombustion Ammonia does not burn readily or sustain combustion, except under narrow fuel-to-air mixtures of 15\u201325% air. When mixed with oxygen, it burns with a pale yellowish-green flame. Ignition occurs when chlorine is passed into ammonia, forming nitrogen and hydrogen chloride; if chlorine is present in excess, then the highly explosive nitrogen trichloride (NCl3) is also formed.\nDecomposition At high temperature and in the presence of a suitable catalyst, ammonia is decomposed into its constituent elements. Decomposition of ammonia is a slightly endothermic process requiring 23 kJ/mol (5.5 kcal/mol) of ammonia, and yields hydrogen and nitrogen gas. Ammonia can also be used as a source of hydrogen for acid fuel cells if the unreacted ammonia can be removed. Ruthenium and platinum catalysts were found to be the most active, whereas supported Ni catalysts were the less active.\n\nStructure\nThe ammonia molecule has a trigonal pyramidal shape as predicted by the valence shell electron pair repulsion theory (VSEPR theory) with an experimentally determined bond angle of 106.7\u00b0. The central nitrogen atom has five outer electrons with an additional electron from each hydrogen atom. This gives a total of eight electrons, or four electron pairs that are arranged tetrahedrally. Three of these electron pairs are used as bond pairs, which leaves one lone pair of electrons. The lone pair repels more strongly than bond pairs, therefore the bond angle is not 109.5\u00b0, as expected for a regular tetrahedral arrangement, but 106.8\u00b0. This shape gives the molecule a dipole moment and makes it polar. The molecule's polarity, and especially, its ability to form hydrogen bonds, makes ammonia highly miscible with water. The lone pair makes ammonia a base, a proton acceptor. Ammonia is moderately basic; a 1.0 M aqueous solution has a pH of 11.6, and if a strong acid is added to such a solution until the solution is neutral (pH = 7), 99.4% of the ammonia molecules are protonated. Temperature and salinity also affect the proportion of NH4+. The latter has the shape of a regular tetrahedron and is isoelectronic with methane.\n\nThe ammonia molecule readily undergoes nitrogen inversion at room temperature; a useful analogy is an umbrella turning itself inside out in a strong wind. The energy barrier to this inversion is 24.7 kJ/mol, and the resonance frequency is 23.79 GHz, corresponding to microwave radiation of a wavelength of 1.260\u00a0cm. The absorption at this frequency was the first microwave spectrum to be observed  and was used in the first maser.\n\nAmphotericity\nOne of the most characteristic properties of ammonia is its basicity. Ammonia is considered to be a weak base. It combines with acids to form salts; thus with hydrochloric acid it forms ammonium chloride (sal ammoniac); with nitric acid, ammonium nitrate, etc. Perfectly dry ammonia gas will not combine with perfectly dry hydrogen chloride gas; moisture is necessary to bring about the reaction.\n\nAs a demonstration experiment under air with ambient moisture, opened bottles of concentrated ammonia and hydrochloric acid solutions produce a cloud of ammonium chloride, which seems to appear \"out of nothing\" as the salt aerosol forms where the two diffusing clouds of reagents meet between the two bottles.\n\n NH3 + HCl \u2192 NH4Cl\n\nThe salts produced by the action of ammonia on acids are known as the ammonium salts and all contain the ammonium ion (NH4+).\n\nAlthough ammonia is well known as a weak base, it can also act as an extremely weak acid. It is a protic substance and is capable of formation of amides (which contain the NH2\u2212 ion). For example, lithium dissolves in liquid ammonia to give a blue solution (solvated electron) of lithium amide:\n\n 2 Li + 2 NH3 \u2192 2 LiNH2 + H2\n\nSelf-dissociation\nLike water, liquid ammonia undergoes molecular autoionisation to form its acid and base conjugates:\n\n 2    + \n\nAmmonia often functions as a weak base, so it has some buffering ability. Shifts in pH will cause more or fewer ammonium cations () and amide anions () to be present in solution. At standard pressure and temperature, K = [] \u00d7 [] = 10.\n\nCombustion\nThe combustion of ammonia to form nitrogen and water is exother would be far more positive unless the amendment is passedmic:\n\n 4 NH3 + 3 O2 \u2192 2 N2 + 6 H2O (g) \u0394H\u00b0r = \u22121267.20 kJ (or \u2212316.8 kJ/mol if expressed per mol of NH3)\n\nThe standard enthalpy change of combustion, \u0394H\u00b0c, expressed per mole of ammonia and with condensation of the water formed, is \u2212382.81\u00a0kJ/mol. Dinitrogen is the thermodynamic product of combustion: all nitrogen oxides are unstable with respect to N2 and O2, which is the principle behind the catalytic converter. Nitrogen oxides can be formed as kinetic products in the presence of appropriate catalysts, a reaction of great industrial importance in the production of nitric acid:\n\n 4 NH3 + 5 O2 \u2192 4 NO + 6 H2O\n\nA subsequent reaction leads to NO2:\n\n 2 NO + O2 \u2192 2 NO2\n\nThe combustion of ammonia in air is very difficult in the absence of a catalyst (such as platinum gauze or warm chromium(III) oxide), due to the relatively low heat of combustion, a lower laminar burning velocity, high auto-ignition temperature, high heat of vaporization, and a narrow flammability range. However, recent studies have shown that efficient and stable combustion of ammonia can be achieved using swirl combustors, thereby rekindling research interest in ammonia as a fuel for thermal power production. The flammable range of ammonia in dry air is 15.15\u201327.35% and in 100% relative humidity air is 15.95\u201326.55%. For studying the kinetics of ammonia combustion, knowledge of a detailed reliable reaction mechanism is required, but this has been challenging to obtain.\n\nFormation of other compounds\nIn organic chemistry, ammonia can act as a nucleophile in substitution reactions. Amines can be formed by the reaction of ammonia with alkyl halides, although the resulting \u2212NH2 group is also nucleophilic and secondary and tertiary amines are often formed as byproducts. An excess of ammonia helps minimise multiple substitution and neutralises the hydrogen halide formed. Methylamine is prepared commercially by the reaction of ammonia with chloromethane, and the reaction of ammonia with 2-bromopropanoic acid has been used to prepare racemic alanine in 70% yield. Ethanolamine is prepared by a ring-opening reaction with ethylene oxide: the reaction is sometimes allowed to go further to produce diethanolamine and triethanolamine.\n\nAmides can be prepared by the reaction of ammonia with carboxylic acid derivatives. Acyl chlorides are the most reactive, but the ammonia must be present in at least a twofold excess to neutralise the hydrogen chloride formed. Esters and anhydrides also react with ammonia to form amides. Ammonium salts of carboxylic acids can be dehydrated to amides so long as there are no thermally sensitive groups present: temperatures of 150\u2013200\u00a0\u00b0C are required.\n\nThe hydrogen in ammonia is susceptible to replacement by a myriad of substituents. When dry ammonia gas is heated with metallic sodium it converts to sodamide, NaNH2.  With chlorine, monochloramine is formed.\n\nPentavalent ammonia is known as \u03bb5-amine or, more commonly, ammonium hydride. This crystalline solid is only stable under high pressure and decomposes back into trivalent ammonia and hydrogen gas at normal conditions. This substance was once investigated as a possible solid rocket fuel in 1966.\n\nAmmonia as a ligand \n\nAmmonia can act as a ligand in transition metal complexes. It is a pure \u03c3-donor, in the middle of the spectrochemical series, and shows intermediate hard\u2013soft behaviour (see also ECW model). Its relative donor strength toward a series of acids, versus other Lewis bases, can be illustrated by C-B plots.  For historical reasons, ammonia is named ammine in the nomenclature of coordination compounds. Some notable ammine complexes include tetraamminediaquacopper(II) ([Cu(NH3)4(H2O)2]2+), a dark blue complex formed by adding ammonia to a solution of copper(II) salts. Tetraamminediaquacopper(II) hydroxide is known as Schweizer's reagent, and has the remarkable ability to dissolve cellulose. Diamminesilver(I) ([Ag(NH3)2]+) is the active species in Tollens' reagent. Formation of this complex can also help to distinguish between precipitates of the different silver halides: silver chloride (AgCl) is soluble in dilute (2\u00a0M) ammonia solution, silver bromide (AgBr) is only soluble in concentrated ammonia solution, whereas silver iodide (AgI) is insoluble in aqueous ammonia.\n\nAmmine complexes of chromium(III) were known in the late 19th century, and formed the basis of Alfred Werner's revolutionary theory on the structure of coordination compounds. Werner noted only two isomers (fac- and mer-) of the complex [CrCl3(NH3)3] could be formed, and concluded the ligands must be arranged around the metal ion at the vertices of an octahedron. This proposal has since been confirmed by X-ray crystallography.\n\nAn ammine ligand bound to a metal ion is markedly more acidic than a free ammonia molecule, although deprotonation in aqueous solution is still rare. One example is the Calomel reaction, where the resulting amidomercury(II) compound is highly insoluble.\n\n HgCl2 + 2 NH3 \u2192 HgCl(NH2) + NH4Cl\n\nAmmonia forms 1:1 adducts with a variety of Lewis acids such as I2, phenol, and Al(CH3)3.   Ammonia is a hard base (HSAB theory) and its E & C parameters are EB = 2.31 and C B = 2.04. Its relative donor strength toward a series of acids, versus other Lewis bases, can be illustrated by C-B plots.\n\nDetection and determination\n\nAmmonia in solution\n\nAmmonia and ammonium salts can be readily detected, in very minute traces, by the addition of Nessler's solution, which gives a distinct yellow colouration in the presence of the slightest trace of ammonia or ammonium salts. The amount of ammonia in ammonium salts can be estimated quantitatively by distillation of the salts with sodium or potassium hydroxide, the ammonia evolved being absorbed in a known volume of standard sulfuric acid and the excess of acid then determined volumetrically; or the ammonia may be absorbed in hydrochloric acid and the ammonium chloride so formed precipitated as ammonium hexachloroplatinate, (NH4)2PtCl6.\n\nGaseous ammonia\nSulfur sticks are burnt to detect small leaks in industrial ammonia refrigeration systems. Larger quantities can be detected by warming the salts with a caustic alkali or with quicklime, when the characteristic smell of ammonia will be at once apparent. Ammonia is an irritant and irritation increases with concentration; the permissible exposure limit is 25\u00a0ppm, and lethal above 500\u00a0ppm. Higher concentrations are hardly detected by conventional detectors, the type of detector is chosen according to the sensitivity required (e.g. semiconductor, catalytic, electrochemical). Holographic sensors have been proposed for detecting concentrations up to 12.5% in volume.\n\nAmmoniacal nitrogen (NH3-N)\nAmmoniacal nitrogen (NH3-N) is a measure commonly used for testing the quantity of ammonium ions, derived naturally from ammonia, and returned to ammonia via organic processes, in water or waste liquids. It is a measure used mainly for quantifying values in waste treatment and water purification systems, as well as a measure of the health of natural and man-made water reserves. It is measured in units of mg/L (milligram per litre).\n\nHistory\n\nThe ancient Greek historian Herodotus mentioned that there were outcrops of salt in an area of Libya that was inhabited by a people called the \"Ammonians\" (now:  the Siwa oasis in northwestern Egypt, where salt lakes still exist). The Greek geographer Strabo also mentioned the salt from this region. However, the ancient authors Dioscorides, Apicius, Arrian, Synesius, and A\u00ebtius of Amida described this salt as forming clear crystals that could be used for cooking and that were essentially rock salt.  Hammoniacus sal appears in the writings of Pliny, although it is not known whether the term is identical with the more modern sal ammoniac (ammonium chloride).\n\nThe fermentation of urine by bacteria produces a solution of ammonia; hence fermented urine was used in Classical Antiquity to wash cloth and clothing, to remove hair from hides in preparation for tanning, to serve as a mordant in dying cloth, and to remove rust from iron.\n\nIn the form of sal ammoniac (\u0646\u0634\u0627\u062f\u0631, nushadir), ammonia was important to the Muslim alchemists as early as the 8th century, first mentioned by the Persian-Arab chemist J\u0101bir ibn Hayy\u0101n, and to the European alchemists since the 13th century, being mentioned by Albertus Magnus. It was also used by dyers in the Middle Ages in the form of fermented urine to alter the colour of vegetable dyes. In the 15th century, Basilius Valentinus showed that ammonia could be obtained by the action of alkalis on sal ammoniac. At a later period, when sal ammoniac was obtained by distilling the hooves and horns of oxen and neutralizing the resulting carbonate with hydrochloric acid, the name \"spirit of hartshorn\" was applied to ammonia.\n\nGaseous ammonia was first isolated by Joseph Black in 1756 by reacting sal ammoniac (ammonium chloride) with calcined magnesia (magnesium oxide). It was isolated again by Peter Woulfe in 1767, by Carl Wilhelm Scheele in 1770 and by Joseph Priestley in 1773 and was termed by him \"alkaline air\". Eleven years later in 1785, Claude Louis Berthollet ascertained its composition.\n\nThe Haber\u2013Bosch process to produce ammonia from the nitrogen in the air was developed by Fritz Haber and Carl Bosch in 1909 and patented in 1910. It was first used on an industrial scale in Germany during World War I, following the allied blockade that cut off the supply of nitrates from Chile. The ammonia was used to produce explosives to sustain war efforts.\n\nBefore the availability of natural gas, hydrogen as a precursor to ammonia production was produced via the electrolysis of water or using the chloralkali process.\n\nWith the advent of the steel industry in the 20th century, ammonia became a byproduct of the production of coking coal.\n\nApplications\n\nSolvent \n\nLiquid ammonia is the best-known and most widely studied nonaqueous ionising solvent. Its most conspicuous property is its ability to dissolve alkali metals to form highly coloured, electrically conductive solutions containing solvated electrons. Apart from these remarkable solutions, much of the chemistry in liquid ammonia can be classified by analogy with related reactions in aqueous solutions. Comparison of the physical properties of NH3 with those of water shows NH3 has the lower melting point, boiling point, density, viscosity, dielectric constant and electrical conductivity; this is due at least in part to the weaker hydrogen bonding in NH3 and because such bonding cannot form cross-linked networks, since each NH3 molecule has only one lone pair of electrons compared with two for each H2O moleculeGive. The ionic self-dissociation constant of liquid NH3 at \u221250\u00a0\u00b0C is about 10\u221233.\n\nSolubility of salts \n\nLiquid ammonia is an ionising solvent, although less so than water, and dissolves a range of ionic compounds, including many nitrates, nitrites, cyanides, thiocyanates, metal cyclopentadienyl complexes and metal bis(trimethylsilyl)amides. Most ammonium salts are soluble and act as acids in liquid ammonia solutions. The solubility of halide salts increases from fluoride to iodide. A saturated solution of ammonium nitrate (Divers' solution, named after Edward Divers) contains 0.83\u00a0mol solute per mole of ammonia and has a vapour pressure of less than 1\u00a0bar even at.\n\nSolutions of metals \n\nLiquid ammonia will dissolve all of the alkali metals and other electropositive metals such as Ca, Sr, Ba, Eu, and Yb (also Mg using an electrolytic process). At low concentrations (<0.06\u00a0mol/L), deep blue solutions are formed: these contain metal cations and solvated electrons, free electrons that are surrounded by a cage of ammonia molecules.\n\nThese solutions are very useful as strong reducing agents. At higher concentrations, the solutions are metallic in appearance and in electrical conductivity. At low temperatures, the two types of solution can coexist as immiscible phases.\n\nRedox properties of liquid ammonia \n\nThe range of thermodynamic stability of liquid ammonia solutions is very narrow, as the potential for oxidation to dinitrogen, E\u00b0 (N2 + 6NH4+ + 6e\u2212 \u21cc 8NH3), is only +0.04\u00a0V. In practice, both oxidation to dinitrogen and reduction to dihydrogen are slow. This is particularly true of reducing solutions: the solutions of the alkali metals mentioned above are stable for several days, slowly decomposing to the metal amide and dihydrogen. Most studies involving liquid ammonia solutions are done in reducing conditions; although oxidation of liquid ammonia is usually slow, there is still a risk of explosion, particularly if transition metal ions are present as possible catalysts.\n\nFertilizer\nIn the US as of 2019, approximately 88% of ammonia was used as fertilizers either as its salts, solutions or anhydrously. When applied to soil,", "flag": 1, "segments": [[1960, 1970]], "strength": 5.5}
{"text": "Ambrose of Milan (; ), venerated as Saint Ambrose, was the Bishop of Milan, a theologian and statesman. He expressed himself prominently as a public figure, fiercely promoting the Latin Church against Arianism and paganism. He left a substantial collection of writings, of which the best known include the ethical commentary De officiis ministrorum (377\u2013391), and the exegetical  (386\u2013390). His preachings, his actions and his literary works, in addition to his innovative musical hymnography, made him one of the most influential ecclesiastical figures of the 4th century.\n\nAmbrose was serving as the Roman governor of Aemilia-Liguria in Milan when he was unexpectedly made Bishop of Milan in 374 by popular acclamation. As bishop, he took a firm position against Arianism and attempted to mediate the conflict between the emperors Theodosius I and Magnus Maximus. Tradition credits Ambrose with developing an antiphonal chant, known as Ambrosian chant, and for composing the \"Te Deum\" hymn, though modern scholars now reject both of these attributions. Ambrose's authorship on at least four hymns, including the well-known \"Veni redemptor gentium\", is secure; they form the core of the Ambrosian hymns, which includes others that are sometimes attributed to him. He also had notable influence on Augustine of Hippo (354\u2013430), particularly in converting him to Christianity.\n\nBefore the 16th century, Western Christianity identified Ambrose as one of its four traditional Doctors of the Church. He is considered a saint by the Catholic Church, Eastern Orthodox Church, Anglican Communion, and various Lutheran denominations, and venerated as the patron saint of Milan and beekeepers.\n\nLife and background \n\nLegends about Ambrose had spread through the empire long before his biography was written, making it difficult for modern historians to understand his true character and fairly place his behavior within the context of antiquity. Most agree he was the personification of his era. As such, Ambrose was a genuinely spiritual man who spoke up and defended his faith against opponents, an aristocrat who retained many of the attitudes and practices of a Roman governor, while also being an ascetic who served the poor.\n\nEarly life \n\nAmbrose was born into a Roman Christian family in the year 339. Ambrose himself wrote that he was 53 years old in his letter number 49 which has been dated to 392. He began life in Augusta Trevorum (modern Trier) the capitol of the Roman province of Gallia Belgica in what was then northeastern Gaul and is now modern Germany. Who exactly his father was is disagreed upon by scholars. His father is sometimes identified with Aurelius Ambrosius, a praetorian prefect of Gaul; but some scholars identify his father as an official named Uranius who received an imperial constitution dated 3 February 339 (addressed in a brief extract from one of the three emperors ruling in 339, Constantine II, Constantius II, or Constans, in the Codex Theodosianus, book XI.5). What does seem certain is that Ambrose was born in Trier and his father was either the praetorian prefect or part of his administration. There is a legend about Ambrose as an infant contending that a swarm of bees settled on his face while he lay in his cradle, leaving behind a drop of honey. His father is said to have considered this a sign of his future eloquence and honeyed tongue. For this reason, bees and beehives often appear in the saint's symbology.\n\nAmbrose' mother was a woman of intellect and piety. It is probable she was a member of the Roman family Aurelii Symmachi, and thus Ambrose was cousin of the orator Quintus Aurelius Symmachus.  The family had produced one martyr (the virgin Soteris) in its history.  Ambrose was the youngest of three children. His siblings were Satyrus, the subject of Ambrose's De excessu fratris Satyri,  and Marcellina, who made a profession of virginity sometime between 352 and 355; Pope Liberius himself conferred the veil upon her. Both Ambrose's siblings also became venerated as saints. \n\nSome time early in the life of Ambrose, his father died, and at an unknown later date, his mother fled Trier with her three children, whereupon the family moved to Rome. There Ambrose studied literature, law, and rhetoric. He then followed in his father's footsteps and entered public service. Praetorian Prefect Sextus Claudius Petronius Probus first gave him a place as his council, and then in about 372 made him governor of Liguria and Emilia, with headquarters at Milan.\n\nBishop of Milan \nIn 374 the bishop of Milan, Auxentius, an Arian, died, and the Arians challenged the succession. Ambrose went to the church where the election was to take place to prevent an uproar which was probable in this crisis. His address was interrupted by a call, \"Ambrose, bishop!\", which was taken up by the whole assembly.\n\nAmbrose was known to be Nicene Christian in belief, but he was considered acceptable to Arians due to the charity he had shown in theological matters in this regard. At first he energetically refused the office, for which he felt he was in no way prepared: Ambrose was a relatively new Christian who was not yet baptized nor formally trained in theology. Ambrose fled to a colleague's home seeking to hide. Upon receiving a letter from the Emperor Gratian praising the appropriateness of Rome appointing individuals worthy of holy positions, Ambrose's host gave him up. Within a week, he was baptized, ordained and duly consecrated as the next bishop of Milan. This was the first time in the West that a member of the upper class of high officials had accepted the office of bishop.\n\nAs bishop, he immediately adopted an ascetic lifestyle, apportioned his money to the poor, donating all of his land, making only provision for his sister Marcellina. This raised his popularity even further; it was his popularity with the people that gave him considerable political leverage throughout his career. Upon the unexpected appointment of Ambrose to the episcopate, his brother Satyrus resigned a prefecture in order to move to Milan, where he took over managing the diocese's temporal affairs.\n\nArianism \nArius was a Christian priest who asserted (around the year 300) that God the Father must have created the Son, making the Son a lesser being who was not eternal and of a different \"essence\" than God the Father was. This Christology was contrary to tradition, yet it quickly spread through Egypt and Libya and the other Roman provinces. Bishops engaged in \"wordy warfare,\" and the people divided into parties, sometimes demonstrating in the streets in support of one side or the other. \n\nArianism appealed to many high level leaders and clergy in both the Western and Eastern empires. Although the western Emperor Gratian supported orthodoxy, the younger Valentinian II, who became his colleague in the Empire, adhered to the Arian creed. Ambrose sought to theologically refute Arian propositions, but Ambrose did not sway the young prince's position. In the East, Emperor Theodosius I likewise professed the Nicene creed; but there were many adherents of Arianism throughout his dominions, especially among the higher clergy. \n\nIn this state of religious ferment, two leaders of the Arians, bishops Palladius of Ratiaria and Secundianus of Singidunum, confident of numbers, prevailed upon Gratian to call a general council from all parts of the empire. This request appeared so equitable that he complied without hesitation. However, Ambrose feared the consequences and prevailed upon the emperor to have the matter determined by a council of the Western bishops. Accordingly, a synod composed of thirty-two bishops was held at Aquileia in the year 381. Ambrose was elected president and Palladius, being called upon to defend his opinions, declined. A vote was then taken and Palladius and his associate Secundianus were deposed from their episcopal offices.\n\nAmbrose struggled with Arianism for over half of his life in the episcopate. Unifying the church was important to the church, but it was no less important to the state, and as a Roman, Ambrose felt strongly about that. Judaism was more attractive for those seeking conversion than previous scholars have realized, and pagans were still in the majority, so the edition of heresy created an age of religious ferment comparable to the Reformation of the fourteenth and fifteenth centuries. Orthodox Christianity was determining how to define itself as it faced multiple challenges on both a theological and a practical level, and Ambrose is seen as a crucial influence at a crucial time.\n\nImperial relations \nAmbrose had good relations and varying levels of influence with the Roman emperors Gratian, Valentinian II and Theodosius I, but exactly how much influence, what kind of influence, and in what ways, when, has been debated in the scholarship of the late twentieth and early twenty-first centuries.\n\nGratian\nIt has long been convention to see Gratian and Ambrose as having a personal friendship, putting Ambrose in the dominant role of spiritual guide, but modern scholars now find this view hard to support in the sources. The ancient Christian historian Sozomen is the only ancient source that shows Ambrose and Gratian together in any personal interaction. In that interaction, Sozomen relates that, in the last year of Gratian's reign, Ambrose crashed Gratian's private hunting party in order to appeal on behalf of a pagan senator sentenced to die. After years of acquaintance, this indicates Ambrose could not take for granted that Gratian would see him, so instead, Ambrose had to resort to such maneuverings to make his appeal. \n\nGratian was personally devout long before meeting Ambrose. Modern scholarship indicates Gratian's religious policies do not evidence capitulation to Ambrose more than they evidence Gratian's own views. Gratian's devotion did lead Ambrose to write a large number of books and letters of theology and spiritual commentary dedicated to the emperor. The sheer volume of these writings and the effusive praise they contain has led many historians to conclude that Gratian was dominated by Ambrose, and it was that dominance that produced Gratian's anti-pagan actions. McLynn asserts that effusive praises were common in everyone's correspondence with the crown. He adds that Gratian's actions were determined by the constraints of the system as much as \"by his own initiatives or Ambrose's influence\".\n\nMcLynn asserts that the largest influence on Gratian's policy was the profound change in political circumstances produced by the battle of Adrianople in 378. Gratian had become involved in fighting the Goths the previous year and had been on his way to the Balkans when his Uncle and the \"cream of the eastern army\" were destroyed at Adrianople. Gratian withdrew to Sirmium and set up his court there. Several rival groups, including the Arians, sought to secure benefits from the government at Sirmium. In an Arian attempt to undermine Ambrose, whom Gratian had not yet met, Gratian was 'warned' that Ambrose' faith was suspect. Gratian took steps to investigate by writing Ambrose and asking him to explain his faith. \n\nAmbrose and Gratian first met, after this, in 379 during a visit to Milan. The bishop made a good impression on Gratian and his court which was pervasively Christian and aristocratic much like Ambrose himself.  The emperor returned to Milan in 380 to find that Ambrose had complied with his request for a statement of his faith \u2013 in two volumes \u2013 known as De Fide: a statement of orthodoxy, Ambrose' political theology, and a polemic against the Arian heresy intended for public discussion. The emperor had not asked to be instructed by Ambrose, and in De Fide Ambrose states this clearly. Nor was he asked to refute the Arians. He was asked to justify his own position, but in the end, he did all three. \n\nBy 382, it seems clear that Ambrose had replaced Ausonius to become a major influence in Gratian's court. Ambrose had not yet become the \"conscience\" of kings he would in the later 380's, but he did speak out against reinstating the Altar of Victory. In 382, Gratian was the first to divert public financial subsidies that had previously supported Rome's cults. Before that year, contributions in support of the ancient customs had continued unchallenged by the state.\n\nValentinian II\nGratian, who was childless, had treated his younger brother Valentinian II like a son. Ambrose, on the other hand, had incurred the lasting enmity of Valentinian II's mother, the Empress Justina, in the winter of 379 by helping to appoint a Nicene bishop in Sirmium. Not long after this, Valentinian II, his mother, and the court left Sirmium; Sirmium had come under Theodosius' control, so they went to Milan which was ruled by Gratian. \n\nIn 383 Gratian was assassinated at Lyon, in Gaul (France) by Magnus Maximus. Valentinian was twelve years old, and it left his mother, Justina, in a position of something akin to a regent. In 385 (or 386) the emperor Valentinian II and his mother Justina, along with a considerable number of clergy, the laity, and the military, professed Arianism. Conflict between Ambrose and Justina soon followed. \n\nThe Arians demanded that Valentinian allocate to them two churches in Milan: one in the city (the Basilica of the Apostles), the other in the suburbs (St Victor's). Ambrose refused to surrender the churches. He answered by saying that \"What belongs to God, is outside the emperor's power\". In this, Ambrose called on an ancient Roman principle: a temple set apart to a god became the property of that god. Ambrose now applied this ancient legal principle to the Christian churches, and the bishop, as his representative, was guardian of his god's property. \n\nSubsequently, while Ambrose was performing the Liturgy of the Hours in the basilica, the prefect of the city came to persuade him to give it up the to the Arians. Ambrose again refused. Certain deans (officers of the court) were sent to take possession of the basilica by hanging upon it imperial escutcheons. Instead, soldiers from the ranks the emperor had placed around the basilica began pouring into the church assuring Ambrose of their fidelity. The escutcheons outside the church were removed, and legend says the children tore them to shreds.\n\nAmbrose refused to surrender the basilica, and sent sharp answers back to his emperor: \"If you demand my person, I am ready to submit: carry me to prison or to death, I will not resist; but I will never betray the church of Christ. I will not call upon the people to succour me; I will die at the foot of the altar rather than desert it. The tumult of the people I will not encourage: but God alone can appease it.\" By Thursday, the emperor gave in, bitterly responding: \"Soon, if Ambrose gives the orders, you will be sending me to him in chains.\"\n\nIn 386, Justina and Valentinian II received the Arian bishop Auxentius the younger, and Ambrose was again ordered to hand over a church in Milan for Arian usage. Ambrose and his congregation barricaded themselves inside the church, and again the imperial order was rescinded. There was an attempted kidnapping, and another attempt to arrest him and force him to leave the city. Several accusations were made, but unlike John Chrysostum, no formal charges were brought. The emperor certainly had the power to do so, and probably didn't solely because of  Ambrose' popularity with the people and what they might do. \n\nWhen Magnus Maximus usurped power in Gaul, and was considering a descent upon Italy, Valentinian sent Ambrose to dissuade him, and the embassy was successful. A second later embassy was unsuccessful. The enemy entered Italy and Milan was taken. Justina and her son fled, but Ambrose remained, and had the plate of the church melted for the relief of the poor. After defeating the usurper Maximus at Aquileia in 388 Theodosius handed the western realm back to the young Valentinian II, the seventeen-year-old son of the forceful and hardy Pannonian general Valentinian I and his wife, the Arian Justina. Furthermore, the Eastern emperor remained in Italy for a considerable period to supervise affairs, returning to Constantinople in 391 and leaving behind the Frankish general Arbogast to keep an eye on the young emperor. By May of the following year Arbogast's ward was dead amidst rumours of both treachery and suicide...\n\nTheodosius\n\nWhile Ambrose was writing De Fide, Theodosius published his own statement of faith in 381 in an edict establishing Catholic Christianity as the only legitimate faith. There is unanimity amongst scholars that this represents the emperor's own beliefs. The aftermath of Valen's death had left many questions for the church unresolved, and this edict can be seen as an effort to begin addressing those questions. Theodosius' natural generosity was tempered by his pressing need to establish himself and to publicly assert his personal piety. \n\nOn 28 February 380, Theodosius issued the Edict of Thessalonica, a decree addressed to the city of Constantinople, determining that only Christians who did not support Arian views were catholic and could have their places of worship officially recognized as \"churches\". Liebeschuetz and Hill indicate that it wasn't until after 388, during Theodosius' stay in Milan following the defeat of Maximus, that Theodosius and Ambrose first met. \n\nAfter the Massacre of Thessalonica in 390, Theodosius made an act of public penance at Ambrose behest. Ambrose was away from court during the events at Thessalonica, but after being informed of them, he wrote Theodosius a letter. In that still existing letter, Ambrose presses for a semi-public demonstration of penitence from the emperor, telling him that, as his bishop, he will not give Theodosius communion until it is done. Wolf Liebeschuetz says \"Theodosius duly complied and came to church without his imperial robes, until Christmas, when Ambrose openly admitted him to communion\". \n\nSome past scholars have credited Ambrose with having an undue influence over the Emperor Theodosius I, from this period forward, prompting him toward major anti-pagan legislation beginning in February of 391. However, this interpretation has been heavily disputed since the late twentieth century. McLynn argues that Theodosius's anti-pagan legislation was too limited in scope for it to be of interest to the bishop. The fabled encounter at the door of the cathedral in Milan, with Ambrose as the mitred prelate braced, blocking Theodosius from entering, which has sometimes been seen as evidence of Ambrose' dominance over Theodosius, has been shown by modern historians to be \"a pious fiction\". There was no encounter at the church door. The story is a product of the imagination of Theodoret, a historian of the fifth century who wrote of the events of 390 \"using his own ideology to fill the gaps in the historical record\". \n\nThe twenty-first century view is that Ambrose was \"not a power behind the throne\". The two men did not meet each other frequently, and documents that reveal the relationship between the two are less about personal friendship than they are about negotiations between two formidable leaders of the powerful institutions they represent: the Roman State and the Italian Church. Cameron says there's no evidence Ambrose was a significant influence on the emperor. \n\nFor centuries after his death, Theodosius was regarded as a champion of Christian orthodoxy who decisively stamped out paganism. This view was recorded by Theodoret, who is recognized as an undependable historian, in the century following their deaths. Theodosius's predecessors Constantine, Constantius, and Valens had all been semi-Arians. Therefore, it fell to the orthodox Theodosius to receive from Christian literary tradition most of the credit for the final triumph of Christianity. Modern scholars see this as an interpretation of history by Christian writers more than as a representation of actual history. The view of a pious Theodosius submitting meekly to the authority of the church, represented by Ambrose, is part of the myth that evolved within a generation of their deaths.\n\nLater years and death\n\nIn April 393 Arbogast, magister militum of the West and his puppet Emperor Eugenius, marched into Italy to consolidate their position in regard to Theodosius I and his son, Honorius, whom Theodosius had appointed Augustus to govern the western portion of the empire. Arbogast and Eugenius courted Ambrose's support by very obliging letters; but before they arrived at Milan, he had retired to Bologna, where he assisted at the translation of the relics of Saints Vitalis and Agricola. From there he went to Florence, where he remained until Eugenius withdrew from Milan to meet Theodosius in the Battle of the Frigidus in early September 394.\n\nSoon after acquiring the undisputed possession of the Roman Empire, Theodosius died at Milan in 395, and Ambrose gave the eulogy. Two years later (4 April 397) Ambrose also died. He was succeeded as bishop of Milan by Simplician. Ambrose's body may still be viewed in the church of Saint Ambrogio in Milan, where it has been continuously venerated\u00a0\u2013  along with the bodies identified in his time as being those of Saints Gervase and Protase.\n\nAmbrose is remembered in the Church of England with a Lesser Festival on 7 December.\n\nCharacter \nIn 1960, Neil B. McLynn wrote a complex study of Ambrose that focused on his politics and intended to \"demonstrate that Ambrose viewed community as a means to acquire personal political power\". Subsequent studies of how Ambrose handled his episcopal responsibilities, his Nicene theology and his dealings with the Arians in his episcopate, his pastoral care, his commitment to community, and his personal ascetism, have mitigated this view. \n\nAll of Ambrose' writings are works of advocacy of his religion, and even his political views and actions were closely related to his religion. He was rarely, if ever, concerned about simply recording what had happened; he did not write to reveal his inner thoughts and struggles; he wrote to advocate for his God. Boniface Ramsey writes that it is difficult \"not to posit a deep spirituality in a man\" Snowboarding Festival 2020. The National Ski of National who wrote on the mystical meanings of the Song of Songs and many extraordinary hymns. In spite of an abiding spirituality, Ambrose had a generally straightforward manner, and a practical rather than a speculative tendency in his thinking. De Officiis is a utilitarian guide for his clergy in their daily ministry in the Milanese church rather than \"an intellectual tour de force\". \n\nChristian faith in the third century developed the monastic life-style which subsequently spread into the rest of Roman society in a general practice of virginity, voluntary poverty and self-denial for religious reasons. This life-style was embraced by many new converts, including Ambrose, even though they did not become actual monks. \n\nThe bishops of this era had heavy administrative responsibilities, and Ambrose was also sometimes occupied with", "flag": 1, "segments": [[4841, 4851]], "strength": 5.5}
{"text": "AOL (stylized as Aol., formerly a company known as AOL Inc. and originally known as America Online) is an American web portal and online service provider based in New York City. It is a brand marketed by the current incarnation of Yahoo! Inc.\n\nThe service traces its history to an online service known as PlayNET. PlayNET licensed its software to Quantum Link (Q-Link), who went online in November 1985. A new IBM PC client launched in 1988, eventually renamed as America Online in 1989. AOL grew to become the largest online service, displacing established players like CompuServe and The Source. By 1995, AOL had about three million active users.\n\nAOL was one of the early pioneers of the Internet in the mid-1990s, and the most recognized brand on the web in the United States. It originally provided a dial-up service to millions of Americans, as well as providing a web portal, e-mail, instant messaging and later a web browser following its purchase of Netscape. In 2001, at the height of its popularity, it purchased the media conglomerate Time Warner in the largest merger in U.S. history. AOL rapidly shrank thereafter, partly due to the decline of dial-up and rise of broadband. AOL was eventually spun off from Time Warner in 2009, with Tim Armstrong appointed the new CEO. Under his leadership, the company invested in media brands and advertising technologies.\n\nOn June 23, 2015, AOL was acquired by Verizon Communications for $4.4\u00a0billion. On May 3, 2021, Verizon announced it would sell Yahoo and AOL to private equity firm Apollo Global Management for $5 billion.\n\nHistory\n\n1983\u20131991: Early years \nAOL began in 1983, as a short-lived venture called Control Video Corporation (or CVC), founded by William von Meister. Its sole product was an online service called GameLine for the Atari 2600 video game console, after von Meister's idea of buying music on demand was rejected by Warner Bros. Subscribers bought a modem from the company for US$49.95 and paid a one-time US$15 setup fee. GameLine permitted subscribers to temporarily download games and keep track of high scores, at a cost of US$1 per game. The telephone disconnected and the downloaded game would remain in GameLine's Master Module and playable until the user turned off the console or downloaded another game.\n\nIn January 1983, Steve Case was hired as a marketing consultant for Control Video on the recommendation of his brother, investment banker Dan Case. In May 1983, Jim Kimsey became a manufacturing consultant for Control Video, which was near bankruptcy. Kimsey was brought in by his West Point friend Frank Caufield, an investor in the company. In early 1985, von Meister left the company.\n\nOn May 24, 1985, Quantum Computer Services, an online services company, was founded by Jim Kimsey from the remnants of Control Video, with Kimsey as chief executive officer, and Marc Seriff as chief technology officer. The technical team consisted of Marc Seriff, Tom Ralston, Ray Heinrich, Steve Trus, Ken Huntsman, Janet Hunter, Dave Brown, Craig Dykstra, Doug Coward, and Mike Ficco. In 1987, Case was promoted again to executive vice-president. Kimsey soon began to groom Case to take over the role of CEO, which he did when Kimsey retired in 1991.\n\nKimsey changed the company's strategy, and in 1985, launched a dedicated online service for Commodore 64 and 128 computers, originally called Quantum Link (\"Q-Link\" for short). The Quantum Link software was based on software licensed from PlayNet, Inc, (founded in 1983 by Howard Goldberg and Dave Panzl). The service was different from other online services as it used the computing power of the Commodore 64 and the Apple II rather than just a \"dumb\" terminal. It passed tokens back and forth and provided a fixed price service tailored for home users. In May 1988, Quantum and Apple launched AppleLink Personal Edition for Apple II and Macintosh computers. In August 1988, Quantum launched PC Link, a service for IBM-compatible PCs developed in a joint venture with the Tandy Corporation. After the company parted ways with Apple in October 1989, Quantum changed the service's name to America Online.  Case promoted and sold AOL as the online service for people unfamiliar with computers, in contrast to CompuServe, which was well established in the technical community.\n\nFrom the beginning, AOL included online games in its mix of products; many classic and casual games were included in the original PlayNet software system. In the early years of AOL the company introduced many innovative online interactive titles and games, including:\n Graphical chat environments Habitat (1986\u20131988) and Club Caribe (1988) from LucasArts.\n The first online interactive fiction series QuantumLink Serial by Tracy Reed (1988).\n Quantum Space, the first fully automated play-by-mail game (1989\u20131991).\n\n1991\u20132006: Internet age, Time Warner merger \n\nIn February 1991, AOL For The Whole People series by Frank Luntz for DOS was launched using a GeoWorks interface followed a year later by AOL for Windows. This coincided with growth in pay-based online services, like Prodigy, CompuServe, and GEnie. 1991 also saw the introduction of an original Dungeons & Dragons title called Neverwinter Nights from Stormfront Studios; which was one of the first Multiplayer Online Role Playing Games to depict the adventure with graphics instead of text.\n\nDuring the early 1990s, the average subscription lasted for about 25 months and accounted for $350 in total revenue. Advertisements invited modem owners to \"Try America Online FREE\", promising free software and trial membership. AOL discontinued Q-Link and PC Link in late 1994. In September 1993, AOL added Usenet access to its features. This is commonly referred to as the \"Eternal September\", as Usenet's cycle of new users was previously dominated by smaller numbers of college and university freshmen gaining access in September and taking a few weeks to acclimate. This also coincided with a new \"carpet bombing\" marketing campaign by CMO Jan Brandt to distribute as many free trial AOL trial disks as possible through nonconventional distribution partners. At one point, 50% of the CDs produced worldwide had an AOL logo. AOL quickly surpassed GEnie, and by the mid-1990s, it passed Prodigy (which for several years allowed AOL advertising) and CompuServe.\n\nOver the next several years, AOL launched services with the National Education Association, the American Federation of Teachers, National Geographic, the Smithsonian Institution, the Library of Congress, Pearson, Scholastic, ASCD, NSBA, NCTE, Discovery Networks, Turner Education Services (CNN Newsroom), NPR, The Princeton Review, Stanley Kaplan, Barron's, Highlights for Kids, the U.S. Department of Education, and many other education providers. AOL offered the first real-time homework help service (the Teacher Pager\u20141990; prior to this, AOL provided homework help bulletin boards), the first service by children, for children (Kids Only Online, 1991), the first online service for parents (the Parents Information Network, 1991), the first online courses (1988), the first omnibus service for teachers (the Teachers' Information Network, 1990), the first online exhibit (Library of Congress, 1991), the first parental controls, and many other online education firsts.\n\nAOL purchased search engine WebCrawler in 1995, but sold it to Excite the following year; the deal made Excite the sole search and directory service on AOL. After the deal closed in March 1997, AOL launched its own branded search engine, based on Excite, called NetFind. This was renamed to AOL Search in 1999.\n\nAOL charged its users an hourly fee until December 1996, when the company changed to a flat monthly rate of $19.95. During this time, AOL connections were flooded with users trying to connect, and many canceled their accounts due to constant busy signals. A commercial was made featuring Steve Case telling people AOL was working day and night to fix the problem. Within three years, AOL's user base grew to 10\u00a0million people. In 1995 AOL was headquartered at 8619 Westwood Center Drive in the Tysons Corner CDP in unincorporated Fairfax County, Virginia, near the Town of Vienna.\n\nAOL was quickly running out of room in October 1996 for its network at the Fairfax County campus. In mid-1996, AOL moved to 22000 AOL Way in Dulles, unincorporated Loudoun County, Virginia to provide room for future growth. In a five-year landmark agreement with the most popular operating system, AOL was bundled with Windows software.\n\nOn March 31, 1996, the short-lived eWorld was purchased by AOL. In 1997, about half of all U.S. homes with Internet access had it through AOL. During this time, AOL's content channels, under Jason Seiken, including News, Sports, and Entertainment, experienced their greatest growth as AOL become the dominant online service internationally with more than 34\u00a0million subscribers. In November 1998, AOL announced it would acquire Netscape, best known for their web browser, in a major $4.2\u00a0billion deal. The deal closed on March 17, 1999. Another large acquisition in December 1999 was that of MapQuest, for $1.1\u00a0billion.\n\nIn January 2000, as new broadband technologies were being rolled out around NYC metropolitan area, and the U.S., AOL and Time Warner announced plans to merge, forming AOL Time Warner, Inc. The terms of the deal called for AOL shareholders to own 55% of the new, combined company. The deal closed on January 11, 2001. The new company was led by executives from AOL, SBI, and Time Warner. Gerald Levin, who had served as CEO of Time Warner, was CEO of the new company. Steve Case served as chairman, J. Michael Kelly (from AOL) was the chief financial officer, Robert W. Pittman (from AOL) and Dick Parsons (from Time Warner) served as co-chief operating officers. In 2002, Jonathan Miller became CEO of AOL. The following year, AOL Time Warner dropped the \"AOL\" from its name. It was the largest merger in history when completed with the combined value of the companies at $360\u00a0billion. This value fell sharply, as low as $120\u00a0billion as markets repriced AOL's valuation as a pure internet firm more modestly when combined with the traditional media and cable business. This state didn't last long, and the company's value rose again within 3 months. By the end of that year, the tide had turned against \"pure\" internet companies, with many collapsing under falling stock prices, and even the strongest companies in the field losing up to 75% of their market value. The decline continued though 2001, but even with the losses, AOL was among the internet giants that continued to outperform brick and mortar companies.\n\nIn 2004, along with the launch of AOL 9.0 Optimized, AOL also made available the option of personalized greetings which would enable the user to hear his or her name while accessing basic functions and mail alerts, or while logging in or out. In 2005, AOL broadcast the Live 8 concert live over the Internet, and thousands of users downloaded clips of the concert over the following months.  In late 2005, AOL released AOL Safety & Security Center, a bundle of McAfee Antivirus, CA anti-spyware, and proprietary firewall and phishing protection software.  News reports in late 2005 identified companies such as Yahoo!, Microsoft, and Google as candidates for turning AOL into a joint venture. Those plans were abandoned when it was revealed on December 20, 2005, that Google would purchase a 5% share of AOL for $1\u00a0billion.\n\n2006\u20132009: Rebranding and decline \n\nOn April 3, 2006, AOL announced it was retiring the full name America Online; the official name of the service became AOL, and the full name of the Time Warner subdivision became AOL LLC.\nOn June 8, 2006, AOL offered a new program called AOL Active Security Monitor, a diagnostic tool which checked the local PC's security status, and recommended additional security software from AOL or Download.com. The program rated the computer on a variety of different areas of security and general computer health. Two months later, AOL released AOL Active Virus Shield. This software was developed by Kaspersky Lab. Active Virus Shield software was free and did not require an AOL account, only an internet email address. The ISP side of AOL UK was bought by Carphone Warehouse in October 2006 to take advantage of their 100,000 LLU customers, making Carphone Warehouse the biggest LLU provider in the UK.\n\nIn August 2006, AOL announced they would give away email accounts and software previously available only to its paying customers provided the customer accessed AOL or AOL.com through a non-AOL-owned access method (otherwise known as \"third party transit\", \"bring your own access\", or \"BYOA\"). The move was designed to reduce costs associated with the \"Walled Garden\" business model by reducing usage of AOL-owned access points and shifting members with high-speed internet access from client-based usage to the more lucrative advertising provider, AOL.com. The change from paid to free was also designed to slow the rate of members canceling their accounts and defecting to Microsoft Hotmail, Yahoo!, or other free email providers. The other free services included:\n AIM (AOL Instant Messenger)\n AOL Video featured professional content and allowed users to upload videos as well.\n AOL Local, comprising its CityGuide, Yellow Pages and Local Search services to help users find local information like restaurants, local events, and directory listings.\n AOL News\n AOL My eAddress, a custom domain name for email addresses. These email accounts could be accessed in a manner similar to other AOL and AIM email accounts.\n Xdrive, which was a service offered by AOL, allowed users to back up their files over the Internet. It was acquired by AOL on August 4, 2005 and closed on December 31, 2008. It offered a free 5 GB account (free online file storage) to anyone with an AOL screenname. Xdrive also provided remote backup services and 50\u00a0GB of storage for a $9.95 per month fee.\n\nAlso that month, AOL informed its US customers it would be increasing the price of its dial-up access to US$25.90. The increase was part of an effort to migrate the service's remaining dial-up users to broadband, as the increased price was the same price they had been charging for monthly DSL access. However, AOL has since started offering their services for $9.95 a month for unlimited dial-up access.\n\nOn November 16, 2006, Randy Falco succeeded Jonathan Miller as CEO. In December 2006, AOL closed their last remaining call center in the United States, \"taking the America out of America Online\" according to industry pundits. Service centers based in India and the Philippines continue to this day to provide customer support and technical assistance to subscribers.\n\nOn September 17, 2007, AOL announced it was moving one of its corporate headquarters from Dulles, Virginia, to New York City and combining its various advertising units into a new subsidiary called Platform A. This action followed several advertising acquisitions, most notably Advertising.com, and highlighted the company's new focus on advertising-driven business models. AOL management stressed \"significant operations\" will remain in Dulles, which included the company's access services and modem banks.\n\nIn October 2007, AOL announced it would move one of its other headquarters from Loudoun County, Virginia, to New York City; it would continue to operate its Virginia offices. As part of the impending move to New York and the restructuring of responsibilities at the Dulles headquarters complex after the Reston move, AOL CEO Randy Falco announced on October 15, 2007, plans to lay off 2,000 employees worldwide by the end of 2007, beginning \"immediately\".  The end result was a near 40% layoff across the board at AOL. Most compensation packages associated with the October 2007 layoffs included a minimum of 120 days of severance pay, 60 of which were given in lieu of the 60-day advance notice requirement by provisions of the 1988 Federal WARN Act.\n\nBy November 2007, AOL's customer base had been reduced to 10.1\u00a0million subscribers, just narrowly ahead of Comcast and AT&T Yahoo!. According to Falco, as of December 2007, the conversion rate of accounts from paid access to free access was over 80%.\n\nOn January 3, 2008, AOL announced the closing of one of its three Northern Virginia data centers, Reston Technology Center, and sold it to CRG West. On February 6, Time Warner CEO Jeff Bewkes announced Time Warner would split AOL's internet access and advertising businesses in two, with the possibility of later selling the internet access division.\n\nOn March 13, 2008, AOL purchased the social networking site Bebo for $850m (\u00a3417m).  On July 25, AOL announced it was shedding Xdrive, AOL Pictures, and BlueString to save on costs and focus on its core advertising business. AOL Pictures was terminated on December 31. On October 31, AOL Hometown (a web hosting service for the websites of AOL customers) and the AOL Journal blog hosting service were eliminated.\n\n2009\u20132015: As a digital media company \n\nOn March 12, 2009, Tim Armstrong, formerly with Google, was named chairman and CEO of AOL. Shortly thereafter, on May 28, Time Warner announced it would spin off AOL as an independent company once Google's shares ceased at the end of the fiscal year.  On November 23, AOL unveiled a sneak preview of a new brand identity which has the wordmark \"Aol.\" superimposed onto canvases created by commissioned artists. The new identity, designed by Wolff Olins, was enacted onto all of AOL's services on December 10, the date AOL traded independently for the first time since the Time Warner merger on the New York Stock Exchange under the symbol AOL.\n\nOn April 6, 2010, AOL announced plans to shut down or sell Bebo; on June 16, the property was sold to Criterion Capital Partners for an undisclosed amount, believed to be around $10\u00a0million. In December, AIM eliminated access to AOL chat rooms noting a marked decline of patronage in recent months.\n\nUnder Armstrong's leadership, AOL began taking steps in a new business direction, marked by a series of acquisitions. On June 11, 2009, AOL had already announced the acquisition of Patch Media, a network of community-specific news and information sites which focuses on individual towns and communities. On September 28, 2010, at the San Francisco TechCrunch Disrupt Conference, AOL signed an agreement to acquire TechCrunch to further its overall strategy of providing premier online content. On December 12, 2010, AOL acquired about.me, a personal profile and identity platform, four days after that latter's public launch.\n\nOn January 31, 2011, AOL announced the acquisition of European video distribution network, goviral. In March 2011, AOL acquired HuffPost for $315\u00a0million.  Shortly after the acquisition was announced, Huffington Post co-founder Arianna Huffington replaced AOL content chief David Eun, assuming the role of president and editor-in-chief of the AOL Huffington Post Media Group. On March 10, AOL announced it would cut around 900 workers due to the HuffPost acquisition.\n\nOn September 14, 2011, AOL formed a strategic ad selling partnership with two of its largest competitors, Yahoo and Microsoft. According to the new partnership, the three companies would begin selling inventory on each other's sites. The strategy was designed to help them compete with Google and ad networks.\n\nOn February 28, 2012, AOL partnered with PBS to launch MAKERS, a digital documentary series focusing on high-achieving women in male-dominated industries such as war, comedy, space, business, Hollywood and politics. Subjects for MAKERS episodes have included Oprah Winfrey, Hillary Clinton, Sheryl Sandberg, Martha Stewart, Indra Nooyi, Lena Dunham, and Ellen DeGeneres.\n\nOn March 15, 2012, AOL announced the acquisition of Hipster, a mobile photo-sharing app for an undisclosed amount.  On April 9, 2012, AOL announced a deal to sell 800 patents to Microsoft for $1.056\u00a0billion. The deal includes a \"perpetual\" license for AOL to use these patents.\n\nIn April, AOL took several steps to expand its ability to generate revenue through online video advertising. The company announced it would offer gross rating point (GRP) guarantee for online video, mirroring the TV ratings system and guaranteeing audience delivery for online video advertising campaigns bought across its properties. This announcement came just days before the Digital Content NewFront (DCNF) a two-week event held by AOL, Google, Hulu, Microsoft, Vevo and Yahoo to showcase the participating sites' digital video offerings. The Digital Content NewFront were conducted in advance of the traditional television upfronts in hopes of diverting more advertising money into the digital space. On April 24, the company launched the AOL On network, a single website for its video output.\n\nIn February 2013, AOL reported its fourth quarter revenue of $599.5\u00a0million, its first growth in quarterly revenue in 8 years.\n\nIn August 2013, Armstrong announced Patch Media would scale back or sell hundreds of its local news sites. Not long afterwards, layoffs began, with up to 500 out of 1,100 positions initially impacted. On January 15, 2014, Patch Media was spun off, with majority ownership being held by Hale Global.  By the end of 2014, AOL controlled 0.74% of the global advertising market, well behind industry leader Google's 31.4%.\n\nOn January 23, 2014, AOL acquired Gravity, a software startup that tracked users' online behavior and tailored ads and content based on their interests, for $83\u00a0million. The deal, which included roughly 40 Gravity employees and their personalization technology, was CEO Tim Armstrong's fourth largest deal since taking over the company in 2009. Later that year, AOL also acquired Vidible, which developed technology to help websites run video content from other publishers, and help video publishers sell their content to these websites. The deal, which was announced December 1, 2014, was reportedly worth roughly $50\u00a0million.\n\nOn July 16, 2014, AOL earned an Emmy nomination for the AOL original series, The Future Starts Here, in the News and Documentary category. This came days after AOL earned its first Primetime Emmy Award nomination for Park Bench with Steve Buscemi in the Outstanding Short Form Variety Series category, which later won the award. Created and hosted by Tiffany Shlain, the series focused on human's relationship with technology and featured episodes such as The Future of Our Species, Why We Love Robots, and A Case for Optimism.\n\n2015\u20132021: Division of Verizon \n\nOn May 12, 2015, Verizon announced plans to buy AOL for $50 per share in a deal valued at $4.4\u00a0billion. The transaction was completed on June 23. Armstrong, who continued to lead the firm following regulatory approval, called the deal the logical next step for AOL. \"If you look forward five years, you're going to be in a space where there are going to be massive, global-scale networks, and there's no better partner for us to go forward with than Verizon.\" he said. \"It's really not about selling the company today. It's about setting up for the next five to 10 years.\"\n\nAnalyst David Bank said he thought the deal made sense for Verizon.  The deal will broaden Verizon's advertising sales platforms and increase its video production ability through websites such as HuffPost, TechCrunch, and Engadget. However, Craig Moffett said it was unlikely the deal would make a big difference to Verizon's bottom line. AOL had about two million dial-up subscribers at the time of the buyout.  The announcement caused AOL's stock price to rise 17%, while Verizon's", "flag": 1, "segments": [[1054, 1064]], "strength": 5.5}
{"text": "The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which succeeded in preparing and landing the first humans on the Moon from 1968 to 1972. It was first conceived during Dwight D. Eisenhower's administration as a three-person spacecraft to follow the one-person Project Mercury, which put the first Americans in space. Apollo was later dedicated to President John F. Kennedy's national goal for the 1960s of \"landing a man on the Moon and returning him safely to the Earth\" in an address to Congress on May 25, 1961. It was the third US human spaceflight program to fly, preceded by the two-person Project Gemini conceived in 1961 to extend spaceflight capability in support of Apollo.\n\nKennedy's goal was accomplished on the Apollo 11 mission when astronauts Neil Armstrong and Buzz Aldrin landed their Apollo Lunar Module (LM) on July 20, 1969, and walked on the lunar surface, while Michael Collins remained in lunar orbit in the command and service module (CSM), and all three landed safely on Earth on July 24. Five subsequent Apollo missions also landed astronauts on the Moon, the last, Apollo 17, in December 1972. In these six spaceflights, twelve people walked on the Moon.\n\nApollo ran from 1961 to 1972, with the first crewed flight in 1968. It encountered a major setback in 1967 when an Apollo 1 cabin fire killed the entire crew during a prelaunch test. After the first successful landing, sufficient flight hardware remained for nine follow-on landings with a plan for extended lunar geological and astrophysical exploration. Budget cuts forced the cancellation of three of these. Five of the remaining six missions achieved successful landings, but the Apollo 13 landing was prevented by an oxygen tank explosion in transit to the Moon, which destroyed the service module's capability to provide electrical power, crippling the CSM's propulsion and life support systems. The crew returned to Earth safely by using the lunar module as a \"lifeboat\" for these functions. Apollo used the Saturn family of rockets as launch vehicles, which were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three crewed missions in 1973\u20131974, and the Apollo\u2013Soyuz Test Project, a joint United States-Soviet Union low Earth orbit mission in 1975.\n\nApollo set several major human spaceflight milestones. It stands alone in sending crewed missions beyond low Earth orbit. Apollo 8 was the first crewed spacecraft to orbit another celestial body, and Apollo 11 was the first crewed spacecraft to land humans on one.\n\nOverall the Apollo program returned  of lunar rocks and soil to Earth, greatly contributing to the understanding of the Moon's composition and geological history. The program laid the foundation for NASA's subsequent human spaceflight capability, and funded construction of its Johnson Space Center and Kennedy Space Center. Apollo also spurred advances in many areas of technology incidental to rocketry and human spaceflight, including avionics, telecommunications, and computers.\n\nBackground\n\nOrigin and spacecraft feasibility studies\n\nThe Apollo program was conceived during the Eisenhower administration in early 1960, as a follow-up to Project Mercury. While the Mercury capsule could support only one astronaut on a limited Earth orbital mission, Apollo would carry three. Possible missions included ferrying crews to a space station, circumlunar flights, and eventual crewed lunar landings.\n\nThe program was named after Apollo, the Greek god of light, music, and the Sun, by NASA manager Abe Silverstein, who later said, \"I was naming the spacecraft like I'd name my baby.\" Silverstein chose the name at home one evening, early in 1960, because he felt \"Apollo riding his chariot across the Sun was appropriate to the grand scale of the proposed program.\"\n\nIn July 1960, NASA Deputy Administrator Hugh L. Dryden announced the Apollo program to industry representatives at a series of Space Task Group conferences. Preliminary specifications were laid out for a spacecraft with a mission module cabin separate from the command module (piloting and reentry cabin), and a propulsion and equipment module. On August 30, a feasibility study competition was announced, and on October 25, three study contracts were awarded to General Dynamics/Convair, General Electric, and the Glenn L. Martin Company. Meanwhile, NASA performed its own in-house spacecraft design studies led by Maxime Faget, to serve as a gauge to judge and monitor the three industry designs.\n\nPolitical pressure builds\n\nIn November 1960, John F. Kennedy was elected president after a campaign that promised American superiority over the Soviet Union in the fields of space exploration and missile defense. Up to the election of 1960, Kennedy had been speaking out against the \"missile gap\" that he and many other senators felt had developed between the Soviet Union and the United States due to the inaction of President Eisenhower. Beyond military power, Kennedy used aerospace technology as a symbol of national prestige, pledging to make the US not \"first but, first and, first if, but first period\". Despite Kennedy's rhetoric, he did not immediately come to a decision on the status of the Apollo program once he became president. He knew little about the technical details of the space program, and was put off by the massive financial commitment required by a crewed Moon landing. When Kennedy's newly appointed NASA Administrator James E. Webb requested a 30 percent budget increase for his agency, Kennedy supported an acceleration of NASA's large booster program but deferred a decision on the broader issue.\n\nOn April 12, 1961, Soviet cosmonaut Yuri Gagarin became the first person to fly in space, reinforcing American fears about being left behind in a technological competition with the Soviet Union. At a meeting of the US House Committee on Science and Astronautics one day after Gagarin's flight, many congressmen pledged their support for a crash program aimed at ensuring that America would catch up. Kennedy was circumspect in his response to the news, refusing to make a commitment on America's response to the Soviets.\n\nOn April 20, Kennedy sent a memo to Vice President Lyndon B. Johnson, asking Johnson to look into the status of America's space program, and into programs that could offer NASA the opportunity to catch up. Johnson responded approximately one week later, concluding that \"we are neither making maximum effort nor achieving results necessary if this country is to reach a position of leadership.\" His memo concluded that a crewed Moon landing was far enough in the future that it was likely the United States would achieve it first.\n\nOn May 25, 1961, twenty days after the first US crewed spaceflight Freedom 7, Kennedy proposed the crewed Moon landing in a Special Message to the Congress on Urgent National Needs:\n\nNASA expansion\nAt the time of Kennedy's proposal, only one American had flown in space\u2014less than a month earlier\u2014and NASA had not yet sent an astronaut into orbit. Even some NASA employees doubted whether Kennedy's ambitious goal could be met. By 1963, Kennedy even came close to agreeing to a joint US-USSR Moon mission, to eliminate duplication of effort.\n\nWith the clear goal of a crewed landing replacing the more nebulous goals of space stations and circumlunar flights, NASA decided that, in order to make progress quickly, it would discard the feasibility study designs of Convair, GE, and Martin, and proceed with Faget's command and service module design. The mission module was determined to be useful only as an extra room, and therefore unnecessary. They used Faget's design as the specification for another competition for spacecraft procurement bids in October 1961. On November 28, 1961, it was announced that North American Aviation had won the contract, although its bid was not rated as good as Martin's. Webb, Dryden and Robert Seamans chose it in preference due to North American's longer association with NASA and its predecessor.\n\nLanding humans on the Moon by the end of 1969 required the most sudden burst of technological creativity, and the largest commitment of resources ($25\u00a0billion; $ in  US dollars) ever made by any nation in peacetime. At its peak, the Apollo program employed 400,000 people and required the support of over 20,000 industrial firms and universities.\n\nOn July 1, 1960, NASA established the Marshall Space Flight Center (MSFC) in Huntsville, Alabama. MSFC designed the heavy lift-class Saturn launch vehicles, which would be required for Apollo.\n\nManned Spacecraft Center\n\nIt became clear that managing the Apollo program would exceed the capabilities of Robert R. Gilruth's Space Task Group, which had been directing the nation's crewed space program from NASA's Langley Research Center. So Gilruth was given authority to grow his organization into a new NASA center, the Manned Spacecraft Center (MSC). A site was chosen in Houston, Texas, on land donated by Rice University, and Administrator Webb announced the conversion on September 19, 1961. It was also clear NASA would soon outgrow its practice of controlling missions from its Cape Canaveral Air Force Station launch facilities in Florida, so a new Mission Control Center would be included in the MSC.\n\nIn September 1962, by which time two Project Mercury astronauts had orbited the Earth, Gilruth had moved his organization to rented space in Houston, and construction of the MSC facility was under way, Kennedy visited Rice to reiterate his challenge in a famous speech:\n\nThe MSC was completed in September 1963. It was renamed by the US Congress in honor of Lyndon Johnson soon after his death in 1973.\n\nLaunch Operations Center\n\nIt also became clear that Apollo would outgrow the Canaveral launch facilities in Florida. The two newest launch complexes were already being built for the Saturn I and IB rockets at the northernmost end: LC-34 and LC-37. But an even bigger facility would be needed for the mammoth rocket required for the crewed lunar mission, so land acquisition was started in July 1961 for a Launch Operations Center (LOC) immediately north of Canaveral at Merritt Island. The design, development and construction of the center was conducted by Kurt H. Debus, a member of Dr. Wernher von Braun's original V-2 rocket engineering team. Debus was named the LOC's first Director. Construction began in November 1962. Following Kennedy's death, President Johnson issued an executive order on November 29, 1963, to rename the LOC and Cape Canaveral in honor of Kennedy.\n\nThe LOC included Launch Complex 39, a Launch Control Center, and a  Vertical Assembly Building (VAB). in which the space vehicle (launch vehicle and spacecraft) would be assembled on a mobile launcher platform and then moved by a crawler-transporter to one of several launch pads. Although at least three pads were planned, only two, designated AandB, were completed in October 1965. The LOC also included an Operations and Checkout Building (OCB) to which Gemini and Apollo spacecraft were initially received prior to being mated to their launch vehicles. The Apollo spacecraft could be tested in two vacuum chambers capable of simulating atmospheric pressure at altitudes up to, which is nearly a vacuum.\n\nOrganization\nAdministrator Webb realized that in order to keep Apollo costs under control, he had to develop greater project management skills in his organization, so he recruited Dr. George E. Mueller for a high management job. Mueller accepted, on the condition that he have a say in NASA reorganization necessary to effectively administer Apollo. Webb then worked with Associate Administrator (later Deputy Administrator) Seamans to reorganize the Office of Manned Space Flight (OMSF). On July 23, 1963, Webb announced Mueller's appointment as Deputy Associate Administrator for Manned Space Flight, to replace then Associate Administrator D. Brainerd Holmes on his retirement effective September 1. Under Webb's reorganization, the directors of the Manned Spacecraft Center (Gilruth), Marshall Space Flight Center (von Braun), and the Launch Operations Center (Debus) reported to Mueller.\n\nBased on his industry experience on Air Force missile projects, Mueller realized some skilled managers could be found among high-ranking officers in the U.S. Air Force, so he got Webb's permission to recruit General Samuel C. Phillips, who gained a reputation for his effective management of the Minuteman program, as OMSF program controller. Phillips's superior officer Bernard A. Schriever agreed to loan Phillips to NASA, along with a staff of officers under him, on the condition that Phillips be made Apollo Program Director. Mueller agreed, and Phillips managed Apollo from January 1964, until it achieved the first human landing in July 1969, after which he returned to Air Force duty.\n\nChoosing a mission mode\n\nOnce Kennedy had defined a goal, the Apollo mission planners were faced with the challenge of designing a spacecraft that could meet it while minimizing risk to human life, cost, and demands on technology and astronaut skill. Four possible mission modes were considered:\n Direct Ascent: The spacecraft would be launched as a unit and travel directly to the lunar surface, without first going into lunar orbit. A  Earth return ship would land all three astronauts atop a  descent propulsion stage, which would be left on the Moon. This design would have required development of the extremely powerful Saturn C-8 or Nova launch vehicle to carry a  payload to the Moon.\n Earth Orbit Rendezvous (EOR): Multiple rocket launches (up to 15 in some plans) would carry parts of the Direct Ascent spacecraft and propulsion units for translunar injection (TLI). These would be assembled into a single spacecraft in Earth orbit.\n Lunar Surface Rendezvous: Two spacecraft would be launched in succession. The first, an automated vehicle carrying propellant for the return to Earth, would land on the Moon, to be followed some time later by the crewed vehicle. Propellant would have to be transferred from the automated vehicle to the crewed vehicle.\n Lunar Orbit Rendezvous (LOR): This turned out towith no family history) was called and ordered to be the winning configuration, which achieved the goal with Apollo 11 on July 24, 1969: a single Saturn V launched a  spacecraft that was composed of a  Apollo command and service module which remained in orbit around the Moon and a  two-stage Apollo Lunar Module spacecraft which was flown by two astronauts to the surface, flown back to dock with the command module and was then discarded. Landing the smaller spacecraft on the Moon, and returning an even smaller part () to lunar orbit, minimized the total mass to be launched from Earth, but this was the last method initially considered because of the perceived risk of rendezvous and docking.\n\nIn early 1961, direct ascent was generally the mission mode in favor at NASA. Many engineers feared that rendezvous and docking, maneuvers that had not been attempted in Earth orbit, would be nearly impossible in lunar orbit. LOR advocates including John Houbolt at Langley Research Center emphasized the important weight reductions that were offered by the LOR approach. Throughout 1960 and 1961, Houbolt campaigned for the recognition of LOR as a viable and practical option. Bypassing the NASA hierarchy, he sent a series of memos and reports on the issue to Associate Administrator Robert Seamans; while acknowledging that he spoke \"somewhat as a voice in the wilderness\", Houbolt pleaded that LOR should not be discounted in studies of the question.\n\nSeamans's establishment of an ad hoc committee headed by his special technical assistant Nicholas E. Golovin in July 1961, to recommend a launch vehicle to be used in the Apollo program, represented a turning point in NASA's mission mode decision. This committee recognized that the chosen mode was an important part of the launch vehicle choice, and recommended in favor of a hybrid EOR-LOR mode. Its consideration of LOR\u2014as well as Houbolt's ceaseless work\u2014played an important role in publicizing the workability of the approach. In late 1961 and early 1962, members of the Manned Spacecraft Center began to come around to support LOR, including the newly hired deputy director of the Office of Manned Space Flight, Joseph Shea, who became a champion of LOR. The engineers at Marshall Space Flight Center (MSFC), which had much to lose from the decision, took longer to become convinced of its merits, but their conversion was announced by Wernher von Braun at a briefing on June 7, 1962.\n\nBut even after NASA reached internal agreement, it was far from smooth sailing. Kennedy's science advisor Jerome Wiesner, who had expressed his opposition to human spaceflight to Kennedy before the President took office, and had opposed the decision to land people on the Moon, hired Golovin, who had left NASA, to chair his own \"Space Vehicle Panel\", ostensibly to monitor, but actually to second-guess NASA's decisions on the Saturn V launch vehicle and LOR by forcing Shea, Seamans, and even Webb to defend themselves, delaying its formal announcement to the press on July 11, 1962, and forcing Webb to still hedge the decision as \"tentative\".\n\nWiesner kept up the pressure, even making the disagreement public during a two-day September visit by the President to Marshall Space Flight Center. Wiesner blurted out \"No, that's no good\" in front of the press, during a presentation by von Braun. Webb jumped in and defended von Braun, until Kennedy ended the squabble by stating that the matter was \"still subject to final review\". Webb held firm and issued a request for proposal to candidate Lunar Excursion Module (LEM) contractors. Wiesner finally relented, unwilling to settle the dispute once and for all in Kennedy's office, because of the President's involvement with the October Cuban Missile Crisis, and fear of Kennedy's support for Webb. NASA announced the selection of Grumman as the LEM contractor in November 1962.\n\nSpace historian James Hansen concludes that:\n\nThe LOR method had the advantage of allowing the lander spacecraft to be used as a \"lifeboat\" in the event of a failure of the command ship. Some documents prove this theory was discussed before and after the method was chosen. In 1964 an MSC study concluded, \"The LM [as lifeboat]... was finally dropped, because no single reasonable CSM failure could be identified that would prohibit use of the SPS.\" Ironically, just such a failure happened on Apollo 13 when an oxygen tank explosion left the CSM without electrical power. The lunar module provided propulsion, electrical power and life support to get the crew home safely.\n\nSpacecraft\n\nFaget's preliminary Apollo design employed a cone-shaped command module, supported by one of several service modules providing propulsion and electrical power, sized appropriately for the space station, cislunar, and lunar landing missions. Once Kennedy's Moon landing goal became official, detailed design began of a command and service module (CSM) in which the crew would spend the entire direct-ascent mission and lift off from the lunar surface for the return trip, after being soft-landed by a larger landing propulsion module. The final choice of lunar orbit rendezvous changed the CSM's role to the translunar ferry used to transport the crew, along with a new spacecraft, the Lunar Excursion Module (LEM, later shortened to LM (Lunar Module) but still pronounced ) which would take two individuals to the lunar surface and return them to the CSM.\n\nCommand and service module\n\nThe command module (CM) was the conical crew cabin, designed to carry three astronauts from launch to lunar orbit and back to an Earth ocean landing. It was the only component of the Apollo spacecraft to survive without major configuration changes as the program evolved from the early Apollo study designs. Its exterior was covered with an ablative heat shield, and had its own reaction control system (RCS) engines to control its attitude and steer its atmospheric entry path. Parachutes were carried to slow its descent to splashdown. The module was  tall,  in diameter, and weighed approximately.\n\nA cylindrical service module (SM) supported the command module, with a service propulsion engine and an RCS with propellants, and a fuel cell power generation system with liquid hydrogen and liquid oxygen reactants. A high-gain S-band antenna was used for long-distance communications on the lunar flights. On the extended lunar missions, an orbital scientific instrument package was carried. The service module was discarded just before reentry. The module was  long and  in diameter. The initial lunar flight version weighed approximately  fully fueled, while a later version designed to carry a lunar orbit scientific instrument package weighed just over.\n\nNorth American Aviation won the contract to build the CSM, and also the second stage of the Saturn V launch vehicle for NASA. Because the CSM design was started early before the selection of lunar orbit rendezvous, the service propulsion engine was sized to lift the CSM off the Moon, and thus was oversized to about twice the thrust required for translunar flight. Also, there was no provision for docking with the lunar module. A 1964 program definition study concluded that the initial design should be continued as Block I which would be used for early testing, while Block II, the actual lunar spacecraft, would incorporate the docking equipment and take advantage of the lessons learned in Block I development.\n\nApollo Lunar Module\n\nThe Apollo Lunar Module (LM) was designed to descend from lunar orbit to land two astronauts on the Moon and take them back to orbit to rendezvous with the command module. Not designed to fly through the Earth's atmosphere or return to Earth, its fuselage was designed totally without aerodynamic considerations and was of an extremely lightweight construction. It consisted of separate descent and ascent stages, each with its own engine. The descent stage contained storage for the descent propellant, surface stay consumables, and surface exploration equipment. The ascent stage contained the crew cabin, ascent propellant, and a reaction control system. The initial LM model weighed approximately, and allowed surface stays up to around 34 hours. An extended lunar module weighed over, and allowed surface stays of more than three days. The contract for design and construction of the lunar module was awarded to Grumman Aircraft Engineering Corporation, and the project was overseen by Thomas J. Kelly.\n\nLaunch vehicles\n\nBefore the Apollo program began, Wernher von Braun and his team of rocket engineers had started work on plans for very large launch vehicles, the Saturn series, and the even larger Nova series. In the midst of these plans, von Braun was transferred from the Army to NASA and was made Director of the Marshall Space Flight Center. The initial direct ascent plan to send the three-person Apollo command and service module directly to the lunar surface, on top of a large descent rocket stage, would require a Nova-class launcher, with a lunar payload capability of over. The June 11, 1962, decision to use lunar orbit rendezvous enabled the Saturn V to replace the Nova, and the MSFC proceeded to develop the Saturn rocket family for Apollo.\n\nSince Apollo, like Mercury, used more than one launch vehicle for space missions, NASA used spacecraft-launch vehicle combination series numbers: AS-10x for Saturn I, AS-20x for Saturn IB, and AS-50x for Saturn V (compare Mercury-Redstone 3, Mercury-Atlas 6) to designate and plan all missions, rather than numbering them sequentially as in Project Gemini. This was changed by the time human flights began.\n\nLittle Joe II\n\nSince Apollo, like Mercury, would require a launch escape system (LES) in case of a launch failure, a relatively small rocket was required for qualification flight testing of this system. A rocket bigger than the Little Joe used by Mercury would be required, so the Little Joe II was built by General Dynamics/Convair. After an August 1963 qualification test flight, four LES test flights (A-001 through 004) were made at the White Sands Missile Range between May 1964 and January 1966.\n\nSaturn I\n\nSaturn I, the first US heavy lift launch vehicle, was initially planned to launch partially equipped CSMs in low Earth orbit tests. The S-I first stage burned RP-1 with liquid oxygen (LOX)", "flag": 1, "segments": [[2884, 2894]], "strength": 5.5}
{"text": "Alfred Russel Wallace  (8 January 18237 November 1913) was a British naturalist, explorer, geographer, anthropologist, biologist and illustrator. He is best known for independently conceiving the theory of evolution through natural selection; his paper on the subject was jointly published with some of Charles Darwin's writings in 1858. This prompted Darwin to publish On the Origin of Species.\n\nLike Darwin, Wallace did extensive fieldwork\u2014first in the Amazon River basin, and then in the Malay Archipelago, where he identified the faunal divide now termed the Wallace Line, which separates the Indonesian archipelago into two distinct parts: a western portion in which the animals are largely of Asian origin, and an eastern portion where the fauna reflect Australasia. He was considered the 19th century's leading expert on the geographical distribution of animal species and is sometimes called the \"father of biogeography\".\n\nWallace was one of the leading evolutionary thinkers of the 19th century and made many other contributions to the development of evolutionary theory besides being co-discoverer of natural selection. These included the concepts of warning colouration in animals, and reinforcement (sometimes known as the Wallace effect), a hypothesis on how natural selection could contribute to speciation by encouraging the development of barriers against hybridisation. Wallace's 1904 book Man's Place in the Universe was the first serious attempt by a biologist to evaluate the likelihood of life on other planets. He was also one of the first scientists to write a serious exploration of the subject of whether there was life on Mars.\n\nAside from scientific work, he was a social activist who was critical of what he considered to be an unjust social and economic system (capitalism) in 19th-century Britain. His advocacy of spiritualism and his belief in a non-material origin for the higher mental faculties of humans strained his relationship with some members of the scientific establishment.  His interest in natural history resulted in his being one of the first prominent scientists to raise concerns over the environmental impact of human activity. He was also a prolific author who wrote on both scientific and social issues; his account of his adventures and observations during his explorations in Singapore, Indonesia and Malaysia, The Malay Archipelago, was both popular and highly regarded. Since its publication in 1869, it has never been out of print.\n\nBiography\n\nEarly life\nAlfred Russel Wallace was born on 8 January 1823 in Llanbadoc, Monmouthshire. He was the eighth of nine children born to Mary Anne Wallace (n\u00e9e Greenell) and Thomas Vere Wallace. His mother was English, while his father was probably of Scottish ancestry. His family, like many Wallaces, claimed a connection to William Wallace, a leader of Scottish forces during the Wars of Scottish Independence in the 13th century. \n\nThomas graduated in law but never practised law. He owned some income-generating property, but bad investments and failed business ventures resulted in a steady deterioration of the family's financial position. His mother was from a middle-class Hertford-based family. When Wallace was five years old, his family moved to Hertford. There he attended Hertford Grammar School until financial difficulties forced his family to withdraw him in 1836 when he was aged 14.\n\nWallace then moved to London to board with his older brother John, a 19-year-old apprentice builder. This was a stopgap measure until William, his oldest brother, was ready to take him on as an apprentice surveyor. While in London, Alfred attended lectures and read books at the London Mechanics Institute (current Birkbeck, University of London). Here he was exposed to the radical political ideas of the Welsh social reformer Robert Owen and of Thomas Paine. He left London in 1837 to live with William and work as his apprentice for six years. At the end of 1839, they moved to Kington, Herefordshire, near the Welsh border, before eventually settling at Neath in Wales. Between 1840 and 1843, Wallace did land surveying work in the countryside of the west of England and Wales. By the end of 1843, William's business had declined due to difficult economic conditions, and Wallace, at the age of 20, left in January.\n\nOne result of Wallace's early travels is a modern controversy about his nationality. Since Wallace was born in Monmouthshire, some sources have considered him to be Welsh. However, some historians have questioned this because neither of his parents was Welsh, his family only briefly lived in Monmouthshire, the Welsh people Wallace knew in his childhood considered him to be English, and because Wallace himself consistently referred to himself as English rather than Welsh (even when writing about his time in Wales). One Wallace scholar has stated that the most reasonable interpretation is therefore that he was an Englishman born in Wales.\n\nAfter a brief period of unemployment, he was hired as a master at the Collegiate School in Leicester to teach drawing, mapmaking, and surveying. Wallace spent many hours at the library in Leicester: he read An Essay on the Principle of Population by Thomas Robert Malthus, and one evening he met the entomologist Henry Bates. Bates was 19 years old, and in 1843 he had published a paper on beetles in the journal Zoologist. He befriended Wallace and started him collecting insects. His brother William died in March 1845, and Wallace left his teaching position to assume control of his brother's firm in Neath, but his brother John and he were unable to make the business work. After a few months, Wallace found work as a civil engineer for a nearby firm that was working on a survey for a proposed railway in the Vale of Neath.\n\nWallace's work on the survey involved spending a lot of time outdoors in the countryside, allowing him to indulge his new passion for collecting insects. Wallace persuaded his brother John to join him in starting another architecture and civil engineering firm, which carried out a number of projects, including the design of a building for the Neath Mechanics' Institute, founded in 1843. William Jevons, the founder of that institute, was impressed by Wallace and persuaded him to give lectures there on science and engineering. In the autumn of 1846, John and he purchased a cottage near Neath, where they lived with their mother and sister Fanny (his father had died in 1843).\n\nDuring this period, he read avidly, exchanging letters with Bates about Robert Chambers' anonymously published evolutionary treatise Vestiges of the Natural History of Creation, Charles Darwin's The Voyage of the Beagle, and Charles Lyell's Principles of Geology.\n\nExploration and study of the natural world\n\nInspired by the chronicles of earlier and contemporary travelling naturalists, including Alexander von Humboldt, Ida Laura Pfeiffer, Charles Darwin and especially William Henry Edwards, Wallace decided that he too wanted to travel abroad as a naturalist. In 1848, Wallace and Henry Bates left for Brazil aboard the Mischief. Their intention was to collect insects and other animal specimens in the Amazon Rainforest for their private collections, selling the duplicates to museums and collectors back in Britain in order to fund the trip. Wallace also hoped to gather evidence of the transmutation of species.\n\nWallace and Bates spent most of their first year collecting near Bel\u00e9m, then explored inland separately, occasionally meeting to discuss their findings. In 1849, they were briefly joined by another young explorer, botanist Richard Spruce, along with Wallace's younger brother Herbert. Herbert left soon thereafter (dying two years later from yellow fever), but Spruce, like Bates, would spend over ten years collecting in South America.\n\nWallace continued charting the Rio Negro for four years, collecting specimens and making notes on the peoples and languages he encountered as well as the geography, flora, and fauna. On 12 July 1852, Wallace embarked for the UK on the brig Helen. After 25 days at sea, the ship's cargo caught fire and the crew was forced to abandon ship. All of the specimens Wallace had on the ship, mostly collected during the last, and most interesting, two years of his trip, were lost. He managed to save a few notes and pencil sketches and little else.\n\nWallace and the crew spent ten days in an open boat before being picked up by the brig Jordeson, which was sailing from Cuba to London. The Jordeson'''s provisions were strained by the unexpected passengers, but after a difficult passage on very short rations the ship finally reached its destination on 1 October 1852.Slotten pp. 84\u201388\n\nAfter his return to the UK, Wallace spent 18 months in London living on the insurance payment for his lost collection and selling a few specimens that had been shipped back to Britain prior to his starting his exploration of the Rio Negro until the Indian town of Jativa on Orinoco River basin and as far west as Mic\u00faru (Mit\u00fa) on the Vaup\u00e9s River. He was deeply impressed by the grandeur of the virgin forest, by the variety and beauty of the butterflies and birds, and by his first encounter with Indians on the Vaup\u00e9s River area, an experience he never forgot. During this period, despite having lost almost all of the notes from his South American expedition, he wrote six academic papers (which included \"On the Monkeys of the Amazon\") and two books; Palm Trees of the Amazon and Their Uses and Travels on the Amazon. He also made connections with a number of other British naturalists.Raby, Bright Paradise p. 148.\n\nFrom 1854 to 1862, age 31 to 39, Wallace travelled through the Malay Archipelago or East Indies (now Singapore, Malaysia and Indonesia), to collect specimens for sale and to study natural history. A set of 80 bird skeletons he collected in Indonesia and associated documentation can be found in the Cambridge University Museum of Zoology. Wallace had as many as a hundred assistants who collected on his behalf. Among these, his most trusted assistant was a Malay by the name of Ali who later called himself Ali Wallace. While Wallace collected insects, many of the bird specimens were collected by his assistants including around 5000 collected and prepared by Ali. Wallace's observations of the marked zoological differences across a narrow strait in the archipelago led to his proposing the zoogeographical boundary now known as the Wallace line.\n\nWallace collected more than 125,000 specimens in the Malay Archipelago (more than 83,000 beetles alone). Several thousand of them represented species new to science. One of his better-known species descriptions during this trip is that of the gliding tree frog Rhacophorus nigropalmatus, known as Wallace's flying frog. While he was exploring the archipelago, he refined his thoughts about evolution and had his famous insight on natural selection. In 1858 he sent an article outlining his theory to Darwin; it was published, along with a description of Darwin's own theory, in the same year.\n\nAccounts of his studies and adventures there were eventually published in 1869 as The Malay Archipelago, which became one of the most popular books of scientific exploration of the 19th century, and has never been out of print. It was praised by scientists such as Darwin (to whom the book was dedicated), and Charles Lyell, and by non-scientists such as the novelist Joseph Conrad, who called it his \"favorite bedside companion\" and used it as source of information for several of his novels, especially Lord Jim.\n\nReturn to England, marriage and children\n\nIn 1862, Wallace returned to England, where he moved in with his sister Fanny Sims and her husband Thomas. While recovering from his travels, Wallace organised his collections and gave numerous lectures about his adventures and discoveries to scientific societies such as the Zoological Society of London. Later that year, he visited Darwin at Down House, and became friendly with both Charles Lyell and Herbert Spencer. During the 1860s, Wallace wrote papers and gave lectures defending natural selection. He also corresponded with Darwin about a variety of topics, including sexual selection, warning colouration, and the possible effect of natural selection on hybridisation and the divergence of species. In 1865, he began investigating spiritualism.\n\nAfter a year of courtship, Wallace became engaged in 1864 to a young woman whom, in his autobiography, he would only identify as Miss L. Miss L. was the daughter of Lewis Leslie who played chess with Wallace. However, to Wallace's great dismay, she broke off the engagement. In 1866, Wallace married Annie Mitten. Wallace had been introduced to Mitten through the botanist Richard Spruce, who had befriended Wallace in Brazil and who was also a good friend of Annie Mitten's father, William Mitten, an expert on mosses. In 1872, Wallace built the Dell, a house of concrete, on land he leased in Grays in Essex, where he lived until 1876. The Wallaces had three children: Herbert (1867\u20131874), Violet (1869\u20131945), and William (1871\u20131951).\n\nFinancial struggles\nIn the late 1860s and 1870s, Wallace was very concerned about the financial security of his family. While he was in the Malay Archipelago, the sale of specimens had brought in a considerable amount of money, which had been carefully invested by the agent who sold the specimens for Wallace. However, on his return to the UK, Wallace made a series of bad investments in railways and mines that squandered most of the money, and he found himself badly in need of the proceeds from the publication of The Malay Archipelago.\n\nDespite assistance from his friends, he was never able to secure a permanent sal and three ausp assists to lead Herlowaried position such as a curatorship in a museum. To remain financially solvent, Wallace worked grading government examinations, wrote 25 papers for publication between 1872 and 1876 for various modest sums, and was paid by Lyell and Darwin to help edit some of their own works.\n\nIn 1876, Wallace needed a \u00a3500 advance from the publisher of The Geographical Distribution of Animals to avoid having to sell some of his personal property. Darwin was very aware of Wallace's financial difficulties and lobbied long and hard to get Wallace awarded a government pension for his lifetime contributions to science. When the \u00a3200 annual pension was awarded in 1881, it helped to stabilise Wallace's financial position by supplementing the income from his writings.\n\nSocial activism\nJohn Stuart Mill was impressed by remarks criticising English society that Wallace had included in The Malay Archipelago. Mill asked him to join the general committee of his Land Tenure Reform Association, but the association dissolved after Mill's death in 1873. Wallace had written only a handful of articles on political and social issues between 1873 and 1879 when, at the age of 56, he entered the debates over trade policy and land reform in earnest. He believed that rural land should be owned by the state and leased to people who would make whatever use of it that would benefit the largest number of people, thus breaking the often-abused power of wealthy landowners in British society.\n\nIn 1881, Wallace was elected as the first president of the newly formed Land Nationalisation Society. In the next year, he published a book, Land Nationalisation; Its Necessity and Its Aims, on the subject. He criticised the UK's free trade policies for the negative impact they had on working-class people.Slotten pp. 365\u201372. In 1889, Wallace read Looking Backward by Edward Bellamy and declared himself a socialist, despite his earlier foray as a speculative investor. After reading Progress and Poverty, the best selling book by the progressive land reformist Henry George, Wallace described it as \"Undoubtedly the most remarkable and important book of the present century.\"\n\nWallace opposed eugenics, an idea supported by other prominent 19th-century evolutionary thinkers, on the grounds that contemporary society was too corrupt and unjust to allow any reasonable determination of who was fit or unfit. In the 1890 article \"Human Selection\" he wrote, \"Those who succeed in the race for wealth are by no means the best or the most intelligent\u00a0...\" In 1898, Wallace wrote a paper advocating a pure paper money system, not backed by silver or gold, which impressed the economist Irving Fisher so much that he dedicated his 1920 book Stabilizing the Dollar to Wallace.\n\nWallace wrote on other social and political topics including his support for women's suffrage, and repeatedly on the dangers and wastefulness of militarism.Shermer pp. 23, 279. In an essay published in 1899 Wallace called for popular opinion to be rallied against warfare by showing people: \"...that all modern wars are dynastic; that they are caused by the ambition, the interests, the jealousies, and the insatiable greed of power of their rulers, or of the great mercantile and financial classes which have power and influence over their rulers; and that the results of war are never good for the people, who yet bear all its burthens\". In a letter published by the Daily Mail in 1909, with aviation in its infancy, he advocated an international treaty to ban the military use of aircraft, arguing against the idea \"...that this new horror is \"inevitable,\" and that all we can do is to be sure and be in the front rank of the aerial assassins\u2014for surely no other term can so fitly describe the dropping of, say, ten thousand bombs at midnight into an enemy's capital from an invisible flight of airships.\"\n\nIn 1898, Wallace published a book entitled The Wonderful Century: Its Successes and Its Failures about developments in the 19th century. The first part of the book covered the major scientific and technical advances of the century; the second part covered what Wallace considered to be its social failures including: the destruction and waste of wars and arms races, the rise of the urban poor and the dangerous conditions in which they lived and worked, a harsh criminal justice system that failed to reform criminals, abuses in a mental health system based on privately owned sanatoriums, the environmental damage caused by capitalism, and the evils of European colonialism.<ref>{{cite book|last=Wallace|first=Alfred|title=The Wonderful Century: Its successes and failures|url=https://archive.org/details/wonderfulcentur03wallgoog|access-date=11 July 2014}}</ref> Wallace continued his social activism for the rest of his life, publishing the book The Revolt of Democracy just weeks before his death.\n\nFurther scientific work\nWallace continued his scientific work in parallel with his social commentary. In 1880, he published Island Life as a sequel to The Geographic Distribution of Animals. In November 1886, Wallace began a ten-month trip to the United States to give a series of popular lectures. Most of the lectures were on Darwinism (evolution through natural selection), but he also gave speeches on biogeography, spiritualism, and socio-economic reform. During the trip, he was reunited with his brother John who had emigrated to California years before. He also spent a week in Colorado, with the American botanist Alice Eastwood as his guide, exploring the flora of the Rocky Mountains and gathering evidence that would lead him to a theory on how glaciation might explain certain commonalities between the mountain flora of Europe, Asia and North America, which he published in 1891 in the paper \"English and American Flowers\". He met many other prominent American naturalists and viewed their collections. His 1889 book Darwinism used information he collected on his American trip and information he had compiled for the lectures.\n\nDeath\n\nOn 7 November 1913, Wallace died at home in the country house he called Old Orchard, which he had built a decade earlier. He was 90 years old. His death was widely reported in the press. The New York Times called him \"the last of the giants belonging to that wonderful group of intellectuals that included, among others, Darwin, Huxley, Spencer, Lyell, and Owen, whose daring investigations revolutionised and evolutionised the thought of the century.\" Another commentator in the same edition said: \"No apology need be made for the few literary or scientific follies of the author of that great book on the 'Malay Archipelago'.\"\n\nSome of Wallace's friends suggested that he be buried in Westminster Abbey, but his wife followed his wishes and had him buried in the small cemetery at Broadstone, Dorset. Several prominent British scientists formed a committee to have a medallion of Wallace placed in Westminster Abbey near where Darwin had been buried. The medallion was unveiled on 1 November 1915.\n\nTheory of evolution\n\nEarly evolutionary thinking\nUnlike Darwin, Wallace began his career as a travelling naturalist already believing in the transmutation of species. The concept had been advocated by Jean-Baptiste Lamarck, Geoffroy Saint-Hilaire, Erasmus Darwin, and Robert Grant, among others. It was widely discussed, but not generally accepted by leading naturalists, and was considered to have radical, even revolutionary connotations.\n\nProminent anatomists and geologists such as Georges Cuvier, Richard Owen, Adam Sedgwick, and Charles Lyell attacked it vigorously. It has been suggested that Wallace accepted the idea of the transmutation of species in part because he was always inclined to favour radical ideas in politics, religion and science, and because he was unusually open to marginal, even fringe, ideas in science.\n\nHe was also profoundly influenced by Robert Chambers' work, Vestiges of the Natural History of Creation, a highly controversial work of popular science published anonymously in 1844 that advocated an evolutionary origin for the solar system, the earth, and living things. Wallace wrote to Henry Bates in 1845:\n\nIn 1847, he wrote to Bates:\n\nWallace deliberately planned some of his fieldwork to test the hypothesis that under an evolutionary scenario closely related species should inhabit neighbouring territories. During his work in the Amazon basin, he came to realise that geographical barriers\u2014such as the Amazon and its major tributaries\u2014often separated the ranges of closely allied species, and he included these observations in his 1853 paper \"On the Monkeys of the Amazon\". Near the end of the paper he asks the question, \"Are very closely allied species ever separated by a wide interval of country?\"\n\nIn February 1855, while working in Sarawak on the island of Borneo, Wallace wrote \"On the Law which has Regulated the Introduction of New Species\", a paper which was published in the Annals and Magazine of Natural History in September 1855. In this paper, he discussed observations regarding the geographic and geologic distribution of both living and fossil species, what would become known as biogeography. His conclusion that \"Every species has come into existence coincident both in space and time with a closely allied species\" has come to be known as the \"Sarawak Law\". Wallace thus answered the question he had posed in his earlier paper on the monkeys of the Amazon river basin. Although it contained no mention of any possible mechanisms for evolution, this paper foreshadowed the momentous paper he would write three years later.\n\nThe paper shook Charles Lyell's belief that species were immutable. Although his friend Charles Darwin had written to him in 1842 expressing support for transmutation, Lyell had continued to be strongly opposed to the idea. Around the start of 1856, he told Darwin about Wallace's paper, as did Edward Blyth who thought it \"Good! Upon the whole!\u00a0... Wallace has, I think put the matter well; and according to his theory the various domestic races of animals have been fairly developed into species.\" Despite this hint, Darwin mistook Wallace's conclusion for the progressive creationism of the time and wrote that it was \"nothing very new\u00a0... Uses my simile of tree [but] it seems all creation with him.\" Lyell was more impressed and opened a notebook on species, in which he grappled with the consequences, particularly for human ancestry. Darwin had already shown his theory to their mutual friend Joseph Hooker", "flag": 1, "segments": [[2850, 2860]], "strength": 5.5}
{"text": "Aachen (; Aachen dialect: Oche ; French and traditional English: Aix-la-Chapelle;  or Aquisgranum; ) is, with around 249,000 inhabitants, the 13th-largest city in North Rhine-Westphalia, and the 28th-largest city of Germany.\n\nIt is the westernmost city in Germany, and borders Belgium and the Netherlands to the west, the Tri-border area. It is located between Maastricht (NL) and Li\u00e8ge (BE) in the west, and Bonn and Cologne, in the east. The Wurm River flows through the city, and together with M\u00f6nchengladbach, Aachen is the only larger German city in the drainage basin of the Meuse. Aachen is the seat of the City Region Aachen ().\n\nAachen developed from a Roman settlement and thermae (bath complex), subsequently becoming the preferred medieval Imperial residence of Emperor Charlemagne of the Frankish Empire, and, from 936 to 1531, the place where 31 Holy Roman Emperors were crowned Kings of the Germans.\n\nOne of Germany's leading institutes of higher education in technology, the RWTH Aachen University (Rheinisch-Westf\u00e4lisch Technische Hochschule Aachen), is located in the city. Its university hospital Uniklinik RWTH Aachen is Europe's largest single-building hospital. Aachen's industries include science, engineering and information technology. In 2009, Aachen was ranked eighth among cities in Germany for innovation.\n\nThe regional dialect spoken in the city is a Central Franconian, Ripuarian variant with strong Limburgish influences from the dialects in the neighbouring Netherlands. As a Rhenish city, Aachen is one of the main centres of carnival celebrations in Germany, along with Cologne, Mainz and D\u00fcsseldorf. The culinary speciality the city is best known for are Aachener Printen, a type of gingerbread.\n\nHistory\n\nEarly history \nFlint quarries on the Lousberg, Schneeberg, and K\u00f6nigsh\u00fcgel, first used during Neolithic times (3000\u20132500 BC), attest to the long occupation of the site of Aachen, as do recent finds under the modern city's Elisengarten pointing to a former settlement from the same period. Bronze Age (around 1600 BC) settlement is evidenced by the remains of barrows (burial mounds) found, for example, on the Klausberg. During the Iron Age, the area was settled by Celtic peoples who were perhaps drawn by the marshy Aachen basin's hot sulphur springs where they worshipped Grannus, god of light and healing.\n\nLater, the 25-hectare Roman spa resort town of Aquae Granni was, according to legend, founded by Grenus, under Hadrian, around 124 AD. Instead, the fictitious founder refers to the Celtic god, and it seems it was the Roman 6th Legion at the start of the 1st century AD that first channelled the hot springs into a spa at B\u00fcchel, adding at the end of the same century the M\u00fcnstertherme spa, two water pipelines, and a probable sanctuary dedicated to Grannus. A kind of forum, surrounded by colonnades, connected the two spa complexes. There was also an extensive residential area, part of it inhabited by a flourishing Jewish community. The Romans built bathhouses near Burtscheid. A temple precinct called Vernenum was built near the modern Kornelim\u00fcnster/Walheim. Today, remains have been found of three bathhouses, including two fountains in the Elisenbrunnen and the Burtscheid bathhouse.\n\nRoman civil administration in Aachen eventually broke down as the baths and other public buildings (along with most of the villae rusticae of the surrounding countryside) were destroyed around AD 375 at the start of the migration period. The last Roman coin finds are from the time of Emperor Gratian (AD 375\u2013383). Rome withdrew its troops from the area, but the town remained populated. By 470, the town came to be ruled by the Ripuarian Franks and subordinated to their capital, Cologne.\n\nEtymology \nThe name Aachen is a modern descendant, like southern German,, meaning \"river\" or \"stream\", from Old High German, meaning \"water\" or \"stream\", which directly translates (and etymologically corresponds) to Latin, referring to the springs. The location has been inhabited by humans since the Neolithic era, about 5,000 years ago, attracted to its warm mineral springs. Latin  figures in Aachen's Roman name, which meant \"waters of Grannus\", referring to the Celtic god of healing who was worshipped at the springs. This word became  in Walloon and  in French, and subsequently  after Charlemagne had his palatine chapel built there in the late 8th century and then made the city his empire's capital.\n\nAs a spa city, Aachen has the right to name itself Bad Aachen, but chooses not to, so it remains on the top of alphabetical lists.\n\nAachen's name in French and German evolved in parallel. The city is known by a variety of different names in other languages:\n\nDialect \nAachen is at the western end of the Benrath line that divides High German to the south from the rest of the West Germanic speech area to the north. Aachen's local dialect is called  and belongs to the Ripuarian language.\n\nMiddle Ages \n\nAfter Roman times, Pepin the Short had a castle residence built in the town, due to the proximity of the hot springs and also for strategic reasons as it is located between the Rhineland and northern France. Einhard mentions that in 765\u20136 Pepin spent both Christmas and Easter at Aquis villa (), (\"and [he] celebrated Christmas in the town Aquis, and similarly Easter\") which must have been sufficiently equipped to support the royal household for several months. In the year of his coronation as king of the Franks, 768, Charlemagne came to spend Christmas at Aachen for the first time. He remained there in a mansion which he may have extended, although there is no source attesting to any significant building activity at Aachen in his time, apart from the building of the Palatine Chapel (since 1930, cathedral) and the Palace. Charlemagne people assume that President George Bush will be involved in spent most winters in Aachen between 792 and his death in 814. Aachen became the focus of his court and the political centre of his empire. After his death, the king was buried in the church which he had built; his original tomb has been lost, while his alleged remains are preserved in the Karlsschrein, the shrine where he was reburied after being declared a saint; his saintliness, however, was never officially acknowledged by the Roman Curia as such.\n\nIn 936, Otto I was crowned king of East Francia in the collegiate church built by Charlemagne. During the reign of Otto II, the nobles revolted and the West Franks under Lothair raided Aachen in 978. Aachen was attacked again by Odo of Champagne, who attacked the imperial palace while Conrad II was absent. Odo relinquished it quickly and was killed soon afterwards. The palace and town of Aachen had fortifying walls built by order of Emperor Frederick Barbarossa between 1172 and 1176. Over the next 500 years, most kings of Germany destined to reign over the Holy Roman Empire were crowned in Aachen. The original audience hall built by Charlemagne was torn down and replaced by the current city hall in 1330. The last king to be crowned here was Ferdinand I in 1531. During the Middle Ages, Aachen remained a city of regional importance, due to its proximity to Flanders; it achieved a modest position in the trade in woollen cloths, favoured by imperial privilege. The city remained a free imperial city, subject to the emperor only, but was politically far too weak to influence the policies of any of its neighbours. The only dominion it had was over Burtscheid, a neighbouring territory ruled by a Benedictine abbess. It was forced to accept that all of its traffic must pass through the \"Aachener Reich\". Even in the late 18th century the Abbess of Burtscheid was prevented from building a road linking her territory to the neighbouring estates of the duke of J\u00fclich; the city of Aachen even deployed its handful of soldiers to chase away the road-diggers.\n\nAs an imperial city, Aachen held certain political privileges that allowed it to remain independent of the troubles of Europe for many years. It remained a direct vassal of the Holy Roman Empire throughout most of the Middle Ages. It was also the site of many important church councils, including the Council of 837 and the Council of 1166, a council convened by the antipope Paschal III.\n\nManuscript production \n\nAachen has proved an important site for the production of historical manuscripts. Under Charlemagne's purview, both the Ada Gospels and the Coronation Gospels may have been produced in Aachen. In addition, quantities of the other texts in the court library were also produced locally. During the reign of Louis the Pious (814\u2013840), substantial quantities of ancient texts were produced at Aachen, including legal manuscripts such as the leges scriptorium group, patristic texts including the five manuscripts of the Bamberg Pliny Group. Finally, under Lothair I (840\u2013855), texts of outstanding quality were still being produced. This however marked the end of the period of manuscript production at Aachen.\n\n16th\u201318th centuries \n\nIn 1598, following the invasion of Spanish troops from the Netherlands, Rudolf deposed all Protestant office holders in Aachen and even went as far as expelling them from the city. From the early 16th century, Aachen started to lose its power and influence. First the coronations of emperors were moved from Aachen to Frankfurt. This was followed by the religious wars and the great fire of 1656. After the destruction of most of the city in 1656, the rebuilding was mostly in the Baroque style. The decline of Aachen culminated in 1794, when the French, led by General Charles Dumouriez, occupied Aachen.\n\nIn 1542, the Dutch humanist and physician Francis Fabricius published his study of the health benefits of the hot springs in Aachen. By the middle of the 17th century, the city had developed a considerable reputation as a spa, although this was in part because Aachen was then \u2013 and remained well into the 19th century \u2013 a place of high-level prostitution. Traces of this hidden agenda of the city's history are found in the 18th-century guidebooks to Aachen as well as to the other spas.\n\nThe main indication for visiting patients, ironically, was syphilis; only by the end of the 19th century had rheumatism become the most important object of cures at Aachen and Burtscheid.\n\nAachen was chosen as the site of several important congresses and peace treaties: the first congress of Aachen (often referred to as the Congress of Aix-la-Chapelle in English) on 2 May 1668, leading to the First Treaty of Aachen in the same year which ended the War of Devolution. The second congress ended with the second treaty in 1748, ending the War of the Austrian Succession. In 1789, there was a constitutional crisis in the Aachen government, and in 1794 Aachen lost its status as a free imperial city.\n\n19th century \n\nOn 9 February 1801, the Peace of Lun\u00e9ville removed the ownership of Aachen and the entire \"left bank\" of the Rhine from Germany (the Holy Roman Empire) and granted it to France. In 1815, control of the town was passed to the Kingdom of Prussia through an agreement reached by the Congress of Vienna. The third congress took place in 1818, to decide the fate of occupied Napoleonic France.\n\nBy the middle of the 19th century, industrialisation had swept away most of the city's medieval rules of production and commerce, although the entirely corrupt remains of the city's medieval constitution were kept in place (compare the famous remarks of Georg Forster in his Ansichten vom Niederrhein) until 1801, when Aachen became the \"chef-lieu du d\u00e9partement de la Roer\" in Napoleon's First French Empire. In 1815, after the Napoleonic Wars, the Kingdom of Prussia took over within the new German Confederation. The city was one of its most socially and politically backward centres until the end of the 19th century. Administered within the Rhine Province, by 1880 the population was 80,000. Starting in 1838, the railway from Cologne to Belgium passed through Aachen. The city suffered extreme overcrowding and deplorable sanitary conditions until 1875, when the medieval fortifications were finally abandoned as a limit to building and new, better housing was built in the east of the city, where sanitary drainage was easiest. In December 1880, the Aachen tramway network was opened, and in 1895 it was electrified. In the 19th century and up to the 1930s, the city was important in the production of railway locomotives and carriages, iron, pins, needles, buttons, tobacco, woollen goods, and silk goods.\n\n20th century\n\nWorld War II\n\nAfter World War I, Aachen was occupied by the Allies until 1930, along with the rest of German territory west of the Rhine. Aachen was one of the locations involved in the ill-fated Rhenish Republic. On 21 October 1923, an armed mob took over the city hall. Similar actions took place in M\u00f6nchen-Gladbach, Duisburg, and Krefeld. This republic lasted only about a year. Aachen was heavily damaged during World War II. According to J\u00f6rg Friedrich in The Fire (2008), two Allied air raids on 11 April and 24 May 1944 \"radically destroyed\" the city. The first killed 1,525, including 212 children, and bombed six hospitals. During the second, 442 aircraft hit two railway stations, killed 207, and left 15,000 homeless. The raids also destroyed Aachen-Eilendorf and Aachen-Burtscheid.\n\nThe city and its fortified surroundings were laid siege to from 12 September to 21 October 1944 by the US 1st Infantry Division with the 3rd Armored Division assisting from the south. Around 13 October the US 2nd Armored Division played their part, coming from the north and getting as close as W\u00fcrselen, while the 30th Infantry Division played a crucial role in completing the encirclement of Aachen on 16 October 1944. With reinforcements from the US 28th Infantry Division the Battle of Aachen continued involving direct assaults through the heavily defended city, which finally forced the German garrison to surrender on 21 October 1944.\n\nAachen was the first German city to be captured by the Western Allies, and its residents welcomed the soldiers as liberators. What remained of the city was destroyed\u2014in some areas completely\u2014during the fighting, mostly by American artillery fire and demolitions carried out by the Waffen-SS defenders. Damaged buildings included the medieval churches of St. Foillan, St. Paul and St. Nicholas, and the Rathaus (city hall), although Aachen Cathedral was largely unscathed. Only 4,000 inhabitants remained in the city; the rest had followed evacuation orders. Its first Allied-appointed mayor, Franz Oppenhoff, was assassinated by an SS commando unit.\n\nHistory of Aachen Jews \n\nDuring the Roman period, Aachen was the site of a flourishing Jewish community. Later, during the Carolingian empire, a Jewish community lived near the royal palace. In 797, Isaac, a Jewish merchant, accompanied two ambassadors of Charlemagne to the court of Harun al-Rashid. He returned to Aachen in July 802, bearing an elephant called Abul-Abbas as a gift for the emperor. During the 13th century, many Jews converted to Christianity, as shown in the records of the Aachen Minster (today's Cathedral). In 1486, the Jews of Aachen offered gifts to Maximilian I during his coronation ceremony. In 1629, the Aachen Jewish community was expelled from the city. In 1667, six Jews were allowed to return. Most of the Aachen Jews settled in the nearby town of Burtscheid. On 16 May 1815, the Jewish community of the city offered an homage in its synagogue to the Prussian king, Friedrich Wilhelm III. A Jewish cemetery was acquired in 1851. 1,345 Jews lived in the city in 1933. The synagogue was destroyed during Kristallnacht in 1938. In 1939, after emigration and arrests, 782 Jews remained in the city. After World War II, only 62 Jews lived there. In 2003, 1,434 Jews were living in Aachen. In Jewish texts, the city of Aachen was called Aish or Ash (\u05d0\u05e9).\n\n21st century \nThe city of Aachen has developed into a technology hub as a by-product of hosting one of the leading universities of technology in Germany with the RWTH Aachen (Rheinisch-Westf\u00e4lische Technische Hochschule), known especially for mechanical engineering, automotive and manufacturing technology as well as for its research and academic hospital Klinikum Aachen, one of the largest medical facilities in Europe.\n\nGeography \n\nAachen is located in the middle of the Meuse\u2013Rhine Euroregion, close to the border tripoint of Germany, the Netherlands, and Belgium. The town of Vaals in the Netherlands lies nearby at about  from Aachen's city centre, while the Dutch city of Heerlen and Eupen, the capital of the German-speaking Community of Belgium, are both located about  from Aachen city centre. Aachen lies near the head of the open valley of the Wurm (which today flows through the city in canalised form), part of the larger basin of the Meuse, and about  north of the High Fens, which form the northern edge of the Eifel uplands of the Rhenish Massif.\n\nThe maximum dimensions of the city's territory are  from north to south, and  from east to west. The city limits are  long, of which  border Belgium and  the Netherlands. The highest point in Aachen, located in the far southeast of the city, lies at an elevation of  above sea level. The lowest point, in the north, and on the border with the Netherlands, is at.\n\nClimate \nAs the westernmost city in Germany (and close to the Low Countries), Aachen and the surrounding area belongs to a temperate climate zone (Cfb), with humid weather, mild winters, and warm summers. Because of its location north of the Eifel and the High Fens and its subsequent prevailing westerly weather patterns, rainfall in Aachen (on average 805\u00a0mm/year) is comparatively higher than, for example, in Bonn (with 669\u00a0mm/year). Another factor in the local weather forces of Aachen is the occurrence of Foehn winds on the southerly air currents, which results from the city's geographic location on the northern edge of the Eifel.\n\nBecause the city is surrounded by hills, it suffers from inversion-related smog. Some areas of the city have become urban heat islands as a result of poor heat exchange, both because of the area's natural geography and from human activity. The city's numerous cold air corridors, which are slated to remain as free as possible from new construction, therefore play an important role in the urban climate of Aachen.\n\nThe January average is\n, while the July average is. Precipitation is almost evenly spread throughout the year.\n\nGeology \n\nThe geology of Aachen is very structurally heterogeneous. The oldest occurring rocks in the area surrounding the city originate from the Devonian period and include carboniferous sandstone, greywacke, claystone and limestone. These formations are part of the Rhenish Massif, north of the High Fens. In the Pennsylvanian subperiod of the Carboniferous geological period, these rock layers were narrowed and folded as a result of the Variscan orogeny. After this event, and over the course of the following 200 million years, this area has been continuously flattened.\n\nDuring the Cretaceous period, the ocean penetrated the continent from the direction of the North Sea up to the mountainous area near Aachen, bringing with it clay, sand, and chalk deposits. While the clay (which was the basis for a major pottery industry in nearby Raeren) is mostly found in the lower areas of Aachen, the hills of the Aachen Forest and the Lousberg were formed from upper Cretaceous sand and chalk deposits. More recent sedimentation is mainly located in the north and east of Aachen and was formed through tertiary and quaternary river and wind activities.\n\nAlong the major thrust fault of the Variscan orogeny, there are over 30 thermal springs in Aachen and Burtscheid. Additionally, the subsurface of Aachen is traversed by numerous active faults that belong to the Rurgraben fault system, which has been responsible for numerous earthquakes in the past, including the 1756 D\u00fcren earthquake and the 1992 Roermond earthquake, which was the strongest earthquake ever recorded in the Netherlands.\n\nDemographics \n\nAachen has 245,885 inhabitants (as of 31 December 2015), of whom 118,272 are female, and 127,613 are male.\n\nThe unemployment rate in the city is, as of April 2012, 9.7 percent. At the end of 2009, the foreign-born residents of Aachen made up 13.6 percent of the total population. A significant portion of foreign residents are students at the RWTH Aachen University.\n\nBoroughs \nThe city is divided into seven administrative districts, or boroughs, each with its own district council, district leader, and district authority. The councils are elected locally by those who live within the district, and these districts are further subdivided into smaller sections for statistical purposes, with each sub-district named by a two-digit number.\n\nThe districts of Aachen, including their constituent statistical districts, are:\n Aachen-Mitte: 10 Markt, 13 Theater, 14 Lindenplatz, 15 St. Jakob, 16 Westpark, 17 Hanbruch, 18 H\u00f6rn, 21 Ponttor, 22 Hansemannplatz, 23 Soers, 24 J\u00fclicher Stra\u00dfe, 25 Kalkofen, 31 Kaiserplatz, 32 Adalbertsteinweg, 33 Panneschopp, 34 Rothe Erde, 35 Trierer Stra\u00dfe, 36 Frankenberg, 37 Forst, 41 Beverau, 42 Burtscheid Kurgarten, 43", "flag": 1, "segments": [[1388, 1398]], "strength": 5.5}
{"text": "Aspirin, also known as acetylsalicylic acid (ASA), is a medication used to reduce pain, fever, or inflammation. Specific inflammatory conditions which aspirin is used to treat include Kawasaki disease, pericarditis, and rheumatic fever.\n\nAspirin given shortly after a heart attack decreases the risk of death. Aspirin is also used long-term to help prevent further heart attacks, ischaemic strokes, and blood clots in people at high risk. For pain or fever, effects typically begin within 30 minutes. Aspirin is a nonsteroidal anti-inflammatory drug (NSAID) and works similarly to other NSAIDs but also suppresses the normal functioning of platelets. Aspirin, often used as an analgesic, anti-pyretic and non-steroidal anti-inflammatory drug (NSAID), is able to have an anti-platelet effect by inhibiting the COX activity in the platelet to prevent the production of thromboxane A2 which acts to bind platelets together during coagulation as well as cause vasoconstriction and bronchoconstriction.\n\nOne common adverse effect is an upset stomach. More significant side effects include stomach ulcers, stomach bleeding, and worsening asthma. Bleeding risk is greater among those who are older, drink alcohol, take other NSAIDs, or are on other blood thinners. Aspirin is not recommended in the last part of pregnancy. It is not generally recommended in children with infections because of the risk of Reye syndrome. High doses may result in ringing in the ears.\n\nA precursor to aspirin found in leaves from the willow tree (genus Salix) has been used for its health effects for at least 2,400 years. In 1853, chemist Charles Fr\u00e9d\u00e9ric Gerhardt treated the medicine sodium salicylate with acetyl chloride to produce acetylsalicylic acid for the first time. For the next 50 years, other chemists established the chemical structure and devised more efficient production methods.\n\nAspirin is one of the most widely used medications globally, with an estimated  (50 to 120 billion pills) consumed each year. It is on the World Health Organization's List of Essential Medicines. It is available as a generic medication. In 2019, it was the 38th most commonly prescribed medication in the United States, with more than 18million prescriptions.\n\nBrand vs. generic name\nIn 1897, scientists at the Bayer company began studying acetylsalicylic acid as a less-irritating replacement medication for common salicylate medicines. By 1899, Bayer had named it \"Aspirin\" and sold it around the world.\n\nAspirin's popularity grew over the first half of the 20th century, leading to competition between many brands and formulations. The word Aspirin was Bayer's brand name; however, their rights to the trademark were lost or sold in many countries. The name is ultimately a blend of the prefix a(cetyl) + spir  Spiraea, the meadowsweet plant genus from which the acetylsalicylic acid was originally derived at Bayer + -in, the common chemical suffix.\n\nChemical properties\nAspirin decomposes rapidly in solutions of ammonium acetate or the acetates, carbonates, citrates, or hydroxides of the alkali metals. It is stable in dry air, but gradually hydrolyses in contact with moisture to acetic and salicylic acids. In solution with alkalis, the hydrolysis proceeds rapidly and the clear solutions formed may consist entirely of acetate and salicylate.\n\nLike flour mills, factories producing aspirin tablets must control the amount of the powder that becomes airborne inside the building, because the powder-air mixture can be explosive. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit in the United States of 5mg/m3 (time-weighted average). In 1989, the Occupational Safety and Health Administration (OSHA) set a legal permissible exposure limit for aspirin of 5mg/m3, but this was vacated by the AFL-CIO v. OSHA decision in 1993.\n\nSynthesis\nThe synthesis of aspirin is classified as an esterification reaction. Salicylic acid is treated with acetic anhydride, an acid derivative, causing a chemical reaction that turns salicylic acid's hydroxyl group into an ester group (R-OH \u2192 R-OCOCH3). This process yields aspirin and acetic acid, which is considered a byproduct of this reaction. Small amounts of sulfuric acid (and occasionally phosphoric acid) are almost always used as a catalyst. This method is commonly demonstrated in undergraduate teaching labs.\n\nReaction mechanism\n\nFormulations containing high concentrations of aspirin often smell like vinegar because aspirin can decompose through hydrolysis in moist conditions, yielding salicylic and acetic acids.\n\nPhysical properties\nAspirin, an acetyl derivative of salicylic acid, is a white, crystalline, weakly acidic substance, with a melting point of, and a boiling point of. Its acid dissociation constant (pKa) is 3.5 at.\n\nPolymorphism\nPolymorphism, or the ability of a substance to form more than one crystal structure, is important in the development of pharmaceutical ingredients. Many drugs receive regulatory approval for only a single crystal form or polymorph. For a long time, only one crystal structure for aspirin was known. That aspirin might have a second crystalline form was suspected since the 1960s. The elusive second polymorph was first discovered by Vishweshwar and coworkers in 2005, and fine structural details were given by Bond et al. A new crystal type was found during experiments after co-crystallization of aspirin and levetiracetam from hot acetonitrile. The form II is only stable at 100K and reverts to form I at ambient temperature. In the (unambiguous) form I, two salicylic molecules form centrosymmetric dimers through the acetyl groups with the (acidic) methyl proton to carbonyl hydrogen bonds, and in the newly claimed form II, each salicylic molecule forms the same hydrogen bonds with two neighboring molecules instead of one. With respect to the hydrogen bonds formed by the carboxylic acid groups, both polymorphs form identical dimer structures.\n\nMechanism of action\n\nDiscovery of the mechanism\nIn 1971, British pharmacologist John Robert Vane, then employed by the Royal College of Surgeons in London, showed aspirin suppressed the production of prostaglandins and thromboxanes. For this discovery he was awarded the 1982 Nobel Prize in Physiology or Medicine, jointly with Sune Bergstr\u00f6m and Bengt Ingemar Samuelsson.\n\nProstaglandins and thromboxanes\nAspirin's ability to suppress the production of prostaglandins and thromboxanes is due to its irreversible inactivation of the cyclooxygenase (COX; officially known as prostaglandin-endoperoxide synthase, PTGS) enzyme required for prostaglandin and thromboxane synthesis. Aspirin acts as an acetylating agent where an acetyl group is covalently attached to a serine residue in the active site of the PTGS enzyme (Suicide inhibition). This makes aspirin different from other NSAIDs (such as diclofenac and ibuprofen), which are reversible inhibitors.\n\nLow-dose aspirin use irreversibly blocks the formation of thromboxane A2 in platelets, producing an inhibitory effect on platelet aggregation during the lifetime of the affected platelet (8\u20139 days). This antithrombotic property makes aspirin useful for reducing the incidence of heart attacks in people who have had a heart attack, unstable angina, ischemic stroke or transient ischemic attack. 40mg of aspirin a day is able to inhibit a large proportion of maximum thromboxane A2 release provoked acutely, with the prostaglandin I2 synthesis being little affected; however, higher doses of aspirin are required to attain further inhibition.\n\nProstaglandins, local hormones produced in the body, have diverse effects, including the transmission of pain information to the brain, modulation of the hypothalamic thermostat, and inflammation. Thromboxanes are responsible for the aggregation of platelets that form blood clots. Heart attacks are caused primarily by blood clots, and low doses of aspirin are seen as an effective medical intervention to prevent a second acute myocardial infarction.\n\nCOX-1 and COX-2 inhibition\nAt least two different types of cyclooxygenases, COX-1 and COX-2, are acted on by aspirin. Aspirin irreversibly inhibits COX-1 and modifies the enzymatic activity of COX-2. COX-2 normally produces prostanoids, most of which are proinflammatory. Aspirin-modified PTGS2 (prostaglandin-endoperoxide synthase 2) produces lipoxins, most of which are anti-inflammatory. Newer NSAID drugs, COX-2 inhibitors (coxibs), have been developed to inhibit only PTGS2, with the intent to reduce the incidence of gastrointestinal side effects.\n\nSeveral COX-2 inhibitors, such as rofecoxib (Vioxx), have been withdrawn from the market, after evidence emerged that PTGS2 inhibitors increase the risk of heart attack and stroke. Endothelial cells lining the microvasculature in the body are proposed to express PTGS2, and, by selectively inhibiting PTGS which increase the security of video. You should use2, prostaglandin production (specifically, PGI2; prostacyclin) is downregulated with respect to thromboxane levels, as PTGS1 in platelets is unaffected. Thus, the protective anticoagulative effect of PGI2 is removed, increasing the risk of thrombus and associated heart attacks and other circulatory problems. Since platelets have no DNA, they are unable to synthesize new PTGS once aspirin has irreversibly inhibited the enzyme, an important difference with reversible inhibitors.\n\nFurthermore, aspirin, while inhibiting the ability of COX-2 to form pro-inflammatory products such as the prostaglandins, converts this enzyme's activity from a prostaglandin-forming cyclooxygenase to a lipoxygenase-like enzyme: aspirin-treated COX-2 metabolizes a variety of polyunsaturated fatty acids to hydroperoxy products which are then further metabolized to specialized proresolving mediators such as the aspirin-triggered lipoxins, aspirin-triggered resolvins, and aspirin-triggered maresins. These mediators possess potent anti-inflammatory activity. It is proposed that this aspirin-triggered transition of COX-2 from cyclooxygenase to lipoxygenase activity and the consequential formation of specialized proresolving mediators contributes to the anti-inflammatory effects of aspirin.\n\nAdditional mechanisms\nAspirin has been shown to have at least three additional modes of action. It uncouples oxidative phosphorylation in cartilaginous (and hepatic) mitochondria, by diffusing from the inner membrane space as a proton carrier back into the mitochondrial matrix, where it ionizes once again to release protons. Aspirin buffers and transports the protons. When high doses are given, it may actually cause fever, owing to the heat released from the electron transport chain, as opposed to the antipyretic action of aspirin seen with lower doses. In addition, aspirin induces the formation of NO-radicals in the body, which have been shown in mice to have an independent mechanism of reducing inflammation. This reduced leukocyte adhesion is an important step in the immune response to infection; however, evidence is insufficient to show aspirin helps to fight infection. More recent data also suggest salicylic acid and its derivatives modulate signalling through NF-\u03baB. NF-\u03baB, a transcription factor complex, plays a central role in many biological processes, including inflammation.\n\nAspirin is readily broken down in the body to salicylic acid, which itself has anti-inflammatory, antipyretic, and analgesic effects. In 2012, salicylic acid was found to activate AMP-activated protein kinase, which has been suggested as a possible explanation for some of the effects of both salicylic acid and aspirin. The acetyl portion of the aspirin molecule has its own targets. Acetylation of cellular proteins is a well-established phenomenon in the regulation of protein function at the post-translational level. Aspirin is able to acetylate several other targets in addition to COX isoenzymes. These acetylation reactions may explain many hitherto unexplained effects of aspirin.\n\nPharmacokinetics\nAcetylsalicylic acid is a weak acid, and very little of it is ionized in the stomach after oral administration. Acetylsalicylic acid is quickly absorbed through the cell membrane in the acidic conditions of the stomach. The increased pH and larger surface area of the small intestine causes aspirin to be absorbed more slowly there, as more of it is ionized. Owing to the formation of concretions, aspirin is absorbed much more slowly during overdose, and plasma concentrations can continue to rise for up to 24 hours after ingestion.\n\nAbout 50\u201380% of salicylate in the blood is bound to human serum albumin, while the rest remains in the active, ionized state; protein binding is concentration-dependent. Saturation of binding sites leads to more free salicylate and increased toxicity. The volume of distribution is 0.1\u20130.2 L/kg. Acidosis increases the volume of distribution because of enhancement of tissue penetration of salicylates.\n\nAs much as 80% of therapeutic doses of salicylic acid is metabolized in the liver. Conjugation with glycine forms salicyluric acid, and with glucuronic acid to form two different glucuronide esters. The conjugate with the acetyl group intact is referred to as the acyl glucuronide; the deacetylated conjugate is the phenolic glucuronide. These metabolic pathways have only a limited capacity. Small amounts of salicylic acid are also hydroxylated to gentisic acid. With large salicylate doses, the kinetics switch from first-order to zero-order, as metabolic pathways become saturated and renal excretion becomes increasingly important.\n\nSalicylates are excreted mainly by the kidneys as salicyluric acid (75%), free salicylic acid (10%), salicylic phenol (10%), and acyl glucuronides (5%), gentisic acid (< 1%), and 2,3-dihydroxybenzoic acid. When small doses (less than 250mg in an adult) are ingested, all pathways proceed by first-order kinetics, with an elimination half-life of about 2.0 h to 4.5 h. When higher doses of salicylate are ingested (more than 4 g), the half-life becomes much longer (15 h to 30 h), because the biotransformation pathways concerned with the formation of salicyluric acid and salicyl phenolic glucuronide become saturated. Renal excretion of salicylic acid becomes increasingly important as the metabolic pathways become saturated, because it is extremely sensitive to changes in urinary pH. A 10- to 20-fold increase in renal clearance occurs when urine pH is increased from 5 to 8. The use of urinary alkalinization exploits this particular aspect of salicylate elimination. It was found that short-term aspirin use in therapeutic doses might precipitate reversible acute kidney injury when the patient was ill with glomerulonephritis or cirrhosis. Aspirin for some patients with chronic kidney disease and some children with congestive heart failure was contraindicated.\n\nHistory\n\nMedicines made from willow and other salicylate-rich plants appear in clay tablets from ancient Sumer as well as the Ebers Papyrus from ancient Egypt. Hippocrates referred to the use of salicylic tea to reduce fevers around 400 BC, and willow bark preparations were part of the pharmacopoeia of Western medicine in classical antiquity and the Middle Ages. Willow bark extract became recognized for its specific effects on fever, pain, and inflammation in the mid-eighteenth century. By the nineteenth century, pharmacists were experimenting with and prescribing a variety of chemicals related to salicylic acid, the active component of willow extract.\n\nIn 1853, chemist Charles Fr\u00e9d\u00e9ric Gerhardt treated sodium salicylate with acetyl chloride to produce acetylsalicylic acid for the first time; in the second half of the 19th century, other academic chemists established the compound's chemical structure and devised more efficient methods of synthesis. In 1897, scientists at the drug and dye firm Bayer began investigating acetylsalicylic acid as a less-irritating replacement for standard common salicylate medicines, and identified a new way to synthesize it. By 1899, Bayer had dubbed this drug Aspirin and was selling it globally. The word Aspirin was Bayer's brand name, rather than the generic name of the drug; however, Bayer's rights to the trademark were lost or sold in many countries. Aspirin's popularity grew over the first half of the 20th century leading to fierce competition with the proliferation of aspirin brands and products.\n\nAspirin's popularity declined after the development of acetaminophen/paracetamol in 1956 and ibuprofen in 1962. In the 1960s and 1970s, John Vane and others discovered the basic mechanism of aspirin's effects, while clinical trials and other studies from the 1960s to the 1980s established aspirin's efficacy as an anti-clotting agent that reduces the risk of clotting diseases. The initial large studies on the use of low-dose aspirin to prevent heart attacks that were published in the 1970s and 1980s helped spur reform in clinical research ethics and guidelines for human subject research and US federal law, and are often cited as examples of clinical trials that included only men, but from which people drew general conclusions that did not hold true for women.\n\nAspirin sales revived considerably in the last decades of the 20th century, and remain strong in the 21st century with widespread use as a preventive treatment for heart attacks and strokes.\n\nTrademark \n\nBayer lost its trademark for Aspirin in the United States in actions taken between 1918 and 1921 because it had failed to use the name for its own product correctly and had for years allowed the use of \"Aspirin\" by other manufacturers without defending the intellectual property rights. Today, aspirin is a generic trademark in many countries. Aspirin, with a capital \"A\", remains a registered trademark of Bayer in Germany, Canada, Mexico, and in over 80 other countries, for acetylsalicylic acid in all markets, but using different packaging and physical aspects for each.\n\nCompendial status\n United States Pharmacopeia\n\n British Pharmacopoeia\n\nMedical use\nAspirin is used in the treatment of a number of conditions, including fever, pain, rheumatic fever, and inflammatory conditions, such as rheumatoid arthritis, pericarditis, and Kawasaki disease. Lower doses of aspirin have also been shown to reduce the risk of death from a heart attack, or the risk of stroke in people who are at high risk or who have cardiovascular disease, but not in elderly people who are otherwise healthy. There is some evidence that aspirin is effective at preventing colorectal cancer, though the mechanisms of this effect are unclear. In the United States, low-dose aspirin is deemed reasonable in those between 50 and 70 years old who have a risk of cardiovascular disease over 10%, are not at an increased risk of bleeding, and are otherwise healthy.\n\nPain\n\nAspirin is an effective analgesic for acute pain, although it is generally considered inferior to ibuprofen because aspirin is more likely to cause gastrointestinal bleeding. Aspirin is generally ineffective for those pains caused by muscle cramps, bloating, gastric distension, or acute skin irritation. As with other NSAIDs, combinations of aspirin and caffeine provide slightly greater pain relief than aspirin alone. Effervescent formulations of aspirin relieve pain faster than aspirin in tablets, which makes them useful for the treatment of migraines. Topical aspirin may be effective for treating some types of neuropathic pain.\n\nAspirin, either by itself or in a combined formulation, effectively treats certain types of a headache, but its efficacy may be questionable for others. Secondary headaches, meaning those caused by another disorder or trauma, should be promptly treated by a medical provider. Among primary headaches, the International Classification of Headache Disorders distinguishes between tension headache (the most common), migraine, and cluster headache. Aspirin or other over-the-counter analgesics are widely recognized as effective for the treatment of tension headache. Aspirin, especially as a component of an aspirin/paracetamol/caffeine combination, is considered a first-line therapy in the treatment of migraine, and comparable to lower doses of sumatriptan. It is most effective at stopping migraines when they are first beginning.\n\nFever\nLike its ability to control pain, aspirin's ability to control fever is due to its action on the prostaglandin system through its irreversible inhibition of COX. Although aspirin's use as an antipyretic in adults is well established, many medical societies and regulatory agencies, including the American Academy of Family Physicians, the American Academy of Pediatrics, and the Food and Drug Administration, strongly advise against using aspirin for treatment of fever in children because of the risk of Reye's syndrome, a rare but often fatal illness associated with the use of aspirin or other salicylates in children during episodes of viral or bacterial infection. Because of the risk of Reye's syndrome in children, in 1986, the US Food and Drug Administration (FDA) required labeling on all aspirin-containing medications advising against its use in children and teenagers.\n\nInflammation\nAspirin is used as an anti-inflammatory agent for both acute and long-term inflammation, as well as for treatment of inflammatory diseases, such as rheumatoid arthritis.\n\nHeart attacks and strokes\nAspirin is an important part of the treatment of those who have had a heart attack. It is generally not recommended for routine use by people with no other health problems, including those over the age of 70.\n\nFor people who have already had a heart attack or stroke, taking aspirin daily for two years prevented 1 in 50 from having a cardiovascular problem (heart attack, stroke, or death), but also caused non-fatal bleeding problems to occur in 1 of 400 people. Data from early trials of aspirin in primary prevention suggested low dose aspirin is more beneficial for people <70\u00a0kg and high dose aspirin is more beneficial for those \u226570\u00a0kg. However, more recent trials have suggested lower dose aspirin is not more efficacious in people with a low body weight and more evidence is required to determine the effect of higher dose aspirin in people with a high body weight.  The United States Preventive Services Task Force (USPSTF),, recommended initiating low-dose aspirin use for the primary prevention of cardiovascular disease and colon cancer in adults aged 50 to 59 years who have a 10% or greater 10-year cardiovascular disease (CVD) risk, are not at increased risk for bleeding, have a life expectancy of at least 10 years, and are willing to take low-dose aspirin daily for at least 10 years. However, in 2021,", "flag": 1, "segments": [[2034, 2044]], "strength": 5.5}
{"text": "The Ainu are the indigenous people of the lands surrounding the Sea of Okhotsk, including Hokkaido Island, Northeast Honshu Island, Sakhalin Island, the Kuril Islands, the Kamchatka Peninsula and Khabarovsk Krai, before the arrival of the Yamato Japanese and Russians. These regions are referred to as  in historical Japanese texts.\n\nOfficial estimates place the total Ainu population of Japan at 25,000. Unofficial estimates place the total population at 200,000 or higher, as the near-total assimilation of the Ainu into Japanese society has resulted in many individuals of Ainu descent having no knowledge of their ancestry. As of 2000, the number of \"pure\" Ainu was estimated at about 300 people.\n\nIn 1966, there were about 300 native Ainu speakers; in 2008, however, there were about 100 native Ainu speakers.\n\nNames\n\nThis people's most widely known ethnonym, \"Ainu\" (; ; ) means \"human\" in the Ainu language, particularly as opposed to, divine beings. Ainu also identify themselves as \"Utari\" (\"comrade\" or \"people\"). Official documents use both names.\n\nHistory\n\nPre-modern \nThe Ainu are the native people of Hokkaido, Sakhalin and the Kurils. Early Ainu-speaking groups (mostly hunters and fishermen) migrated also into the Kamchatka Peninsula and into Honshu, where their descendants are today known as the Matagi hunters, who still use a large amount of Ainu vocabulary in their dialect. Other evidence for Ainu-speaking hunters and fishermen migrating down from Northern Hokkaido into Honshu is through the Ainu toponyms which are found in several places of northern Honshu, mostly among the western coast and the T\u014dhoku region. Evidence for Ainu speakers in the Amur region is found through Ainu loanwords in the Uilta and Ulch people.\n\nResearch suggests that Ainu culture originated from a merger of the Okhotsk and Satsumon cultures. According to Lee and Hasegawa, the Ainu-speakers descend from the Okhotsk people which rapidly expanded from northern Hokkaido into the Kurils and Honshu. These early inhabitants did not speak the Japanese language; some were conquered by the Japanese early in the 9th century. In 1264, the Ainu invaded the land of the Nivkh people. The Ainu also started an expedition into the Amur region, which was then controlled by the Yuan Dynasty, resulting in reprisals by the Mongols who invaded Sakhalin. Active contact between the Wa-jin (the ethnically Japanese, also known as Yamato-jin) and the Ainu of Ezogashima (now known as Hokkaid\u014d) began in the 13th century. The Ainu formed a society of hunter-gatherers, surviving mainly by hunting and fishing. They followed a religion which was based on natural phenomena.\n\nDuring the Muromachi period (1336\u20131573), many Ainu were subject to Japanese rule. Disputes between the Japanese and Ainu developed into large-scale violence, Koshamain's Revolt, in 1456. Takeda Nobuhiro killed the Ainu leader, Koshamain.\n\nAfter Manchuria under Yuan rule, Ainu and Nivkh of Sakhalin became tributaries to the Ming dynasty of China after Manchuria came under Ming rule as part of the Nurgan Regional Military Commission. Boluohe, Nanghar and Wuliehe were Yuan posts set up to receive tribute from the Ainu after their war with the Yuan ended in 1308. Ming Chinese outposts in Sakhalin and the Amur river area received animal skin tribute from Ainu on Sakhalin, Uilta and Nivkh in the 15th century after the Tyr based Yongning Temple was set up along with the Nurkan (Nurgan) outposts by the Yongle emperor in 1409. The Ming also held the post at Wuliehe and received marten pelt fur tribute from the assistant commander Alige in 1431 from Sakhalin after the Ming assigned titles like weizhenfu (official charged with subjugation), zhihui qianshi (assistance commander), zhihui tongzhi (vice commander) and Zhihuishi (commander) from Sakhalin indigenous headmen. The Ming received tribute from the headmen Alingge, Tuolingha, Sanchiha and Zhaluha in 1437. The position of headman among Sakhalin indigenous peoples was inherited paternally from father to son and the sons came with their fathers to Wuliehe. Ming officials gave silk uniforms with the appropriate rank to the Sakhalin Ainu, Uilta and Nivkh after they gave tribute. The Maritime Province region had the Ming \"system for subjugated peoples' implementers in it for the Sakhalin indigenous peoples. Sakhalin received iron tools from mainland Asia through this trade as Tungus groups joined in from 1456-1487. Local indigenous hierarchies had Ming Chinese given political offices integrated with them. The Ming system on Sakhalin was imitated by the Qing. Nivkh women in Sakhalin married Han Chinese Ming officials when the Ming took tribute from Sakhalin and the Amur river region. Due to Ming rule in Manchuria, Chinese cultural and religious influence such as Chinese New Year, the \"Chinese god\", Chinese motifs like the dragon, spirals, scrolls, and material goods like agriculture, husbandry, heating, iron cooking pots, silk, and cotton spread among the Amur natives like the Udeghes, Ulchis, and Nanais.\n\nDuring the Edo period (1601\u20131868) the Ainu, who controlled the northern island which is now named Hokkaid\u014d, became increasingly involved in trade with the Japanese who controlled the southern portion of the island. The Tokugawa bakufu (feudal government) granted the Matsumae clan exclusive rights to trade with the Ainu in the northern part of the island. Later, the Matsumae began to lease out trading rights to Japanese merchants, and contact between Japanese and Ainu became more extensive. Throughout this period Ainu groups competed with each other to import goods from the Japanese, and epidemic diseases such as smallpox reduced the population. Although the increased contact created by the trade between the Japanese and the Ainu contributed to increased mutual understanding, it also sometimes led to conflict which occasionally intensified into violent Ainu revolts. The most important was Shakushain's Revolt (1669\u20131672), an Ainu rebellion against Japanese authority. Another large-scale revolt by Ainu against Japanese rule was the Menashi-Kunashir Battle in 1789. Throughout this period and thereafter, however, the Ainu-Japanese relationship continued to be marked by trade and commercial relationships, not conflicts.\n\nFrom 1799 to 1806, the shogunate took direct control of southern Hokkaid\u014d. During this period, Ainu women were separated from their husbands and either subjected to rape or forcibly married to Japanese men, while Ainu men were deported to merchant subcontractors for five and ten-year terms of service. Policies of family separation and assimilation, combined with the impact of smallpox, caused the Ainu population to drop significantly in the early 19th century.\n\nIn the 18th century, there were 80,000 Ainu. In 1868, there were about 15,000 Ainu in Hokkaid\u014d, 2000 in Sakhalin and around 100 in the Kuril islands.\n\nThe Santan Japanese traders seized Rishiri Ainu women when they were trading in Sakhalin to become their  wives.\n\nJapanese annexation of Hokkaido\nIn 1869, the imperial government established Hokkaid\u014d Colonization Office as part of the measures of the Meiji Restoration. Sj\u00f6berg quotes Baba's (1890) account of the Japanese government's reasoning:\n\n... The development of Japan's large northern island had several objectives: First, it was seen as a means to defend Japan from a rapidly developing and expansionist Russia. Second... it offered a solution to the unemployment for the former samurai class... Finally, development promised to yield the needed natural resources for a growing capitalist economy.\n\nAs a result of the Treaty of Saint Petersburg (1875), the Kuril Islands \u2013 along with their Ainu inhabitants \u2013 came under Japanese administration. In 1899, the Japanese government passed an act labelling the Ainu as \"former aborigines\", with the idea they would assimilate\u2014this resulted in the Japanese government taking the land where the Ainu people lived and placing it from then on under Japanese control. Also at this time, the Ainu were granted automatic Japanese citizenship, effectively denying them the status of an indigenous group.\n\nThe Ainu went from being a relatively isolated group of people to having their land, language, religion and customs assimilated into those of the Japanese. Their land was distributed to the Yamato Japanese settlers and to create and maintain farms in the model of Western industrial agriculture. It was known as \"colonization\" (\u62d3\u6b96) at the time, but later by the euphemism \"opening up undeveloped land\" (\u958b\u62d3). As well as this, factories such as flour mills, beer breweries and mining practices resulted in the creation of infrastructure such as roads and railway lines, during a development period that lasted until 1904. During this time, the Ainu were ordered to cease religious practices such as animal sacrifice and the custom of tattooing. The same act applied to the native Ainu on Sakhalin after the Japanese annexation of it as the Karafuto Prefecture.\n\nAssimilation after annexation\nThe Ainu have historically suffered from economic and social discrimination as the government as well as people in contact with the Ainu regarded them as a dirty and primitive barbarians. The majority of Ainu were forced to be petty laborers during the Meiji Restoration, which saw the introduction of Hokkaid\u014d into the Japanese Empire and the privatization of traditional Ainu lands. The Japanese government during the 19th and 20th centuries denied the rights of the Ainu to their traditional cultural practices, most notably the right to speak their language, as well as their right to hunt and gather. These policies were designed to fully integrate the Ainu into Japanese society with the cost of erasing Ainu culture and identity. The Ainu's position as manual laborers and their forced integration into larger Japanese society have led to discriminatory practices by the Japanese government that can still be felt today.\nIntermarriage between Japanese nationals who take a picture of diplomatic officers at foreign and Ainu was actively promoted by the Ainu to lessen the chances of discrimination against their offspring. As a result, many Ainu are indistinguishable from their Japanese neighbors, but some Ainu-Japanese are interested in traditional Ainu culture. For example, Oki, born as a child of an Ainu father and a Japanese mother, became a musician who plays the traditional Ainu instrument. There are also many small towns in the southeastern or Hidaka region where ethnic Ainu live such as in Nibutani (). Many live in Sambutsu especially, on the eastern coast.\n\nStandard of living \nThis discrimination and negative stereotypes assigned to the Ainu have manifested in the Ainu's lower levels of education, income levels and participation in the economy as compared to their ethnically Japanese counterparts. The Ainu community in Hokkaid\u014d in 1993 received welfare payments at a 2.3 times higher rate, had an 8.9% lower enrollment rate from junior high school to high school and a 15.7% lower enrollment into college from high school than that of Hokkaid\u014d as a whole. The Japanese government has been lobbied by activists to research the Ainu's standard of living nationwide due to this noticeable and growing gap. The Japanese government will provide \u00a57\u00a0million (US$63,000) beginning in 2015, to conduct surveys nationwide on this matter.\n\nChallenging the notion of ethnic homogeneity in Japan\nThe existence of the Ainu challenges the notion of ethnic homogeneity in post-WWII Japan. After the demise of the multi-ethnic Empire of Japan in 1945, successive governments had forged a single Japanese identity by advocating monoculturalism and denying the existence of more than one ethnic group in Japan. It was not until 2019 when the Japanese parliament passed an act to recognize the Ainu to be the indigenous people. However, the notion of ethnic homogeneity was so ingrained in Japan, which the former Prime Minister Taro Aso, in 2020, notably claimed \u201cNo other country but this one has lasted for as long as 2,000 years with one language, one ethnic group and one dynasty\u201d.\n\nBefore the 2019 law, an earlier development on Ainu rights happened in 2008. After the United Nations Declaration on the Rights of Indigenous Peoples in 2007, Hokkaido politicians pressured the government to act. A much-quoted remarks on the Ainu came from Prime Minister Fukuda Yasuo, who answered a parliamentary question on 20 May 2008 by stating \"[I]t is a historical fact that the Ainu are the precursors in the northern Japanese archipelago, in particular Hokkaido. The government acknowledges the Ainu to be an ethnic minority as it has maintained a unique cultural identity and having a unique language and religion.\" On 6 June 2008, the Japanese parliament passed a non-binding, bipartisan resolution calling upon the government to take actions on recognizing the Ainu as indigenous people.\n\nOrigins \n\nThe Ainu have often been considered to descend from the diverse J\u014dmon people, who lived in northern Japan from the J\u014dmon period ( 14,000 to 300 BCE). One of their, or legends, tells that \"[t]he Ainu lived in this place a hundred thousand years before the Children of the Sun came\".\n\nRecent research suggests that the historical Ainu culture originated from a merger of the Okhotsk culture with the Satsumon culture, cultures thought to have derived from the diverse J\u014dmon-period cultures of the Japanese archipelago.\n\nThe Ainu economy was based on farming, as well as on hunting, fishing and gathering.\n\nAccording to Lee and Hasegawa of the Waseda University, the direct ancestors of the later Ainu people formed during the late J\u014dmon period from the combination of  the local but diverse population of Hokkaido, long before the arrival of contemporary Japanese people. Lee and Hasegawa suggest that the Ainu language expanded from northern Hokkaido and may have originated from a relative more recent Northeast Asian/Okhotsk population, which established themselves in northern Hokkaido and had significant impact on the formation of Hokkaido's J\u014dmon culture.\n\nThe linguist and historian Joran Smale similarly found that the Ainu language likely originated from the ancient Okhotsk people, which had strong cultural influence on the \"Epi-J\u014dmon\" of southern Hokkaido and northern Honshu, but that the Ainu people themselves formed from the combination of both ancient groups. Additionally he notes that the historical distribution of Ainu dialects and its specific vocabulary correspond to the distribution of the maritime Okhotsk culture.\n\nRecently in 2021, it was confirmed that the Hokkaido J\u014dmon people formed from \"J\u014dmon tribes of Honshu\" and from \"Terminal Upper-Paleolithic people\" (TUP people) indigenous to Hokkaido and Paleolithic Northern Eurasia. The Honshu J\u014dmon groups arrived about 15,000 BC and merged with the indigenous \"TUP people\" to form the Hokkaido J\u014dmon. The Ainu in turn formed from the Hokkaido J\u014dmon and from the Okhotsk people.\n\nAnother study in 2021 (Sato et al.) analyzed the indigenous populations of northern Japan and the Russian Far East. They concluded that Siberia and northern Japan was populated by two distinct waves: \"the southern migration wave seems to have diversified into the local populations in East Asia (defined in this paper as a region including China, Japan, Korea, Mongol, and Taiwan) and Southeast Asia, and the northern wave, which probably runs through the Siberian and Eurasian steppe regions and mixed with the southern wave, probably in Siberia. Archaeologists have considered that bear worship, which is a religious practice widely observed among the northern Eurasian ethnic groups, including the Ainu, Finns, Nivkh, and Sami, was also shared by the Okhotsk people. On the other hand, no traces of such a religious practice have ever been discovered from archaeological sites of the Jomon and Epi-Jomon periods, which were anterior to the Ainu cultural period. This implies that the Okhotsk culture contributed to the forming of the Ainu culture.\"\n\nGenetics\n\nPaternal lineages \nGenetic testing has shown that the Ainu belong mainly to Y-DNA haplogroup D-M55 (D1a2) and C-M217. Y\u00a0DNA haplogroup D\u00a0M55 is found throughout the Japanese Archipelago, but with very high frequencies among the Ainu of Hokkaid\u014d in the far north, and to a lesser extent among the Ryukyuans in the Ryukyu Islands of the far south. Recently it was confirmed that the Japanese branch of haplogroup D\u00a0M55 is distinct and isolated from other D\u00a0branches for more than 53,000\u00a0years.\n\nSeveral studies (Hammer et al. 2006, Shinoda 2008, Matsumoto 2009, Cabrera et al. 2018) suggest that haplogroup D originated somewhere in Central Asia. According to Hammer et al., the ancestral haplogroup\u00a0D originated between Tibet and the Altai mountains. He suggests that there were multiple waves into Eastern Eurasia.\n\nA study by Tajima et al. (2004) found two out of a sample of sixteen Ainu men (or 12.5%) belong to Haplogroup C\u00a0M217, which is the most common Y\u00a0chromosome haplogroup among the indigenous populations of Siberia and Mongolia. Hammer et al. (2006) found that one in a sample of four Ainu men belonged to haplogroup C\u00a0M217.\n\nMaternal lineages \nBased on analysis of one sample of 51\u00a0modern Ainu, their mtDNA lineages consist mainly of haplogroup\u00a0Y [ = 21.6% according to Tanaka et al. 2004, or  = 19.6% according to Adachi et al. 2009, who have cited Tajima et al. 2004], haplogroup D [ = 17.6%, particularly D4 (xD1)], haplogroup M7a ( = 15.7%), and haplogroup G1 ( = 15.7%). Other mtDNA haplogroups detected in this sample include A (), M7b2 (), N9b (), B4f (), F1b (), and M9a (). Most of the remaining individuals in this sample have been classified definitively only as belonging to macro-haplogroup\u00a0M.\n\nAccording to Sato et al. (2009), who have studied the mtDNA of the same sample of modern Ainus (=51), the major haplogroups of the Ainu are N9 [ = 27.5%, including  Y and  N9 (xY)], D [ = 23.5%, including  D (xD5) and  D5], M7 ( = 19.6%), and G ( = 19.6%, including  G1 and  G2); the minor haplogroups are A (), B (), F (), and M (xM7, M8, CZ, D, G) ().\n\nStudies published in 2004 and 2007 show the combined frequency of M7a and N9b were observed in J\u014dmons and which are believed by some to be J\u014dmon maternal contribution at 28% in Okinawans [ M7a1,  M7a (xM7a1),  N9b], 17.6% in Ainus [ M7a (xM7a1),  N9b], and from 10% [ M7a (xM7a1),  M7a1,  N9b] to 17% [ M7a1,  M7a (xM7a1)] in mainstream Japanese.\n\nIn addition, haplogroups D4, D5, M7b, M9a, M10, G, A, B, and F have been found in J\u014dmon people as well. These mtDNA haplogroups were found in various J\u014dmon samples and in some modern Japanese people.\n\nA study by Kanazawa-Kiriyama in 2013 about mitochondrial haplogroups, found that the Ainu people (including samples from Hokkaido and T\u014dhoku) have a high frequency of N9b, which is also found among Udege people of eastern Siberia, and more common among Europeans than Eastern Asians, but absent from the geographically close Kant\u014d J\u014dmon period samples, which have a higher frequency of M7a7, which is commonly found among East and Southeast Asians. According to the authors, these results add to the internal-diversity observed among the J\u014dmon period population and that a significant percentage of the J\u014dmon period people had ancestry from a Northeast Asian source population, suggested to be the source of the proto-Ainu language and culture, which is not detected in samples from Kant\u014d.\n\nAutosomal DNA \nA 2004 reevaluation of cranial traits suggests that the Ainu resemble the Okhotsk more than they do the J\u014dmon but there are large variations. This agrees with the references to the Ainu as a merger of Okhotsk and Satsumon referenced above. Similarly more recent studies link the Ainu to the local Hokkaido J\u014dmon period samples, such as the 3,800 year old Rebun sample.\n\nGenetic analyses of HLA I and HLA II genes as well as HLA-A, -B, and -DRB1 gene frequencies links the Ainu to Indigenous peoples of the Americas. Genetic of variety Asian groups shows Ainu and of Native Americans are place relatively close can be traced back to Paleolithic groups in Siberia.\n\nHideo Matsumoto (2009) suggested, based on immunoglobulin analyses, that the Ainu (and J\u014dmon) have a Siberian origin. Compared with other East Asian populations, the Ainu have the highest amount of Siberian (immunoglobulin) components, higher than mainland Japanese people.\n\nA 2012 genetic study has revealed that the closest genetic relatives of the Ainu are the Ryukyuan people, followed by the Yamato people and Nivkh.\n\nA genetic analysis in 2016 showed that although the Ainu have some genetic relations to the Japanese people and Eastern Siberians (especially Itelmens and Chukchis), they are not directly related to any modern ethnic group. Further, the study detected genetic contribution from the Ainu to populations around the Sea of Okhotsk but no genetic influence on the Ainu themselves. According to the study, the Ainu-like genetic contribution in the Ulch people is about 17.8% or 13.5% and about 27.2% in the Nivkhs. The study also disproved the idea about a relation to Andamanese or Tibetans; instead, it presented evidence of gene flow between the Ainu and \"lowland East Asian farmer populations\" (represented in the study by the Ami and Atayal in Taiwan, and the Dai and Lahu in Mainland East Asia).\n\nA genetic study in 2016 about historical Ainu samples from southern Sakhalin (8)", "flag": 1, "segments": [[2238, 2248]], "strength": 5.5}
{"text": "Acupuncture is a form of alternative medicine and a component of traditional Chinese medicine (TCM) in which thin needles are inserted into the body. Acupuncture is a pseudoscience; the theories and practices of TCM are not based on scientific knowledge, and it has been characterized as quackery. There is a range of acupuncture variants which originated in different philosophies, and techniques vary depending on the country in which it is performed, but can be divided into two main foundational philosophical applications and approaches, the first being the modern standardized form called eight principles TCM and the second an older system that is based on the ancient Taoist Wuxing or better known as the five elements or phases in the West. Acupuncture is most often used to attempt pain relief, though acupuncturists say that it can also be used for a wide range of other conditions. Acupuncture is generally used only in combination with other forms of treatment.\n\nThe global acupuncture market was worth US$24.55 billion in 2017. The market was led by Europe with a 32.7% share, followed by Asia-Pacific with a 29.4% share and the Americas with a 25.3% share. It is estimated that the industry will reach a market size of $55bn by 2023.\n\nThe conclusions of trials and systematic reviews of acupuncture are inconsistent, which suggests that it is not effective. An overview of Cochrane reviews found that acupuncture is not effective for a wide range of conditions. A systematic review conducted by medical scientists at the universities of Exeter and Plymouth found little evidence of acupuncture's effectiveness in treating pain. Overall, the evidence suggests that short-term treatment with acupuncture does not produce long-term benefits. Some research results suggest that acupuncture can alleviate some forms of pain, though the majority of research suggests that acupuncture's apparent effects are not caused by the treatment itself. A systematic review concluded that the analgesic effect of acupuncture seemed to lack clinical relevance and could not be clearly distinguished from bias. One meta-analysis found that acupuncture for chronic low back pain was cost-effective as an adjunct to standard care, while a separate systematic review found insufficient evidence for the cost-effectiveness of acupuncture in the treatment of chronic low back pain.\n\nAcupuncture is generally safe when done by appropriately trained practitioners using clean needle technique and single-use needles. When properly delivered, it has a low rate of mostly minor adverse effects. Accidents and infections do occur, though, and are associated with neglect on the part of the practitioner, particularly in the application of sterile techniques. A review conducted in 2013 stated that reports of infection transmission increased significantly in the preceding decade. The most frequently reported adverse events were pneumothorax and infections. Since serious adverse events continue to be reported, it is recommended that acupuncturists be trained sufficiently to reduce the risk.\n\nScientific investigation has not found any histological or physiological evidence for traditional Chinese concepts such as qi, meridians, and acupuncture points, and many modern practitioners no longer support the existence of life force energy (qi) or meridians, which was a major part of early belief systems. Acupuncture is believed to have originated around 100\u00a0BC in China, around the time The Inner Classic of Huang Di (Huangdi Neijing) was published, though some experts suggest it could have been practiced earlier. Over time, conflicting claims and belief systems emerged about the effect of lunar, celestial and earthly cycles, yin and yang energies, and a body's \"rhythm\" on the effectiveness of treatment. Acupuncture fluctuated in popularity in China due to changes in the country's political leadership and the preferential use of rationalism or Western medicine. Acupuncture spread first to Korea in the 6th century AD, then to Japan through medical missionaries, and then to Europe, beginning with France. In the 20th century, as it spread to the United States and Western countries, spiritual elements of acupuncture that conflicted with Western beliefs were sometimes abandoned in favor of simply tapping needles into acupuncture points.\n\nClinical practice \n\nAcupuncture is a form of alternative medicine. It is used most commonly for pain relief, though it is also used to treat a wide range of conditions. Acupuncture is generally only used in combination with other forms of treatment. For example, the American Society of Anesthesiologists states it may be considered in the treatment for nonspecific, noninflammatory low back pain only in conjunction with conventional therapy.\n\nAcupuncture is the insertion of thin needles into the skin. According to the Mayo Foundation for Medical Education and Research (Mayo Clinic), a typical session entails lying still while approximately five to twenty needles are inserted; for the majority of cases, the needles will be left in place for ten to twenty minutes. It can be associated with the application of heat, pressure, or laser light. Classically, acupuncture is individualized and based on philosophy and intuition, and not on scientific research. There is also a non-invasive therapy developed in early 20th century Japan using an elaborate set of instruments other than needles for the treatment of children (sh\u014dnishin or sh\u014dnihari).\n\nClinical practice varies depending on the country. A comparison of the average number of patients treated per hour found significant differences between China (10) and the United States (1.2). Chinese herbs are often used. There is a diverse range of acupuncture approaches, involving different philosophies. Although various different techniques of acupuncture practice have emerged, the method used in traditional Chinese medicine (TCM) seems to be the most widely adopted in the US. Traditional acupuncture involves needle insertion, moxibustion, and cupping therapy, and may be accompanied by other procedures such as feeling the pulse and other parts of the body and examining the tongue. Traditional acupuncture involves the belief that a \"life force\" (qi) circulates within the body in lines called meridians. The main methods practiced in the UK are TCM and Western medical acupuncture. The term Western medical acupuncture is used to indicate an adaptation of TCM-based acupuncture which focuses less on TCM. The Western medical acupuncture approach involves using acupuncture after a medical diagnosis. Limited research has compared the contrasting acupuncture systems used in various countries for determining different acupuncture points and thus there is no defined standard for acupuncture points.\n\nIn traditional acupuncture, the acupuncturist decides which points to treat by observing and questioning the patient to make a diagnosis according to the tradition used. In TCM, the four diagnostic methods are: inspection, auscultation and olfaction, inquiring, and palpation. Inspection focuses on the face and particularly on the tongue, including analysis of the tongue size, shape, tension, color and coating, and the absence or presence of teeth marks around the edge. Auscultation and olfaction involve listening for particular sounds such as wheezing, and observing body odor. Inquiring involves focusing on the \"seven inquiries\": chills and fever; perspiration; appetite, thirst and taste; defecation and urination; pain; sleep; and menses and leukorrhea. Palpation is focusing on feeling the body for tender \"A-shi\" points and feeling the pulse.\n\nNeedles \n\nThe most common mechanism of stimulation of acupuncture points employs penetration of the skin by thin metal needles, which are manipulated manually or the needle may be further stimulated by electrical stimulation (electroacupuncture). Acupuncture needles are typically made of stainless steel, making them flexible and preventing them from rusting or breaking. Needles are usually disposed of after each use to prevent contamination. Reusable needles when used should be sterilized between applications. In many areas, only sterile, single-use acupuncture needles are allowed, including the State of California, USA. Needles vary in length between, with shorter needles used near the face and eyes, and longer needles in areas with thicker tissues; needle diameters vary from 0 to 0, with thicker needles used on more robust patients. Thinner needles may be flexible and require tubes for insertion. The tip of the needle should not be made too sharp to prevent breakage, although blunt needles cause more pain.\n\nApart from the usual filiform needle, other needle types include three-edged needles and the Nine Ancient Needles. Japanese acupuncturists use extremely thin needles that are used superficially, sometimes without penetrating the skin, and surrounded by a guide tube (a 17th-century invention adopted in China and the West). Korean acupuncture uses copper needles and has a greater focus on the hand.\n\nNeedling technique\n\nInsertion \n\nThe skin is sterilized and needles are inserted, frequently with a plastic guide tube. Needles may be manipulated in various ways, including spinning, flicking, or moving up and down relative to the skin. Since most pain is felt in the superficial layers of the skin, a quick insertion of the needle is recommended. Often the needles are stimulated by hand in order to cause a dull, localized, aching sensation that is called de qi, as well as \"needle grasp,\" a tugging feeling felt by the acupuncturist and generated by a mechanical interaction between the needle and skin. Acupuncture can be painful. The skill level of the acupuncturist may influence how painful the needle insertion is, and a sufficiently skilled practitioner may be able to insert the needles without causing any pain.\n\nDe-qi sensation \n\nDe-qi (; \"arrival of qi\") refers to a claimed sensation of numbness, distension, or electrical tingling at the needling site. If these sensations are not observed then inaccurate location of the acupoint, improper depth of needle insertion, inadequate manual manipulation, are blamed. If de-qi is not immediately observed upon needle insertion, various manual manipulation techniques are often applied to promote it (such as \"plucking\", \"shaking\" or \"trembling\").\n\nOnce de-qi is observed, techniques might be used which attempt to \"influence\" the de-qi; for example, by certain manipulation the de-qi can allegedly be conducted from the needling site towards more distant sites of the body. Other techniques aim at \"tonifying\" () or \"sedating\" () qi. The former techniques are used in deficiency patterns, the latter in excess patterns. De qi is more important in Chinese acupuncture, while Western and Japanese patients may not consider it a necessary part of the treatment.\n\nRelated practices \n Acupressure, a non-invasive form of bodywork, uses physical pressure applied to acupressure points by the hand or elbow, or with various devices.\n Acupuncture is often accompanied by moxibustion, the burning of cone-shaped preparations of moxa (made from dried mugwort) on or near the skin, often but not always near or on an acupuncture point. Traditionally, acupuncture was used to treat acute conditions while moxibustion was used for chronic diseases. Moxibustion could be direct (the cone was placed directly on the skin and allowed to burn the skin, producing a blister and eventually a scar), or indirect (either a cone of moxa was placed on a slice of garlic, ginger or other vegetable, or a cylinder of moxa was held above the skin, close enough to either warm or burn it).\n Cupping therapy is an ancient Chinese form of alternative medicine in which a local suction is created on the skin; practitioners believe this mobilizes blood flow in order to promote healing.\n Tui na is a TCM method of attempting to stimulate the flow of qi by various bare-handed techniques that do not involve needles.\n Electroacupuncture is a form of acupuncture in which acupuncture needles are attached to a device that generates continuous electric pulses (this has been described as \"essentially transdermal electrical nerve stimulation [TENS] masquerading as acupuncture\").\n Fire needle acupuncture also known as fire needling is a technique which involves quickly inserting a flame-heated needle into areas on the body.\n Sonopuncture is a stimulation of the body similar to acupuncture using sound instead of needles. This may be done using purpose-built transducers to direct a narrow ultrasound beam to a depth of 6\u20138 centimetres at acupuncture meridian points on the body. Alternatively, tuning forks or other sound emitting devices are used.\n Acupuncture point injection is the injection of various substances (such as drugs, vitamins or herbal extracts) into acupoints. This technique combines traditional acupuncture with injection of what is often an effective dose of an approved pharmaceutical drug, and proponents claim that it may be more effective than either treatment alone, especially for the treatment of some kinds of chronic pain. However, a 2016 review found that most published trials of the technique were of poor value due to methodology issues and larger trials would be needed to draw useful conclusions.\n Auriculotherapy, commonly known as ear acupuncture, auricular acupuncture, or auriculoacupuncture, is considered to date back to ancient China. It involves inserting needles to stimulate points on the outer ear. The modern approach was developed in France during the early 1950s. There is no scientific evidence that it can cure disease; the evidence of effectiveness is negligible.\n Scalp acupuncture, developed in Japan, is based on reflexological considerations regarding the scalp.\n Hand acupuncture, developed in Korea, centers around assumed reflex zones of the hand. Medical acupuncture attempts to integrate reflexological concepts, the trigger point model, and anatomical insights (such as dermatome distribution) into acupuncture practice, and emphasizes a more formulaic approach to acupuncture point location.\n Cosmetic acupuncture is the use of acupuncture in an attempt to reduce wrinkles on the face.\n Bee venom acupuncture is a treatment approach of injecting purified, diluted bee venom into acupoints.\n Veterinary acupuncture is the use of acupuncture on domesticated animals.\n\nEfficacy \nAcupuncture has been researched extensively; as of 2013, there were almost 1,500 randomized controlled trials on PubMed with \"acupuncture\" in the title. The results of reviews of acupuncture's efficacy, however, have been inconclusive.\n\nIn January 2020, David Gorski analyzed a 2020 review of systematic reviews (\"Acupuncture for the Relief of Chronic Pain: A Synthesis of Systematic Reviews\") concerning the use of acupuncture to treat chronic pain. Writing in Science-Based Medicine, Gorski said that its findings highlight the conclusion that acupuncture is \"a theatrical placebo whose real history has been retconned beyond recognition.\" He also said this review \"reveals the many weaknesses in the design of acupuncture clinical trials\".\n\nSham acupuncture and research \nIt is difficult but not impossible to design rigorous research trials for acupuncture. Due to acupuncture's invasive nature, one of the major challenges in efficacy research is in the design of an appropriate placebo control group. For efficacy studies to determine whether acupuncture has specific effects, \"sham\" forms of acupuncture where the patient, practitioner, and analyst are blinded seem the most acceptable approach. Sham acupuncture uses non-penetrating needles or needling at non-acupuncture points, e.g. inserting needles on meridians not related to the specific condition being studied, or in places not associated with meridians. The under-performance of acupuncture in such trials may indicate that therapeutic effects are due entirely to non-specific effects, or that the sham treatments are not inert, or that systematic protocols yield less than optimal treatment.\n\nA 2014 review in Nature Reviews Cancer found that \"contrary to the claimed mechanism of redirecting the flow of qi through meridians, researchers usually find that it generally does not matter where the needles are inserted, how often (that is, no dose-response effect is observed), or even if needles are actually inserted. In other words,'sham' or 'placebo' acupuncture generally produces the same effects as'real' acupuncture and, in some cases, does better.\" A 2013 meta-analysis found little evidence that the effectiveness of acupuncture on pain (compared to sham) was modified by the location of the needles, the number of needles used, the experience or technique of the practitioner, or by the circumstances of the sessions. The same analysis also suggested that the number of needles and sessions is important, as greater numbers improved the outcomes of acupuncture compared to non-acupuncture controls. There has been little systematic investigation of which components of an acupuncture session may be important for any therapeutic effect, including needle placement and depth, type and intensity of stimulation, and number of needles used. The research seems to suggest that needles do not need to stimulate the traditionally specified acupuncture points or penetrate the skin to attain an anticipated effect (e.g. psychosocial factors).\n\nA response to \"sham\" acupuncture in osteoarthritis may be used in the elderly, but placebos have usually been regarded as deception and thus unethical. However, some physicians and ethicists have suggested circumstances for applicable uses for placebos such as it might present a theoretical advantage of an inexpensive treatment without adverse reactions or interactions with drugs or other medications. As the evidence for most types of alternative medicine such as acupuncture is far from strong, the use of alternative medicine in regular healthcare can present an ethical question.\n\nUsing the principles of evidence-based medicine to research acupuncture is controversial, and has produced different results. Some research suggests acupuncture can alleviate pain but the majority of research suggests that acupuncture's effects are mainly due to placebo. Evidence suggests that any benefits of acupuncture are short-lasting. There is insufficient evidence to support use of acupuncture compared to mainstream medical treatments. Acupuncture is not better than mainstream treatment in the long term.\n\nThe use of acupuncture has been criticized owing to there being little scientific evidence for explicit effects, or the mechanisms for its supposed effectiveness, for any condition that is discernible from placebo. Acupuncture has been called 'theatrical placebo', and David Gorski argues that when acupuncture proponents advocate 'harnessing of placebo effects' or work on developing'meaningful placebos', they essentially concede it is little more than that.\n\nPublication bias \n\nPublication bias is cited as a concern in the reviews of randomized controlled trials of acupuncture. A 1998 review of studies on acupuncture found that trials originating in China, Japan, Hong Kong, and Taiwan were uniformly favourable to acupuncture, as were ten out of eleven studies conducted in Russia. A 2011 assessment of the quality of randomized controlled trials on traditional Chinese medicine, including acupuncture, concluded that the methodological quality of most such trials (including randomization, experimental control, and blinding) was generally poor, particularly for trials published in Chinese journals (though the quality of acupuncture trials was better than the trials testing traditional Chinese medicine remedies). The study also found that trials published in non-Chinese journals tended to be of higher quality. Chinese authors use more Chinese studies, which have been demonstrated to be uniformly positive. A 2012 review of 88 systematic reviews of acupuncture published in Chinese journals found that less than half of these reviews reported testing for publication bias, and that the majority of these reviews were published in journals with impact factors of zero. A 2015 study comparing pre-registered records of acupuncture trials with their published results found that it was uncommon for such trials to be registered before the trial began. This study also found that selective reporting of results and changing outcome measures to obtain statistically significant results was common in this literature.\n\nScientist and journalist Steven Salzberg identifies acupuncture and Chinese medicine generally as a focus for \"fake medical journals\" such as the Journal of Acupuncture and Meridian Studies and Acupuncture in Medicine.\n\nSpecific conditions\n\nPain \n\nThe conclusions of many trials and numerous systematic reviews of acupuncture are largely inconsistent with each other. A 2011 systematic review of systematic reviews found that for reducing pain, real acupuncture was no better than sham acupuncture, and concluded that numerous reviews have shown little convincing evidence that acupuncture is an effective treatment for reducing pain. The same review found that neck pain was one of only four types of pain for which a positive effect was suggested, but cautioned that the primary studies used carried a considerable risk of bias. A 2009 overview of Cochrane reviews found acupuncture is not effective for a wide range of conditions.\n\nA 2014 systematic review suggests that the nocebo effect of acupuncture is clinically relevant and that the rate of adverse events may be a gauge of the nocebo effect. A 2012 meta-analysis conducted by the Acupuncture Trialists' Collaboration found \"relatively modest\" efficacy of acupuncture (in comparison to sham) for the treatment of four different types of chronic pain (back and neck pain, knee osteoarthritis, chronic headache, and shoulder pain) and on that basis concluded that it \"is more than a placebo\" and a reasonable referral option. Commenting on this meta-analysis, both Edzard Ernst and David Colquhoun said the results were of negligible clinical significance. Ernst later stated that \"I fear that, once we manage to eliminate this bias [that operators are not blind] \u2026 we might find that the effects of acupuncture exclusively are a placebo response.\" In 2017, the same research group updated their previous meta-analysis and again found acupuncture to be superior to sham acupuncture for non-specific musculoskeletal pain, osteoarthritis, chronic headache, and shoulder pain. They also found that the effects of acupuncture decreased by about 15% after one year.\n\nA 2010 systematic review suggested that acupuncture is more than a placebo for commonly occurring chronic pain conditions, but the authors acknowledged that it is still unknown if the overall benefit is clinically meaningful or cost-effective. A 2010 review found real acupuncture and sham acupuncture produce similar improvements, which can only be accepted as evidence against the efficacy of acupuncture. The same review found limited evidence that real acupuncture and sham acupuncture appear to produce biological differences despite similar effects. A 2009 systematic review and meta-analysis found that acupuncture had a small analgesic effect, which appeared to lack any clinical importance and could not be discerned from bias. The same review found that it remains unclear whether acupuncture reduces pain independent of a psychological impact of the needling ritual. A 2017 systematic review and meta-analysis found that ear acupuncture may be effective at reducing pain within 48 hours of its use, but the mean difference between the acupuncture and control groups was small..21am. Police were assisted by a helicopter\n\nLower back pain\nA 2013 systematic review found that acupuncture may be effective for nonspecific lower back pain, but the authors noted there were limitations in the studies examined, such as heterogeneity in study characteristics and low methodological quality in many studies. A 2012 systematic review found some supporting evidence that acupuncture was more effective than no treatment for chronic non-specific low back pain; the evidence was conflicting comparing the effectiveness over other treatment approaches. A 2011 systematic review of systematic reviews found that \"for chronic low back pain, individualized acupuncture is not better in reducing symptoms than formula acupuncture or sham acupuncture with a toothpick that does not penetrate the skin.\" A 2010 review found that sham acupuncture was as effective as real acupuncture for chronic low back pain. The specific therapeutic effects of acupuncture were small, whereas its clinically relevant benefits were mostly due to contextual and psychosocial circumstances. Brain imaging studies have shown that traditional acupuncture and sham acupuncture differ in their effect on limbic structures, while at the same time showed equivalent analgesic effects. A 2005 Cochrane review found insufficient evidence to recommend for or against either acupuncture or dry needling for acute low back pain. The same review found low quality evidence for pain relief and improvement compared to no treatment or sham therapy for chronic low back pain only in the short term immediately after treatment. The same review also found that acupuncture is not more effective than conventional therapy and other alternative medicine treatments. A 2017 systematic review and meta-analysis concluded that, for neck pain, acupuncture was comparable in effectiveness to conventional treatment, while electroacupuncture was even more effective in reducing pain than was conventional acupuncture. The same review noted that \"It is difficult to draw conclusion [sic] because the included studies have a high risk of bias and imprecision.\" A 2015 overview of systematic reviews of variable quality showed that acupuncture can provide short-term improvements to people with chronic Low Back Pain. The overview said this was true when acupuncture was used either in isolation or in addition to conventional therapy. A 2017 systematic review for an American College of Physicians clinical practice guideline found low to moderate evidence that acupuncture was effective for chronic low back", "flag": 1, "segments": [[4576, 4586]], "strength": 5.5}
{"text": "Andrew Jackson (March 15, 1767\u00a0\u2013 June 8, 1845) was an American lawyer, general, and statesman who served as the seventh president of the United States from 1829 to 1837. Before being elected to the presidency, Jackson gained fame as a general in the United States Army and served in both houses of the U.S. Congress. An expansionist president, Jackson sought to advance the rights of the \"common man\" against a \"corrupt aristocracy\" and to preserve the Union.\n\nBorn in the colonial Carolinas in the decade before the American Revolutionary War, Jackson became a frontier lawyer and married Rachel Donelson Robards. He served briefly in the United States House of Representatives and the United States Senate, representing Tennessee. After resigning, he served as a justice on the Tennessee Supreme Court from 1798 until 1804. Jackson purchased a property later known as The Hermitage, and became a wealthy, slaveowning planter. In 1801, he was appointed colonel of the Tennessee militia and was elected its commander the following year. He led troops during the Creek War of 1813\u20131814, winning the Battle of Horseshoe Bend. The subsequent Treaty of Fort Jackson required the Creek surrender of vast lands in present-day Alabama and Georgia. In the concurrent war against the British, Jackson's victory in 1815 at the Battle of New Orleans made him a national hero. Jackson then led U.S. forces in the First Seminole War, which led to the annexation of Florida from Spain. Jackson briefly served as Florida's first territorial governor before returning to the Senate. He ran for president in 1824, winning a plurality of the popular and electoral vote. As no candidate won an electoral majority, the House of Representatives elected John Quincy Adams in a contingent election. In reaction to the alleged \"corrupt bargain\" between Adams and Henry Clay and the ambitious agenda of President Adams, Jackson's supporters founded the Democratic Party.\n\nJackson ran again in 1828, defeating Adams in a landslide. Jackson faced the threat of secession by South Carolina over what opponents called the \"Tariff of Abominations\". The crisis was defused when the tariff was amended, and Jackson threatened the use of military force if South Carolina attempted to secede. In Congress, Henry Clay led the effort to reauthorize the Second Bank of the United States. Jackson, regarding the Bank as a corrupt institution that benefited the wealthy at the expense of ordinary Americans, vetoed the renewal of its charter. After a lengthy struggle, Jackson and his allies thoroughly dismantled the Bank. In 1835, Jackson became the only president to completely pay off the national debt, fulfilling a longtime goal. While Jackson pursued numerous reforms designed to eliminate waste and corruption, his presidency marked the beginning of the ascendancy of the party \"spoils system\" in American politics. In 1830, Jackson signed the Indian Removal Act, which forcibly removed most members of the major tribes of the Southeast to Indian Territory; these removals were subsequently known as the Trail of Tears. The relocation process dispossessed these nations of their land and resulted in widespread death and disease. Jackson opposed the abolitionist movement, which grew stronger in his second term. In foreign affairs, Jackson's administration concluded a \"most favored nation\" treaty with the United Kingdom, settled claims of damages against France from the Napoleonic Wars, and recognized the Republic of Texas. In January 1835, he survived the first assassination attempt on a sitting president.\n\nIn his retirement, Jackson remained active in Democratic Party politics, supporting the presidencies of Martin Van Buren and James K. Polk. Though fearful of its effects on the slavery debate, Jackson advocated the annexation of Texas, which was accomplished shortly before his death. Jackson has been widely revered in the United States as an advocate for democracy and the common man. Many of his actions proved divisive, garnering both fervent support and strong opposition from many in the country. His reputation has suffered since the 1970s, largely due to his anti-abolitionist views and policy of the forcible removal of Native Americans from their ancestral homelands. However, surveys of historians and scholars have ranked Jackson favorably among U.S. presidents.\n\nEarly life and education\nAndrew Jackson was born on March 15, 1767, in the Waxhaws region of the Carolinas. His parents were Scots-Irish colonists Andrew Jackson and his wife Elizabeth Hutchinson, Presbyterians who had emigrated from Ulster, Ireland, two years earlier. Jackson's father was born in Carrickfergus, County Antrim, around 1738. Jackson's parents lived in the village of Boneybefore, also in County Antrim. His paternal ancestors originated in Killingswold Grove, Yorkshire, England.\n\nWhen they migrated to North America in 1765, Jackson's parents brought two children with them from Ireland, Hugh (born 1763) and Robert (born 1764). The family probably landed in Philadelphia. Most likely they traveled overland through the Appalachian Mountains to the Scots-Irish community in the Waxhaws, straddling the border between North and South Carolina. Jackson's father died in February 1767 at the age of 29, in a logging accident while clearing land, three weeks before his son Andrew was born. Jackson, his mother, and his brothers lived with Jackson's aunt and uncle in the Waxhaws region, and Jackson received schooling from two nearby priests.\n\nJackson's exact birthplace is unclear because of a lack of knowledge of his mother's actions immediately following her husband's funeral. The area was so remote that the border between North and South Carolina had not been officially surveyed. In 1824, Jackson wrote a letter saying he had been born on the plantation of his uncle James Crawford in Lancaster County, South Carolina. Jackson may have claimed to be a South Carolinian because the state was considering nullification of the Tariff of 1824, which he opposed. In the mid-1850s, second-hand evidence indicated that he might have been born at a different uncle's home in North Carolina. As a young boy, Jackson was easily offended and was considered something of a bully. He was, however, also said to have taken a group of younger and weaker boys under his wing and been kind to them.\n\nRevolutionary War service\n \nDuring the Revolutionary War, Jackson's eldest brother, Hugh, died from heat exhaustion after the Battle of Stono Ferry on June 20, 1779. Anti-British sentiment intensified following the Waxhaws Massacre on May 29, 1780. Jackson's mother encouraged him and his elder brother Robert to attend the local militia drills. Soon, they began to help the militia as couriers. They served under Colonel William Richardson Davie at the Battle of Hanging Rock on August 6. Andrew and Robert were captured by the British in April 1781 while staying at the home of the Crawford family. When Andrew refused to clean the boots of a British officer, the officer slashed at the youth with a sword, leaving him with scars on his left hand and head, as well as an intense hatred for the British. Robert also refused to do as commanded and was struck with the sword. The two brothers were held as prisoners, contracted smallpox, and nearly starved to death in captivity.\n\nLater that year, their mother Elizabeth secured the brothers' release. She then began to walk both boys back to their home in the Waxhaws, a distance of some 40 miles (64\u00a0km). Both were in very poor health. Robert, who was far worse, rode on the only horse they had, while Andrew walked behind them. In the final two hours of the journey, a torrential downpour began which worsened the effects of the smallpox. Within two days of arriving back home, Robert was dead and Andrew in mortal danger. After nursing Andrew back to health, Elizabeth volunteered to nurse American prisoners of war on board two British ships in the Charleston harbor, where there had been an outbreak of cholera. In November, she died from the disease and was buried in an unmarked grave. Andrew became an orphan at age 14. He blamed the British personally for the loss of his brothers and mother.\n\nEarly career\n\nLegal career and marriage\nAfter the Revolutionary War, Jackson received a sporadic education in a local Waxhaw school. On bad terms with much of his extended family, he boarded with several different people. In 1781, he worked for a time as a saddle-maker, and eventually taught school. He apparently prospered in neither profession. In 1784, he left the Waxhaws region for Salisbury, North Carolina, where he studied law under attorney Spruce Macay. With the help of various lawyers, he was able to learn enough to qualify for the bar. In September 1787, Jackson was admitted to the North Carolina bar. Shortly thereafter, his friend John McNairy helped him get appointed to a vacant prosecutor position in the Western District of North Carolina, which would later become the state of Tennessee. During his travel west, Jackson bought his first slave, a woman who was older than him. In 1788, having been offended by fellow lawyer Waightstill Avery, Jackson fought his first duel. The duel ended with both men firing into the air, having made a secret agreement to do so before the engagement.\n\nJackson moved to the small frontier town of Nashville in 1788, where he lived as a boarder with Rachel Stockly Donelson, the widow of John Donelson. Here Jackson became acquainted with their daughter, Rachel Donelson Robards. The younger Rachel was in an unhappy marriage with Captain Lewis Robards; he was subject to fits of jealous rage. The two were separated in 1790. According to Jackson, he married Rachel after hearing that Robards had obtained a divorce. Her divorce had not been made final, making Rachel's marriage to Jackson bigamous and therefore invalid. After the divorce was officially completed, Rachel and Jackson remarried in 1794. To complicate matters further, evidence shows that Rachel had been living with Jackson and referred to herself as Mrs. Jackson before the petition for divorce was ever made. It was not uncommon on the frontier for relationships to be formed and dissolved unofficially, as long as they were recognized by the community.\n\nLand speculation and early public career\nIn 1794, Jackson formed a partnership with fellow lawyer John Overton, dealing in claims for land reserved by treaty for the Cherokee and Chickasaw. Like many of their contemporaries, they dealt in such claims although the land was in Indian territory. Most of the transactions involved grants made under a 'land grab' act of 1783 that briefly opened Indian lands west of the Appalachians within North Carolina to claim by that state's residents. He was one of the three original investors who founded Memphis, Tennessee, in 1819.\n\nAfter moving to Nashville, Jackson became a protege of William Blount, a friend of the Donelsons and one of the most powerful men in the territory. Jackson became attorney general in 1791, and he won election as a delegate to the Tennessee constitutional convention in 1796. When Tennessee achieved statehood that year, he was elected its only U.S. Representative. He was a member of the Democratic-Republican Party, the dominant party in Tennessee. As a representative, Jackson staunchly advocated for the rights of Tennesseans against Native American tribal interests. He strongly opposed the Jay Treaty and criticized George Washington for allegedly removing Democratic-Republicans from public office. Jackson joined several other Democratic-Republican congressmen in voting against a resolution of thanks for Washington, a vote that would later haunt him when he sought the presidency. In 1797, the state legislature elected him as U.S. senator. Jackson seldom participated in debate and found the job dissatisfying. He pronounced himself \"disgusted with the administration\" of President John Adams and resigned the following year without explanation. Upon returning home, with strong support from western Tennessee, he was elected to serve as a judge of the Tennessee Supreme Court at an annual salary of $600. Jackson's service as a judge is generally viewed as a success and earned him a reputation for honesty and good decision-making. Jackson resigned the judgeship in 1804. His official reason for resigning was ill health. He had been suffering financially from poor land ventures, and so it is also possible that he wanted to return full-time to his business interests.\n\nAfter arriving in Tennessee, Jackson won the appointment of judge advocate of the Tennessee militia. In 1802, while serving on the Tennessee Supreme Court, he declared his candidacy for major general, or commander, of the Tennessee militia, a position voted on by the officers. At that time, most free men were members of the militia. The organizations, intended to be called up in case of armed conflicts, resembled large social clubs. Jackson saw it as a way to advance his stature. With strong support from western Tennessee, he tied with John Sevier with seventeen votes. Sevier was a popular Revolutionary War veteran and former governor, the recognized leader of politics in eastern Tennessee. On February 5, Governor Archibald Roane broke the tie in Jackson's favor. Jackson had also presented Roane with evidence of land fraud against Sevier. Subsequently, in 1803, when Sevier announced his intention to regain the governorship, Roane released the evidence. Jackson then published a newspaper article accusing Sevier of fraud and bribery. Sevier insulted Jackson in public, and the two nearly fought a duel over the matter. Despite the charges leveled against Sevier, he defeated Roane and continued to serve as governor until 1809.\n\nPlanting career and controversy\n\nIn addition to his legal and political career, Jackson prospered as a planter and merchant. He built a home and the first general store in Gallatin, Tennessee, in 1803. The next year, he acquired The Hermitage, a  plantation in Davidson County, near Nashville. He later added  to the plantation, which eventually totaled. The primary crop was cotton. Like most successful American planters at the time, Jackson's plantation depended on slave labor. The cotton cultivated at the Hermitage was planted and picked by slaves. The Hermitage was quite profitable; Jackson began with nine slaves, owned as many as 44 by 1820, and later up to 150, placing him among the planter elite. Jackson also co-owned with his son Andrew Jackson Jr. the Halcyon plantation in Coahoma County, Mississippi, which housed 51 slaves at the time of his death. Throughout his lifetime, Jackson may have owned as many as 500 slaves.\n\nMen, women, and child slaves were owned by Jackson on three sections of the Hermitage plantation. Slaves lived in extended family units of between five and ten persons and were quartered in  cabins made either of brick or logs. The size and quality of the Hermitage slave quarters exceeded the standards of the time. To help slaves acquire food, Jackson supplied them with guns, knives, and fishing equipment. At times he paid his slaves with money and coins to trade in local markets. Jackson permitted slaves to be whipped to increase productivity or if he believed his slaves' offenses were severe enough. At various times he posted advertisements for fugitive slaves who had escaped from his plantation. In one advertisement placed in the Tennessee Gazette in October 1804, Jackson offered \"ten dollars extra, for every hundred lashes any person will give him, to the amount of three hundred.\"\n\nThe controversy surrounding his marriage to Rachel remained a sore point for Jackson, who deeply resented attacks on his wife's honor. By May 1806, Charles Dickinson, who, like Jackson, raced horses, had published an attack on Jackson in the local newspaper, and it resulted in a written challenge from Jackson to a duel. Since Dickinson was considered an expert shot, Jackson determined it would be best to let Dickinson turn and fire first, hoping that his aim might be spoiled in his quickness; Jackson would wait and take careful aim at Dickinson. Dickinson did fire first, hitting Jackson in the chest. The bullet that struck Jackson was so close to his heart that it could not be removed. Under the rules of dueling, Dickinson had to remain still as Jackson took aim and shot and killed him. Jackson's behavior in the duel outraged many in Tennessee, who called it a brutal, cold-blooded killing and saddled Jackson with a reputation as a violent, vengeful man. He became a social outcast.\n\nAfter the Sevier affair and the duel, Jackson was looking for a way to salvage his reputation. He chose to align himself with former vice president Aaron Burr. Burr's political career ended after the killing of Alexander Hamilton in a duel in 1804; in 1805 he set out on a tour of what was then the western United States. Burr was extremely well received by the people of Tennessee, and stayed for five days at the Hermit flight's destination at dawn when an airline complained thatage. Burr's true intentions are not known with certainty. He seems to have been planning a military operation to conquer Spanish Florida and drive the Spanish from Texas. To many westerners like Jackson, the promise seemed enticing. Western American settlers had long held bitter feelings towards Spain due to territorial disputes and their persistent failure to stop Indians living in Spanish territory from raiding American settlements. On October 4, 1806, Jackson addressed the Tennessee militia, declaring that the men should be \"at a moment's warning ready to march.\" On the same day, he wrote to James Winchester, proclaiming that the United States \"can conquer not only the Floridas [at that time there was an East Florida and a West Florida.], but all Spanish North America.\" He continued:\n\nJackson agreed to provide boats and other provisions for the expedition. However, on November 10, he learned from a military captain that Burr's plans apparently included seizure of New Orleans, then part of the Louisiana Territory of the United States, and incorporating it, along with lands won from the Spanish, into a new empire. He was further outraged when he learned from the same man of the involvement of Brigadier General James Wilkinson, whom he deeply disliked, in the plan. Jackson acted cautiously at first, but wrote letters to public officials, including President Thomas Jefferson, vaguely warning them about the scheme. In December, Jefferson, a political opponent of Burr, issued a proclamation declaring that a treasonous plot was underway in the West and calling for the arrest of the perpetrators. Jackson, safe from arrest because of his extensive paper trail, organized the militia. Burr was soon captured, and the men were sent home. Jackson traveled to Richmond, Virginia, to testify on Burr's behalf in trial. The defense team decided against placing him on the witness stand, fearing his remarks were too provocative. Burr was acquitted of treason, despite Jefferson's efforts to have him convicted. Jackson endorsed James Monroe for president in 1808 against James Madison. The latter was part of the Jeffersonian wing of the Democratic-Republican Party. Jackson lived relatively quietly at the Hermitage in the years after the Burr trial, eventually accumulating 640 acres of land.\n\nMilitary career\n\nWar of 1812\n\nCreek campaign and treaty\n\nLeading up to 1812, the United States found itself increasingly drawn into international conflict. Formal hostilities with Spain or France never materialized, but tensions with Britain increased for a number of reasons. Among these was the desire of many Americans for more land, particularly British Canada and Florida, the latter still controlled by Spain, Britain's European ally. On June 18, 1812, Congress officially declared war on the United Kingdom of Great Britain and Ireland, beginning the War of 1812. Jackson responded enthusiastically, sending a letter to Washington offering 2,500 volunteers. However, the men were not called up for many months. Biographer Robert V. Remini claims that Jackson saw the apparent slight as payback by the Madison administration for his support of Burr and Monroe. Meanwhile, the United States military repeatedly suffered devastating defeats on the battlefield.\n\nOn January 10, 1813, Jackson led an army of 2,071 volunteers to New Orleans to defend the region against British and Native American attacks. He had been instructed to serve under General Wilkinson, who commanded Federal forces in New Orleans. Lacking adequate provisions, Wilkinson ordered Jackson to halt in Natchez, then part of the Mississippi Territory, and await further orders. Jackson reluctantly obeyed. The newly appointed Secretary of War, John Armstrong Jr., sent a letter to Jackson dated February 6 ordering him to dismiss his forces and to turn over his supplies to Wilkinson. In reply to Armstrong on March 15, Jackson defended the character and readiness of his men, and promised to turn over his supplies. He also promised, instead of dismissing the troops without provisions in Natchez, to march them back to Nashville. The march was filled with agony. Many of the men had fallen ill. Jackson and his officers turned over their horses to the sick. He paid for provisions for the men out of his own pocket. The soldiers began referring to their commander as \"Hickory,\" after a hickory nut, because of his toughness, and Jackson became known as \"Old Hickory\". After about a month long march, the army finally arrived in Nashville. His actions earned him respect and praise from the people of Tennessee. Jackson faced financial ruin, until his former aide-de-camp Thomas Benton persuaded Armstrong to order the army to pay the expenses Jackson had incurred. On June 14, Jackson served as a second in a duel on behalf of his junior officer William Carroll against Jesse Benton, the brother of Thomas. On September 3, Jackson and his top cavalry officer, Brigadier General John Coffee, were involved in a street brawl with the Benton brothers. Jackson was severely wounded by Jesse with a gunshot to the shoulder.\n\n On August 30, 1813, a group of Muscogee (or Creek) called the Red Sticks, so named for the color of their war paint, perpetrated the Fort Mims massacre in which hundreds of white American settlers and non-Red Stick Creeks were slaughtered. The Red Sticks, led by William Weatherford (also called Red Eagle) and Peter McQueen, had broken away from the rest of the Creek Confederacy, which wanted peace with the United States. They were allied with Tecumseh, a Shawnee chief who had launched Tecumseh's War against the United States, and who was fighting alongside the British. The resulting conflict became known as the Creek War.\n\nJackson, with 2,500 American soldiers, was ordered to crush the Red Sticks. On October 10, he set out on the expedition, his arm still in a sling from fighting the Bentons. Jackson established Fort Strother as a supply base. On November 3, Coffee defeated a band of Red Sticks at the Battle of Tallushatchee. Coming to the relief of friendly Creeks besieged by Red Sticks, Jackson won another decisive victory at the Battle of Talladega. In the winter, Jackson, encamped at Fort Strother, faced a severe shortage of troops due to the expiration of enlistments and chronic desertions. He sent Coffee with the cavalry (which abandoned him) back to Tennessee to secure more enlistments. Jackson decided to combine his force with that of the Georgia militia, and marched to meet the Georgia troops. From January 22\u201324, 1814, while on their way, the Tennessee militia and allied Muscogee were attacked by the Red Sticks at the Battles of Emuckfaw and Enotachopo Creek. Jackson's troops repelled the attackers, but outnumbered, were forced to withdraw to Fort Strother. Jackson, now with over 2,000 troops, marched most of his army south to confront the Red Sticks at a fortress they had constructed at a bend in the Tallapoosa River. Jackson, together with Lower Creek and Cherokee allies and enjoying an advantage of more than 2\u00a0to 1, engaged them on March 27 at the Battle of Horseshoe Bend. An initial artillery barrage did little damage to the well-constructed fort. A subsequent Infantry charge, in addition to an assault by Coffee's cavalry and diversions caused by the allied Creeks, overwhelmed the Red Sticks.\n\nThe campaign ended three weeks later with Red Eagle's surrender, although some Red Sticks such as McQueen fled to East Florida. On June 8, Jackson accepted a commission as brigadier general", "flag": 1, "segments": [[3468, 3478]], "strength": 5.5}
{"text": "Andrew Johnson (December 29, 1808July 31, 1875) was the 17th president of the United States, serving from 1865 to 1869. He assumed the presidency as he was vice president at the time of the assassination of Abraham Lincoln. Johnson was a Democrat who ran with Lincoln on the National Union ticket, coming to office as the Civil War concluded. He favored quick restoration of the seceded states to the Union without protection for the former slaves. This led to conflict with the Republican-dominated Congress, culminating in his impeachment by the House of Representatives in 1868. He was acquitted in the Senate by one vote.\n\nJohnson was born into poverty and never attended school. He was apprenticed as a tailor and worked in several frontier towns before settling in Greeneville, Tennessee. He served as alderman and mayor there before being elected to the Tennessee House of Representatives in 1835. After briefly serving in the Tennessee Senate, Johnson was elected to the House of Representatives in 1843, where he served five two-year terms. He became governor of Tennessee for four years, and was elected by the legislature to the Senate in 1857. In his congressional service, he sought passage of the Homestead Bill which was enacted soon after he left his Senate seat in 1862. Southern slave states seceded to form the Confederate States of America, including Tennessee, but Johnson remained firmly with the Union. He was the only sitting senator from a Confederate state who did not resign his seat upon learning of his state's secession. In 1862, Lincoln appointed him as Military Governor of Tennessee after most of it had been retaken. In 1864, Johnson was a logical choice as running mate for Lincoln, who wished to send a message of national unity in his re-election campaign; and became vice president after a victorious election in 1864.\n\nJohnson implemented his own form of Presidential Reconstruction, a series of proclamations directing the seceded states to hold conventions and elections to reform their civil governments. Southern states returned many of their old leaders and passed Black Codes to deprive the freedmen of many civil liberties, but Congressional Republicans refused to seat legislators from those states and advanced legislation to overrule the Southern actions. Johnson vetoed their bills, and Congressional Republicans overrode him, setting a pattern for the remainder of his presidency. Johnson opposed the Fourteenth Amendment which gave citizenship to former slaves. In 1866, he went on an unprecedented national tour promoting his executive policies, seeking to break Republican opposition. As the conflict grew between the branches of government, Congress passed the Tenure of Office Act restricting Johnson's ability to fire Cabinet officials. He persisted in trying to dismiss Secretary of War Edwin Stanton, but ended up being impeached by the House of Representatives and narrowly avoided conviction in the Senate. He did not win the 1868 Democratic presidential nomination and left office the following year.\n\nJohnson returned to Tennessee after his presidency and gained some vindication when he was elected to the Senate in 1875, making him the only former president to serve in the Senate. He died five months into his term. Johnson's strong opposition to federally guaranteed rights for black Americans is widely criticized; he is regarded by many historians as one of the worst presidents in American history.\n\nEarly life and career\n\nChildhood \n\nAndrew Johnson was born in Raleigh, North Carolina, on December 29, 1808, to Jacob Johnson (1778\u20131812) and Mary (\"Polly\") McDonough (1783\u20131856), a laundress. He was of English, Scots-Irish, and Irish ancestry. He had a brother William, four years his senior, and an older sister Elizabeth, who died in childhood. Johnson's birth in a two-room shack was a political asset in the mid-19th century, and he would frequently remind voters of his humble origins. Jacob Johnson was a poor man, as had been his father, William Johnson, but he became town constable of Raleigh before marrying and starting a family. Both Jacob and Mary were illiterate, and had worked as tavern servants, while Johnson never attended school and grew up in poverty. Jacob died of an apparent heart attack while ringing the town bell, shortly after rescuing three drowning men, when his son Andrew was three. Polly Johnson worked as a washerwoman and became the sole support of her family. Her occupation was then looked down on, as it often took her into other homes unaccompanied. Since Andrew did not resemble either of his siblings, there are rumors that he may have been fathered by another man. Polly Johnson eventually remarried to a man named Turner Doughtry, who was as poor as she was.\n\nJohnson's mother apprenticed her son William to a tailor, James Selby. Andrew also became an apprentice in Selby's shop at age ten and was legally bound to serve until his 21st birthday. Johnson lived with his mother for part of his service, and one of Selby's employees taught him rudimentary literacy skills. His education was augmented by citizens who would come to Selby's shop to read to the tailors as they worked. Even before he became an apprentice, Johnson came to listen. The readings caused a lifelong love of learning, and one of his biographers, Annette Gordon-Reed, suggests that Johnson, later a gifted public speaker, learned the art as he threaded needles and cut cloth.\n\nJohnson was not happy at James Selby's, and after about five years, both he and his brother ran away. Selby responded by placing a reward for their return: \"Ten Dollars Reward. Ran away from the subscriber, two apprentice boys, legally bound, named William and Andrew Johnson\u00a0... [payment] to any person who will deliver said apprentices to me in Raleigh, or I will give the above reward for Andrew Johnson alone.\" The brothers went to Carthage, North Carolina, where Andrew Johnson worked as a tailor for several months. Fearing he would be arrested and returned to Raleigh, Johnson moved to Laurens, South Carolina. He found work quickly, met his first love, Mary Wood, and made her a quilt as a gift. However, she rejected his marriage proposal. He returned to Raleigh, hoping to buy out his apprenticeship, but could not come to terms with Selby. Unable to stay in Raleigh, where he risked being apprehended for abandoning Selby, he decided to move west.\n\nMove to Tennessee \n\nJohnson left North Carolina for Tennessee, traveling mostly on foot. After a brief period in Knoxville, he moved to Mooresville, Alabama. He then worked as a tailor in Columbia, Tennessee, but was called back to Raleigh by his mother and stepfather, who saw limited opportunities there and who wished to emigrate west. Johnson and his party traveled through the Blue Ridge Mountains to Greeneville, Tennessee. Andrew Johnson fell in love with the town at first sight, and when he became prosperous purchased the land where he had first camped and planted a tree in commemoration.\n\nIn Greeneville, Johnson established a successful tailoring business in the front of his home. In 1827, at the age of 18, he married 16-year-old Eliza McCardle, the daughter of a local shoemaker. The pair were married by Justice of the Peace Mordecai Lincoln, first cousin of Thomas Lincoln, whose son would become president. The Johnsons were married for almost 50 years and had five children: Martha (1828), Charles (1830), Mary (1832), Robert (1834), and Andrew Jr. (1852). Though she suffered from tuberculosis, Eliza supported her husband's endeavors. She taught him mathematics skills and tutored him to improve his writing. Shy and retiring by nature, Eliza Johnson usually remained in Greeneville during Johnson's political rise. She was not often seen during her husband's presidency; their daughter Martha usually served as official hostess.\n\nJohnson's tailoring business prospered during the early years of the marriage, enabling him to hire help and giving him the funds to invest profitably in real estate. He later boasted of his talents as a tailor, \"my work never ripped or gave way\". He was a voracious reader. Books about famous orators aroused his interest in political dialogue, and he had private debates on the issues of the day with customers who held opposing views. He also took part in debates at Greeneville College.\n\nJohnson's slaves \nIn 1843, Johnson purchased his first slave, Dolly, who was 14 years old at the time. Soon after, he purchased Dolly's half-brother Sam. Dolly had three children\u2014Liz, Florence and William. In 1857, Andrew Johnson purchased Henry, who was 13 at the time and would later accompany the Johnson family to the White House. Sam Johnson and his wife Margaret had nine children. Sam became a commissioner of the Freedmen's Bureau and was known for being a proud man who negotiated the nature of his work with the Johnson family. Notably, he received some monetary compensation for his labors and negotiated with Andrew Johnson to receive a tract of land which Andrew Johnson gave him for free in 1867. Ultimately, Johnson owned at least ten slaves.\n\nAndrew Johnson freed his slaves on August 8, 1863; they remained with him as paid servants. A year later, Johnson, as military governor of Tennessee, proclaimed the freedom of Tennessee's slaves. Sam and Margaret, Johnson's former slaves, lived in his tailor shop while he was president, without rent. As a sign of appreciation for proclaiming freedom, Andrew Johnson was given a watch by newly emancipated people in Tennessee inscribed with \"\u2026for his Untiring Energy in the Cause of Freedom\".\n\nPolitical rise\n\nTennessee politician \nJohnson helped organize a mechanics' (working men's) ticket in the 1829 Greeneville municipal election. He was elected town alderman, along with his friends Blackston McDannel and Mordecai Lincoln. Following the 1831 Nat Turner slave rebellion, a state convention was called to pass a new constitution, including provisions to disenfranchise free people of color. The convention also wanted to reform real estate tax rates, and provide ways of funding improvements to Tennessee's infrastructure. The constitution was submitted for a public vote, and Johnson spoke widely for its adoption; the successful campaign provided him with statewide exposure. On January 4, 1834, his fellow aldermen elected him mayor of Greeneville.\n\nIn 1835, Johnson made a bid for election to the \"floater\" seat which Greene County shared with neighboring Washington County in the Tennessee House of Representatives. According to his biographer, Hans L. Trefousse, Johnson \"demolished\" the opposition in debate and won the election with almost a two to one margin. During his Greeneville days, Johnson joined the Tennessee Militia as a member of the 90th Regiment. He attained the rank of colonel, though while an enrolled member, Johnson was fined for an unknown offense. Afterwards, he was often addressed or referred to by his rank.\n\nIn his first term in the legislature, which met in the state capital of Nashville, Johnson did not consistently vote with either the Democratic or the newly formed Whig Party, though he revered President Andrew Jackson, a Democrat and fellow Tennessean. The major parties were still determining their core values and policy proposals, with the party system in a state of flux. The Whig Party had organized in opposition to Jackson, fearing the concentration of power in the Executive Branch of the government; Johnson differed from the Whigs as he opposed more than minimal government spending and spoke against aid for the railroads, while his constituents hoped for improvements in transportation. After Brookins Campbell and the Whigs defeated Johnson for reelection in 1837, Johnson would not lose another race for thirty years. In 1839, he sought to regain his seat, initially as a Whig, but when another candidate sought the Whig nomination, he ran as a Democrat and was elected. From that time he supported the Democratic party and built a powerful political machine in Greene County. Johnson became a strong advocate of the Democratic Party, noted for his oratory, and in an era when public speaking both informed the public and entertained it, people flocked to hear him.\n\nIn 1840, Johnson was selected as a presidential elector for Tennessee, giving him more statewide publicity. Although Democratic President Martin Van Buren was defeated by former Ohio senator William Henry Harrison, Johnson was instrumental in keeping Tennessee and Greene County in the Democratic column. He was elected to the Tennessee Senate in 1841, where he served a two-year term. He had achieved financial success in his tailoring business, but sold it to concentrate on politics. He had also acquired additional real estate, including a larger home and a farm (where his mother and stepfather took residence), and among his assets numbered eight or nine slaves.\n\nUnited States Representative (1843\u20131853) \n\nHaving served in both houses of the state legislature, Johnson saw election to Congress as the next step in his political career. He engaged in a number of political maneuvers to gain Democratic support, including the displacement of the Whig postmaster in Greeneville, and defeated Jonesborough lawyer John A. Aiken by 5,495 votes to 4,892. In Washington, he joined a new Democratic majority in the House of Representatives. Johnson advocated for the interests of the poor, maintained an anti-abolitionist stance, argued for only limited spending by the government and opposed protective tariffs. With Eliza remaining in Greeneville, Congressman Johnson shunned social functions in favor of study in the Library of Congress. Although a fellow Tennessee Democrat, James K. Polk, was elected president in 1844, and Johnson had campaigned for him, the two men had difficult relations, and President Polk refused some of his patronage suggestions.\n\nJohnson believed, as did many Southern Democrats, that the Constitution protected private property, including slaves, and thus prohibited the federal and state governments from abolishing slavery. He won a second term in 1845 against William G. Brownlow, presenting himself as the defender of the poor against the aristocracy. In his second term, Johnson supported the Polk administration's decision to fight the Mexican War, seen by some Northerners as an attempt to gain territory to expand slavery westward, and opposed the Wilmot Proviso, a proposal to ban slavery in any territory gained from Mexico. He introduced for the first time his Homestead Bill, to grant  to people willing to settle the land and gain title to it. This issue was especially important to Johnson because of his own humble beginnings.\n\nIn the presidential election of 1848, the Democrats split over the slavery issue, and abolitionists formed the Free Soil Party, with former president Van Buren as their nominee. Johnson supported the Democratic candidate, former Michigan senator Lewis Cass. With the party split, Whig nominee General Zachary Taylor was easily victorious, and carried Tennessee. Johnson's relations with Polk remained poor; the President recorded of his final New Year's reception in 1849 that\n\nJohnson, due to national interest in new railroad construction and in response to the need for better transportation in his own district, also supported government assistance for the East Tennessee and Virginia Railroad.\n\nIn his campaign for a fourth term, Johnson concentrated on three issues: slavery, homesteads and judicial elections. He defeated his opponent, Nathaniel G. Taylor, in August 1849, with a greater margin of victory than in previous campaigns. When the House convened in December, the party division caused by the Free Soil Party precluded the formation of the majority needed to elect a Speaker. Johnson proposed adoption of a rule allowing election of a Speaker by a plurality; some weeks later others took up a similar proposal, and Democrat Howell Cobb was elected.\n\nOnce the Speaker election had concluded and Congress was ready to conduct legislative business, the issue of slavery took center stage. Northerners sought to admit California, a free state, to the Union. Kentucky's Henry Clay introduced in the Senate a series of resolutions, the Compromise of 1850, to admit California and pass legislation sought by each side. Johnson voted for all the provisions except for the abolition of slavery in the nation's capital. He pressed resolutions for constitutional amendments to provide for popular election of senators (then elected by state legislatures) and of the president (chosen by the Electoral College), and limiting the tenure of federal judges to 12 years. These were all defeated.\n\nA group of Democrats nominated Landon Carter Haynes to oppose Johnson as he sought a fifth term; the Whigs were so pleased with the internecine battle among the Democrats in the general election that they did not nominate a candidate of their own. The campaign included fierce debates: Johnson's main issue was the passage of the Homestead Bill; Haynes contended it would facilitate abolition. Johnson won the election by more than 1600 votes. Though he was not enamored of the party's presidential nominee in 1852, former New Hampshire senator Franklin Pierce, Johnson campaigned for him. Pierce was elected, but he failed to carry Tennessee. In 1852, Johnson managed to get the House to pass his Homestead Bill, but it failed in the Senate. The Whigs had gained control of the Tennessee legislature, and, under the leadership of Gustavus Henry, redrew the boundaries of Johnson's First District to make it a safe seat for their party. The Nashville Union termed this \"Henry-mandering\"; lamented Johnson, \"I have no political future.\"\n\nGovernor of Tennessee (1853\u20131857) \n\nIf Johnson considered retiring from politics upon deciding not to seek reelection, he soon changed his mind. His political friends began to maneuver to get him the nomination for governor. The Democratic convention unanimously named him, though some party members were not happy at his selection. The Whigs had won the past two gubernatorial elections, and still controlled the legislature. That party nominated Henry, making the \"Henry-mandering\" of the First District an immediate issue. The two men debated in county seats the length of Tennessee before the meetings were called off two weeks before the August 1853 election due to illness in Henry's family. Johnson won the election by 63,413 votes to 61,163; some votes for him were cast in return for his promise to support Whig Nathaniel Taylor for his old seat in Congress.\n\nTennessee's governor had little power: Johnson could propose legislation but not veto it, and most appointments were made by the Whig-controlled legislature. Nevertheless, the office was a \"bully pulpit\" that allowed him to publicize himself and his political views. He succeeded in getting the appointments he wanted in return for his endorsement of John Bell, a Whig, for one of the state's U.S. Senate seats. In his first biennial speech, Johnson urged simplification of the state judicial system, abolition of the Bank of Tennessee, and establishment of an agency to provide uniformity in weights and measures; the last was passed. Johnson was critical of the Tennessee common school system and suggested funding be increased via taxes, either statewide or county by county\u2014a mixture of the two was passed. Reforms carried out during Johnson's time as governor included the foundation of the State's public library (making books available to all) and its first public school system, and the initiation of regular state fairs to benefit craftsmen and farmers.\n\nAlthough the Whig Party was on its final decline nationally, it remained strong in Tennessee, and the outlook for Democrats there in 1855 was poor. Feeling that reelection as governor was necessary to give him a chance at the higher offices he sought, Johnson agreed to make the run. Meredith P. Gentry received the Whig nomination. A series of more than a dozen vitriolic debates ensued. The issues in the campaign were slavery, the prohibition of alcohol, and the nativist positions of the Know Nothing Party. Johnson favored the first, but opposed the others. Gentry was more equivocal on the alcohol question, and had gained the support of the Know Nothings, a group Johnson portrayed as a secret society. Johnson was unexpectedly victorious, albeit with a narrower margin than in 1853.\n\nWhen the presidential election of 1856 approached, Johnson hoped to be nominated; some Tennessee county conventions designated him a \"favorite son\". His position that the best interests of the Union were served by slavery in some areas made him a practical compromise candidate for president. He was never a major contender; the nomination fell to former Pennsylvania senator James Buchanan. Though he was not impressed by either, Johnson campaigned for Buchanan and his running mate, John C. Breckinridge, who were elected.\n\nJohnson decided not to seek a third term as governor, with an eye towards election to the U.S. Senate. In 1857, while returning from Washington, his train derailed, causing serious damage to his right arm. This injury would trouble him in the years to come.\n\nUnited States Senator\n\nHomestead Bill advocate \n\nThe victors in the 1857 state legislative campaign would, once they convened in October, elect a United States Senator. Former Whig governor William B. Campbell wrote to his uncle, \"The great anxiety of the Whigs is to elect a majority in the legislature so as to defeat Andrew Johnson for senator. Should the Democrats have the majority, he will certainly be their choice, and there is no man living to whom the Americans and Whigs have as much antipathy as Johnson.\" The governor spoke widely in the campaign, and his party won the gubernatorial race and control of the legislature. Johnson's final address as governor gave him the chance to influence his electors, and he made proposals popular among Democrats. Two days later the legislature elected him to the Senate. The opposition was appalled, with the Richmond Whig newspaper referring to him as \"the vilest radical and most unscrupulous demagogue in the Union\".\n\nJohnson gained high office due to his proven record as a man popular among the small farmers and self-employed tradesmen who made up much of Tennessee's electorate. He called them the \"plebeians\"; he was less popular among the planters and lawyers who led the Senate confirmed Justice Anthony Kennedy last week. Not exactly state Democratic Party, but none could match him as a vote-getter. After his death, one Tennessee voter wrote of him, \"Johnson was always the same to everyone\u00a0... the honors heaped upon him did not make him forget to be kind to the humblest citizen.\" Always seen in impeccably tailored clothing, he cut an impressive figure, and had the stamina to endure lengthy campaigns with daily travel over bad roads leading to another speech or debate. Mostly denied the party's machinery, he relied on a network of friends, advisers, and contacts. One friend, Hugh Douglas, stated in a letter to him, \"you have been in the way of our would be great men for a long time. At heart many of us never wanted you to be Governor only none of the rest of us Could have been elected at the time and we only wanted to use you. Then we did not want you to go to the Senate but the people would send you.\"\n\nThe new senator took his seat when Congress convened in December 1857 (the term of his predecessor, James C. Jones, had expired in March). He came to Washington as usual without his wife and family; Eliza would visit Washington only once during Johnson's first time as senator, in 1860. Johnson immediately set about introducing the Homestead Bill in the Senate, but as most senators who supported it were Northern (many associated with the newly founded Republican Party), the matter became caught up in suspicions over the slavery issue. Southern senators felt that those who took advantage of the provisions of the Homestead Bill were more likely to be Northern non-slaveholders. The issue of slavery had been complicated by the Supreme Court's ruling earlier in the year in Dred Scott v. Sandford that slavery could not be prohibited in the territories. Johnson, a slaveholding senator from a Southern state, made a major speech in the Senate the following May in an attempt to convince his colleagues that the Homestead Bill and slavery were not incompatible. Nevertheless, Southern opposition was key to defeating the legislation, 30\u201322. In 1859, it failed on a procedural vote when Vice President Breckinridge broke a tie against the bill, and in", "flag": 1, "segments": [[4557, 4567]], "strength": 5.5}
{"text": "Aleksandr Isayevich Solzhenitsyn (11 December 1918 \u2013 3 August 2008) was a Russian novelist, philosopher, historian, short story writer, and political prisoner. One of the most famous Soviet dissidents, Solzhenitsyn was an outspoken critic of communism and helped to raise global awareness of political repression in the Soviet Union (USSR), in particular the Gulag system.\n\nSolzhenitsyn was born into a family that defied the Soviet anti-religious campaign in the 1920s and remained devout members of the Russian Orthodox Church. While still young, Solzhenitsyn lost his faith in Christianity and became a firm believer in both atheism and Marxism\u2013Leninism; in his later life, he gradually became a philosophically minded Eastern Orthodox Christian as a result of his experience in prison and the camps. While serving as a captain in the Red Army during World War II, Solzhenitsyn was arrested by the SMERSH and sentenced to eight years in the Gulag and then internal exile for criticizing Soviet leader Joseph Stalin in a private letter.\n\nAs a result of the Khrushchev Thaw, Solzhenitsyn was released and exonerated. After he had returned to the Christian faith of his childhood, he pursued writing novels about repressions in the Soviet Union and his experiences. He published his first novel, One Day in the Life of Ivan Denisovich in 1962, with approval from Soviet leader Nikita Khrushchev, which was an account of Stalinist repressions. Solzhenitsyn's last work to be published in the Soviet Union was Matryona's Place in 1963. Following the removal of Khrushchev from power, the Soviet authorities attempted to discourage him from continuing to write. Solzhenitsyn continued to work on further novels and their publication in other countries including Cancer Ward in 1968, August 1914 in 1971, and The Gulag Archipelago in 1973, the publication of which outraged the Soviet authorities. In 1974 Solzhenitsyn lost his Soviet citizenship and was flown to West Germany. In 1976, he moved with his family to the United States, where he continued to write. In 1990, shortly before the dissolution of the Soviet Union, his citizenship was restored, and four years later he returned to Russia, where he remained until his death in 2008.\n\nHe was awarded the 1970 Nobel Prize in Literature \"for the ethical force with which he has pursued the indispensable traditions of Russian literature\", and The Gulag Archipelago was a highly influential work that \"amounted to a head-on challenge to the Soviet state\", and sold tens of millions of copies.\n\nBiography\n\nEarly years \n\nSolzhenitsyn was born in Kislovodsk (now in Stavropol Krai, Russia). His father was of Russian descent and his mother, Taisiya Zakharovna (n\u00e9e Shcherbak), was of Ukrainian descent. Her father had risen from humble beginnings to become a wealthy landowner, acquiring a large estate in the Kuban region in the northern foothills of the Caucasus. During World War I, Taisiya went to Moscow to study. While there she met and married Isaakiy Semyonovich Solzhenitsyn, a young officer in the Imperial Russian Army of Cossack origin and fellow native of the Caucasus region. The family background of his parents is vividly brought to life in the opening chapters of August 1914, and in the later Red Wheel novels.\n\nIn 1918, Taisiya became pregnant with Aleksandr.  On 15 June, shortly after her pregnancy was confirmed, Isaakiy was killed in a hunting accident.  Aleksandr was raised by his widowed mother and his aunt in lowly circumstances.  His earliest years coincided with the Russian Civil War. By 1930 the family property had been turned into a collective farm. Later, Solzhenitsyn recalled that his mother had fought for survival and that they had to keep his father's background in the old Imperial Army a secret.  His educated mother (who never remarried) encouraged his literary and scientific learnings and raised him in the Russian Orthodox faith; she died in 1944.\n\nAs early as 1936, Solzhenitsyn began developing the characters and concepts for a planned epic work on World War I and the Russian Revolution. This eventually led to the novel August 1914; some of the chapters he wrote then still survive. Solzhenitsyn studied mathematics and physics at Rostov State University. At the same time he took correspondence courses from the Moscow Institute of Philosophy, Literature and History, by this time heavily ideological in scope.  As he himself makes clear, he did not question the state ideology or the superiority of the Soviet Union until he spent time in the camps.\n\nWorld War II \n\nDuring the war, Solzhenitsyn served as the commander of a sound-ranging battery in the Red Army, was involved in major action at the front, and was twice decorated.  He was awarded the Order of the Red Star on 8 July 1944 for sound-ranging two German artillery batteries and adjusting counterbattery fire onto them, resulting in their destruction.\n\nA series of writings published late in his life, including the early uncompleted novel Love the Revolution!, chronicle his wartime experience and growing doubts about the moral foundations of the Soviet regime.\n\nWhile serving as an artillery officer in East Prussia, Solzhenitsyn witnessed war crimes against local German civilians by Soviet military personnel. Of the atrocities, Solzhenitsyn wrote: \"You know very well that we've come to Germany to take our revenge\" for Nazi atrocities committed in the Soviet Union. The noncombatants and the elderly were robbed of their meager possessions and women and girls were gang-raped. A few years later, in the forced labor camp, he memorized a poem titled \"Prussian Nights\" about a woman raped to death in East Prussia. In this poem, which describes the gang-rape of a Polish woman whom the Red Army soldiers mistakenly thought to be a German, the first-person narrator comments on the events with sarcasm and refers to the responsibility of official Soviet writers like Ilya Ehrenburg.\n\nIn The Gulag Archipelago, Solzhenitsyn wrote, \"There is nothing that so assists the awakening of omniscience within us as insistent thoughts about one's own transgressions, errors, mistakes. After the difficult cycles of such ponderings over many years, whenever I mentioned the heartlessness of our highest-ranking bureaucrats, the cruelty of our executioners, I remember myself in my Captain's shoulder boards and the forward march of my battery through East Prussia, enshrouded in fire, and I say: 'So were we any better?'\"\n\nImprisonment \n\nIn February 1945, while serving in East Prussia, Solzhenitsyn was arrested by SMERSH for writing derogatory comments in private letters to a friend, Nikolai Vitkevich, about the conduct of the war by Joseph Stalin, whom he called \"Khozyain\" (\"the boss\"), and \"Balabos\" (Yiddish rendering of Hebrew baal ha-bayit for \"master of the house\"). He also had talks with the same friend about the need for a new organization to replace the Soviet regime.\n\nHe was accused of anti-Soviet propaganda under Article 58 paragraph 10 of the Soviet criminal code, and of \"founding a hostile organization\" under paragraph 11. Solzhenitsyn was taken to the Lubyanka prison in Moscow, where he was interrogated. On 9 May 1945, it was announced that Germany had surrendered and all of Moscow broke out in celebrations with fireworks and searchlights illuminating the sky to celebrate the victory in the Great Patriotic War. From his cell in the Lubyanka, Solzhenitsyn remembered: \"Above the muzzle of our window, and from all the other cells of the Lubyanka, and from all the windows of the Moscow prisons, we too, former prisoners of war and former front-line soldiers, watched the Moscow heavens, patterned with fireworks and crisscrossed with beams of searchlights. There was no rejoicing in our cells and no hugs and no kisses for us. That victory was not ours.\" On 7 July 1945, he was sentenced in his absence by Special Council of the NKVD to an eight-year term in a labour camp.  This was the normal sentence for most crimes under Article 58 at the time.\n\nThe first part of Solzhenitsyn's sentence was served in several work camps; the \"middle phase\", as he later referred to it, was spent in a sharashka (a special scientific research facility run by Ministry of State Security), where he met Lev Kopelev, upon whom he based the character of Lev Rubin in his book The First Circle, published in a self-censored or \"distorted\" version in the West in 1968 (an English translation of the full version was eventually published by Harper Perennial in October 2009). In 1950, he was sent to a \"Special Camp\" for political prisoners.  During his imprisonment at the camp in the town of Ekibastuz in Kazakhstan, he worked as a miner, bricklayer, and foundry foreman. His experiences at Ekibastuz formed the basis for the book One Day in the Life of Ivan Denisovich.  One of his fellow political prisoners, Ion Moraru, remembers that Solzhenitsyn spent some of his time at Ekibastuz writing. While there Solzhenitsyn had a tumor removed. His cancer was not diagnosed at the time.\n\nIn March 1953, after his sentence ended, Solzhenitsyn was sent to internal exile for life at Birlik, a village in Baidibek District of South Kazakhstan. His undiagnosed cancer spread until, by the end of the year, he was close to death. In 1954, he was permitted to be treated in a hospital in Tashkent, where his tumor went into remission. His experiences there became the basis of his novel Cancer Ward and also found an echo in the short story \"The Right Hand.\" It was during this decade of imprisonment and exile that Solzhenitsyn developed the philosophical and religious positions of his later life, gradually becoming a philosophically minded Eastern Orthodox Christian as a result of his experience in prison and the camps. He repented for some of his actions as a Red Army captain, and in prison compared himself to the perpetrators of the Gulag. His transformation is described at some length in the fourth part of The Gulag Archipelago (\"The Soul and Barbed Wire\"). The narrative poem The Trail (written without benefit of pen or paper in prison and camps between 1947 and 1952) and the 28 poems composed in prison, forced-labour camp, and exile also provide crucial material for understanding Solzhenitsyn's intellectual and spiritual odyssey during this period. These \"early\" works, largely unknown in the West, were published for the first time in Russianest peppers that you can eat. However, you in 1999 and excerpted in English in 2006.\n\nMarriages and children \n\nOn 7 April 1940, while at the university, Solzhenitsyn married Natalia Alekseevna Reshetovskaya. They had just over a year of married life before he went into the army, then to the Gulag. They divorced in 1952, a year before his release, because wives of Gulag prisoners faced loss of work or residence permits. After the end of his internal exile, they remarried in 1957, divorcing a second time in 1972. Reshetovskaya wrote negatively of Solzhenitsyn in her memoirs, accusing him of having affairs, and said of the relationship that \"[Solzhenitsyn]'s despotism... would crush my independence and would not permit my personality to develop.\"\n\nIn 1973, Solzhenitsyn married his second wife, Natalia Dmitrievna Svetlova, a mathematician who had a son, Dmitri Turin, from a brief prior marriage. He and Svetlova (born 1939) had three sons: Yermolai (1970), Ignat (1972), and Stepan (1973). Dmitri Turin died on 18 March 1994, aged 32, at his home in New York City.\n\nAfter prison \n\nAfter Khrushchev's Secret Speech in 1956, Solzhenitsyn was freed from exile and exonerated. Following his return from exile, Solzhenitsyn was, while teaching at a secondary school during the day, spending his nights secretly engaged in writing. In his Nobel Prize acceptance speech he wrote that \"during all the years until 1961, not only was I convinced I should never see a single line of mine in print in my lifetime, but, also, I scarcely dared allow any of my close acquaintances to read anything I had written because I feared this would become known.\"\n\nIn 1960, aged 42, he approached Aleksandr Tvardovsky, a poet and the chief editor of the Novy Mir magazine, with the manuscript of One Day in the Life of Ivan Denisovich. It was published in edited form in 1962, with the explicit approval of Nikita Khrushchev, who defended it at the presidium of the Politburo hearing on whether to allow its publication, and added: \"There's a Stalinist in each of you; there's even a Stalinist in me. We must root out this evil.\" The book quickly sold out and became an instant hit. In the 1960s, while he was publicly known to be writing Cancer Ward, he was simultaneously writing The Gulag Archipelago. During Khrushchev's tenure, One Day in the Life of Ivan Denisovich was studied in schools in the Soviet Union, as were three more short works of Solzhenitsyn's, including his short story \"Matryona's Home\", published in 1963. These would be the last of his works published in the Soviet Union until 1990.\n\nOne Day in the Life of Ivan Denisovich brought the Soviet system of prison labour to the attention of the West.  It caused as much of a sensation in the Soviet Union as it did in the West\u2014not only by its striking realism and candor, but also because it was the first major piece of Soviet literature since the 1920s on a politically charged theme, written by a non-party member, indeed a man who had been to Siberia for \"libelous speech\" about the leaders, and yet its publication had been officially permitted. In this sense, the publication of Solzhenitsyn's story was an almost unheard of instance of free, unrestrained discussion of politics through literature. However, after Khrushchev had been ousted from power in 1964, the time for such raw exposing works came to an end.\n\nLater years in the Soviet Union \n\nSolzhenitsyn made an unsuccessful attempt, with the help of Tvardovsky, to have his novel Cancer Ward legally published in the Soviet Union. This required the approval of the Union of Writers. Though some there appreciated it, the work was ultimately denied publication unless it was to be revised and cleaned of suspect statements and anti-Soviet insinuations.\n\nAfter Khrushchev's removal in 1964, the cultural climate again became more repressive. Publishing of Solzhenitsyn's work quickly stopped; as a writer, he became a non-person, and, by 1965, the KGB had seized some of his papers, including the manuscript of The First Circle. Meanwhile, Solzhenitsyn continued to secretly and feverishly work on the most well-known of his writings, The Gulag Archipelago.  The seizing of his novel manuscript first made him desperate and frightened, but gradually he realized that it had set him free from the pretenses and trappings of being an \"officially acclaimed\" writer, a status which had become familiar but which was becoming increasingly irrelevant.\n\nAfter the KGB had confiscated Solzhenitsyn's materials in Moscow, during 1965\u201367, the preparatory drafts of The Gulag Archipelago were turned into finished typescript in hiding at his friends' homes in Soviet Estonia. Solzhenitsyn had befriended Arnold Susi, a lawyer and former Minister of Education of Estonia in a Lubyanka Building prison cell. After completion, Solzhenitsyn's original handwritten script was kept hidden from the KGB in Estonia by Arnold Susi's daughter Heli Susi until the collapse of the Soviet Union.\n\nIn 1969, Solzhenitsyn was expelled from the Union of Writers. In 1970, he was awarded the Nobel Prize in Literature. He could not receive the prize personally in Stockholm at that time, since he was afraid he would not be let back into the Soviet Union. Instead, it was suggested he should receive the prize in a special ceremony at the Swedish embassy in Moscow.  The Swedish government refused to accept this solution because such a ceremony and the ensuing media coverage might upset the Soviet Union and damage Swedish-Soviet relations. Instead, Solzhenitsyn received his prize at the 1974 ceremony after he had been expelled from the Soviet Union.\n\nThe Gulag Archipelago was composed from 1958 to 1967, and  has sold over thirty million copies in thirty-five languages. It was a three-volume, seven-part work on the Soviet prison camp system, which drew from Solzhenitsyn's experiences and the testimony of 256 former prisoners and Solzhenitsyn's own research into the history of the Russian penal system.  It discusses the system's origins from the founding of the Communist regime, with Vladimir Lenin having responsibility, detailing interrogation procedures, prisoner transports, prison camp culture, prisoner uprisings and revolts such as the Kengir uprising, and the practice of internal exile. Soviet and Communist studies historian and archival researcher Stephen G. Wheatcroft wrote that the book was essentially a \"literary and political work\", and \"never claimed to place the camps in a historical or social-scientific quantitative perspective\" but that in the case of qualitative estimates, Solzhenitsyn gave his high estimate as he wanted to challenge the Soviet authorities to show that \"the scale of the camps was less than this.\" Historian J. Arch Getty wrote of Solzhenitsyn's methodology that \"such documentation is methodically unacceptable in other fields of history\", which gives priority to vague hearsay and leads towards selective bias. According to journalist Anne Applebaum, who has made extensive research on the Gulag, The Gulag Archipelago'''s rich and varied authorial voice, its unique weaving together of personal testimony, philosophical analysis, and historical investigation, and its unrelenting indictment of Communist ideology made it one of the most influential books of the 20th century.\n\nOn 8 August 1971, the KGB allegedly attempted to assassinate Solzhenitsyn using an unknown chemical agent (most likely ricin) with an experimental gel-based delivery method. The attempt left him seriously ill but he survived.\n\nAlthough The Gulag Archipelago was not published in the Soviet Union, it was extensively criticized by the Party-controlled Soviet press. An editorial in Pravda on 14 January 1974 accused Solzhenitsyn of supporting \"Hitlerites\" and making \"excuses for the crimes of the Vlasovites and Bandera gangs.\" According to the editorial, Solzhenitsyn was \"choking with pathological hatred for the country where he was born and grew up, for the socialist system, and for Soviet people.\"\n\nDuring this period, he was sheltered by the cellist Mstislav Rostropovich, who suffered considerably for his support of Solzhenitsyn and was eventually forced into exile himself.\n\n Expulsion from the Soviet Union \n\nIn a discussion of its options in dealing with Solzhenitsyn the members of the Politburo considered his arrest and imprisonment and his expulsion to a capitalist country willing to take him. Guided by KGB chief Yury Andropov, and following a statement from West German Chancellor Willy Brandt that Solzhenitsyn could live and work freely in West Germany, it was decided to deport the writer directly to that country.\n\n In the West \n\nOn 12 February 1974, Solzhenitsyn was arrested and deported the next day from the Soviet Union to Frankfurt, West Germany and stripped of his Soviet citizenship. The KGB had found the manuscript for the first part of The Gulag Archipelago. U.S. military attach\u00e9 William Odom managed to smuggle out a large portion of Solzhenitsyn's archive, including the author's membership card for the Writers' Union and his Second World War military citations. Solzhenitsyn paid tribute to Odom's role in his memoir Invisible Allies (1995).\n\nIn West Germany, Solzhenitsyn lived in Heinrich B\u00f6ll's house in. He then moved to Z\u00fcrich, Switzerland before Stanford University invited him to stay in the United States to \"facilitate your work, and to accommodate you and your family\". He stayed at the Hoover Tower, part of the Hoover Institution, before moving to Cavendish, Vermont, in 1976. He was given an honorary literary degree from Harvard University in 1978 and on 8 June 1978 he gave a commencement address, condemning, among other things, the press, the lack of spirituality and traditional values, and the anthropocentrism of Western culture.\n\nOn 19 September 1974, Yuri Andropov approved a large-scale operation to discredit Solzhenitsyn and his family and cut his communications with Soviet dissidents. The plan was jointly approved by Vladimir Kryuchkov, Philipp Bobkov, and Grigorenko (heads of First, Second and Fifth KGB Directorates). The residencies in Geneva, London, Paris, Rome and other European cities participated in the operation. Among other active measures, at least three StB agents became translators and secretaries of Solzhenitsyn (one of them translated the poem Prussian Nights), keeping the KGB informed regarding all contacts by Solzhenitsyn.\n\nThe KGB also sponsored a series of hostile books about Solzhenitsyn, most notably a \"memoir published under the name of his first wife, Natalia Reshetovskaya, but probably mostly composed by Service\", according to historian Christopher Andrew. Andropov also gave an order to create \"an atmosphere of distrust and suspicion between Pauk and the people around him\" by feeding him rumors that the people around him were KGB agents, and deceiving him at every opportunity.  Among other things, he continually received envelopes with photographs of car crashes, brain surgery and other disturbing imagery. After the KGB harassment in Z\u00fcrich, Solzhenitsyn settled in Cavendish, Vermont, reduced communications with others.  His influence and moral authority for the West diminished as he became increasingly isolated and critical of Western individualism. KGB and CPSU experts finally concluded that he alienated American listeners by his \"reactionary views and intransigent criticism of the US way of life\", so no further active measures would be required.\n\nOver the next 17 years, Solzhenitsyn worked on his dramatized history of the Russian Revolution of 1917, The Red Wheel. By 1992, four sections had been completed and he had also written several shorter works.\n\nDespite spending almost two decades in the United States, Solzhenitsyn did not become fluent in spoken English. He had, however, been reading English-language literature since his teens, encouraged by his mother. More importantly, he resented the idea of becoming a media star and of tempering his ideas or ways of talking in order to suit television. Solzhenitsyn's warnings about the dangers of Communist aggression and the weakening of the moral fiber of the West were generally well received in Western conservative circles (e.g. Ford administration staffers Dick Cheney and Donald Rumsfeld advocated on Solzhenitsyn's behalf for him to speak directly to President Gerald Ford about the Soviet threat), prior to and alongside the tougher foreign policy pursued by US President Ronald Reagan. At the same time, liberals and secularists became increasingly critical of what they perceived as his reactionary preference for Russian nationalism and the Russian Orthodox religion.\n\nSolzhenitsyn also harshly criticised what he saw as the ugliness and spiritual vapidity of the dominant pop culture of the modern West, including television and much of popular music: \"...the human soul", "flag": 1, "segments": [[2260, 2270]], "strength": 5.5}
{"text": "Aberdeen (;  ;  ; ) is a city in North East Scotland. It is the third most populous city in Scotland, one of Scotland's 32 local government council areas (as Aberdeen City) and the United Kingdom's 39th most populous built-up area, with an official 2018 population estimate of  for the city of Aberdeen and  for the local council area.\n\nDuring the mid-18th to mid-20th centuries, Aberdeen's buildings incorporated locally quarried grey granite, which may sparkle like silver because of its high mica content. Since the discovery of North Sea oil in 1969, Aberdeen has been known as the offshore oil capital of Europe.\nThe area around Aberdeen has been settled for at least 8,000 years, when prehistoric villages lay around the mouths of the rivers Dee and Don. The city has a long, sandy coastline and a marine climate, the latter resulting in chilly summers and mild winters.\n\nAberdeen received Royal burgh status from David I of Scotland (1124\u20131153), transforming the city economically. The city has two universities, the University of Aberdeen, in Old Aberdeen, founded in 1495, and Robert Gordon University, in Garthdee, which was awarded university status in 1992, making Aberdeen the educational centre of north-east Scotland. The traditional industries of fishing, paper-making, shipbuilding, and textiles have been overtaken by the oil industry and Aberdeen's seaport. Aberdeen Heliport is one of the busiest commercial heliports in the world and the seaport is the largest in the north-east of Scotland.\n\nIn 2012, HSBC named Aberdeen as a leading business hub and one of eight'super cities' spearheading the UK's economy, marking it as the only city in Scotland so designated. In 2018, Aberdeen was found to be the best city in the UK to start a business in a study released by card payment firm Paymentsense.\n\nHistory\n\nThe Aberdeen area has seen human settlement for at least 8,000 years. The city began as two separate burghs: Old Aberdeen at the mouth of the river Don; and New Aberdeen, a fishing and trading settlement, where the Denburn waterway entered the river Dee estuary. The earliest charter was granted by William the Lion in 1179 and confirmed the corporate rights granted by David I.\n\nIn 1319, the Great Charter of Robert the Bruce transformed Aberdeen into a property-owning and financially independent community. Granted with it was the nearby Forest of Stocket, whose income formed the basis for the city's Common Good Fund which still benefits Aberdonians.\n\nDuring the Wars of Scottish Independence, Aberdeen was under English rule, so Robert the Bruce laid siege to Aberdeen Castle before destroying it in 1308, followed by executing the English garrison. The city was burned by Edward III used four knives and drove into an embankment of England in 1336, but was rebuilt and extended. The city was strongly fortified to prevent attacks by neighbouring lords, but the gates were removed by 1770.\n\nAberdeen's medieval council registers survive from 1398 onwards and are exceptional for their quantity and continuity among surviving Scottish burgh records. The earliest eight volumes, from 1398 to 1511, have been included in the UNESCO UK Memory of the World Register, and have been edited in a digital edition.\n\nDuring the Wars of the Three Kingdoms of 1644 to 1647 the city was plundered by both sides. In 1644, it was taken and ransacked by Royalist troops after the Battle of Aberdeen and two years later it was stormed by a Royalist force under the command of the Marquis of Huntly. In 1647 an outbreak of bubonic plague killed a quarter of the population. In the 18th century, a new Town Hall was built and the first social services appeared with the Infirmary at Woolmanhill in 1742 and the Lunatic Asylum in 1779. The council began major road improvements at the end of the 18th century with the main thoroughfares of George Street, King Street and Union Street all completed at the beginning of the 19th century.\n\nThe expensive infrastructure works led to the city becoming bankrupt in 1817 during the Post-Napoleonic depression, an economic downturn immediately after the Napoleonic Wars; but the city's prosperity later recovered. The increasing economic importance of Aberdeen and the development of the shipbuilding and fishing industries led to the construction of the present harbour including Victoria Dock and the South Breakwater, and the extension of the North Pier. Gas street lighting arrived in 1824 and an enhanced water supply appeared in 1830 when water was pumped from the Dee to a reservoir in Union Place. An underground sewer system replaced open sewers in 1865. The city was incorporated in 1891. Although Old Aberdeen has a separate history and still holds its ancient charter, it is no longer officially independent. It is an integral part of the city, as is Woodside and the Royal Burgh of Torry to the south of the River Dee.\n\nOver the course of the Second World War Aberdeen was attacked 32 times by the German Luftwaffe. One of the most devastating attacks was on Wednesday 21 April 1943 when 29 Luftwaffe Dornier 217s flying from Stavanger, Norway attacked the city between the hours of 22:17 and 23:04. A total of 98 civilians and 27 servicemen were killed, along with 9,668 houses damaged, after a mixture of 127 Incendiary, High Explosive and Cluster bombs were dropped on the city in one night. It was also the last German raid on a Scottish city during the war.\n\nToponymy\n\nThe name given to Aberdeen translates as'mouth of the river Don', and is recorded as Aberdon in 1172 and Aberden in c. 1180. The first element of the name is the Pictish word aber 'river mouth'. The second element is from the Celtic river goddess Devona.\n\nAberdeen is usually described as within the historical Pictish territory, and became Gaelic-speaking at some time in the medieval period. Old Aberdeen is the approximate location of Aberdon, the first settlement of Aberdeen; this literally means \"the mouth of the Don\". The Celtic word  means \"river mouth\", as in modern Welsh (Aberystwyth, Aberdare, Aberbeeg etc.). The Scottish Gaelic name is  (variation: ;  presumably being a loan from the earlier Pictish; the Gaelic term is ), and in Latin, the Romans referred to the river as. Medieval (or Ecclesiastical) Latin has it as.\n\nGovernance\n\nAberdeen is locally governed by Aberdeen City Council, which comprises forty-five councillors who represent the city's wards and is headed by the Lord Provost. The current Lord Provost is Barney Crockett. From May 2003 until May 2007 the council was run by a Liberal Democrat and Conservative Party coalition. Following the May 2007 local elections, the Liberal Democrats formed a new coalition with the Scottish National Party. After a later SNP by-election gain from the Conservatives, this coalition held 28 of the 43 seats. Following the election of 4 May 2017, the council was controlled by a coalition of Scottish Labour, Scottish Conservatives and independent councillors; the Labour councillors were subsequently suspended by Scottish Labour Party leader, Kezia Dugdale.\n\nAberdeen is represented in the Parliament of the United Kingdom by three constituencies: Aberdeen North and Aberdeen South which are wholly within the Aberdeen City council area, and Gordon, which includes a large area of the Aberdeenshire Council area.\n\nIn the Scottish Parliament, the city is represented by three constituencies with different boundaries: Aberdeen Central and Aberdeen Donside are wholly within the Aberdeen City council area. Aberdeen South and North Kincardine includes the North Kincardine ward of Aberdeenshire Council. A further seven MSPs are elected as part of the North East Scotland electoral region. In the European Parliament the city was represented by six MEPs as part of the all-inclusive Scotland constituency.\n\nHeraldry\n\nThe arms and banner of the city show three silver towers on red. This motif dates from at least the time of Robert the Bruce and represents the buildings that stood on the three hills of medieval Aberdeen: Aberdeen Castle on Castle Hill (today's Castlegate); the city gate on Port Hill; and a church on St\u00a0Catherine's Hill (now levelled).\n\n\"Bon Accord\" is the motto of the city and is French for \"Good Agreement\". Legend tells that its use dates from a password used by Robert the Bruce during the 14th-century Wars of Scottish Independence, when he and his men laid siege to the English-held Aberdeen Castle before destroying it in 1308. It is still widely present in the city, throughout street names, business names and the city's Bon Accord shopping mall.\n\nThe shield in the coat of arms is supported by two leopards. A local magazine is called the \"Leopard\" and, when Union Bridge was widened in the 20th century, small statues of the creature in a sitting position were cast and placed on top of the railing posts (known locally as Kelly's Cats). The city's toast is \"Happy to meet, sorry to part, happy to meet again\"; this has been commonly misinterpreted as the translation of Bon Accord.\n\nGeography\n\nBeing sited between two river mouths, the city has little natural exposure of bedrock. This leaves local geologists in a slight quandary: despite the high concentration of geoscientists in the area (courtesy of the oil industry), there is only a vague understanding of what underlies the city. To the south side of the city, coastal cliffs expose high-grade metamorphic rocks of the Grampian Group; to the southwest and west are extensive granites intruded into similar high-grade schists; to the north the metamorphics are intruded by gabbroic complexes instead.\n\nThe small amount of geophysics done, and occasional building-related exposures, combined with small exposures in the banks of the River Don, suggest that it is actually sited on an inlier of Devonian \"Old Red\" sandstones and silts. The outskirts of the city spread beyond the (inferred) limits of the outlier onto the surrounding metamorphic/ igneous complexes formed during the Dalradian period (approximately 480\u2013600\u00a0million years ago) with sporadic areas of igneous Diorite granites to be found, such as that at the Rubislaw quarry which was used to build much of the Victorian parts of the city.\n\nOn the coast, Aberdeen has a long sand beach between the two rivers, the Dee and the Don, which turns into high sand dunes north of the Don stretching as far as Fraserburgh; to the south of the Dee are steep rocky cliff faces with only minor pebble and shingle beaches in deep inlets. A number of granite outcrops along the south coast have been quarried in the past, making for spectacular scenery and good rock-climbing.\n\nThe city extends to, and includes the former burghs of Old Aberdeen, New Aberdeen, Woodside and the Royal Burgh of Torry to the south of River Dee. In  this gave the city a population density of. The city is built on many hills, with the original beginnings of the city growing from Castle Hill, St. Catherine's Hill and Windmill Hill.\n\nClimate\nAberdeen features an oceanic climate (K\u00f6ppen Cfb). Aberdeen has far milder winter temperatures than one might expect for its northern location, although statistically it is the coldest city in the UK. During the winter, especially throughout December, the length of the day is very short, averaging 6 hours and 41 minutes between sunrise and sunset at winter solstice. As winter progresses, the length of the day grows fairly quickly, to 8 hours and 20 minutes by the end of January. Around summer solstice, the days will be around 18 hours long, having 17 hours and 55 minutes between sunrise and sunset. During this time of the year marginal nautical twilight lasts the entire night. Temperatures at this time of year hover around  during the day in most of the urban area, though nearer  directly on the coast, and around  in the westernmost suburbs, illustrating the cooling effect of the North Sea during summer. In addition, from June onward skies are more overcast than in April/May, as reflected in a lower percentage of possible sunshine (the percentage of daylight hours that are sunny). These factors render both summer and winter temperate and mild for the latitude, both by European standards and those of far-inland climates on other continents.\n\nFor example, all coastal Bothnian and even some elevated climates in Scandinavia near or above the polar circle have warmer summers than Aberdeen. During winter, the city is instead having similar temperatures to Milan much further south due to said maritime influence.\n\nTwo weather stations collect climate data for the area, Aberdeen/Dyce Airport, and Craibstone. Both are about  to the north west of the city centre, and given that they are in close proximity to each other, exhibit very similar climatic regimes. Dyce tends to have marginally warmer daytime temperatures year round owing to its slightly lower elevation, though it is more susceptible to harsh frosts. The coldest temperature to occur in recent years was  during December 2010, while the following winter, Dyce set a new February high temperature station record on 28 February 2012 of, and a new March high temperature record of  on 25 March 2012.\n\nThe average temperature of the sea ranges from  in March to  in August.\n\nDemography\n\nThe latest population estimate (mid-2016) for the City of Aberdeen is. For the wider settlement of Aberdeen including Cove Bay and Dyce the latest population estimate (mid-2016) is. For the local council area of Aberdeen City the latest estimate (mid-2019) is \n\nIn 1396 the population was about 3,000. By 1801 it had become 26,992; (1901) 153,503; (1941) 182,467.\n\nThe 2011 census showed that there are fewer young people in Aberdeen, with 16.4% under 16, opposed to the national average of 19.2%. According to the 2011 census Aberdeen is 91.9% white, ethnically, 24.7% were born outside Scotland, higher than the national average of 16%. Of this population 7.6% were born in other parts of the UK. 8.2% of Aberdonians stated to be from an ethnic minority (non-white) in the 2011 census, with 9,519 (4.3%) being Asian, with 3,385 (1.5%) coming from India and 2,187 (1.0%) being Chinese. The city has around 5,610 (2.6%) residents of African or Caribbean origin, which is a higher percentage than both Glasgow and Edinburgh.\n\nIn the household, there were 97,013 individual dwellings recorded in the city of which 61% were privately owned, 9% privately rented and 23% rented from the council. The most popular type of dwellings are apartments which comprise 49% of residences followed by semi-detached at just below 22%.\nThe median income of a household in the city is \u00a316,813 (the mean income is \u00a320,292) (2005) which places approximately 18% households in the city below the poverty line (defined as 60% of the mean income). Conversely, an Aberdeen postcode has the second highest number of millionaires of any postcode in the UK.\n\nReligion\n\nChristianity is the main religion practised in the city. Aberdeen's largest denominations are the Church of Scotland (through the Presbytery of Aberdeen) and the Roman Catholic Church, both with numerous churches across the city, with the Scottish Episcopal Church having the third-largest number. The most recent census in 2001 showed that Aberdeen has the highest proportion of non-religious residents of any city in Scotland, with nearly 43% of citizens claiming to have no religion and several former churches in the city have been converted into bars and restaurants. In the Middle Ages, the Kirk of St\u00a0Nicholas was the only burgh kirk and one of Scotland's largest parish churches. Like a number of other Scottish kirks, it was subdivided after the Reformation, in this case into the East and West churches. At this time, the city also was home to houses of the Carmelites (Whitefriars) and Franciscans (Greyfriars), the latter of which surviving in modified form as the chapel of Marischal College as late as the early 20th century.\n\nSt Machar's Cathedral was built twenty years after David I (1124\u20131153) transferred the pre-Reformation Diocese from Mortlach in Banffshire to Old Aberdeen in 1137. With the exception of the episcopate of William Elphinstone (1484\u20131511), building progressed slowly. Gavin Dunbar, who followed him in 1518, completed the structure by adding the two western spires and the southern transept. It is now a congregation of the Church of Scotland. Aberdeen has two other cathedrals: St. Mary's Cathedral is a Roman Catholic cathedral in Gothic style, erected in 1859. In addition, St. Andrew's Cathedral serves the Scottish Episcopal Church. It was constructed in 1817 as Archibald Simpson's first commission and contains a memorial to the consecration of the first bishop of the Episcopal Church in the United States of America, which took place nearby. In 1804, St Peter's Church, the first permanent Roman Catholic church in the city after the Reformation was built.\n\nNumerous other Protestant denominations have a presence in Aberdeen. The Salvation Army citadel on the Castlegate dominates the view of east end of Union Street. In addition, there is a Unitarian church, established in 1833 and located in Skene Terrace. Christadelphians have been present in Aberdeen since at least 1844. Over the years, they have rented space to meet at a number of locations and currently meet in the Inchgarth Community Centre in Garthdee. There is also a Quaker meetinghouse on Crown street, the only purpose built Friends meeting house in Scotland that is still in use today. In addition, there are a number of Baptist congregations in the city, and Evangelical congregations have been appearing in significant numbers since the late 2000s. The city also has two meetinghouses of The Church of Jesus Christ of Latter-day Saints (LDS Church).\n\nThere is also a mosque in Old Aberdeen which serves the Islamic community in the city, and an Orthodox Jewish Synagogue established in 1945. There is also a Thai Buddhist temple located in the Hazelhead area of the city. There are no formal Hindu buildings, although the University of Aberdeen has a small Bah\u00e1\u02bc\u00ed society and there is a fortnightly Hindu religious gathering in the 1st and 3rd Sunday afternoons at Queens Cross Parish church hall.\n\nEconomy\n\nTraditionally, Aberdeen was home to fishing, textile mills, shipbuilding and paper making. These industries have been largely replaced. High technology developments in the electronics design and development industry, research in agriculture and fishing and the oil industry, which has been largely responsible for Aberdeen's economic boom in the last three decades, are now major parts of Aberdeen's economy.\n\nUntil the 1970s, most of Aberdeen's leading industries dated from the 18th century; mainly these were textiles, foundry work, shipbuilding and paper-making, the oldest industry in the city, with paper having been first made there in 1694. Paper-making has reduced in importance since the closures of Donside Paper Mill in 2001 and the Davidson Mill in 2005 leaving the Stoneywood Paper Mill with a workforce of approximately 500. Textile production ended in 2004 when Richards of Aberdeen closed.\n\nGrey granite was quarried at Rubislaw quarry for more than 300 years, and used for paving setts, kerb and building stones, and monumental and other ornamental pieces. Aberdeen granite was used to build the terraces of the Houses of Parliament and Waterloo Bridge in London. Quarrying finally ceased in 1971. The current owners have begun pumping 40 years of rain water from the quarry with the aim of developing a heritage centre on the site.\n\nFishing was once the predominant industry, but was surpassed by deep-sea fisheries, which derived a great impetus from improved technologies throughout the 20th century. Catches have fallen because of overfishing and the use of the harbour by oil support vessels, and so although still an important fishing port it is now eclipsed by the more northerly ports of Peterhead and Fraserburgh. The Fisheries Research Services are headquartered in Aberdeen, and there is a marine research lab in Torry.\n\nAberdeen is well regarded for the agricultural and soil research carried out at The James Hutton Institute (formerly the Macaulay Land Use Research Institute), which has close links to the city's two universities. The Rowett Research Institute is a world-renowned research centre for studies into food and nutrition located in Aberdeen. It has produced three Nobel laureates and there is a high concentration of life scientists working in the city.\n\nAs oil reserves in the North Sea decrease there is an effort to rebrand Aberdeen as \"Energy Capital of Europe\" rather than \"Oil Capital of Europe\", and there is interest in the development of new energy sources; and technology transfer from oil into renewable energy and other industries is under way. The \"Energetica\" initiative led by Scottish Enterprise has been designed to accelerate this process. As of 2013, Aberdeen remained a major world centre for undersea petroleum technology.\n\nNorth Sea oil and gas\n\nAberdeen had been a major maritime centre throughout the 19th century, when a group of local entrepreneurs launched the first steam-powered trawler. The steam trawling industry expanded and by 1933 Aberdeen was Scotland's top fishing port, employing nearly 3,000 men with 300 vessels sailing from its harbour. By the time oil was coming on stream, much of the trawling fleet had relocated to Peterhead. Although Aberdeen still brings in substantial catches, the tugs, safety vessels and supply ships which pack the harbour far outnumber the trawlers.\n\nGeologists had speculated about the existence of oil and gas in the North Sea since the middle of the 20th century, but tapping its deep and inhospitable waters was another story. With the Middle Eastern oil sheiks becoming more aware of the political and economic power of their oil reserves and government threats of rationing, the industry began to consider the North Sea as a viable source of oil. Exploration commenced in the 1960s and the first major find in the British sector was in November 1970 in the Forties field,  east of Aberdeen.\n\nBy late 1975, after years of intense construction the necessary infrastructure was in place. In Aberdeen, at BP's (British Petroleum) headquarters, the Queen pressed the button that would set the whole thing moving. Oil flowed from the rig directly to the refinery at far-away Grangemouth. While many ports have suffered decline, Aberdeen remains busy because of the oil trade and the influx of people connected with the industry, a subsequent rise in property prices have brought prosperity to the area.\n\nThe industry supports about 47,000 jobs locally, and known reserves ensure that oil will continue to flow well into the 21st century. As a major port in the UK, Aberdeen receives many ships calling at the port. Seafarers' welfare organisation, Apostleship of the Sea has a port chaplain in Aberdeen to offer practical and pastoral support to them.\n\nBusiness\nIn 2011, the Centre for Cities named Aberdeen as the best placed city for growth in Britain, as the country looked to emerge from the recent economic downturn. With energy still providing the backbone of the local economy, recent years have seen very large new investment in the North Sea owing to rising oil prices and favourable government tax incentives. This has led to several oil", "flag": 1, "segments": [[585, 595]], "strength": 5.5}
{"text": "Aquaculture (less commonly spelled aquiculture), also known as aquafarming, is the controlled cultivation (\"farming\") of aquatic organisms such as fish, crustaceans, mollusks, algae and other organisms of value such as aquatic plants (e.g. lotus). Aquaculture involves cultivating freshwater, brackish water and saltwater populations under controlled or semi-natural conditions, and can be contrasted with commercial fishing, which is the harvesting of wild fish.  Mariculture, commonly known as marine farming, refers specifically to aquaculture practiced in seawater habitats and lagoons, opposed to in freshwater aquaculture. Pisciculture is a type of aquaculture that consists of the culturing of fish (fish farming) to obtain fish and fish products as food.\n\nAquaculture can be conducted in completely artificial facilities built on land (onshore aquaculture), as in the case of fish tank, ponds, aquaponics or raceways, where the living conditions rely on human control such as water quality (oxygen), feed, temperature. Alternatively, they can be conducted on well-sheltered shallow waters nearshore of a body of water (inshore aquaculture), where the cultivated species are subjected to a relatively more naturalistic environments; or on fenced/enclosed sections of open water away from the shore (offshore aquaculture), where the species are either cultured in cages, racks or bags, and are exposed to more diverse natural conditions such as water currents (such as ocean currents), diel vertical migration and nutrient cycles.\n\nAccording to the Food and Agriculture Organization (FAO), aquaculture \"is understood to mean the farming of aquatic organisms including fish, molluscs, crustaceans and aquatic plants. Farming implies some form of intervention in the rearing process to enhance production, such as regular stocking, feeding, protection from predators, etc. Farming also implies individual or corporate ownership of the stock being cultivated.\" The reported output from global aquaculture operations in 2019 was over 120 million tonnes valued at\u00a0US$274 billion. However, there are issues about the reliability of the reported figures. Further, in current aquaculture practice, products from several pounds of wild fish are used to produce one pound of a piscivorous fish like salmon. Plant and insect-based feeds are also being developed to help reduce wild fish been used for aquaculture feed.\n\nParticular kinds of aquaculture include fish farming, shrimp farming, oyster farming, mariculture, pisciculture, algaculture (such as seaweed farming), and the cultivation of ornamental fish. Particular methods include aquaponics and integrated multi-trophic aquaculture, both of which integrate fish farming and aquatic plant farming. The FAO describes aquaculture as one of the industries most directly affected by climate change and its impacts. Some forms of aquaculture have negative impacts on the environment, such as through nutrient pollution or disease transfer to wild populations.\n\nThe UN SDG 14, Target 14.7 includes aquaculture: \"By 2030, increase the economic benefits to small island developing states and least developed countries from the sustainable use of marine resources, including through sustainable management of fisheries, aquaculture and tourism\". Aquaculture's contribution to GDP is not included in SDG Target 14.7 but methods for quantifying this have been explored by FAO.\n\nOverview\n\nHarvest stagnation in wild fisheries and overexploitation of popular marine species, combined with a growing demand for high-quality protein, encouraged aquaculturists to domesticate other marine species. At the outset of modern aquaculture, many were optimistic that a \"Blue Revolution\" could take place in aquaculture, just as the Green Revolution of the 20th century had revolutionized agriculture. Although land animals had long been domesticated, most seafood species were still caught from the wild. Concerned about the impact of growing demand for seafood on the world's oceans, prominent ocean explorer Jacques Cousteau wrote in 1973: \"With earth's burgeoning human populations to feed, we must turn to the sea with new understanding and new technology.\"\n\nAbout 430 (97%) of the species cultured  were domesticated during the 20th and 21st centuries, of which an estimated 106 came in the decade to 2007. Given the long-term importance of agriculture,  to date, only 0.08% of known land plant species and 0.0002% of known land animal species have been domesticated, compared with 0.17% of known marine plant species and 0.13% of known marine animal species. Domestication typically involves about a decade of scientific research. Domesticating aquatic species involves fewer risks to humans than do land animals, which took a large toll in human lives. Most major human diseases originated in domesticated animals, including diseases such as smallpox and diphtheria, that like most infectious diseases, move to humans from animals. No human pathogens of comparable virulence have yet emerged from marine species. \n\nBiological control methods to manage parasites are already being used, such as cleaner fish (e.g. lumpsuckers and wrasse) to control sea lice populations in salmon farming. Models are being used to help with spatial planning and siting of fish farms in order to minimize impact.\n\nThe decline in wild fish stocks has increased the demand for farmed fish. However, finding alternative sources of protein and oil for fish feed is necessary so the aquaculture industry can grow sustainably; otherwise, it represents a great risk for the over-exploitation of forage fish.\n\nAquaculture production now exceeds capture fishery production and together the relative GDP contribution has ranged from 0.01 to 10%. Singling out aquaculture's relative contribution to GDP, however, is not easily derived due to lack of data.\n\nAnother recent issue following the banning in 2008 of organotins by the International Maritime Organization is the need to find environmentally friendly, but still effective, compounds with antifouling effects.\n\nMany new natural compounds are discovered every year, but producing them on a large enough scale for commercial purposes is almost impossible.\n\nIt is highly probable that future developments in this field will rely on microorganisms, but greater funding and further research is needed to overcome the lack of knowledge in this field.\n\nSpecies groups\n\nAquatic plants\n\nMicroalgae, also referred to as phytoplankton, microphytes, or planktonic algae, constitute the majority of cultivated algae. Macroalgae commonly known as seaweed also have many commercial and industrial uses, but due to their size and specific requirements, they are not easily cultivated on a large scale and are most often taken in the wild.\n\nIn 2016, aquaculture was the source of 96.5 percent by volume of the total 31.2 million tonnes of wild-collected and cultivated aquatic plants combined. Global production of farmed aquatic plants, overwhelmingly dominated by seaweeds, grew in output volume from 13.5 million tonnes in 1995 to just over 30 million tonnes in 2016.\n\nSeaweed farming\n\nFish\n\nThe farming of fish is the most common form of aquaculture. It involves raising fish commercially in tanks, fish ponds, or ocean enclosures, usually for food. A facility that releases juvenile fish into the wild for recreational fishing or to supplement a species' natural numbers is generally referred to as a fish hatchery. Worldwide, the most important fish species used in fish farming are, in order, carp, salmon, tilapia, and catfish.\n\nIn the Mediterranean, young bluefin tuna are netted at sea and towed slowly towards the shore. They are then interned in offshore pens (sometimes made from floating HDPE pipe) where they are further grown for the market. In 2009, researchers in Australia managed for the first time to coax southern bluefin tuna to breed in landlocked tanks. Southern bluefin tuna are also caught in the wild and fattened in grow-out sea cages in southern Spencer Gulf, South Australia.\n\nA similar process is used in the salmon-farming section of this industry; juveniles are taken from hatcheries and a variety of methods are used to aid them in their maturation. For example, as stated above, some of the most important fish species in the industry, salmon, can be grown using a cage system. This is done by having netted cages, preferably in open water that has a strong flow, and feeding the salmon a special food mixture that aids their growth. This process allows for year-round growth of the fish, thus a higher harvest during the correct seasons. An additional method, known sometimes as sea ranching, has also been used within the industry. Sea ranching involves raising fish in a hatchery for a brief time and then releasing them into marine waters for further development, whereupon the fish are recaptured when they have matured.\n\nCrustaceans\n\nCommercial shrimp farming began in the 1970s, and production grew steeply thereafter. Global production reached more than 1.6 million tonnes in 2003, worth about US$9 billion. About 75% of farmed shrimp is produced in Asia, in particular in China and Thailand. The other 25% is produced mainly in Latin America, where Brazil is the largest producer. Thailand is the largest exporter.\n\nShrimp farming has changed from its traditional, small-scale form in Southeast Asia into a global industry. Technological advances have led to ever higher densities per unit area, and broodstock is shipped worldwide. Virtually all farmed shrimp are penaeids (i.e., shrimp of the family Penaeidae), and just two species of shrimp, the Pacific white shrimp and the giant tiger prawn, account for about 80% of all farmed shrimp. These industrial monocultures are very susceptible to disease, which has decimated shrimp populations across entire regions. Increasing ecological problems, repeated disease outbreaks, and pressure and criticism from both nongovernmental organizations and consumer countries led to changes in the industry in the late 1990s and generally stronger regulations. In 1999, governments, industry representatives, and environmental organizations initiated a program aimed at developing and promoting more sustainable farming practices through the Seafood Watch program.\n\nFreshwater prawn farming shares many characteristics with, including many problems with, marine shrimp farming. Unique problems are introduced by the developmental lifecycle of the main species, the giant river prawn.\n\nThe global annual production of freshwater prawns (excluding crayfish and crabs) in 2007 was about 460,000 tonnes, exceeding 1.86 billion dollars. Additionally, China produced about 370,000 tonnes of Chinese river crab.\n\nIn addition astaciculture is the freshwater farming of crayfish (mostly in the US, Australia, and Europe).\n\nMolluscs\n\nAquacultured shellfish include various oyster, mussel, and clam species. These bivalves are filter and/or deposit feeders, which rely on ambient primary production rather than inputs of fish or other feed. As such, shellfish aquaculture is generally perceived as benign or even beneficial.\n\nDepending on the species and local conditions, bivalve molluscs are either grown on the beach, on longlines, or suspended from rafts and harvested by hand or by dredging. In May 2017 a Belgian consortium installed the first of two trial mussel farms on a wind farm in the North Sea.\n\nAbalone farming began in the late 1950s and early 1960s in Japan and China. Since the mid-1990s, this industry has become increasingly successful. Overfishing and poaching have reduced wild populations to the extent that farmed abalone now supplies most abalone meat. Sustainably farmed molluscs can be certified by Seafood Watch and other organizations, including the World Wildlife Fund (WWF). WWF initiated the \"Aquaculture Dialogues\" in 2004 to develop measurable and performance-based standards for responsibly farmed seafood. In 2009, WWF co-founded the Aquaculture Stewardship Council with the Dutch Sustainable Trade Initiative to manage the global standards and certification programs.\n\nAfter trials in 2012, a  commercial \"sea ranch\" was set up in Flinders Bay, Western Australia, to raise abalone. The ranch is based on an artificial reef made up of 5000 () separate concrete units called abitats (abalone habitats). The 900\u00a0kg abitats can host 400 abalone each. The reef is seeded with young abalone from an onshore hatchery. The abalone feed on seaweed that has grown naturally on the habitats, with the ecosystem enrichment of the bay also resulting in growing numbers of dhufish, pink snapper, wrasse, and Samson fish, among other species.\n\nBrad Adams, from the company, has emphasised the similarity to wild abalone and the difference from shore-based aquaculture. \"We're not aquaculture, we're ranching, because once they're in the water they look after themselves.\"\n\nOther groups\nOther groups include aquatic reptiles, amphibians, and miscellaneous invertebrates, such as echinoderms and jellyfish. They are separately graphed at the top right of this section, since they do not contribute enough volume to show clearly on the main graph.\n\nCommercially harvested echinoderms include sea cucumbers and sea urchins. In China, sea cucumbers are farmed in artificial ponds as large as.\n\nGlobal fish production\nGlobal fish production peaked at about 171 million tonnes in 2016, with aquaculture representing 47 percent of the total and 53 percent if non-food uses (including reduction to fishmeal and fish oil) are excluded. With capture fishery production relatively static since the late 1980s, aquaculture has been responsible for the continuing growth in the supply of fish for human consumption. Global aquaculture production (including aquatic plants) in 2016 was 110.2 million tonnes, with the first-sale value estimated at US$244 billion. Three years later, in 2019 the reported output from global aquaculture operations was over 120 million tonnes valued at\u00a0US$274 billion.\n\nThe contribution of aquaculture to the global production of capture fisheries and aquaculture combined has risen continuously, reaching 46.8 percent in 2016, up from 25.7 percent in 2000. With 5.8 percent annual growth rate during the period 2001\u20132016, aquaculture continues to grow faster than other major food production sectors, but it no longer has the high annual growth rates experienced in the 1980s and 1990s.\n\nIn 2012, the total world production of fisheries was 158 million tonnes, of which aquaculture contributed 66.6 million tonnes, about 42%. The growth rate of worldwide aquaculture has been sustained and rapid, averaging about 8% per year for over 30 years, while the take from wild fisheries has been essentially flat for the last decade. The aquaculture market reached $86 billion in 2009.\n\nAquaculture is an especially important economic activity in China. Between 1980 and 1997, the Chinese Bureau of Fisheries reports, aquaculture harvests grew at an annual rate of 16.7%, jumping from 1.9 million tonnes to nearly 23 million tonnes. In 2005, China accounted for 70% of world production. Aquaculture is also currently one of the fastest-growing areas of food production in the U.S.\n\nAbout 90% of all U.S. shrimp consumption is farmed and imported. In recent years, salmon aquaculture has become a major export in southern Chile, especially in Puerto Montt, Chile's fastest-growing city.\n\nA United Nations report titled The State of the World Fisheries and Aquaculture released in May 2014 maintained fisheries and aquaculture support the livelihoods of some 60 million people in Asia and Africa. FAO estimates that in 2016, overall, women accounted for nearly 14 percent of all people directly engaged in the fisheries and aquaculture primary sector.\n\nOver-reporting by China\nChina overwhelmingly dominates the world in reported aquaculture output, reporting a total output which is double that of the rest of the world put together. However, there are some historical issues with the accuracy of China's returns.\n\nIn 2001, scientists Reg Watson and Daniel Pauly expressed concerns that China was over reporting its catch from wild fisheries in the 1990s. They said that made it appear that the global catch since 1988 was increasing annually by 300,000 tonnes, whereas it was really shrinking annually by 350,000 tonnes. Watson and Pauly suggested this may be have been related to Chinese policies where state entities that monitored the economy were also tasked with increasing output. Also, until more recently, the promotion of Chinese officials was based on production increases from their own areas.\n\nChina disputed this claim. The official Xinhua News Agency quoted Yang Jian, director general of the Agriculture Ministry's Bureau of Fisheries, as saying that China's figures were \"basically correct\". However, the FAO accepted there were issues with the reliability of China's statistical returns, and for a period treated data from China, including the aquaculture data, apart from the rest of the world.\n\nAquacultural methods\n\nMariculture\n\nMariculture refers to the cultivation of marine organisms in seawater, usually in sheltered coastal or offshore waters. The farming of marine fish is an example of mariculture, and so also is the farming of marine crustaceans (such as shrimp), mollusks (such as oysters), and seaweed. Channel catfish (Ictalurus punctatus), hard clams (Mercenaria mercenaria) and Atlantic salmon (Salmo salar) are prominent in the U.S. mariculture.\n\nMariculture may consist of raising the organisms on or in artificial enclosures such as in floating netted enclosures for salmon and on racks for oysters. In the case of enclosed salmon, they are fed by the operators; oysters on racks filter feed on naturally available food. Abalone have been farmed on an artificial reef consuming seaweed which grows naturally on the reef units.\n\nIntegrated\n\nIntegrated multi-trophic aquaculture (IMTA) is a practice in which more broadly, as Indigenous leaders and some lawmakers from the byproducts (wastes) from one species are recycled to become inputs (fertilizers, food) for another. Fed aquaculture (for example, fish, shrimp) is combined with inorganic extractive and organic extractive (for example, shellfish) aquaculture to create balanced systems for environmental sustainability (biomitigation), economic stability (product diversification and risk reduction) and social acceptability (better management practices).\n\n\"Multi-trophic\" refers to the incorporation of species from different trophic or nutritional levels in the same system. This is one potential distinction from the age-old practice of aquatic polyculture, which could simply be the co-culture of different fish species from the same trophic level. In this case, these organisms may all share the same biological and chemical processes, with few synergistic benefits, which could potentially lead to significant shifts in the ecosystem. Some traditional polyculture systems may, in fact, incorporate a greater diversity of species, occupying several niches, as extensive cultures (low intensity, low management) within the same pond. A working IMTA system can result in greater total production based on mutual benefits to the co-cultured species and improved ecosystem health, even if the production of individual species is lower than in a monoculture over a short-term period.\n\nSometimes the term \"integrated aquaculture\" is used to describe the integration of monocultures through water transfer. For all intents and purposes, however, the terms \"IMTA\" and \"integrated aquaculture\" differ only in their degree of descriptiveness. Aquaponics, fractionated aquaculture, integrated agriculture-aquaculture systems, integrated peri-urban-aquaculture systems, and integrated fisheries-aquaculture systems are other variations of the IMTA concept.\n\nNetting materials\nVarious materials, including nylon, polyester, polypropylene, polyethylene, plastic-coated welded wire, rubber, patented rope products (Spectra, Thorn-D, Dyneema), galvanized steel and copper are used for netting in aquaculture fish enclosures around the world. All of these materials are selected for a variety of reasons, including design feasibility, material strength, cost, and corrosion resistance.\n\nRecently, copper alloys have become important netting materials in aquaculture because they are antimicrobial (i.e., they destroy bacteria, viruses, fungi, algae, and other microbes) and they therefore prevent biofouling (i.e., the undesirable accumulation, adhesion, and growth of microorganisms, plants, algae, tubeworms, barnacles, mollusks, and other organisms). By inhibiting microbial growth, copper alloy aquaculture cages avoid costly net changes that are necessary with other materials. The resistance of organism growth on copper alloy nets also provides a cleaner and healthier environment for farmed fish to grow and thrive.\n\nIssues\n\nIf performed without consideration for potential local environmental impacts, aquaculture in inland waters can result in more environmental damage than wild fisheries, though with less waste produced per kg on a global scale. Local concerns with aquaculture in inland waters may include waste handling, side-effects of antibiotics, competition between farmed and wild animals, and the potential introduction of invasive plant and animal species, or foreign pathogens, particularly if unprocessed fish are used to feed more marketable carnivorous fish. If non-local live feeds are used, aquaculture may introduce exotic plants or animals with disastrous effects. Improvements in methods resulting from advances in research and the availability of commercial feeds has reduced some of these concerns since their greater prevalence in the 1990s and 2000s.\n\nFish waste is organic and composed of nutrients necessary in all components of aquatic food webs. In-ocean aquaculture often produces much higher than normal fish waste concentrations. The waste collects on the ocean bottom, damaging or eliminating bottom-dwelling life. Waste can also decrease dissolved oxygen levels in the water column, putting further pressure on wild animals. An alternative model to food being added to the ecosystem, is the installation of artificial reef structures to increase the habitat niches available, without the need to add any more than ambient feed and nutrient. This has been used in the \"ranching\" of abalone in Western Australia.\n\nImpacts on wild fish\nSome carnivorous and omnivorous farmed fish species are fed wild forage fish. Although carnivorous farmed fish represented only 13 percent of aquaculture production by weight in 2000, they represented 34 percent of aquaculture production by value.\n\nFarming of carnivorous species like salmon and shrimp leads to a high demand for forage fish to match the nutrition they get in the wild. Fish do not actually produce omega-3 fatty acids, but instead accumulate them from either consuming microalgae that produce these fatty acids, as is the case with forage fish like herring and sardines, or, as is the case with fatty predatory fish, like salmon, by eating prey fish that have accumulated omega-3 fatty acids from microalgae. To satisfy this requirement, more than 50 percent of the world fish oil production is fed to farmed salmon.\n\nFarmed salmon consume more wild fish than they generate as a final product, although the efficiency of production is improving. To produce one pound of farmed salmon, products from several pounds of wild fish are fed to them \u2013 this can be described as the \"fish-in-fish-out\" (FIFO) ratio. In 1995, salmon had a FIFO ratio of 7.5 (meaning 7.5 pounds of wild fish feed were required to produce 1 pound of salmon); by 2006 the ratio had fallen to 4.9. Additionally, a growing share of fish", "flag": 1, "segments": [[3800, 3810]], "strength": 5.5}
{"text": "Alfred the Great (848/849 \u2013 26 October 899) was King of the West Saxons from 871 to  and King of the Anglo-Saxons from  until his death in 899. He was the youngest son of King \u00c6thelwulf and his first wife Osburh, who both died when Alfred was young. Three of Alfred's brothers, \u00c6thelbald, \u00c6thelberht and \u00c6thelred, reigned in turn before him. Under Alfred's rule, considerable administrative and military reforms were introduced, prompting lasting change in England.\n\nAfter ascending the throne, Alfred spent several years fighting Viking invasions. He won a decisive victory in the Battle of Edington in 878 and made an agreement with the Vikings, dividing England between Anglo-Saxon territory and the Viking-ruled Danelaw, composed of northern England, the north-east Midlands and East Anglia. Alfred also oversaw the conversion of Viking leader Guthrum to Christianity. He defended his kingdom against the Viking attempt at conquest, becoming the dominant ruler in England. Details of his life are described in a work by 9th-century Welsh scholar and bishop Asser.\n\nAlfred had a reputation as a learned and merciful man of a gracious and level-headed nature who encouraged education, proposing that primary education be conducted in Old English rather than Latin and improving the legal system and military structure and his people's quality of life. He was given the epithet \"the Great\" in the 16th century.\n\nFamily\n\nAlfred was a son of \u00c6thelwulf, king of Wessex, and his wife Osburh. According to his biographer, Asser, writing in 893, \"In the year of our Lord's Incarnation 849 Alfred, King of the Anglo-Saxons\", was born at the royal estate called Wantage, in the district known as Berkshire (which is so called from Berroc Wood, where the box tree grows very abundantly).\" This date has been accepted by the editors of Asser's biography, Simon Keynes and Michael Lapidge, and by other historians such as David Dumville and Richard Huscroft. West Saxon genealogical lists state that Alfred was 23 when he became king in April 871, implying that he was born between April 847 and April 848. This dating is adopted in the biography of Alfred by Alfred Smyth, who regards Asser's biography as fraudulent, an allegation which is rejected by other historians. Richard Abels in his biography discusses both sources but does not decide between them and dates Alfred's birth as 847/849, while Patrick Wormald in his Oxford Dictionary of National Biography article dates it 848/849. Berkshire had been historically disputed between Wessex and Mercia, and as late as 844, a charter showed that it was part of Mercia, but Alfred's birth in the county is evidence that, by the late 840s, control had passed to Wessex.\n\nHe was the youngest of six children. His eldest brother, \u00c6thelstan, was old enough to be appointed sub-king of Kent in 839, almost 10 years before Alfred was born. He died in the early 850s. Alfred's next three brothers were successively kings of Wessex. \u00c6thelbald (858-860) and \u00c6thelberht (860-865) were also much older than Alfred, but \u00c6thelred (865-871) was only a year or two older. Alfred's only known sister, \u00c6thelswith, married Burgred, king of the midland kingdom of Mercia in 853. Most historians think that Osburh was the mother of all \u00c6thelwulf's children, but some suggest that the older ones were born to an unrecorded first wife. Osburh was descended from the rulers of the Isle of Wight. She was described by Alfred's biographer Asser as \"a most religious woman, noble by temperament and noble by birth\". She had died by 856 when \u00c6thelwulf married Judith, daughter of Charles the Bald, king of West Francia.\n\nIn 868, Alfred married Ealhswith, daughter of the Mercian nobleman \u00c6thelred Mucel, ealdorman of the Gaini, and his wife Eadburh, who was of royal Mercian descent. Their children were \u00c6thelfl\u00e6d, who married \u00c6thelred, Lord of the Mercians; Edward the Elder, Alfred's successor as king; \u00c6thelgifu, abbess of Shaftesbury; \u00c6lfthryth, who married Baldwin, count of Flanders; and \u00c6thelweard.\n\nBackground\n\nAlfred's grandfather, Ecgberht, became king of Wessex in 802, and in the view of the historian Richard Abels, it must have seemed very unlikely to contemporaries that he would establish a lasting dynasty. For 200 years, three families had fought for the West Saxon throne, and no son had followed his father as king. No ancestor of Ecgberht had been a king of Wessex since Ceawlin in the late sixth century, but he was believed to be a paternal descendant of Cerdic, the founder of the West Saxon dynasty. This made Ecgberht an \u00e6theling \u2013 a prince eligible for the throne. But after Ecgberht's reign, descent from Cerdic was no longer sufficient to make a man an \u00e6theling. When Ecgberht died in 839, he was succeeded by his son \u00c6thelwulf; all subsequent West Saxon kings were descendants of Ecgberht and \u00c6thelwulf, and were also sons of kings.\n\nAt the beginning of the ninth century, England was almost wholly under the control of the Anglo-Saxons. Mercia dominated southern England, but its supremacy came to an end in 825 when it was decisively defeated by Ecgberht at the Battle of Ellendun. The two kingdoms became allies, which was important in the resistance to Viking attacks. In 853, King Burgred of Mercia requested West Saxon help to suppress a Welsh rebellion, and \u00c6thelwulf led a West Saxon contingent in a successful joint campaign. In the same year Burgred married \u00c6thelwulf's daughter, \u00c6thelswith.\n\nIn 825, Ecgberht sent \u00c6thelwulf to invade the Mercian sub-kingdom of Kent, and its sub-king, Baldred, was driven out shortly afterwards. By 830, Essex, Surrey and Sussex had submitted to Ecgberht, and he had appointed \u00c6thelwulf to rule the south-eastern territories as king of Kent. The Vikings ravaged the Isle of Sheppey in 835, and the following year they defeated Ecgberht at Carhampton in Somerset, but in 838 he was victorious over an alliance of Cornishmen and Vikings at the Battle of Hingston Down, reducing Cornwall to the status of a client kingdom. When \u00c6thelwulf succeeded, he appointed his eldest son \u00c6thelstan as sub-king of Kent. Ecgberht and \u00c6thelwulf may not have intended a permanent union between Wessex and Kent because they both appointed sons as sub-kings, and charters in Wessex were attested (witnessed) by West Saxon magnates, while Kentish charters were witnessed by the Kentish elite; both kings kept overall control, and the sub-kings were not allowed to issue their own coinage.\n\nViking raids increased in the early 840s on both sides of the English Channel, and in 843 \u00c6thelwulf was defeated at Carhampton. In 850, \u00c6thelstan defeated a Danish fleet off Sandwich in the first recorded naval battle in English history. In 851 \u00c6thelwulf and his second son, \u00c6thelbald, defeated the Vikings at the Battle of Aclea and, according to the Anglo-Saxon Chronicle, \"there made the greatest slaughter of a heathen raiding-army that we have heard tell of up to this present day, and there took the victory\". \u00c6thelwulf died in 858 and was succeeded by his oldest surviving son, \u00c6thelbald, as king of Wessex and by his next oldest son, \u00c6thelberht, as king of Kent. \u00c6thelbald only survived his father by two years, and \u00c6thelberht then for the first time united Wessex and Kent into a single kingdom.\n\nChildhood\n\nAccording to Asser, in his childhood Alfred won a beautifully decorated book of English poetry, offered as a prize by his mother to the first of her sons able to memorise it. He must have had it read to him because his mother died when he was about six and he did not learn to read until he was 12. In 853, Alfred is reported by the Anglo-Saxon Chronicle to have been sent to Rome where he was confirmed by Pope Leo IV, who \"anointed him as king\". Victorian writers later interpreted this as an anticipatory coronation in preparation for his eventual succession to the throne of Wessex. This is unlikely; his succession could not have been foreseen at the time because Alfred had three living elder brothers. A letter of Leo IV shows that Alfred was made a \"consul\" and a misinterpretation of this investiture, deliberate or accidental, could explain later confusion. It may be based upon the fact that Alfred later accompanied his father on a pilgrimage to Rome where he spent some time at the court of Charles the Bald, king of the Franks, around 854\u2013855. On their return from Rome in 856, \u00c6thelwulf was deposed by his son \u00c6thelbald. With civil war looming, the magnates of the realm met in council to form a compromise. \u00c6thelbald retained the western shires (i.e. historical Wessex), and \u00c6thelwulf ruled in the east. After King \u00c6thelwulf died in 858, Wessex was ruled by three of Alfred's brothers in succession: \u00c6thelbald, \u00c6thelberht and \u00c6thelred.\n\nThe reigns of Alfred's brothers\n\nAlfred is not mentioned during the short reigns of his older brothers \u00c6thelbald and \u00c6thelberht. The Anglo-Saxon Chronicle describes the Great Heathen Army of Danes landing in East Anglia with the intent of conquering the four kingdoms which constituted Anglo-Saxon England in 865. Alfred's public life began in 865 at age 16 with the accession of his third brother, 18-year-old \u00c6thelred. During this period, Bishop Asser gave Alfred the unique title of secundarius, which may indicate a position similar to the Celtic tanist, a recognised successor closely associated with the reigning monarch. This arrangement may have been sanctioned by Alfred's father or by the Witan to guard against the danger of a disputed succession should \u00c6thelred fall in battle. It was a well known tradition among other Germanic peoples - such as the Swedes and Franks to whom the Anglo-Saxons were closely related - to crown a successor as royal prince and military commander.\n\nViking invasion\nIn 868, Alfred was recorded as fighting beside \u00c6thelred in a failed attempt to keep the Great Heathen Army led by Ivar the Boneless out of the adjoining Kingdom of Mercia. The Danes arrived in his homeland at the end of 870, and nine engagements were fought in the following year, with mixed results; the places and dates of two of these battles have not been recorded. A successful skirmish at the Battle of Englefield in Berkshire on 31 December 870 was followed by a severe defeat at the siege and the Battle of Reading by Ivar's brother Halfdan Ragnarsson on 5 January 871. Four days later, the Anglo-Saxons won a victory at the Battle of Ashdown on the Berkshire Downs, possibly near Compton or Aldworth. The Saxons were defeated at the Battle of Basing on 22 January. They were defeated again on 22 March at the Battle of Merton (perhaps Marden in Wiltshire or Martin in Dorset). \u00c6thelred died shortly afterwards in April.\n\nKing at war\n\nEarly struggles\nIn April 871 King \u00c6thelred died and Alfred acceded to the throne of Wessex and the burden of its defence, even though \u00c6thelred left two under-age sons, \u00c6thelhelm and \u00c6thelwold. This was in accordance with the agreement that \u00c6thelred and Alfred had made earlier that year in an assembly at an unidentified place called Swinbeorg. The brothers had agreed that whichever of them outlived the other would inherit the personal property that King \u00c6thelwulf had left jointly to his sons in his will. The deceased's sons would receive only whatever property and riches their father had settled upon them and whatever additional lands their uncle had acquired. The unstated premise was that the surviving brother would be king. Given the Danish invasion and the youth of his nephews, Alfred's accession probably went uncontested.\n\nWhile he was busy with the burial ceremonies for his brother, the Danes defeated the Saxon army in his absence at an unnamed spot and then again in his presence at Wilton in May. The defeat at Wilton smashed any remaining hope that Alfred could drive the invaders from his kingdom. Alfred was forced instead to make peace with them. Although the terms of the peace are not recorded, Bishop Asser wrote that the pagans agreed to vacate the realm and made good their promise.\n\nThe Viking army withdrew from Reading in the autumn of 871 to take up winter quarters in Mercian London. Although not mentioned by Asser or by the Anglo-Saxon Chronicle, Alfred probably paid the Vikings cash to leave, much as the Mercians were to do in the following year. Hoards dating to the Viking occupation of London in 871/872 have been excavated at Croydon, Gravesend and Waterloo Bridge. These finds hint at the cost involved in making peace with the Vikings. For the next five years, the Danes occupied other parts of England.\n\nIn 876, under their three leaders Guthrum, Oscetel and Anwend, the Danes slipped past the Saxon army and attacked and occupied Wareham in Dorset. Alfred blockaded them but was unable to take Wareham by assault. He negotiated a peace that involved an exchange of hostages and oaths, which the Danes swore on a \"holy ring\" associated with the worship of Thor. The Danes broke their word, and after killing all the hostages, slipped away under cover of night year's holiday, the U.S. does to Exeter in Devon.\n\nAlfred blockaded the Viking ships in Devon, and with a relief fleet having been scattered by a storm, the Danes were forced to submit. The Danes withdrew to Mercia. In January 878, the Danes made a sudden attack on Chippenham, a royal stronghold in which Alfred had been staying over Christmas \"and most of the people they killed, except the King Alfred, and he with a little band made his way by wood and swamp, and after Easter he made a fort at Athelney in the marshes of Somerset, and from that fort kept fighting against the foe\". From his fort at Athelney, an island in the marshes near North Petherton, Alfred was able to mount a resistance campaign, rallying the local militias from Somerset, Wiltshire and Hampshire. 878 was the nadir of the history of the Anglo-Saxon kingdoms. With all the other kingdoms having fallen to the Vikings, Wessex alone was resisting.\n\nThe cake legend\nA legend tells how when Alfred first fled to the Somerset Levels, he was given shelter by a peasant woman who, unaware of his identity, left him to watch some wheaten cakes she had left cooking on the fire. Preoccupied with the problems of his kingdom, Alfred accidentally let the cakes burn and was roundly scolded by the woman upon her return. There is no contemporary evidence for the legend, but it is possible that there was an early oral tradition. The first known written account of the incident is from about 100 years after Alfred's death.\n\nCounter-attack and victory\n\nIn the seventh week after Easter (4\u201310 May 878), around Whitsuntide, Alfred rode to Egbert's Stone east of Selwood where he was met by \"all the people of Somerset and of Wiltshire and of that part of Hampshire which is on this side of the sea (that is, west of Southampton Water), and they rejoiced to see him\". Alfred's emergence from his marshland stronghold was part of a carefully planned offensive that entailed raising the fyrds of three shires. This meant not only that the king had retained the loyalty of ealdormen, royal reeves and king's thegns, who were charged with levying and leading these forces, but that they had maintained their positions of authority in these localities well enough to answer his summons to war. Alfred's actions also suggest a system of scouts and messengers.\n\nAlfred won a decisive victory in the ensuing Battle of Edington which may have been fought near Westbury, Wiltshire. He then pursued the Danes to their stronghold at Chippenham and starved them into submission. One of the terms of the surrender was that Guthrum convert to Christianity. Three weeks later, the Danish king and 29 of his chief men were baptised at Alfred's court at Aller, near Athelney, with Alfred receiving Guthrum as his spiritual son.\n\nAccording to Asser,\n\nAt Wedmore, Alfred and Guthrum negotiated what some historians have called the Treaty of Wedmore, but it was to be some years after the cessation of hostilities that a formal treaty was signed. Under the terms of the so-called Treaty of Wedmore, the converted Guthrum was required to leave Wessex and return to East Anglia. Consequently, in 879 the Viking army left Chippenham and made its way to Cirencester. The formal Treaty of Alfred and Guthrum, preserved in Old English in Corpus Christi College, Cambridge (Manuscript 383), and in a Latin compilation known as Quadripartitus, was negotiated later, perhaps in 879 or 880, when King Ceolwulf II of Mercia was deposed.\n\nThat treaty divided up the kingdom of Mercia. By its terms, the boundary between Alfred's and Guthrum's kingdoms was to run up the River Thames to the River Lea, follow the Lea to its source (near Luton), from there extend in a straight line to Bedford, and from Bedford follow the River Ouse to Watling Street.\n\nAlfred succeeded to Ceolwulf's kingdom consisting of western Mercia, and Guthrum incorporated the eastern part of Mercia into an enlarged Kingdom of East Anglia (henceforward known as the Danelaw). By terms of the treaty, moreover, Alfred was to have control over the Mercian city of London and its mints\u2014at least for the time being. In 825, the Anglo-Saxon Chronicle had recorded that the people of Essex, Sussex, Kent and Surrey surrendered to Egbert, Alfred's grandfather. From then until the arrival of the Great Heathen Army, Essex had formed part of Wessex. After the foundation of Danelaw, it appears that some of Essex would have been ceded to the Danes, but how much is not clear.\n\n880s\n\nWith the signing of the Treaty of Alfred and Guthrum, an event most commonly held to have taken place around 880 when Guthrum's people began settling East Anglia, Guthrum was neutralised as a threat. The Viking army, which had stayed at Fulham during the winter of 878\u2013879, sailed for Ghent and was active on the continent from 879 to 892.\n\nThere were local raids on the coast of Wessex throughout the 880s. In 882, Alfred fought a small sea battle against four Danish ships. Two of the ships were destroyed, and the others surrendered. This was one of four sea battles recorded in the Anglo-Saxon Chronicle, three of which involved Alfred. Similar small skirmishes with independent Viking raiders would have occurred for much of the period as they had for decades.\n\nIn 883, Pope Marinus exempted the Saxon quarter in Rome from taxation, probably in return for Alfred's promise to send alms annually to Rome, which may be the origin of the medieval tax called Peter's Pence. The pope sent gifts to Alfred, including what was reputed to be a piece of the True Cross.\n\nAfter the signing of the treaty with Guthrum, Alfred was spared any large-scale conflicts for some time. Despite this relative peace, the king was forced to deal with a number of Danish raids and incursions. Among these was a raid in Kent, an allied kingdom in South East England, during the year 885, which was possibly the largest raid since the battles with Guthrum. Asser's account of the raid places the Danish raiders at the Saxon city of Rochester, where they built a temporary fortress in order to besiege the city. In response to this incursion, Alfred led an Anglo-Saxon force against the Danes who, instead of engaging the army of Wessex, fled to their beached ships and sailed to another part of Britain. The retreating Danish force supposedly left Britain the following summer.\n\nNot long after the failed Danish raid in Kent, Alfred dispatched his fleet to East Anglia. The purpose of this expedition is debated, but Asser claims that it was for the sake of plunder. After travelling up the River Stour, the fleet was met by Danish vessels that numbered 13 or 16 (sources vary on the number), and a battle ensued. The Anglo-Saxon fleet emerged victorious, and as Huntingdon accounts, \"laden with spoils\". The victorious fleet was surprised when attempting to leave the River Stour and was attacked by a Danish force at the mouth of the river. The Danish fleet defeated Alfred's fleet, which may have been weakened in the previous engagement.\n\nA year later, in 886, Alfred reoccupied the city of London and set out to make it habitable again. Alfred entrusted the city to the care of his son-in-law \u00c6thelred, ealdorman of Mercia. The restoration of London progressed through the latter half of the 880s and is believed to have revolved around a new street plan; added fortifications in addition to the existing Roman walls; and, some believe, the construction of matching fortifications on the south bank of the River Thames.\n\nThis is also the period in which almost all chroniclers agree that the Saxon people of pre-unification England submitted to Alfred. In 888, \u00c6thelred, the archbishop of Canterbury, also died. One year later Guthrum, or Athelstan by his baptismal name, Alfred's former enemy and king of East Anglia, died and was buried in Hadleigh, Suffolk. Guthrum's death changed the political landscape for Alfred. The resulting power vacuum stirred other power-hungry warlords eager to take his place in the following years. The quiet years of Alfred's life were coming to a close.\n\nViking attacks (890s)\nAfter another lull, in the autumn of 892 or 893, the Danes attacked again. Finding their position in mainland Europe precarious, they crossed to England in 330 ships in two divisions. They entrenched themselves, the larger body at Appledore, Kent, and the lesser under Hastein,", "flag": 1, "segments": [[3114, 3124]], "strength": 5.5}
{"text": "\u1e24asan Ibn al-Haytham, Latinized as Alhazen (; full name  ; ), was a Muslim Arab mathematician, astronomer, and physicist of the Islamic Golden Age. Referred to as \"the father of modern optics\", he made significant contributions to the principles of optics and visual perception in particular. His most influential work is titled Kit\u0101b al-Man\u0101\u1e93ir (Arabic:, \"Book of Optics\"), written during 1011\u20131021, which survived in a Latin edition. A polymath, he also wrote on philosophy, theology and medicine.\n\nIbn al-Haytham was the first to explain that vision occurs when light reflects from an object and then passes to one's eyes. He was also the first to demonstrate that vision occurs in the brain, rather than in the eyes. Ibn al-Haytham was an early proponent of the concept that a hypothesis must be supported by experiments based on confirmable procedures or mathematical evidence\u2014an early pioneer in the scientific method five centuries before Renaissance scientists. On account of this, he is sometimes described as the world's \"first true scientist\".\n\nBorn in Basra, he spent most of his productive period in the Fatimid capital of Cairo and earned his living authoring various treatises and tutoring members of the nobilities. Ibn al-Haytham is sometimes given the byname al-Ba\u1e63r\u012b after his birthplace, or al-Mi\u1e63r\u012b (\"of Egypt\"). Al-Haytham was dubbed the \"Second Ptolemy\" by Abu'l-Hasan Bayhaqi and  \"The Physicist\" by John Peckham. Ibn al-Haytham paved the way for the modern science of physical optics.\n\nBiography \n\nIbn al-Haytham (Alhazen) was born c. 965 to an Arab family in Basra, Iraq,\nwhich was at the time part of the Buyid emirate.\nHis initial influences were in the study of religion and service to the community. At the time, the society had a number of conflicting views of religion that he ultimately sought to step aside from religion. This led to him delving into the study of mathematics and science. He held a position with the title vizier in his native Basra, and made a name for himself for his knowledge of applied mathematics.\nAs he claimed to be able to regulate the flooding of the Nile, he was invited to Fatimid Caliph by al-Hakim in order to realise a hydraulic project at Aswan. However, Ibn al-Haytham was forced to concede the impracticability of his project.\nUpon his return to Cairo, he was given an administrative post. After he proved unable to fulfill this task as well, he contracted the ire of the caliph Al-Hakim bi-Amr Allah, and is said to have been forced into hiding until the caliph's death in 1021, after which his confiscated possessions were returned to him.\nLegend has it that Alhazen feigned madness and was kept under house arrest during this period. During this time, he wrote his influential Book of Optics.\nAlhazen continued to live in Cairo, in the neighborhood of the famous University of al-Azhar, and lived from the proceeds of his literary production until his death in c. 1040. (A copy of Apollonius' Conics, written in Ibn al-Haytham's own handwriting exists in Aya Sofya: (MS Aya Sofya 2762, 307 fob., dated Safar 415 a.h. [1024]).)\n\nAmong his students were Sorkhab (Sohrab), a Persian from Semnan, and Abu al-Wafa Mubashir ibn Fatek, an Egyptian prince.\n\nBook of Optics \n\nAlhazen's most famous work is his seven-volume treatise on optics Kitab al-Manazir (Book of Optics), written from 1011 to 1021.\n\nOptics was translated into Latin by an unknown scholar at the end of the 12th century or the beginning of the 13th century. \n\nThis work enjoyed a great reputation during the Middle Ages. The Latin version of De aspectibus was translated at the end of the 14th century into Italian vernacular, under the title De li aspecti.\n\nIt was printed by Friedrich Risner in 1572, with the title Opticae thesaurus: Alhazeni Arabis libri septem, nuncprimum editi; Eiusdem liber De Crepusculis et nubium ascensionibus (English: Treasury of Optics: seven books by the Arab Alhazen, first edition; by the same, on twilight and the height of clouds). \nRisner is also the author of the name variant \"Alhazen\"; before Risner he was known in the west as Alhacen. \nWorks by Alhazen on geometric subjects were discovered in the Biblioth\u00e8que nationale in Paris in 1834 by E. A. Sedillot. In all, A. Mark Smith has accounted for 18 full or near-complete manuscripts, and five fragments, which are preserved in 14 locations, including one in the Bodleian Library at Oxford, and one in the library of Bruges.\n\nTheory of optics \n\nTwo major theories on vision prevailed in classical antiquity. The first theory, the emission theory, was supported by such thinkers as Euclid and Ptolemy, who believed that sight worked by the eye emitting rays of light. The second theory, the intromission theory supported by Aristotle and his followers, had physical forms entering the eye from an object. Previous Islamic writers (such as al-Kindi) had argued essentially on Euclidean, Galenist, or Aristotelian lines. The strongest influence on the Book of Optics was from Ptolemy's Optics, while the description of the anatomy and physiology of the eye was based on Galen's account. Alhazen's achievement was to come up with a theory that successfully combined parts of the mathematical ray arguments of Euclid, the medical tradition of Galen, and the intromission theories of Aristotle. Alhazen's intromission theory followed al-Kindi (and broke with Aristotle) in asserting that \"from each point of every colored body, illuminated by any light, issue light and color along every straight line that can be drawn from that point\". This left him with the problem of explaining how a coherent image was formed from many independent sources of radiation; in particular, every point of an object would send rays to every point on the eye. \n\nWhat Alhazen needed was for each point on an object to correspond to one point only on the eye. He attempted to resolve this by asserting that the eye would only perceive perpendicular rays from the object\u2014for any one point on the eye, only the ray that reached it directly, without being refracted by any other part of the eye, would be perceived. He argued, using a physical analogy, that perpendicular rays were stronger than oblique rays: in the same way that a ball thrown directly at a board might break the board, whereas a ball thrown obliquely at the board would glance off, perpendicular rays were stronger than refracted rays, and it was only perpendicular rays which were perceived by the eye. As there was only one perpendicular ray that would enter the eye at any one point, and all these rays would converge on the centre of the eye in a cone, this allowed him to resolve the problem of each point on an object sending many rays to the eye; if only the perpendicular ray mattered, then he had a one-to-one correspondence and the confusion could be resolved. He later asserted (in book seven of the Optics) that other rays would be refracted through the eye and perceived as if perpendicular. His arguments regarding perpendicular rays do not clearly explain why only perpendicular rays were,073 million or Rs 3.08 crore perceived; why would the weaker oblique rays not be perceived more weakly? His later argument that refracted rays would be perceived as if perpendicular does not seem persuasive. However, despite its weaknesses, no other theory of the time was so comprehensive, and it was enormously influential, particularly in Western Europe. Directly or indirectly, his De Aspectibus (Book of Optics) inspired much activity in optics between the 13th and 17th centuries. Kepler's later theory of the retinal image (which resolved the problem of the correspondence of points on an object and points in the eye) built directly on the conceptual framework of Alhazen.\n\nAlthough only one commentary on Alhazen's optics has survived the Islamic Middle Ages, Geoffrey Chaucer mentions the work in The Canterbury Tales: \n\"They spoke of Alhazen and Vitello,\nAnd Aristotle, who wrote, in their lives,\nOn strange mirrors and optical instruments.\"\n\nIbn al-Haytham was known for his contributions to Optics specifically thereof vision and theory of light. He assumed ray of light was radiated from specific points on the surface. Possibility of light propagation suggest that light was independent of vision. Light also moves at a very fast speed. \n\nAlhazen showed through experiment that light travels in straight lines, and carried out various experiments with lenses, mirrors, refraction, and reflection. His analyses of reflection and refraction considered the vertical and horizontal components of light rays separately.\n\nAlhazen studied the process of sight, the structure of the eye, image formation in the eye, and the visual system. Ian P. Howard argued in a 1996 Perception article that Alhazen should be credited with many discoveries and theories previously attributed to Western Europeans writing centuries later. For example, he described what became in the 19th century Hering's law of equal innervation. He wrote a description of vertical horopters 600 years before Aguilonius that is actually closer to the modern definition than Aguilonius's\u2014and his work on binocular disparity was repeated by Panum in 1858. Craig Aaen-Stockdale, while agreeing that Alhazen should be credited with many advances, has expressed some caution, especially when considering Alhazen in isolation from Ptolemy, with whom Alhazen was extremely familiar. Alhazen corrected a significant error of Ptolemy regarding binocular vision, but otherwise his account is very similar; Ptolemy also attempted to explain what is now called Hering's law. In general, Alhazen built on and expanded the optics of Ptolemy. \n\nIn a more detailed account of Ibn al-Haytham's contribution to the study of binocular vision based on Lejeune and Sabra, Raynaud showed that the concepts of correspondence, homonymous and crossed diplopia were in place in Ibn al-Haytham's optics. But contrary to Howard, he explained why Ibn al-Haytham did not give the circular figure of the horopter and why, by reasoning experimentally, he was in fact closer to the discovery of Panum's fusional area than that of the Vieth-M\u00fcller circle. In this regard, Ibn al-Haytham's theory of binocular vision faced two main limits: the lack of recognition of the role of the retina, and obviously the lack of an experimental investigation of ocular tracts.\n\nAlhazen's most original contribution was that, after describing how he thought the eye was anatomically constructed, he went on to consider how this anatomy would behave functionally as an optical system. His understanding of pinhole projection from his experiments appears to have influenced his consideration of image inversion in the eye, which he sought to avoid. He maintained that the rays that fell perpendicularly on the lens (or glacial humor as he called it) were further refracted outward as they left the glacial humor and the resulting image thus passed upright into the optic nerve at the back of the eye. He followed Galen in believing that the lens was the receptive organ of sight, although some of his work hints that he thought the retina was also involved.\n\nAlhazen's synthesis of light and vision adhered to the Aristotelian scheme, exhaustively describing the process of vision in a logical, complete fashion.\n\nScientific method \n\nAn aspect associated with Alhazen's optical research is related to systemic and methodological reliance on experimentation (i'tibar)(Arabic: \u0625\u0639\u062a\u0628\u0627\u0631) and controlled testing in his scientific inquiries.  Moreover, his experimental directives rested on combining classical physics (ilm tabi'i) with mathematics (ta'alim; geometry in particular). This mathematical-physical approach to experimental science supported most of his propositions in Kitab al-Manazir (The Optics; De aspectibus or Perspectivae) and grounded his theories of vision, light and colour, as well as his research in catoptrics and dioptrics (the study of the reflection and refraction of light, respectively). \n\nAccording to Matthias Schramm, Alhazen \"was the first to make a systematic use of the method of varying the experimental conditions in a constant and uniform manner, in an experiment showing that the intensity of the light-spot formed by the projection of the moonlight through two small apertures onto a screen diminishes constantly as one of the apertures is gradually blocked up.\" G. J. Toomer expressed some skepticism regarding Schramm's view, partly because at the time (1964) the Book of Optics had not yet been fully translated from Arabic, and Toomer was concerned that without context, specific passages might be read anachronistically. While acknowledging Alhazen's importance in developing experimental techniques, Toomer argued that Alhazen should not be considered in isolation from other Islamic and ancient thinkers. Toomer concluded his review by saying that it would not be possible to assess Schramm's claim that Ibn al-Haytham was the true founder of modern physics without translating more of Alhazen's work and fully investigating his influence on later medieval writers.\n\nAlhazen's problem \n\nHis work on catoptrics in Book V of the Book of Optics contains a discussion of what is now known as Alhazen's problem, first formulated by Ptolemy in 150 AD. It comprises drawing lines from two points in the plane of a circle meeting at a point on the circumference and making equal angles with the normal at that point. This is equivalent to finding the point on the edge of a circular billiard table at which a player must aim a cue ball at a given point to make it bounce off the table edge and hit another ball at a second given point. Thus, its main application in optics is to solve the problem, \"Given a light source and a spherical mirror, find the point on the mirror where the light will be reflected to the eye of an observer.\" This leads to an equation of the fourth degree. This eventually led Alhazen to derive a formula for the sum of fourth powers, where previously only the formulas for the sums of squares and cubes had been stated. His method can be readily generalized to find the formula for the sum of any integral powers, although he did not himself do this (perhaps because he only needed the fourth power to calculate the volume of the paraboloid he was interested in). He used his result on sums of integral powers to perform what would now be called an integration, where the formulas for the sums of integral squares and fourth powers allowed him to calculate the volume of a paraboloid. Alhazen eventually solved the problem using conic sections and a geometric proof. His solution was extremely long and complicated and may not have been understood by mathematicians reading him in Latin translation.\nLater mathematicians used Descartes' analytical methods to analyse the problem. An algebraic solution to the problem was finally found in 1965 by Jack M. Elkin, an actuarian. Other solutions were discovered in 1989, by Harald Riede and in 1997 by the Oxford mathematician Peter M. Neumann.\nRecently, Mitsubishi Electric Research Laboratories (MERL) researchers solved the extension of Alhazen's problem to general rotationally symmetric quadric mirrors including hyperbolic, parabolic and elliptical mirrors.\n\nCamera Obscura \nThe camera obscura was known to the ancient Chinese, and was described by the Han Chinese polymathic genius Shen Kuo in his scientific book Dream Pool Essays, published in the year 1088 C.E. Aristotle had discussed the basic principle behind it in his Problems, but Alhazen's work also contained the first clear description, outside of China, of camera obscura in the areas of the Middle East, Europe, Africa and India. and early analysis of the device.\n\nIbn al-Haytham used a camera obscura mainly to observe a partial solar eclipse.\nIn his essay, Ibn al-Haytham writes that he observed the sickle-like shape of the sun at the time of an eclipse. The introduction reads as follows: \"The image of the sun at the time of the eclipse, unless it is total, demonstrates that when its light passes through a narrow, round hole and is cast on a plane opposite to the hole it takes on the form of a moonsickle.\" \n\nIt is admitted that his findings solidified the importance in the history of the camera obscura but this treatise is important in many other respects.\n\nAncient optics and medieval optics were divided into optics and burning mirrors. Optics proper mainly focused on the study of vision, while burning mirrors focused on the properties of light and luminous rays. On the shape of the eclipse is probably one of the first attempts made by Ibn al-Haytham to articulate these two sciences.\n\nVery often Ibn al-Haytham's discoveries benefited from the intersection of mathematical and experimental contributions. This is the case with On the shape of the eclipse. Besides the fact that this treatise allowed more people to study partial eclipses of the sun, it especially allowed to better understand how the camera obscura works. This treatise is a physico-mathematical study of image formation inside the camera obscura. Ibn al-Haytham takes an experimental approach, and determines the result by varying the size and the shape of the aperture, the focal length of the camera, the shape and intensity of the light source.\n\nIn his work he explains the inversion of the image in the camera obscura, the fact that the image is similar to the source when the hole is small, but also the fact that the image can differ from the source when the hole is large. All these results are produced by using a point analysis of the image.\n\nOther contributions \n The Kitab al-Manazir (Book of Optics) describes several experimental observations that Alhazen made and how he used his results to explain certain optical phenomena using mechanical analogies. He conducted experiments with projectiles and concluded that only the impact of perpendicular projectiles on surfaces was forceful enough to make them penetrate, whereas surfaces tended to deflect oblique projectile strikes. For example, to explain refraction from a rare to a dense medium, he used the mechanical analogy of an iron ball thrown at a thin slate covering a wide hole in a metal sheet. A perpendicular throw breaks the slate and passes through, whereas an oblique one with equal force and from an equal distance does not. He also used this result to explain how intense, direct light hurts the eye, using a mechanical analogy: Alhazen associated'strong' lights with perpendicular rays and 'weak' lights with oblique ones. The obvious answer to the problem of multiple rays and the eye was in the choice of the perpendicular ray, since only one such ray from each point on the surface of the object could penetrate the eye.\n\nSudanese psychologist Omar Khaleefa has argued that Alhazen should be considered the founder of experimental psychology, for his pioneering work on the psychology of visual perception and optical illusions. Khaleefa has also argued that Alhazen should also be considered the \"founder of psychophysics\", a sub-discipline and precursor to modern psychology. Although Alhazen made many subjective reports regarding vision, there is no evidence that he used quantitative psychophysical techniques and the claim has been rebuffed.\n\nAlhazen offered an explanation of the Moon illusion, an illusion that played an important role in the scientific tradition of medieval Europe. Many authors repeated explanations that attempted to solve the problem of the Moon appearing larger near the horizon than it does when higher up in the sky. Alhazen argued against Ptolemy's refraction theory, and defined the problem in terms of perceived, rather than real, enlargement. He said that judging the distance of an object depends on there being an uninterrupted sequence of intervening bodies between the object and the observer. When the Moon is high in the sky there are no intervening objects, so the Moon appears close. The perceived size of an object of constant angular size varies with its perceived distance. Therefore, the Moon appears closer and smaller high in the sky, and further and larger on the horizon. Through works by Roger Bacon, John Pecham and Witelo based on Alhazen's explanation, the Moon illusion gradually came to be accepted as a psychological phenomenon, with the refraction theory being rejected in the 17th century. Although Alhazen is often credited with the perceived distance explanation, he was not the first author to offer it. Cleomedes ( 2nd century) gave this account (in addition to refraction), and he credited it to Posidonius ( 135\u201350 BCE). Ptolemy may also have offered this explanation in his Optics, but the text is obscure. Alhazen's writings were more widely available in the Middle Ages than those of these earlier authors, and that probably explains why Alhazen received the credit.\n\nOther works on physics\n\nOptical treatises \n\nBesides the Book of Optics, Alhazen wrote several other treatises on the same subject, including his Risala fi l-Daw (Treatise on Light). He investigated the properties of luminance, the rainbow, eclipses, twilight, and moonlight. Experiments with mirrors and the refractive interfaces between air, water, and glass cubes, hemispheres, and quarter-spheres provided the foundation for his theories on catoptrics.\n\n Celestial physics \nAlhazen discussed the physics of the celestial region in his Epitome of Astronomy, arguing that Ptolemaic models must be understood in terms of physical objects rather than abstract hypotheses\u2014in other words that it should be possible to create physical models where (for example) none of the celestial bodies would collide with each other. The suggestion of mechanical models for the Earth centred Ptolemaic model \"greatly contributed to the eventual triumph of the Ptolemaic system among the Christians of the West\". Alhazen's determination to root astronomy in the realm of physical objects was important, however, because it meant astronomical hypotheses \"were accountable to the laws of physics\", and could be criticised and improved upon in those terms.\n\nHe also wrote Maqala fi daw al-qamar (On the Light of the Moon).\n\n Mechanics \n\nIn his work, Alhazen discussed theories on the motion of a body. In his Treatise on Place, Alhazen disagreed with Aristotle's view that nature abhors a void, and he used geometry in an attempt to demonstrate that place (al-makan) is the imagined three-dimensional void between the inner surfaces of a containing body.\n\n Astronomical works \n\n On the Configuration of the World \n\nIn his On the", "flag": 1, "segments": [[1681, 1691]], "strength": 5.5}
{"text": "\u0100nanda (5th4th century BCE) was the primary attendant of the Buddha and one of his ten principal disciples. Among the Buddha's many disciples, \u0100nanda stood out for having the best memory. Most of the texts of the early Buddhist Sutta-Pi\u1e6daka (P\u0101li; ) are attributed to his recollection of the Buddha's teachings during the First Buddhist Council. For that reason, he is known as the Treasurer of the Dhamma, with Dhamma () referring to the Buddha's teaching. In Early Buddhist Texts, \u0100nanda was the first cousin of the Buddha. Although the early texts do not agree on many parts of \u0100nanda's early life, they do agree that \u0100nanda was ordained as a monk and that Pu\u1e47\u1e47a Mant\u0101n\u012bputta () became his teacher. Twenty years in the Buddha's ministry, \u0100nanda became the attendant of the Buddha, when the Buddha selected him for this task. \u0100nanda performed his duties with great devotion and care, and acted as an intermediary between the Buddha and the laypeople, as well as the sa\u1e45gha (). He accompanied the Buddha for the rest of his life, acting not only as an assistant, but also a secretary and a mouthpiece.\n\nScholars are skeptical about the historicity of many events in \u0100nanda's life, especially the First Council, and consensus about this has yet to be established. A traditional account can be drawn from early texts, commentaries, and post-canonical chronicles. \u0100nanda had an important role in establishing the order of bhikkhun\u012bs (), when he requested the Buddha on behalf of the latter's foster-mother Mah\u0101paj\u0101pati Gotam\u012b () to allow her to be ordained. \u0100nanda also accompanied the Buddha in the last year of his life, and therefore was witness to many tenets and principles that the Buddha conveyed before his death, including the well-known principle that the Buddhist community should take his teaching and discipline as their refuge, and that he would not appoint a new leader. The final period of the Buddha's life also shows that \u0100nanda was very much attached to the Buddha's person, and he saw the Buddha's passing with great sorrow.\n\nShortly after the Buddha's death, the First Council was convened, and \u0100nanda managed to attain enlightenment just before the council started, which was a requirement. He had a historical role during the council as the living memory of the Buddha, reciting many of the Buddha's discourses and checking them for accuracy. During the same council, however, he was chastised by Mah\u0101kassapa () and the rest of the sa\u1e45gha for allowing women to be ordained and failing to understand or respect the Buddha at several crucial moments. \u0100nanda continued to teach until the end of his life, passing on his spiritual heritage to his pupils S\u0101\u1e47av\u0101s\u012b () and Majjhantika (), among others, who later assumed leading roles in the Second and Third Councils. \u0100nanda died 20 years after the Buddha, and st\u016bpas (monuments) were erected at the river where he died.\n\n\u0100nanda is one of the most loved figures in Buddhism. He was known for his memory, erudition and compassion, and was often praised by the Buddha for these matters. He functioned as a foil to the Buddha, however, in that he still had worldly attachments and was not yet enlightened, as opposed to the Buddha. In the Sanskrit textual traditions, \u0100nanda is considered the patriarch of the Dhamma who stood in a spiritual lineage, receiving the teaching from Mah\u0101kassapa and passing them on to his own pupils. \u0100nanda has been honored by bhikkhun\u012bs since early medieval times for his merits in establishing the nun's order. In recent times, the composer Richard Wagner and Indian poet Rabindranath Tagore were inspired by stories about \u0100nanda in their work.\n\nName \nThe word \u0101nanda means 'bliss, joy' in P\u0101li and in Sanskrit. P\u0101li commentaries explain that when \u0100nanda was born, his relatives were joyous about this. Texts from the M\u016blasarv\u0101stiv\u0101da tradition, however, state that since \u0100nanda was born on the day of the Buddha's enlightenment, there was great rejoicing in the cityhence the name.\n\nAccounts\n\nPrevious lives \nAccording to the texts, in a previous life, \u0100nanda made an aspiration to become a Buddha's attendant. He made this aspiration in the time of a previous Buddha called Padumuttara, many eons (, ) before the present age. He met the attendant of Padumuttara Buddha and aspired to be like him in a future life. After having done many good deeds, he made his resolution known to the Padumuttara Buddha, who confirmed that his wish will come true in a future life. After having been born and reborn throughout many lifetimes, and doing many good deeds, he was born as \u0100nanda in the time of the current Buddha Gotama.\n\nEarly life \n\n\u0100nanda was born in the same time period as the Buddha (formerly Prince Siddhattha), which scholars place at 5th4th centuries BCE. Tradition says that \u0100nanda was the first cousin of the Buddha, his father being the brother of Suddhodana (), the Buddha's father. In the P\u0101li and M\u016blasarv\u0101stiv\u0101da textual traditions, his father was Amitodana operations for 24 months, the U.K. (), but the Mah\u0101vastu states that his father was \u015auklodanaboth are brothers of Suddhodana. The Mah\u0101vastu also mentions that \u0100nanda's mother's name was M\u1e5bg\u012b (Sanskrit; lit. 'little deer'; P\u0101li is unknown). The P\u0101li tradition has it that \u0100nanda was born on the same day as Prince Siddhatta (), but texts from the M\u016blasarv\u0101stiv\u0101da and subsequent Mah\u0101y\u0101na traditions state \u0100nanda was born at the same time the Buddha attained enlightenment (when Prince Siddhattha was 35 years old), and was therefore much younger than the Buddha. The latter tradition is corroborated by several instances in the Early Buddhist Texts, in which \u0100nanda appears younger than the Buddha, such as the passage in which the Buddha explained to \u0100nanda how old age was affecting him in body and mind. It is also corroborated by a verse in the P\u0101li text called Therag\u0101th\u0101, in which \u0100nanda stated he was a \"learner\" for twenty-five years, after which he attended to the Buddha for another twenty-five years.Following the P\u0101li, Mah\u012b\u015basaka and Dharmaguptaka textual traditions, \u0100nanda became a monk in the second year of the Buddha's ministry, during the Buddha's visit to Kapilavatthu (). He was ordained by the Buddha himself, together with many other princes of the Buddha's clan (, ), in the mango grove called Anupiya, part of Malla territory. According to a text from the Mah\u0101sa\u1e45ghika tradition, King Suddhodana wanted the Buddha to have more followers of the khattiya caste (), and less from the brahmin (priest) caste. He therefore ordered that any khattiya who had a brother follow the Buddha as a monk, or had his brother do so. \u0100nanda used this opportunity, and asked his brother Devadatta to stay at home, so that he could leave for the monkhood. The later timeline from the M\u016blasarv\u0101stiv\u0101da texts and the P\u0101li Therag\u0101th\u0101, however, have \u0100nanda ordain much later, about twenty-five years before the Buddha's deathin other words, twenty years in the Buddha's ministry. Some Sanskrit sources have him ordain even later. The M\u016blasarv\u0101stiv\u0101da texts on monastic discipline (P\u0101li and ) relate that soothsayers predicted \u0100nanda would be the Buddha's attendant. In order to prevent \u0100nanda from leaving the palace to ordain, his father brought him to Ves\u0101l\u012b () during the Buddha's visit to Kapilavatthu, but later the Buddha met and taught \u0100nanda nonetheless. On a similar note, the Mah\u0101vastu relates, however, that M\u1e5bg\u012b was initially opposed to \u0100nanda joining the holy life, because his brother Devadatta had already ordained and left the palace. \u0100nanda responded to his mother's resistance by moving to Videha () and lived there, taking a vow of silence. This led him to gain the epithet Videhamuni (), meaning 'the silent wise one from Videha'. When \u0100nanda did become ordained, his father had him ordain in Kapilavatthu in the Nigrodh\u0101r\u0101ma monastery () with much ceremony, \u0100nanda's preceptor (; ) being a certain Da\u015bab\u0101la K\u0101\u015byapa.\n\nAccording to the P\u0101li tradition, \u0100nanda's first teachers were Bela\u1e6d\u1e6dhas\u012bsa and Pu\u1e47\u1e47a Mant\u0101n\u012bputta. It was Pu\u1e47\u1e47a's teaching that led \u0100nanda to attain the stage of sot\u0101panna (), an attainment preceding that of enlightenment. \u0100nanda later expressed his debt to Pu\u1e47\u1e47a. Another important figure in the life of \u0100nanda was S\u0101riputta (), one of the Buddha's main disciples. S\u0101riputta often taught \u0100nanda about the finer points of Buddhist doctrine; they were in the habit of sharing things with one another, and their relationship is described as a good friendship. In some M\u016blasarv\u0101stiv\u0101da texts, an attendant of \u0100nanda is also mentioned who helped motivate \u0100nanda when he was banned from the First Buddhist Council. He was a \"Vajjiputta\" (), i.e. someone who originated from the Vajji confederacy. According to later texts, an enlightened monk also called Vajjiputta () had an important role in \u0100nanda's life. He listened to a teaching of \u0100nanda and realized that \u0100nanda was not enlightened yet. Vajjiputta encouraged \u0100nanda to talk less to laypeople and deepen his meditation practice by retreating in the forest, advice that very much affected \u0100nanda.\n\nAttending to the Buddha \n\nIn the first twenty years of the Buddha's ministry, the Buddha had several personal attendants. However, after these twenty years, when the Buddha was aged 55, the Buddha announced that he had need for a permanent attendant. The Buddha had been growing older, and his previous attendants had not done their job very well. Initially, several of the Buddha's foremost disciples responded to his request, but the Buddha did not accept them. All the while \u0100nanda remained quiet. When he was asked why, he said that the Buddha would know best whom to choose, upon which the Buddha responded by choosing \u0100nanda. \u0100nanda agreed to take on the position, on the condition that he did not receive any material benefits from the Buddha. Accepting such benefits would open him up to criticism that he chose the position because of ulterior motives. He also requested that the Buddha allow him to accept invitations on his behalf, allow him to ask questions about his doctrine, and repeat any teaching that the Buddha had taught in \u0100nanda's absence. These requests would help people trust \u0100nanda and show that the Buddha was sympathetic to his attendant. Furthermore, \u0100nanda considered these the real advantages of being an attendant, which is why he requested them.\n\nThe Buddha agreed to \u0100nanda's conditions, and \u0100nanda became the Buddha's attendant, accompanying the Buddha on most of his wanderings. \u0100nanda took care of the Buddha's daily practical needs, by doing things such as bringing water and cleaning the Buddha's dwelling place. He is depicted as observant and devoted, even guarding the dwelling place at night. \u0100nanda takes the part of interlocutor in many of the recorded dialogues. He tended the Buddha for a total of 25 years, a duty which entailed much work. His relationship with the Buddha is depicted as warm and trusting: when the Buddha grew ill, \u0100nanda had a sympathetic illness; when the Buddha grew older, \u0100nanda kept taking care of him with devotion.\n\n\u0100nanda sometimes literally risked his life for his teacher. At one time, the rebellious monk Devadatta tried to kill the Buddha by having a drunk and wild elephant released in the Buddha's presence. \u0100nanda stepped in front of the Buddha to protect him. When the Buddha told him to move, he refused, although normally he always obeyed the Buddha. Through a supernatural accomplishment (; ) the Buddha then moved \u0100nanda aside and subdued the elephant, by touching it and speaking to it with loving-kindness.\n\n\u0100nanda often acted as an intermediary and secretary, passing on messages from the Buddha, informing the Buddha of news, invitations, or the needs of lay people, and advising lay people who wanted to provide gifts to the sa\u1e45gha. At one time, Mah\u0101paj\u0101pat\u012b, the Buddha's foster-mother, requested to offer robes for personal use for the Buddha. She said that even though she had raised the Buddha in his youth, she never gave anything in person to the young prince; she now wished to do so. The Buddha initially insisted that she give the robe to the community as a whole rather than to be attached to his person. However, \u0100nanda interceded and mediated, suggesting that the Buddha had better accept the robe. Eventually the Buddha did, but not without pointing out to \u0100nanda that good deeds like giving should always be done for the sake of the action itself, not for the sake of the person.\n\nThe texts say that the Buddha sometimes asked \u0100nanda to substitute for him as teacher, and was often praised by the Buddha for his teachings. \u0100nanda was often given important teaching roles, such as regularly teaching Queen Mallik\u0101, Queen S\u0101m\u0101vat\u012b, () and other people from the ruling class. Once \u0100nanda taught a number of King Udena ()'s concubines. They were so impressed by \u0100nanda's teaching, that they gave him five hundred robes, which \u0100nanda accepted. Having heard about this, King Udena criticized \u0100nanda for being greedy; \u0100nanda responded by explaining how every single robe was carefully used, reused and recycled by the monastic community, prompting the king to offer another five hundred robes. \u0100nanda also had a role in the Buddha's visit to Ves\u0101l\u012b. In this story, the Buddha taught the well-known text Ratana Sutta to \u0100nanda, which \u0100nanda then recited in Ves\u0101l\u012b, ridding the city from illness, drought and evil spirits in the process. Another well-known passage in which the Buddha taught \u0100nanda is the passage about spiritual friendship (). In this passage, \u0100nanda stated that spiritual friendship is half of the holy life; the Buddha corrected \u0100nanda, stating that such friendship is the entire holy life. In summary, \u0100nanda worked as an assistant, intermediary and a mouthpiece, helping the Buddha in many ways, and learning his teachings in the process.\n\nResisting temptations \n\u0100nanda was attractive in appearance. A P\u0101li account related that a bhikkhun\u012b (nun) became enamored with \u0100nanda, and pretended to be ill to have \u0100nanda visit her. When she realized the error of her ways, she confessed her mistakes to \u0100nanda. Other accounts relate that a low-caste woman called Prak\u1e5bti (also known in China as ) fell in love with \u0100nanda, and persuaded her mother M\u0101ta\u1e45g\u012b to use a black magic spell to enchant him. This succeeded, and \u0100nanda was lured into her house, but came to his senses and called upon the help of the Buddha. The Buddha then taught Prak\u1e5bti to reflect on the repulsive qualities of the human body, and eventually Prak\u1e5bti was ordained as a bhikkhun\u012b, giving up her attachment for \u0100nanda. In an East Asian version of the story in the \u015a\u016bra\u1e43gamas\u016btra, the Buddha sent Ma\u00f1ju\u015br\u012b to help \u0100nanda, who used recitation to counter the magic charm. The Buddha then continued by teaching \u0100nanda and other listeners about the Buddha nature.\n\nEstablishing the nun's order \n\nIn the role of mediator between the Buddha and the lay communities, \u0100nanda sometimes made suggestions to the Buddha for amendments in the monastic discipline. Most importantly, the early texts attribute the inclusion of women in the early sa\u1e45gha (monastic order) to \u0100nanda. Fifteen years after the Buddha's enlightenment, his foster mother Mah\u0101paj\u0101pat\u012b came to see him to ask him to be ordained as the first Buddhist bhikkhun\u012b. Initially, the Buddha refused this. Five years later, Mah\u0101paj\u0101pat\u012b came to request the Buddha again, this time with a following of other S\u0101kiya women, including the Buddha's former wife Yasodhar\u0101 (). They had walked, looked dirty, tired and depressed, and \u0100nanda felt pity for them. \u0100nanda therefore confirmed with the Buddha whether women could become enlightened as well. Although the Buddha conceded this, he did not allow the S\u0101kiya women to be ordained yet. \u0100nanda then discussed with the Buddha how Mah\u0101paj\u0101pat\u012b took care of him during his childhood, after the death of his real mother. \u0100nanda also mentioned that previous Buddhas had also ordained bhikkhun\u012bs. In the end, the Buddha allowed the S\u0101kiya women to be ordained, being the start of the bhikkhun\u012b order. \u0100nanda had Mah\u0101paj\u0101pati ordained by her acceptance of a set of rules, set by the Buddha. These came to be known as the garudhamma, and they describe the subordinate relation of the bhikkhun\u012b community to that of the bhikkhus or monks. Scholar of Asian religions Reiko Ohnuma argues that the debt the Buddha had toward his foster-mother Mah\u0101paj\u0101pati may have been the main reason for his concessions with regard to the establishment of a bhikkhun\u012b order.\n\nMany scholars interpret this account to mean that the Buddha was reluctant in allowing women to be ordained, and that \u0100nanda successfully persuaded the Buddha to change his mind. For example, Indologist and translator I.B. Horner wrote that \"this is the only instance of his [the Buddha] being over-persuaded in argument\". However, some scholars interpret the Buddha's initial refusal rather as a test of resolve, following a widespread pattern in the P\u0101li Canon and in monastic procedure of repeating a request three times before final acceptance. Some also argue that the Buddha was believed by Buddhists to be omniscient, and therefore is unlikely to have been depicted as changing his mind. Other scholars argue that other passages in the texts indicate the Buddha intended all along to establish a bhikkhun\u012b order. Regardless, during the acceptance of women into the monastic order, the Buddha told \u0100nanda that the Buddha's Dispensation would last shorter because of this. At the time, the Buddhist monastic order consisted of wandering celibate males, without many monastic institutions. Allowing women to join the Buddhist celibate life might have led to dissension, as well as temptation between the sexes. The garudhamma, however, were meant to fix these problems, and prevent the dispensation from being curtailed.\n\nThere are some chronological discrepancies in the traditional account of the setting up of the bhikkhun\u012b order. According to the P\u0101li and Mah\u012b\u015basaka textual traditions, the bhikkhun\u012b order was set up five years after the Buddha's enlightenment, but, according to most textual traditions, \u0100nanda only became attendant twenty years after the Buddha's enlightenment. Furthermore, Mah\u0101paj\u0101pati was the Buddha's foster mother, and must therefore have been considerably older than him. However, after the bhikkhun\u012b order was established, Mah\u0101paj\u0101pati still had many audiences with the Buddha, as reported in P\u0101li and Chinese Early Buddhist Texts. Because of this and other reasons, it could be inferred that establishment of the bhikkhun\u012b order actually took place early in the Buddha's ministry. If this is the case, \u0100nanda's role in establishing the order becomes less likely. Some scholars therefore interpret the names in the account, such as \u0100nanda and Mah\u0101paj\u0101pati, as symbols, representing groups rather than specific individuals.\n\nAccording to the texts, \u0100nanda's role in founding the bhikkhun\u012b order made him popular with the bhikkhun\u012b community. \u0100nanda often taught bhikkhun\u012bs, often encouraged women to ordain, and when he was criticized by the monk Mah\u0101kassapa, several bhikkhun\u012bs tried to defend him. According to Indologist Oskar von Hin\u00fcber, \u0100nanda's pro-bhikkhun\u012b attitude may well be the reason why there was frequent discussion between \u0100nanda and Mah\u0101kassapa, eventually leading Mah\u0101kasapa to charge \u0100nanda with several offenses during the First Buddhist Council. Von Hin\u00fcber further argues that the establishment of the bhikkhun\u012b order may have well been initiated by \u0100nanda  the Buddha's death, and the introduction of Mah\u0101paj\u0101pati as the person requesting to do so is merely a literary device to connect the ordination of women with the person of the Buddha, through his foster mother. Von Hin\u00fcber concludes this based on several patterns in the early texts, including the apparent distance between the Buddha and the bhikkhun\u012b order, and the frequent discussions and differences of opinion that take place between \u0100nanda and Mah\u0101kassapa. Some scholars have seen merits in von Hin\u00fcber's argument with regard to the pro- and anti-factions, but as of 2017, no definitive evidence has been found for the theory of establishment of the bhikkhuni order after the Buddha's death. Buddhist studies scholar Bhikkhu An\u0101layo has responded to most of von Hinuber's arguments, writing: \"Besides requiring too many assumptions, this hypothesis conflicts with nearly 'all the evidence preserved in the texts together'\", arguing that it was monastic discipline that created a distance between the Buddha and the bhikkhun\u012bs, and even so, there were many places in the early texts where the Buddha did address bhikkhun\u012bs directly.\n\nThe Buddha's death \n\nDespite", "flag": 1, "segments": [[1192, 1202]], "strength": 5.5}
{"text": "Apollo 13 (April 1117, 1970) was the seventh crewed mission in the Apollo space program and the third meant to land on the Moon. The craft was launched from Kennedy Space Center on April\u00a011, 1970, but the lunar landing was aborted after an oxygen tank in the service module (SM) failed two days into the mission. The crew instead looped around the Moon and returned safely to Earth on April\u00a017. The mission was commanded by Jim Lovell, with Jack Swigert as command module (CM) pilot and Fred Haise as Lunar Module (LM) pilot. Swigert was a late replacement for Ken Mattingly, who was grounded after exposure to rubella.\n\nA routine stir of an oxygen tank ignited damaged wire insulation inside it, causing an explosion that vented the contents of both of the SM's oxygen tanks to space. Without oxygen, needed for breathing and for generating electric power, the SM's propulsion and life support systems could not operate. The CM's systems had to be shut down to conserve its remaining resources for reentry, forcing the crew to transfer to the LM as a lifeboat. With the lunar landing canceled, mission controllers worked to bring the crew home alive.\n\nAlthough the LM was designed to support two men on the lunar surface for two days, Mission Control in Houston improvised new procedures so it could support three men for four days. The crew experienced great hardship, caused by limited power, a chilly and wet cabin and a shortage of potable water. There was a critical need to adapt the CM's cartridges for the carbon dioxide scrubber system to work in the LM; the crew and mission controllers were successful in improvising a solution. The astronauts' peril briefly renewed public interest in the Apollo program; tens of millions watched the splashdown in the South Pacific Ocean on television.\n\nAn investigative review board found fault with preflight testing of the oxygen tank and Teflon being placed inside it. The board recommended changes, including minimizing the use of potentially combustible items inside the tank; this was done for Apollo 14. The story of Apollo\u00a013 has been dramatized several times, most notably in the 1995 film Apollo\u00a013 \u2013 based on Lost Moon, the 1994 memoir co-authored by Lovell \u2013 and an episode of the 1998 miniseries From the Earth to the Moon.\n\nBackground \nIn 1961, U.S. President John F. Kennedy challenged his nation to land an astronaut on the Moon by the end of the decade, with a safe return to Earth. NASA worked towards this goal incrementally, sending astronauts into space during Project Mercury and Project Gemini, leading up to the Apollo program. The goal was achieved with Apollo 11, which landed on the Moon on July\u00a020, 1969. Neil Armstrong and Buzz Aldrin walked on the lunar surface while Michael Collins orbited the Moon in Command Module Columbia. The mission returned to Earth on July\u00a024, 1969, fulfilling Kennedy's challenge.\n\nNASA had contracted for fifteen Saturn\u00a0V rockets to achieve the goal; at the time no one knew how many missions this would require. Since success was obtained in 1969 with the sixth SaturnV on Apollo\u00a011, nine rockets remained available for a hoped-for total of ten landings. After the excitement of Apollo\u00a011, the general public grew apathetic towards the space program and Congress continued to cut NASA's budget; Apollo 20 was canceled. Despite the successful lunar landing, the missions were considered so risky that astronauts could not afford life insurance to provide for their families if they died in space.\n\nEven before the first U.S. astronaut entered space in 1961, planning for a centralized facility to communicate with the spacecraft and monitor its performance had begun, for the most part the brainchild of Christopher C. Kraft Jr., who became NASA's first flight director. During John Glenn's Mercury Friendship 7 flight in February 1962 (the first crewed orbital flight by the U.S.), one of Kraft's decisions was overruled by NASA managers. He was vindicated by post-mission analysis and implemented a rule that, during the mission, the flight director's word was absolute \u2013 to overrule him, NASA would have to fire him on the spot. Flight directors during Apollo had a one-sentence job description, \"The flight director may take any actions necessary for crew safety and mission success.\"\n\nIn 1965, Houston's Mission Control Center opened, in part designed by Kraft and now named for him.  In Mission Control, each flight controller, in addition to monitoring telemetry from the spacecraft, was in communication via voice loop to specialists in a Staff Support Room (or \"back room\"), who focused on specific spacecraft systems.\n\nApollo\u00a013 was to be the second H mission, meant to demonstrate precision lunar landings and explore specific sites on the Moon. With Kennedy's goal accomplished by Apollo\u00a011, and Apollo 12 demonstrating that the astronauts could perform a precision landing, mission planners were able to focus on more than just landing safely and having astronauts minimally trained in geology gather lunar samples to take home to Earth. There was a greater role for science on Apollo\u00a013, especially for geology, something emphasized by the mission's motto, Ex luna, scientia (From the Moon, knowledge).\n\nAstronauts and key Mission Control personnel \n\nApollo\u00a013's mission commander, Jim Lovell, was 42 years old at the time of the spaceflight. He was a graduate of the United States Naval Academy and had been a naval aviator and test pilot before being selected for the second group of astronauts in 1962; he flew with Frank Borman in Gemini\u00a07 in 1965 and Buzz Aldrin in Gemini\u00a012 the following year before flying in Apollo 8 in 1968, the first spacecraft to orbit the Moon. At the time of Apollo 13, Lovell was the NASA astronaut with the most time in space, with 572 hours over the three missions.\n\nJack Swigert, the command module pilot (CMP), was 38\u00a0years old and held a B.S. in mechanical engineering and an M.S. in aerospace science; he had served in the Air Force and in state Air National Guards and was an engineering test pilot before being selected for the fifth group of astronauts in 1966. Fred Haise, the lunar module pilot (LMP), was 35 years old. He held a B.S. in aeronautical engineering, had been a Marine Corps fighter pilot, and was a civilian research pilot for NASA when he was selected as a Group5 astronaut.\n\nAccording to the standard Apollo crew rotation, the prime crew for Apollo\u00a013 would have been the backup crew for Apollo 10, with Mercury and Gemini veteran Gordon Cooper in command, Donn F. Eisele as CMP and Edgar Mitchell as LMP. Deke Slayton, NASA's Director of Flight Crew Operations, never intended to rotate Cooper and Eisele to a prime crew assignment, as both were out of favorCooper for his lax attitude towards training, and Eisele for incidents aboard Apollo7 and an extramarital affair. He assigned them to the backup crew because no other veteran astronauts were available. Slayton's original choices for Apollo\u00a013 were Alan Shepard as commander, Stuart Roosa as CMP, and Mitchell as LMP. However, management felt Shepard needed more training time, as he had only recently resumed active status after surgery for an inner ear disorder and had not flown since 1961. Thus, Lovell's crew (himself, Haise and Ken Mattingly), having all backed up Apollo 11 and being slated for Apollo 14, was swapped with Shepard's.\n\nSwigert was originally CMP of Apollo\u00a013's backup crew, with John Young as commander and Charles Duke as lunar module pilot. Seven days before launch, Duke contracted rubella from a friend of his son. This exposed both the prime and backup crews, who trained together. Of the five, only Mattingly was not immune through prior exposure. Normally, if any member of the prime crew had to be grounded, the remaining crew would be replaced as well, and the backup crew substituted, but Duke's illness ruled this out, so two days before launch, Mattingly was replaced by Swigert. Mattingly never developed rubella and later flew on Apollo 16.\n\nFor Apollo, a third crew of astronauts, known as the support crew, was designated in addition to the prime and backup crews used on projects Mercury and Gemini. Slayton created the support crews because James McDivitt, who would command Apollo 9, believed that, with preparation going on in facilities across the US, meetings that needed a member of the flight crew would be missed. Support crew members were to assist as directed by the mission commander. Usually low in seniority, they assembled the mission's rules, flight plan, and checklists, and kept them updated; for Apollo\u00a013, they were Vance D. Brand, Jack Lousma and either William Pogue or Joseph Kerwin.\n\nFor Apollo\u00a013, flight directors were Gene Kranz, White team (the lead flight director); Glynn Lunney, Black team; Milton Windler, Maroon team and Gerry Griffin, Gold team. The CAPCOMs (the person in Mission Control, during the Apollo program an astronaut, who was responsible for voice communications with the crew) for Apollo\u00a013 were Kerwin, Brand, Lousma, Young and Mattingly.\n\nMission insignia and call signs \n\nThe Apollo\u00a013 mission insignia depicts the Greek god of the Sun, Apollo, with three horses pulling his chariot across the face of the Moon, and the Earth seen in the distance. This is meant to symbolize the Apollo flights bringing the light of knowledge to all people. The mission motto, Ex luna, scientia (\"From the Moon, knowledge\"), appears. In choosing it, Lovell adapted the motto of his alma mater, the Naval Academy, Ex scientia, tridens (\"From knowledge, sea power\").\n\nOn the patch, the mission number appeared in Roman numerals as Apollo XIII. It did not have to be modified after Swigert replaced Mattingly, as it is one of only two Apollo mission insigniathe other being Apollo 11not to include the names of the crew. It was designed by artist Lumen Martin Winter, who based it on a mural he had painted for the St. Regis Hotel in New York City. The mural was later purchased by actor Tom Hanks, who portrayed Lovell in the movie Apollo\u00a013, and is now in the Captain James A. Lovell Federal Health Care Center in Illinois.\n\nThe mission's motto was in Lovell's mind when he chose the call sign Aquarius for the lunar module, taken from Aquarius, the bringer of water. Some in the media erroneously reported that the call sign was taken from a song by that name from the musical Hair. The command module's call sign, Odyssey, was chosen not only for its Homeric association but to refer to the recent movie, 2001: A Space Odyssey, based on a short story by science fiction author Arthur C. Clarke. In his book, Lovell indicated he chose the name Odyssey because he liked the word and its definition: a long voyage with many changes of fortune.\n\nSpace vehicle \n\nThe Saturn V rocket used to carry Apollo\u00a013 to the Moon was numbered SA-508, and was almost identical to those used on Apollo8 through 12. Including the spacecraft, the rocket weighed in at. The S-IC stage's engines were rated to generate  less total thrust than Apollo 12's, though they remained within specifications. Extra propellant was carried as a test, since future J missions to the Moon would require more propellant for their heavier payloads. This made the vehicle the heaviest yet flown by NASA, and Apollo\u00a013 was visibly slower to clear the launch tower than earlier missions.\n\nThe Apollo\u00a013 spacecraft consisted of Command Module\u00a0109 and Service Module\u00a0109 (together CSM-109), called Odyssey, and Lunar Module7 (LM-7), called Aquarius. Also considered part of the spacecraft was the launch escape system, which would propel the command module (CM) to safety in the event of a problem during liftoff, and the Spacecraft\u2013LM Adapter, numbered as SLA-16, which housed the lunar module (LM) during the first hours of the mission.\n\nThe LM stages, CM and service module (SM) were received at Kennedy Space Center (KSC) in June 1969; the portions of the Saturn\u00a0V were received in June and July. Thereafter, testing and assembly proceeded, culminating with the rollout of the launch vehicle, with the spacecraft atop it, on December 15, 1969. Apollo\u00a013 was originally scheduled for launch on March 12, 1970; in January of that year, NASA announced the mission would be postponed until April 11, both to allow more time for planning and to spread the Apollo missions over a longer period of time. The plan was to have two Apollo flights per year and was in response to budgetary constraints that had recently seen the cancellation of Apollo 20.\n\nTraining and preparation \n\nThe Apollo\u00a013 prime crew undertook over 1,000 hours of mission-specific training, more than five hours for every hour of the mission's ten-day planned duration. Each member of the prime crew spent over 400 hours in simulators of the CM and (for Lovell and Haise) of the LM at KSC and at Houston, some of which involved the flight controllers at Mission Control. Flight controllers participated in many simulations of problems with the spacecraft in flight, which taught them how to react in an emergency.  Specialized simulators at other locations were also used by the crew members.\n\nThe astronauts of Apollo 11 had minimal time for geology training, with only six months between crew assignment and launch; higher priorities took much of their time. Apollo 12 saw more such training, including practice in the field, using a CAPCOM and a simulated backroom of scientists, to whom the astronauts had to describe what they saw. Scientist-astronaut Harrison Schmitt saw that there was limited enthusiasm for geology field trips. Believing an inspirational teacher was needed, Schmitt arranged for Lovell and Haise to meet his old professor, Caltech's Lee Silver. The two astronauts, and backups Young and Duke, went on a field trip with Silver at their own time and expense. At the end of their week together, Lovell made Silver their geology mentor, who would be extensively involved in the geology planning for Apollo\u00a013. Farouk El-Baz oversaw the training of Mattingly and his backup, Swigert, which involved describing and photographing simulated lunar landmarks from airplanes. El-Baz had all three prime crew astronauts describe geologic features they saw during their flights between Houston and KSC; Mattingly's enthusiasm caused other astronauts, such as Apollo 14's CMP, Roosa, to seek out El-Baz as a teacher.\n\nConcerned about how close Apollo 11's LM, Eagle, had come to running out of propellant during its lunar descent, mission planners decided that beginning with Apollo\u00a013, the CSM would bring the LM to the low orbit from which the landing attempt would commence. This was a change from Apollo 11 and 12, on which the LM made the burn to bring it to the lower orbit. The change was part of an effort to increase the amount of hover time available to the astronauts as the missions headed into rougher terrain.\n\nThe plan was to devote the first of the two four-hour lunar surface extravehicular activities (EVAs) to setting up the Apollo Lunar Surface Experiments Package (ALSEP) group of scientific instruments; during the second, Lovell and Haise would investigate Cone crater, near the planned landing site. The two astronauts wore their spacesuits for some 20 walk-throughs of EVA procedures, including sample gathering and use of tools and other equipment. They flew in the \"Vomit Comet\" in simulated microgravity or lunar gravity, including practice in donning and doffing spacesuits. To prepare for the descent to the Moon's surface, Lovell flew the Lunar Landing Training Vehicle (LLTV). Despite four of the five LLTVs and similar Lunar Landing Research Vehicles having crashed during the Apollo program, mission commanders considered flying them invaluable experience.\n\nExperiments and scientific objectives \n\nApollo\u00a013's designated landing site was near Fra Mauro crater; the Fra Mauro formation was believed to contain much material spattered by the impact that had filled the Imbrium basin early in the Moon's history. Dating it would provide information not only about the Moon, but about the Earth's early history. Such material was likely to be available at Cone crater, a site where an impact was believed to have drilled deep into the lunar regolith.\n\nApollo 11 had left a seismometer on the Moon, but the solar-powered unit did not survive its first two-week-long lunar night. The Apollo 12 astronauts also left one as part of its ALSEP, which was nuclear-powered. Apollo\u00a013 also carried a seismometer (known as the Passive Seismic Experiment, or PSE), similar to Apollo 12's, as part of its ALSEP,  to be left on the Moon by the astronauts. That seismometer was to be calibrated by the impact, after jettison, of the ascent stage of Apollo\u00a013's LM, an object of known mass and velocity impacting at a known location.\n\nOther ALSEP experiments on Apollo\u00a013 included a Heat Flow Experiment (HFE), which would involve drilling two holes  deep. This was Haise's responsibility; he was also to drill a third hole of that depth for a core sample. A Charged Particle Lunar Environment Experiment (CPLEE) measured the protons and electrons of solar origin reaching the Moon. The package also included a Lunar Atmosphere Detector (LAD) and a Dust Detector, to measure the accumulation of debris. The Heat Flow Experiment and the CPLEE were flown for the first time on Apollo\u00a013; the other experiments had been flown before.\n\nTo power the ALSEP, the SNAP-27 radioisotope thermoelectric generator (RTG) was flown. Developed by the U.S. Atomic Energy Commission, SNAP-27 was first flown on Apollo 12. The fuel capsule contained about  of plutonium oxide. The cask placed around the capsule for transport to the Moon was built with heat shields of graphite and of beryllium, and with structural parts of titanium and of Inconel materials. Thus, it was built to withstand the heat of reentry into the Earth's atmosphere rather than pollute the air with plutonium in the event of an aborted mission.\n\nA United States flag was also taken, to be erected on the Moon's surface. For Apollo 11 and 12, the flag had been placed in a heat-resistant tube on the front landing leg; it was moved for Apollo\u00a013 to the Modularized Equipment Stowage Assembly (MESA) in the LM descent stage. The structure to fly the flag on the airless Moon was improved from Apollo 12's.\n\nFor the first time, red stripes were placed on the helmet, arms and legs of the commander's A7L spacesuit. This was done as, after Apollo 11, those reviewing the images taken had trouble distinguishing Armstrong from Aldrin, but the change was approved too late for Apollo 12. New drink bags that attached inside the helmets and were to be sipped from as the astronauts walked on the Moon were demonstrated by Haise during Apollo\u00a013's final television broadcast before the accident.\n\nApollo\u00a013's primary mission objectives were to: \"Perform selenological inspection, survey, and sampling of materials in a preselected region of the Fra Mauro Formation. Deploy and activate an Apollo Lunar Surface Experiments Package. Develop man's capability to work in the lunar environment. Obtain photographs of candidate exploration sites.\" The astronauts were also to accomplish other photographic objectives, including of the Gegenschein from lunar orbit, and of the Moon itself on the journey back to Earth. Some of this photography was to be performed by Swigert as Lovell and Haise walked on the Moon. Swigert was also to take photographs of the Lagrangian points of the Earth-Moon system. Apollo\u00a013 had twelve cameras on board, including those for television and moving pictures. The crew was also to downlink bistatic radar observations of the Moon. None of these was attempted because of the accident.\n\nFlight of Apollo satellite communications giant SpaceSat builds a fleet of satellites 13\n\nLaunch and translunar injection\n\nThe mission was launched at the planned time, 2:13:00\u00a0pm EST (19:13:00\u00a0UTC) on April 11. An anomaly occurred when the second-stage, center (inboard) engine shut down about two minutes early. This was caused by severe pogo oscillations. Starting with Apollo 10, the vehicle's guidance system was designed to shut the engine down in response to chamber pressure excursions. Pogo oscillations had occurred on Titan rockets (used during the Gemini program) and on previous Apollo missions, but on Apollo\u00a013 they were amplified by an interaction with turbopump cavitation. A fix to prevent pogo was ready for the mission, but schedule pressure did not permit the hardware's integration into the Apollo\u00a013 vehicle. A post-flight investigation revealed the engine was one cycle away from catastrophic failure.\nIn spite of the shutdown, the four outboard engines and the S-IVB third stage burned longer to compensate, and the vehicle achieved very close to the planned circular  parking orbit, followed by a translunar injection (TLI) about two hours later, setting the mission on course for the Moon.\n\nAfter TLI, Swigert performed the separation and transposition maneuvers before docking the CSM Odyssey to the LM Aquarius, and the spacecraft pulled away from the third stage. Ground controllers then sent the third stage on a course to impact the Moon in range of the Apollo 12 seismometer, which it did just over three days into the mission.\n\nThe crew settled in for the three-day trip to Fra Mauro. At 30:40:50 into the mission, with the TV camera running, the crew performed a burn to place Apollo\u00a013 on a hybrid trajectory. The departure from a free-return trajectory meant that if no further burns were performed, Apollo\u00a013 would miss Earth on its return trajectory, rather than intercept it, as with a free return. A free return trajectory could only reach sites near the lunar equator; a hybrid trajectory, which could be started at any point after TLI, allowed sites with higher latitudes, such as Fra Mauro, to be reached. Communications were enlivened when Swigert realized that in the last-minute rush, he had omitted to file his federal income tax return (due April 15), and amid laughter from mission controllers, asked how he could get an extension. He was found to be entitled to a 60-day extension for being out of the country at the deadline.\n\nEntry into the LM to test its systems had been scheduled for 58:00:00; when the crew awoke on the third day of the mission, they were informed it had been moved up three hours and was later moved up again by another hour. A television broadcast was scheduled for 55:00:00; Lovell, acting as emcee, showed the audience the interiors of Odyssey and Aquarius. The audience was limited since none of the television networks were carrying the broadcast, forcing Marilyn Lovell (Jim Lovell's wife) to go to the VIP room at Mission Control if she wanted to watch her husband and his crewmates.\n\nAccident \n\nApproximately six and a half minutes after the TV broadcastapproaching 56:00:00Apollo\u00a013 was about  from Earth. Haise was completing the shutdown of the LM after testing its systems while Lovell stowed the TV camera. Jack Lousma", "flag": 1, "segments": [[4284, 4294]], "strength": 5.5}
{"text": "Arnold Alois Schwarzenegger (; ; born July 30, 1947) is an Austrian-American actor, former bodybuilder, film producer, businessman, and former politician who served as the 38th governor of California from 2003 to 2011. As of 2022, he is the most recent Republican governor of California.\n\nSchwarzenegger began lifting weights at the age of 15 and went on to win the Mr. Universe title at age 20, subsequently winning the Mr. Olympia contest seven times; he remains a prominent figure in bodybuilding, and has written many books and articles on it. The Arnold Sports Festival, considered the second-most important bodybuilding event after Mr. Olympia, is named after him. He appeared in the bodybuilding documentary Pumping Iron (1977). Schwarzenegger retired from bodybuilding and gained worldwide fame as a Hollywood action star, with his breakthrough the sword and sorcery epic Conan the Barbarian (1982), a box-office hit with a sequel in 1984. After playing the title character in the science fiction film The Terminator (1984), he starred in the sequels Terminator 2: Judgment Day (1991), Terminator 3: Rise of the Machines (2003), Terminator Genisys (2015), and Terminator: Dark Fate (2019). His other successful action films included Commando (1985), The Running Man (1987), Predator (1987), Red Heat (1988), Total Recall (1990), and True Lies (1994), in addition to comedy films such as Twins (1988), Kindergarten Cop (1990), Junior (1994), and Jingle All the Way (1996). He is the founder of the film production company Oak Productions.\n\nAs a Republican candidate, Schwarzenegger was first elected on October 7, 2003, in a special recall election to replace then-Governor Gray Davis. He received 48.6% of the vote, 17 points ahead of Democrat runner-up Cruz Bustamante. He was sworn in on November 17 to serve the remainder of Davis' term, and was re-elected in the 2006 California gubernatorial election with an increased vote share of 55.9% to serve a full term as governor. In 2011, he reached his term limit as Governor and returned to acting.\n\nSchwarzenegger was nicknamed the \"Austrian Oak\" in his bodybuilding days, \"Arnie\" or \"Schwarzy\" during his acting career, and \"The Governator\" (a portmanteau of \"Governor\" and \"Terminator\") during his political career. He married Maria Shriver, a niece of President John F. Kennedy, in 1986. They separated in 2011 after he admitted to having fathered a child with their housemaid in 1997; their divorce was finalized in 2021.\n\nEarly life \n\nArnold Alois Schwarzenegger was born in Thal, Austria on July 30, 1947, the second son of Gustav Schwarzenegger and his wife, Aurelia (n\u00e9e Jadrny). His mother was of Czech descent, while his paternal great-grandfather, Wenzel Mach, was also Czech and came from the village of Chocov near Mlad\u00e1 Vo\u017eice. Wenzel had a child out of wedlock with Kunigunde Schwarzenegger, and the child (Schwarzenegger's paternal grandfather) was originally named Carl Mach but later adopted his mother's surname Schwarzenegger.\n\nSchwarzenegger's father was the local chief of police. After the Anschluss in 1938, he joined the Nazi Party and, in 1939 the Sturmabteilung (SA). In World War II, he served as a military policeman in the invasions of Poland, France and the Soviet Union, including the siege of Leningrad, rising to the rank of Hauptfeldwebel. He was wounded in the Battle of Stalingrad, and was discharged in 1943 following a bout of malaria. According to Holocaust scholar Michael Berenbaum, Gustav Schwarzenegger served \"in theaters of the war where atrocities were committed. But there is no way to know from the documents whether he played a role.\" Gustav's background received wide press attention during the 2003 California gubernatorial recall election in which Schwarzenegger was elected governor.\n\nGustav Schwarzenegger married Aurelia on October 20, 1945; he was 38 and she was 23. According to Schwarzenegger, his parents were very strict: \"Back then in Austria it was a very different world [...] if we did something bad or we disobeyed our parents, the rod was not spared.\" He grew up in a Catholic family. Gustav preferred his elder son, Meinhard, over Arnold. His favoritism was \"strong and blatant\", which stemmed from unfounded suspicion that Arnold was not his biological child. Schwarzenegger has said that his father had \"no patience for listening or understanding your problems\". He had a good relationship with his mother, with whom he kept in touch until her death.\n\nEarly education and bodybuilding beginnings \nAt school, Schwarzenegger was reportedly academically average but stood out for his \"cheerful, good-humored, and exuberant\" character. Money was a problem in their household; Schwarzenegger recalled that one of the highlights of his youth was when the family bought a refrigerator. Schwarzenegger's father Gustav was an athlete, and wished for his sons to become a champion in Bavarian curling. Influenced by his father, Schwarzenegger played several sports as a boy.\n\nSchwarzenegger began weight training in 1960 when his football coach took his team to a local gym. At the age of 14, he chose bodybuilding over football as a career. He later said, \"I actually started weight training when I was 15, but I'd been participating in sports, like soccer, for years, so I felt that although I was slim, I was well-developed, at least enough so that I could start going to the gym and start Olympic lifting.\" However, his official website biography claims that \"at 14, he started an intensive training program with Dan Farmer, studied psychology at 15 (to learn more about the power of mind over body) and at 17, officially started his competitive career.\" During a speech in 2001, he said, \"My own plan formed when I was 14 years old. My father had wanted me to be a police officer like he was. My mother wanted me to go to trade school.\"\n\nSchwarzenegger took to visiting a gym in Graz, where he also frequented the local movie theaters to see bodybuilding idols such as Reg Park, Steve Reeves, and Johnny Weissmuller on the big screen. When Reeves died in 2000, Schwarzenegger fondly remembered him: \"As a teenager, I grew up with Steve Reeves. His remarkable accomplishments allowed me a sense of what was possible when others around me didn't always understand my dreams. Steve Reeves has been part of everything I've ever been fortunate enough to achieve.\" In 1961, Schwarzenegger met former Mr. Austria Kurt Marnul, who invited him to train at the gym in Graz. He was so dedicated as a youngster that he broke into the local gym on weekends in order to train even when it was closed. \"It would make me sick to miss a workout... I knew I couldn't look at myself in the mirror the next morning if I didn't do it.\" When Schwarzenegger was asked about his first cinema experience as a boy, he replied: \"I was very young, but I remember my father taking me to the Austrian theaters and seeing some newsreels. The first real movie I saw, that I distinctly remember, was a John Wayne movie.\" In Graz, Schwarzenegger was mentored by Alfred Gerstl, who had Jewish ancestry and later became president of the Federal Council, and befriended his son Karl.\n\nSchwarzenegger's brother, Meinhard, died in a car crash on May 20, 1971. He was driving drunk and died instantly. Schwarzenegger did not attend his funeral. Meinhard was engaged to Erika Knapp, and they had a three-year-old son named Patrick. Schwarzenegger paid for Patrick's education and helped him to move to the U.S. Gustav died of a stroke on December 13, 1972. In Pumping Iron, Schwarzenegger claimed that he did not attend his father's funeral because he was training for a bodybuilding contest. Later, he and the film's producer said this story was taken from another bodybuilder to show the extremes some would go to for their sport and to make Schwarzenegger's image colder to create controversy for the film. However, Barbara Baker, his first serious girlfriend, recalled that he informed her of his father's death without emotion and that he never spoke of his brother. Over time, he has given at least three versions of why he was absent from his father's funeral.\n\nIn an interview with Fortune in 2004, Schwarzenegger told how he suffered what \"would now be called child abuse\" at the hands of his father: \"My hair was pulled. I was hit with belts. So was the kid next door. It was just the way it was. Many of the children I've seen were broken by their parents, which was the German-Austrian mentality. They didn't want to create an individual. It was all about conforming. I was one who did not conform, and whose will could not be broken. Therefore, I became a rebel. Every time I got hit, and every time someone said, 'You can't do this,' I said, 'This is not going to be for much longer because I'm going to move out of here. I want to be rich. I want to be somebody.'\"\n\nSchwarzenegger served in the Austrian Army in 1965 to fulfill the one year of service required at the time of all 18-year-old Austrian males. During his army service, he won the Junior Mr. Europe contest. He went AWOL during basic training so he could take part in the competition and then spent a week in military prison: \"Participating in the competition meant so much to me that I didn't carefully think through the consequences.\" He entered another bodybuilding contest in Graz, at Steirerhof Hotel, where he placed second. He was voted \"best-built man of Europe\", which made him famous in bodybuilding circles. \"The Mr. Universe title was my ticket to America\u2014the land of opportunity, where I could become a star and get rich.\" Schwarzenegger made his first plane trip in 1966, attending the NABBA Mr. Universe competition in London. He placed second in the Mr. Universe competition, not having the muscle definition of American winner Chester Yorton.\n\nCharles \"Wag\" Bennett, one of the judges at the 1966 competition, was impressed with Schwarzenegger and he offered to coach him. As Schwarzenegger had little money, Bennett invited him to stay in his crowded family home above one of his two gyms in Forest Gate, London. Yorton's leg definition had been judged superior, and Schwarzenegger, under a training program devised by Bennett, concentrated on improving the muscle definition and power in his legs. Staying in the East End of London helped Schwarzenegger improve his rudimentary grasp of the English language. Living with the Bennetts also changed him as a person: \"Being with them made me so much more sophisticated. When you're the age I was then, you're always looking for approval, for love, for attention and also for guidance. At the time, I wasn't really aware of that. But now, looking back, I see that the Bennett family fulfilled all those needs. Especially my need to be the best in the world. To be recognized and to feel unique and special. They saw that I needed that care and attention and love.\"\n\nAlso in 1966, while at Bennett's home, Schwarzenegger had the opportunity to meet childhood idol Reg Park, who became his friend and mentor. The training paid off and, in 1967, Schwarzenegger won the title for the first time, becoming the youngest ever Mr. Universe at the age of 20. He would go on to win the title a further three times. Schwarzenegger then flew back to Munich, where he attended a business school and worked in a health club (Rolf Putziger's gym, where he worked and trained from 1966 to 1968), returning in 1968 to London to win his next Mr. Universe title. He frequently told Roger C. Field, his English coach and friend in Munich at that time, \"I'm going to become the greatest actor!\"\n\nSchwarzenegger, who dreamed of moving to the U.S. since the age of 10, and saw bodybuilding as the avenue through which to do so, realized his dream by moving to the United States in October 1968 at the age of 21, speaking little English. There he trained at Gold's Gym in Venice, Los Angeles, California, under Joe Weider's supervision. From 1970 to 1974, one of Schwarzenegger's weight training partners was Ric Drasin, a professional wrestler who designed the original Gold's Gym logo in 1973. Schwarzenegger also became good friends with professional wrestler Superstar Billy Graham. In 1970, at age 23, he captured his first Mr. Olympia title in New York, and would go on to win the title a total of seven times.\n\nThe immigration law firm Siskind & Susser has stated that Schwarzenegger may have been an illegal immigrant at some point in the late 1960s or early 1970s because of violations in the terms of his visa. LA Weekly would later say in 2002 that Schwarzenegger is the most famous immigrant in America, who \"overcame a thick Austrian accent and transcended the unlikely background of bodybuilding to become the biggest movie star in the world in the 1990s\".\n\nIn 1977, Schwarzenegger's autobiography/weight-training guide Arnold: The Education of a Bodybuilder became a huge success. In 1977, he posed for the gay magazine After Dark. Due to taking an assortment of courses at Santa Monica College in California (including English classes), as well as further upper division classes at the University of California, Los Angeles as part of UCLA's extension program, Schwarzenegger had by then accumulated enough credits so as to be \"within striking distance\" of graduation. In 1979, he enrolled in the University of Wisconsin\u2013Superior as a distance education student, completing most of his coursework by correspondence and flying out to Superior to meet professors and take final exams. In May 1980, he formally graduated and received his bachelor's degree in business administration and marketing. He received his United States citizenship in 1983.\n\nBodybuilding career \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSchwarzenegger is considered among the most important figures in the history of bodybuilding, and his legacy is commemorated in the Arnold Classic annual bodybuilding competition. He has remained a prominent face in bodybuilding long after his retirement, in part because of his ownership of gyms and fitness magazines. He has presided over numerous contests and awards shows.\n\nFor many years, he wrote a monthly column for the bodybuilding magazines Muscle & Fitness and Flex. Shortly after being elected governor, he was appointed the executive editor of both magazines, in a largely symbolic capacity. The magazines agreed to donate $250,000 a year to the Governor's various physical fitness initiatives. When the deal, including the contract that gave Schwarzenegger at least $1\u00a0million a year, was made public in 2005, many criticized it as being a conflict of interest since the governor's office made decisions concerning regulation of dietary supplements in California. Consequently, Schwarzenegger relinquished the executive editor role in 2005. American Media Inc., which owns Muscle & Fitness and Flex, announced in March 2013 that Schwarzenegger had accepted their renewed offer to be executive editor of the magazines.\n\nOne of the first competitions he won was the Junior Mr. Europe contest in 1965. He won Mr. Europe the following year, at age 19. He would go on to compete in many bodybuilding contests, and win most of them. His bodybuilding victories included five Mr. Universe wins (4\u00a0\u2013 NABBA [England], 1\u00a0\u2013 IFBB [USA]), and seven Mr. Olympia wins, a record which would stand until Lee Haney won his eighth consecutive Mr. Olympia title in 1991.\n\nSchwarzenegger continues to work out. When asked about his personal training during the 2011 Arnold Classic he said that he was still working out a half an hour with weights every day.\n\nPowerlifting/weightlifting \nDuring Schwarzenegger's early years in bodybuilding, he also competed in several Olympic weightlifting and powerlifting contests. Schwarzenegger's first professional competition was in 1963 and he won two weightlifting contests in 1964 and 1965, as well as two powerlifting contests in 1966 and 1968.\n\nIn 1967, Schwarzenegger won the Munich stone-lifting contest, in which a stone weighing 508 German pounds (254\u00a0kg / 560\u00a0lb) is lifted between the legs while standing on two footrests.\n\nPersonal records \n Clean and press \u2013 \n Snatch \u2013 \n Clean and jerk \u2013 \n Squat \u2013 \n Bench press \u2013 \n Deadlift \u2013\n\nMr. Olympia \nSchwarzenegger's goal was to become the greatest bodybuilder in the world, which meant becoming Mr. Olympia. His first attempt was in 1969, when he lost to three-time champion Sergio Oliva. However, Schwarzenegger came back in 1970 and won the competition, making him the youngest ever Mr. Olympia at the age of 23, a record he still holds to this day.\n\nHe continued his winning streak in the 1971\u201374 competitions. He also toured different countries selling vitamins, as in Helsinki, Finland in 1972, when he lived at the YMCA Hotel Hospiz (nowadays Hotel Arthur) on Vuorikatu and presented vitamin pills at the Stockmann shopping center. In 1975, Schwarzenegger was once again in top form, and won the title for the sixth consecutive time, beating Franco Columbu. After the 1975 Mr. Olympia contest, Schwarzenegger announced his retirement from professional bodybuilding.\n\nMonths before the 1975 Mr. Olympia contest, filmmakers George Butler and Robert Fiore persuaded Schwarzenegger to compete and film his training in the bodybuilding documentary called Pumping Iron. Schwarzenegger had only three months to prepare for the competition, after losing significant weight to appear in the film Stay Hungry with Jeff Bridges. Although significantly taller and heavier, Lou Ferrigno proved not to be a threat, and a lighter-than-usual Schwarzenegger convincingly won the 1975 Mr. Olympia.\n\nSchwarzenegger came out of retirement, however, to compete in the 1980 Mr. Olympia. Schwarzenegger was training for his role in Conan, and he got into such good shape because of the running, horseback riding and sword training, that he decided he wanted to win the Mr. Olympia contest one last time. He kept this plan a secret in the event that a training accident would prevent his entry and cause him to lose face. Schwarzenegger had been hired to provide color commentary for network television when he announced at the eleventh hour that, while he was there, \"Why not compete?\" Schwarzenegger ended up winning the event with only seven weeks of preparation. Having been declared Mr. Olympia for a seventh time, Schwarzenegger then officially retired from competition. This victory (subject of the documentary The Comeback) was highly controversial, though, as fellow competitors and many observers felt that his lack of muscle mass (especially in his thighs) and subpar conditioning should not have allowed him to win against a very competitive lineup that year. Mike Mentzer, in particular, felt cheated and withdrew from competitive bodybuilding after that contest.\n\nSteroid use \nSchwarzenegger has acknowledged using performance-enhancing anabolic steroids while they were legal, writing in 1977 that \"steroids were helpful to me in maintaining muscle size while on a strict diet in preparation for a contest. I did not use them for muscle growth, but rather for muscle maintenance when cutting up.\" He has called the drugs \"tissue building\".\n\nIn 1999, Schwarzenegger sued Willi Heepe, a German doctor who publicly predicted his early death on the basis of a link between his steroid use and later heart problems. Since the doctor never examined him personally, Schwarzenegger collected a US$10,000 libel judgment against him in a German court. In 1999, Schwarzenegger also sued and settled with Globe, a U.S. tabloid which had made similar predictions about the bodybuilder's future health.\n\nList of competitions\n\nStatistics \n Height: \n Contest weight: \u2014the lightest in 1980 Mr. Olympia: around, the heaviest in 1974 Mr. Olympia: around \n Off-season weight: \n Chest: \n Waist: \n Arms: \n Thighs: \n Calves:\n\nActing career\n\nEarly roles \nSchwarzenegger wanted to move from bodybuilding into acting, finally achieving it when he was chosen to play the title role in Hercules in New York (1970). Credited under the stage name \"Arnold Strong\", his accent in the film was so thick that his lines were dubbed after production. His second film appearance was as a deaf-mute mob hitman in The Long Goodbye (1973), which was followed by a much more significant part in the film Stay Hungry (1976), for which he won the Golden Globe Award for New Star of the Year \u2013 Actor. Schwarzenegger has discussed his early struggles in developing his acting the model just took to Instagram. \u201cBlack career: \"It was very difficult for me in the beginning\u00a0\u2013 I was told by agents and casting people that my body was 'too weird', that I had a funny accent, and that my name was too long. You name it, and they told me I had to change it. Basically, everywhere I turned, I was told that I had no chance.\"\n\nSchwarzenegger drew attention and boosted his profile in the bodybuilding film Pumping Iron (1977), elements of which were dramatized. In 1991, he purchased the rights to the film, its outtakes, and associated still photography. In 1977, he made guest appearances in single episodes of the ABC sitcom The San Pedro Beach Bums and the ABC police procedural The Streets of San Francisco. Schwarzenegger auditioned for the title role of The Incredible Hulk, but did not win the role because of his height. Later, Lou Ferrigno got the part of Dr. David Banner's alter ego. Schwarzenegger appeared with Kirk Douglas and Ann-Margret in the 1979 comedy The Villain. In 1980, he starred in a biographical film of the 1950s actress Jayne Mansfield as Mansfield's husband, Mickey Hargitay.\n\nAction superstar \nSchwarzenegger's breakthrough film was the sword and sorcery epic Conan the Barbarian in 1982, which was a box-office hit. This was followed by a sequel, Conan the Destroyer, in 1984, although it was not as successful as its predecessor. In 1983, Schwarzenegger starred in the promotional video Carnival in Rio. In 1984, he made his first appearance as the eponymous character in James Cameron's science fiction action film The Terminator. It has been called his acting career's signature role. Following this, Schwarzenegger made another sword and sorcery film, Red Sonja, in 1985. During the 1980s, audiences had an appetite for action films, with both Schwarzenegger and Sylvester Stallone becoming international stars. The two rivals attacked each other in the press, and tried to surpass the other with more on-screen killings and larger weapons. Schwarzenegger's roles reflected his sense of humor, separating him from more serious action hero films. He made a number of successful action films in the 1980s, such as Commando (1985), Raw Deal (1986), The Running Man (1987), Predator (1987), and Red Heat (1988).\n\nTwins (1988), a comedy with Danny DeVito, also proved successful. Total Recall (1990) netted Schwarzenegger $10\u00a0million (equivalent to $ million today) and 15% of the film's gross. A science fiction script, the film was based on the Philip K. Dick short story \"We Can Remember It for You Wholesale\". Kindergarten Cop (1990) reunited him with director", "flag": 1, "segments": [[4435, 4445]], "strength": 5.5}
{"text": "Adam Smith  (baptized  1723 \u2013 17 July 1790) was a Scottish economist and philosopher who was a pioneer of political economy and key figure during the Scottish Enlightenment. Also known as \"The Father of Economics\" or \"The Father of Capitalism\", he wrote two classic works, The Theory of Moral Sentiments (1759) and An Inquiry into the Nature and Causes of the Wealth of Nations (1776). The latter, often abbreviated as The Wealth of Nations, is considered his magnum opus and the first modern work of economics. In his work, Smith introduced his theory of absolute advantage.\n\nSmith studied social philosophy at the University of Glasgow and at Balliol College, Oxford, where he was one of the first students to benefit from scholarships set up by fellow Scot John Snell. After graduating, he delivered a successful series of public lectures at the University of Edinburgh, leading him to collaborate with David Hume during the Scottish Enlightenment. Smith obtained a professorship at Glasgow, teaching moral philosophy and during this time, wrote and published The Theory of Moral Sentiments. In his later life, he took a tutoring position that allowed him to travel throughout Europe, where he met other intellectual leaders of his day.\n\nSmith laid the foundations of classical free market economic theory. The Wealth of Nations was a precursor to the modern academic discipline of economics. In this and other works, he developed the concept of division of labour and expounded upon how rational self-interest and competition can lead to economic prosperity. Smith was controversial in his own day and his general approach and writing style were often satirised by writers such as Horace Walpole.\n\nBiography\n\nEarly life\n\nSmith was born in Kirkcaldy, in Fife, Scotland. His father, also Adam Smith, was a Scottish Writer to the Signet (senior solicitor), advocate and prosecutor (judge advocate) and also served as comptroller of the customs in Kirkcaldy. Smith's mother was born Margaret Douglas, daughter of the landed Robert Douglas of Strathendry, also in Fife; she married Smith's father in 1720. Two months before Smith was born, his father died, leaving his mother a widow. The date of Smith's baptism into the Church of Scotland at Kirkcaldy was 5 June 1723 and this has often been treated as if it were also his date of birth, which is unknown.\n\nAlthough few events in Smith's early childhood are known, the Scottish journalist John Rae, Smith's biographer, recorded that Smith was abducted by Romani at the age of three and released when others went to rescue him. Smith was close to his mother, who probably encouraged him to pursue his scholarly ambitions. He attended the Burgh School of Kirkcaldy\u2014characterised by Rae as \"one of the best secondary schools of Scotland at that period\"\u2014from 1729 to 1737, he learned Latin, mathematics, history, and writing.\n\nFormal education\n\nSmith entered the University of Glasgow when he was 14 and studied moral philosophy under Francis Hutcheson. Here he developed his passion for liberty, reason, and free speech. In 1740, he was the graduate scholar presented to undertake postgraduate studies at Balliol College, Oxford, under the Snell Exhibition.\n\nSmith considered the teaching at Glasgow to be far superior to that at Oxford, which he found intellectually stifling. In Book V, Chapter II of The Wealth of Nations, he wrote: \"In the University of Oxford, the greater part of the public professors have, for these many years, given up altogether even the pretence of teaching.\"\nSmith is also reported to have complained to friends that Oxford officials once discovered him reading a copy of David Hume's A Treatise of Human Nature, and they subsequently confiscated his book and punished him severely for reading it. According to William Robert Scott, \"The Oxford of [Smith's] time gave little if any help towards what was to be his lifework.\" Nevertheless, he took the opportunity while at Oxford to teach himself several subjects by reading many books from the shelves of the large Bodleian Library. When Smith was not studying on his own, his time at Oxford was not a happy one, according to his letters. Near the end of his time there, he began suffering from shaking fits, probably the symptoms of a nervous breakdown. He left Oxford University in 1746, before his scholarship ended.\n\nIn Book V of The Wealth of Nations, Smith comments on the low quality of instruction and the meager intellectual activity at English universities, when compared to their Scottish counterparts. He attributes this both to the rich endowments of the colleges at Oxford and Cambridge, which made the income of professors independent of their ability to attract students, and to the fact that distinguished men of letters could make an even more comfortable living as ministers of the Church of England.\n\nSmith's discontent at Oxford might be in part due to the absence of his beloved teacher in Glasgow, Francis Hutcheson, who was well regarded as one of the most prominent lecturers at the University of Glasgow in his day and earned the approbation of students, colleagues, and even ordinary residents with the fervor and earnestness of his orations (which he sometimes opened to the public). His lectures endeavoured not merely to teach philosophy, but also to make his students embody that philosophy in their lives, appropriately acquiring the epithet, the preacher of philosophy. Unlike Smith, Hutcheson was not a system builder; rather, his magnetic personality and method of lecturing so influenced his students and caused the greatest of those to reverentially refer to him as \"the never to be forgotten Hutcheson\"\u2014a title that Smith in all his correspondence used to describe only two people, his good friend David Hume and influential mentor Francis Hutcheson.\n\nTeaching career\nSmith began delivering public lectures in 1748 at the University of Edinburgh, sponsored by the Philosophical Society of Edinburgh under the patronage of Lord Kames. His lecture topics included rhetoric and belles-lettres, and later the subject of \"the progress of opulence\". On this latter topic, he first expounded his economic philosophy of \"the obvious and simple system of natural liberty\". While Smith was not adept at public speaking, his lectures met with success.\n\nIn 1750, Smith met the philosopher David Hume, who was his senior by more than a decade. In their writings covering history, politics, philosophy, economics, and religion, Smith and Hume shared closer intellectual and personal bonds than with other important figures of the Scottish Enlightenment.\n\nIn 1751, Smith earned a professorship at Glasgow University teaching logic courses, and in 1752, he was elected a member of the Philosophical Society of Edinburgh, having been introduced to the society by Lord Kames. When the head of Moral Philosophy in Glasgow died the next year, Smith took over the position. He worked as an academic for the next 13 years, which he characterised as \"by far the most useful and therefore by far the happiest and most honorable period [of his life]\".\n\nSmith published The Theory of Moral Sentiments in 1759, embodying some of his Glasgow lectures. This work was concerned with how human morality depends on sympathy between agent and spectator, or the individual and other members of society. Smith defined \"mutual sympathy\" as the basis of moral sentiments. He based his explanation, not on a special \"moral sense\" as the Third Lord Shaftesbury and Hutcheson had done, nor on utility as Hume did, but on mutual sympathy, a term best captured in modern parlance by the 20th-century concept of empathy, the capacity to recognise feelings that are being experienced by another being.\n\nFollowing the publication of The Theory of Moral Sentiments, Smith became so popular that many wealthy students left their schools in other countries to enroll at Glasgow to learn under Smith. After the publication of The Theory of Moral Sentiments, Smith began to give more attention to jurisprudence and economics in his lectures and less to his theories of morals. For example, Smith lectured that the cause of increase in national wealth is labour, rather than the nation's quantity of gold or silver, which is the basis for mercantilism, the economic theory that dominated Western European economic policies at the time.\n\nIn 1762, the University of Glasgow conferred on Smith the title of Doctor of Laws (LL.D.). At the end of 1763, he obtained an offer from Charles Townshend\u2014who had been introduced to Smith by David Hume\u2014to tutor his stepson, Henry Scott, the young Duke of Buccleuch. Smith resigned from his professorship in 1764 to take the tutoring position. He subsequently attempted to return the fees he had collected from his students because he had resigned partway through the term, but his students refused.\n\nTutoring and travels\nSmith's tutoring job entailed touring Europe with Scott, during which time he educated Scott on a variety of subjects, such as etiquette and manners. He was paid \u00a3300 per year (plus expenses) along with a \u00a3300 per year pension; roughly twice his former income as a teacher. Smith first travelled as a tutor to Toulouse, France, where he stayed for a year and a half. According to his own account, he found Toulouse to be somewhat boring, having written to Hume that he \"had begun to write a book to pass away the time\". After touring the south of France, the group moved to Geneva, where Smith met with the philosopher Voltaire.\n\nFrom Geneva, the party moved to Paris. Here, Smith met Benjamin Franklin, and discovered the Physiocracy school founded by Fran\u00e7ois Quesnay. Physiocrats were opposed to mercantilism, the dominating economic theory of the time, illustrated in their motto Laissez faire et laissez passer, le monde va de lui m\u00eame! (Let do and let pass, the world goes on by itself!).\n\nThe wealth of France had been virtually depleted by Louis\u00a0XIV and Louis\u00a0XV in ruinous wars, and was further exhausted in aiding the American insurgents against the British. The excessive consumption of goods and services deemed to have no economic contribution was considered a source of unproductive labour, with France's agriculture the only economic sector maintaining the wealth of the nation. Given that the British economy of the day yielded an income distribution that stood in contrast to that which existed in France, Smith concluded that \"with all its imperfections, [the Physiocratic school] is perhaps the nearest approximation to the truth that has yet been published upon the subject of political economy.\" The distinction between productive versus unproductive labour\u2014the physiocratic classe steril\u2014was a predominant issue in the development and understanding of what would become classical economic theory.\n\nLater years\nIn 1766, Henry Scott's younger brother died in Paris, and Smith's tour as a tutor ended shortly thereafter. Smith returned home that year to Kirkcaldy, and he devoted much of the next decade to writing his magnum opus. There, he befriended Henry Moyes, a young blind man who showed precocious aptitude. Smith secured the patronage of David Hume and Thomas Reid in the young man's education. In May 1773, Smith was elected fellow of the Royal Society of London, and was elected a member of the Literary Club in 1775. The Wealth of Nations was published in 1776 and was an instant success, selling out its first edition in only six months.\n\nIn 1778, Smith was appointed to a post as commissioner of customs in Scotland and went to live with his mother (who died in 1784) in Panmure House in Edinburgh's Canongate. Five years later, as a member of the Philosophical Society of Edinburgh when it received its royal charter, he automatically became one of the founding members of the Royal Society of Edinburgh. From 1787 to 1789, he occupied the honorary position of Lord Rector of the University of Glasgow.\n\nDeath\n\nSmith died in the northern wing of Panmure House in Edinburgh on 17 July 1790 after a painful illness. His body was buried in the Canongate Kirkyard. On his deathbed, Smith expressed disappointment that he had not achieved more.\n\nSmith's literary executors were two friends from the Scottish academic world: the physicist and chemist Joseph Black and the pioneering geologist James Hutton. Smith left behind many notes and some unpublished material, but gave instructions to destroy anything that was not fit for publication. He mentioned an early unpublished History of Astronomy as probably suitable, and it duly appeared in 1795, along with other material such as Essays on Philosophical Subjects.\n\nSmith's library went by his will to David Douglas, Lord Reston (son of his cousin Colonel Robert Douglas of Strathendry, Fife), who lived with Smith. It was eventually divided between his two surviving children, Cecilia Margaret (Mrs.\u00a0Cunningham) and David Anne (Mrs.\u00a0Bannerman). On the death in 1878 of her husband, the Reverend W.\u00a0B. Cunningham of Prestonpans, Mrs.\u00a0Cunningham sold some of the books. The remainder passed to her son, Professor Robert Oliver Cunningham of Queen's College, Belfast, who presented a part to the library of Queen's College. After his death, the remaining books were sold. On the death of Mrs. Bannerman in 1879, her portion of the library went intact to the New College (of the Free Church) in Edinburgh and the collection was transferred to the University of Edinburgh Main Library in 1972.\n\nPersonality and beliefs\n\nCharacter\n\nNot much is known about Smith's personal views beyond what can be deduced from his published articles. His personal papers were destroyed after his death at his request. He never married, and seems to have maintained a close relationship with his mother, with whom he lived after his return from France and who died six years before him.\n\nSmith was described by several of his contemporaries and biographers as comically absent-minded, with peculiar habits of speech and gait, and a smile of \"inexpressible benignity\". He was known to talk to himself, a habit that began during his childhood when he would smile in rapt conversation with invisible companions. He also had occasional spells of imaginary illness, and he is reported to have had books and papers placed in tall stacks in his study. According to one story, Smith took Charles Townshend on a tour of a tanning factory, and while discussing free trade, Smith walked into a huge tanning pit from which he needed help to escape. He is also said to have put bread and butter into a teapot, drunk the concoction, and declared it to be the worst cup of tea he ever had. According to another account, Smith distractedly went out walking in his nightgown and ended up  outside of town, before nearby church bells brought him back to reality.\n\nJames Boswell, who was a student of Smith's at Glasgow University, and later knew him at the Literary Club, says that Smith thought that speaking about his ideas in conversation might reduce the sale of his books, so his conversation was unimpressive. According to Boswell, he once told Sir Joshua Reynolds, that \"he made it a rule when in company never to talk of what he understood\".\n\nSmith has been alternatively described as someone who \"had a large nose, bulging eyes, a protruding lower lip, a nervous twitch, and a speech impediment\" and one whose \"countenance was manly and agreeable\". Smith is said to have acknowledged his looks at one point, saying, \"I am a beau in nothing but my books.\" Smith rarely sat for portraits, so almost all depictions of him created during his lifetime were drawn from memory. The best-known portraits of Smith are the profile by James Tassie and two etchings by John Kay. The line engravings produced for the covers of 19th-century reprints of The Wealth of Nations were based largely on Tassie's medallion.\n\nReligious views\nConsiderable scholarly debate has occurred about the nature of Smith's religious views. Smith's father had shown a strong interest in Christianity and belonged to the moderate wing of the Church of Scotland. The fact that Adam Smith received the Snell Exhibition suggests that he may have gone to Oxford with the intention of pursuing a career in the Church of England.\n\nAnglo-American economist Ronald Coase has challenged the view that Smith was a deist, based on the fact that Smith's writings never explicitly invoke God as an explanation of the harmonies of the natural or the human worlds. According to Coase, though Smith does sometimes refer to the \"Great Architect of the Universe\", later scholars such as Jacob Viner have \"very much exaggerated the extent to which Adam Smith was committed to a belief in a personal God\", a belief for which Coase finds little evidence in passages such as the one in the Wealth of Nations in which Smith writes that the curiosity of mankind about the \"great phenomena of nature\", such as \"the generation, the life, growth, and dissolution of plants and animals\", has led men to \"enquire into their causes\", and that \"superstition first attempted to satisfy this curiosity, by referring all those wonderful appearances to the immediate agency of the gods. Philosophy afterwards endeavoured to account for them, from more familiar causes, or from such as mankind were better acquainted with than the agency of the gods\".\n\nSome other authors argue that Smith's social and economic philosophy is inherently theological and that his entire model of social order is logically dependent on the notion of God's action in nature.\n\nSmith was also a close friend of David Hume, who was commonly characterised in his own time as an atheist. The publication in 1777 of Smith's letter to William Strahan, in which he described Hume's courage in the face of death in spite of his irreligiosity, attracted considerable controversy.\n\nPublished works\n\nThe Theory of Moral Sentiments\n\nIn 1759, Smith published his first work, The Theory of Moral Sentiments, sold by co-publishers Andrew Millar of London and Alexander Kincaid of Edinburgh. Smith continued making extensive revisions to the book until his death. Although The Wealth of Nations is widely regarded as Smith's most influential work, Smith himself is believed to have considered The Theory of Moral Sentiments to be a superior work.\n\nIn the work, Smith critically examines the moral thinking of his time, and suggests that conscience arises from dynamic and interactive social relationships through which people seek \"mutual sympathy of sentiments.\" His goal in writing the work was to explain the source of mankind's ability to form moral judgment, given that people begin life with no moral sentiments at all. Smith proposes a theory of sympathy, in which the act of observing others and seeing the judgments they form of both others and oneself makes people aware of themselves and how others perceive their behaviour. The feedback we receive fromaniels would pay one percentage point less on every perceiving (or imagining) others' judgment creates an incentive to achieve \"mutual sympathy of sentiments\" with them and leads people to develop habits, and then principles, of behaviour, which come to constitute one's conscience.\n\nSome scholars have perceived a conflict between The Theory of Moral Sentiments and The Wealth of Nations; the former emphasises sympathy for others, while the latter focuses on the role of self-interest. In recent years, however, some scholars of Smith's work have argued that no contradiction exists. They claim that in The Theory of Moral Sentiments, Smith develops a theory of psychology in which individuals seek the approval of the \"impartial spectator\" as a result of a natural desire to have outside observers sympathise with their sentiments. Rather than viewing The Theory of Moral Sentiments and The Wealth of Nations as presenting incompatible views of human nature, some Smith scholars regard the works as emphasising different aspects of human nature that vary depending on the situation. Otteson argues that both books are Newtonian in their methodology and deploy a similar \"market model\" for explaining the creation and development of large-scale human social orders, including morality, economics, as well as language. Ekelund and Hebert offer a differing view, observing that self-interest is present in both works and that \"in the former, sympathy is the moral faculty that holds self-interest in check, whereas in the latter, competition is the economic faculty that restrains self-interest.\"\n\nThe Wealth of Nations\n\nDisagreement exists between classical and neoclassical economists about the central message of Smith's most influential work: An Inquiry into the Nature and Causes of the Wealth of Nations (1776). Neoclassical economists emphasise Smith's invisible hand, a concept mentioned in the middle of his work \u2013 Book\u00a0IV, Chapter\u00a0II \u2013 and classical economists believe that Smith stated his programme for promoting the \"wealth of nations\" in the first sentences, which attributes the growth of wealth and prosperity to the division of labour.\n\nSmith used the term \"the invisible hand\" in \"History of Astronomy\" referring to \"the invisible hand of Jupiter\", and once in each of his The Theory of Moral Sentiments (1759) and The Wealth of Nations (1776). This last statement about \"an invisible hand\" has been interpreted in numerous ways.\n\nAs every individual, therefore, endeavours as much as he can both to employ his capital in the support of domestic industry, and so to direct that industry that its produce may be of the greatest value; every individual necessarily labours to render the annual revenue of the society as great as he can. He generally, indeed, neither intends to promote the public interest, nor knows how much he is promoting it. By preferring the support of domestic to that of foreign industry, he intends only his own security; and by directing that industry in such a manner as its produce may be of the greatest value, he intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention. Nor is it always the worse for the society that it was no part of it. By pursuing his own interest he frequently promotes that of the society more effectually than when he really intends to promote it. I have never known much good done by those who affected to trade for the public good. It is an affectation, indeed, not very common among merchants, and very few words need be employed in dissuading them from it.\n\nThose who regard that statement as Smith's central message also quote frequently Smith's dictum:\n\nIt is not from the benevolence of the butcher, the brewer, or the baker, that we expect our dinner, but from their regard to their own interest. We address ourselves, not to their humanity but to their self-love, and never talk to them of our own necessities but of their advantages.However, in The Theory of Moral Sentiments he had a more sceptical approach to self-interest as driver of behaviour:How selfish soever man may be supposed, there are evidently some principles in his nature, which interest him in the fortune of others, and render their happiness necessary to him, though he derives nothing from it except the pleasure of seeing it.\nSmith's statement about the benefits of \"an invisible hand\" may be meant to answer Mandeville's contention that \"Private Vices... may be turned into Public Benefits\". It shows Smith's belief that when an individual pursues his self-interest under conditions of justice, he unintentionally promotes the good of society. Self-interested competition in the free market, he argued, would tend to benefit society as a whole by keeping prices low, while still building in an incentive for a wide variety of goods and services. Nevertheless, he was wary of businessmen and warned of their \"conspiracy against the public or in some other contrivance to raise prices\". Again and again, Smith warned of the collusive nature of business interests, which may form cabals or monopolies, fixing the highest price \"which can be squeezed out of the buyers\". Smith also warned that a business-dominated political system would allow a conspiracy of businesses and industry against consumers, with the former scheming to influence", "flag": 1, "segments": [[3921, 3931]], "strength": 5.5}
{"text": "Arizona State University (Arizona State or ASU) is a public research university in the Phoenix metropolitan area. Founded in 1885 by the 13th Arizona Territorial Legislature, ASU is one of the largest public universities by enrollment in the U.S.\n\nOne of three universities governed by the Arizona Board of Regents, ASU is a member of the Universities Research Association and classified among \"R1: Doctoral Universities \u2013 Very High Research Activity\". ASU has nearly 150,000 students attending classes, with more than 38,000 students attending online, and 90,000 undergraduates and more nearly 20,000 postgraduates across its five campuses and four regional learning centers throughout Arizona. ASU offers 350 degree options from its 17 colleges and more than 170 cross-discipline centers and institutes for undergraduates students, as well as more than 400 graduate degree and certificate programs. The Arizona State Sun Devils compete in 26 varsity-level sports in the NCAA Division I Pac-12 Conference and is home to over 1,100 registered student organizations.\n\nASU's charter, approved by the board of regents in 2014, is based on the New American University model created by ASU President Michael M. Crow upon his appointment as the institution's 16th president in 2002. It defines ASU as \"a comprehensive public research university, measured not by whom it excludes, but rather by whom it includes and how they succeed; advancing research and discovery of public value; and assuming fundamental responsibility for the economic, social, cultural and overall health of the communities it serves.\" The model is widely credited with boosting ASU's acceptance rate and increasing class size.\n\nAs of January, 2022, ASU reported that its faculty of more than 4,700 scholars included 5 Nobel laureates, 6 MacArthur Fellows, 9 Pulitzer Prize winners, 9 National Academy of Engineering members, 23 National Academy of Sciences members, 26 American Academy of Arts and Sciences members, 40 Guggenheim fellows, 149 National Endowment for the Humanities fellows, and 270 Fulbright Program American Scholars.\n\nHistory\n\n1885\u20131929\n\nArizona State University was established as the Territorial Normal School at Tempe on March 12, 1885, when the 13th Arizona Territorial Legislature passed an act to create a normal school to train teachers for the Arizona Territory. The campus consisted of a single, four-room schoolhouse on a 20-acre plot largely donated by Tempe residents George and Martha Wilson. Classes began with 33 students on February 8, 1886. The curriculum evolved over the years and the name was changed several times; the institution was also known as Tempe Normal School of Arizona (1889\u20131903), Tempe Normal School (1903\u20131925), Tempe State Teachers College (1925\u20131929), Arizona State Teachers College (1929\u20131945), Arizona State College (1945\u20131958) and, by a 2\u20131 margin of the state's voters, Arizona State University in 1958.\n\nIn 1923, the school stopped offering high school courses and added a high school diploma to the admissions requirements. In 1925, the school became the Tempe State Teachers College and offered four-year Bachelor of Education degrees as well as two-year teaching certificates. In 1929, the 9th Arizona State Legislature authorized Bachelor of Arts in Education degrees as well, and the school was renamed the Arizona State Teachers College. Under the 30-year tenure of president Arthur John Matthews (1900\u20131930), the school was given all-college student status. The first dormitories built in the state were constructed under his supervision in 1902. Of the 18 buildings constructed while Matthews was president, six are still in use. Matthews envisioned an \"evergreen campus\", with many shrubs brought to the campus, and implemented the planting of 110 Mexican Fan Palms on what is now known as Palm Walk, a century-old landmark of the Tempe campus.\n\nDuring the Great Depression, Ralph Waldo Swetman was hired to succeed President Matthews, coming to Arizona State Teachers College in 1930 from Humboldt State Teachers College where he had served as president. He served a three-year term, during which he focused on improving teacher-training programs. During his tenure, enrollment at the college doubled, topping the 1,000 mark for the first time. Matthews also conceived of a self-supported summer session at the school at Arizona State Teachers College, a first for the school.\n\n1930\u20131989\n\nIn 1933, Grady Gammage, then president of Arizona State Teachers College at Flagstaff, became president of Arizona State Teachers College at Tempe, beginning a tenure that would last for nearly 28 years, second only to Swetman's 30 years at the college's helm. Like President Arthur John Matthews before him, Gammage oversaw the construction of several buildings on the Tempe campus. He also guided the development of the university's graduate programs; the first Master of Arts in Education was awarded in 1938, the first Doctor of Education degree in 1954 and 10 non-teaching master's degrees were approved by the Arizona Board of Regents in 1956. During his presidency, the school's name was changed to Arizona State College in 1945, and finally to Arizona State University in 1958. At the time, two other names were considered: Tempe University and State University at Tempe. Among Gammage's greatest achievements in Tempe was the Frank Lloyd Wright-designed construction of what is Grady Gammage Memorial Auditorium/ASU Gammage. One of the university's hallmark buildings, ASU Gammage was completed in 1964, five years after the president's (and Wright's) death.\n\nGammage was succeeded by Harold D. Richardson, who had served the school earlier in a variety of roles beginning in 1939, including director of graduate studies, college registrar, dean of instruction, dean of the College of Education and academic vice president. Although filling the role of acting president of the university for just nine months (Dec. 1959 to Sept. 1960), Richardson laid the groundwork for the future recruitment and appointment of well-credentialed research science faculty.\n\nBy the 1960s, under G. Homer Durham, the university's 11th president, ASU began to expand its curriculum by establishing several new colleges and, in 1961, the Arizona Board of Regents authorized doctoral degree programs in six fields, including Doctor of Philosophy. By the end of his nine-year tenure, ASU had more than doubled enrollment, reporting 23,000 in 1969.\n\nThe next three presidents\u2014Harry K. Newburn (1969\u201371), John W. Schwada (1971\u201381) and J. Russell Nelson (1981\u201389), including and Interim President Richard Peck (1989)\u2014led the university to increased academic stature, the establishment of the ASU West campus in 1984 and its subsequent construction in 1986, a focus on computer-assisted learning and research, and rising enrollment.\n\n1990\u2013present\nUnder the leadership of Lattie F. Coor, president from 1990 to 2002, ASU grew through the creation of the Polytechnic campus and extended education sites. Increased commitment to diversity, quality in undergraduate education, research, and economic development occurred over his 12-year tenure. Part of Coor's legacy to the university was a successful fundraising campaign: through private donations, more than $500\u00a0million was invested in areas that would significantly impact the future of ASU. Among the campaign's achievements were the naming and endowing of Barrett, The Honors College, and the Herberger Institute for Design and the Arts; the creation of many new endowed faculty positions; and hundreds of new scholarships and fellowships.\n\nIn 2002, Michael M. Crow became the university's 16th president. At his inauguration, he outlined his vision for transforming ASU into a \"New American University\"\u2014one that would be open and inclusive, and set a goal for the university to meet Association of American Universities criteria and to become a member. Crow initiated the idea of transforming ASU into \"One university in many places\"\u2014a single institution comprising several campuses, sharing students, faculty, staff and accreditation. Subsequent reorganizations combined academic departments, consolidated colleges and schools, and reduced staff and administration as the university expanded its West and Polytechnic campuses. ASU's Downtown Phoenix campus was also expanded, with several colleges and schools relocating there. The university established learning centers throughout the state, including the ASU Colleges at Lake Havasu City and programs in Thatcher, Yuma, and Tucson. Students at these centers can choose from several ASU degree and certificate programs.\n\nDuring Crow's tenure, and aided by hundreds of millions of dollars in donations, ASU began a years-long research facility capital building effort that led to the establishment of the Biodesign Institute at Arizona State University, the Julie Ann Wrigley Global Institute of Sustainability, and several large interdisciplinary research buildings. Along with the research facilities, the university faculty was expanded, including the addition of five Nobel Laureates. Since 2002, the university's research expenditures have tripled and more than 1.5\u00a0million square feet of space has been added to the university's research facilities.\n\nThe economic downturn that began in 2008 took a particularly hard toll on Arizona, resulting in large cuts to ASU's budget. In response to these cuts, ASU capped enrollment, closed some four dozen academic programs, combined academic departments, consolidated colleges and schools, and reduced university faculty, staff and administrators; however, with an economic recovery underway in 2011, the university continued its campaign to expand the West and Polytechnic Campuses, and establish a low-cost, teaching-focused extension campus in Lake Havasu City.\n\nAs of 2011, an article in Slate reported that, \"the bottom line looks good\", noting that: Since Crow's arrival, ASU's research funding has almost tripled to nearly $350 million. Degree production has increased by 45 percent. And thanks to an ambitious aid program, enrollment of students from Arizona families below poverty is up 647 percent.\n\nIn 2015, the Thunderbird School of Global Management became the fifth ASU campus, as the Thunderbird School of Global Management at ASU. Partnerships for education and research with Mayo Clinic established collaborative degree programs in health care and law, and shared administrator positions, laboratories and classes at the Mayo Clinic Arizona campus.\n\nThe Beus Center for Law and Society, the new home of ASU's Sandra Day O'Connor College of Law, opened in fall 2016 on the Downtown Phoenix campus, relocating faculty and students from the Tempe campus to the state capital.\n\nOrganization and administration\n\nThe Arizona Board of Regents governs Arizona State University as well as the state's other public universities; University of Arizona and Northern Arizona University. The Board of Regents is composed of 12 members including 11 who are voting members, and one non-voting member. Members of the board include the state governor and superintendent of public instruction acting as ex-officio members, eight volunteer Regents members with eight-year terms who are appointed by the Governor, and two student regents, each with two-year terms, and each serving a one-year term as non-voting apprentices. ABOR provides policy guidance to the state universities of Arizona. ASU has four campuses in metropolitan Phoenix, Arizona, including the Tempe campus in Tempe; the West campus in Glendale; the Downtown Phoenix campus; and the Polytechnic campus in Mesa. ASU also offers courses and degrees through ASU Online and at the ASU Colleges at Lake Havasu City in western Arizona, and offers regional learning programs in Thatcher, Yuma and Tucson.\n\nThe Arizona Board of Regents appoints and elects the president of the university, who is considered the institution's chief executive officer and the chief budget officer. The president executes measures enacted by the Board of Regents, controls the university's property, and acts as the university's official representative to the Board of Regents. The chief executive officer is assisted through the administration of the institution by the provost, vice presidents, deans, faculty, directors, department chairs, and other officers. The president also selects and appoints administrative officers and general counsels. The 16th ASU president is Michael M. Crow, who has served since July 1, 2002.\n\nCampuses and locations\nAcademic programs are spread across four distinct campuses in the Phoenix Metropolitan Area; however, unlike most multi-campus institutions, ASU describes itself as \"one university in many places\", inferring there is \"not a system with separate campuses, and not one main campus with branch campuses.\" The university considers each campus \"distinctive\" and academically focused on certain aspects of the overall university mission. The Tempe campus is the university's research and graduate school center. Undergraduate studies on the Tempe campus are research-based programs that prepare students for graduate school, professional school, or employment. The Polytechnic campus is designed with an emphasis on professional and technological programs for direct workforce preparation. The Polytechnic campus is the site of many of the university's simulators and laboratories dedicated for project-based learning. The West campus is focused on interdisciplinary degrees and the liberal arts, while maintaining professional programs with a direct impact on the community and society. The Downtown Phoenix campus focuses on direct urban and public programs such as nursing, public policy, criminal justice, mass communication, and journalism. ASU recently relocated some nursing and health related programs to its new ASU-Mayo Medical School campus. Inter-campus shuttles and light rail allow students and faculty to easily travel between the campuses. In addition to the physical campuses, ASU's \"virtual campus\" at the university's SkySong Innovation Center, provides online and extended education.\n\nThe Arizona Board of Regents reports the ASU facilities inventory totals more than 23 million gross square feet.\n\nTempe campus\n\nASU's Tempe campus is in downtown Tempe, Arizona, about  east of downtown Phoenix. The campus is considered urban, and is approximately  in size. It is arranged around broad pedestrian malls and is completely encompassed by an arboretum. The Tempe campus is also the largest of ASU's campuses, with more than 70,000 students enrolled in at least one class on campus in fall 2017. The campus is considered to range from the streets Rural Road on the east to Mill Avenue on the west, and Apache Boulevard on the south to Rio Salado Parkway on the north.\n\nThe Tempe campus is ASU's original campus, and Old Main, the oldest building on campus, still stands. Today's university and the Tempe campus were founded as the Territorial Normal School when first constructed, and was originally a teachers college. There are many notable landmarks on campus, including Grady Gammage Memorial Auditorium, designed by Frank Lloyd Wright; Palm Walk, which is lined by 111 palm trees; Charles Trumbull Hayden Library; the University Club building; Margaret Gisolo Dance Theatre; Arizona State University Art Museum; and University Bridge. Furthermore, the Tempe campus is home to Barrett, The Honors College. In addition, the campus has an extensive public art collection; It was named \"the single most impressive venue for contemporary art in Arizona\" by Art in America magazine. Against the northwest edge of campus is the Mill Avenue district (part of downtown Tempe), which has a college atmosphere that attracts many students to its restaurants and bars. Students also have Tempe Marketplace, a shopping, dining and entertainment center with an outdoor setting near the northeast border of the campus. The Tempe campus is also home to all of the university's athletic facilities.\n\nWest campus\n\nEstablished in 1984 by the Arizona legislature, the West campus sits on  in a suburban area of northwest billion, up 1 percent from September, the year Phoenix. The West campus lies about  northwest of Downtown Phoenix, and about  northwest of the Tempe campus. The West campus is designated as a Phoenix Point of Pride and is nearly completely powered by a solar array. The campus serves more than 4,000 students enrolled in at least a single course and offers more than 100 degree programs from the New College of Interdisciplinary Arts and Sciences, the Mary Lou Fulton Teachers College, W. P. Carey School of Business, College of Public Service and Community Solutions, College of Health Solutions, and the College of Nursing and Health Innovation. Patterned after the University of Oxford's architecture, the West campus provides modern amenities in its residence halls, dining facilities and the Sun Devil Fitness Complex and swimming pool. Subtropical landscaping, fountains and outdoor enclaves are third-space opportunities for students to socialize or collaborate while pursuing any of the undergraduate and graduate degree programs available.\n\nPolytechnic campus\n\nFounded in 1996 as \"ASU East\", the ASU Polytechnic campus serves more than 4,800 students and is home to more than 130 bachelor's, master's and doctoral degrees in professional and technical programs through the W. P. Carey School of Business/Morrison School of Management and Agribusiness, Mary Lou Fulton Teachers College, Ira A. Fulton Schools of Engineering, and College of Integrative Sciences and Arts, and focuses on professional and technological programs including simulators and lab space in various fields of study. The  campus is in southeast Mesa, Arizona, approximately  southeast of the Tempe campus, and  southeast of downtown Phoenix. The Polytechnic campus sits on the former Williams Air Force Base.\n\nDowntown Phoenix campus\n\nThe Downtown Phoenix campus was established in 2006 on the north side of Downtown Phoenix. The campus has an urban design, with several large modern academic buildings intermingled with commercial and retail office buildings. In addition to the new buildings, the campus included the adaptive reuse of several existing structures, including a 1930s era Post Office that is on the National Register of Historic Places. Serving 11,465 students, the campus houses the College of Health Solutions, College of Integrative Arts and Sciences, College of Nursing and Health Innovation, College of Public Service and Community Solutions, Mary Lou Fulton Teachers College, and Walter Cronkite School of Journalism and Mass Communication. In 2013, the campus added the Sun Devil Fitness Center in conjunction with the original YMCA building. ASU's Sandra Day O'Connor College of Law relocated from Tempe to the Downtown Phoenix campus in 2016.\n\nASU Colleges at Lake Havasu City\n\nIn response to demands for lower-cost public higher education in Arizona, ASU developed the small, undergraduate-only college in Lake Havasu City. ASU Colleges are teaching-focused and provide a selection of popular undergraduate majors. The Lake Havasu City campus offers undergraduate degrees at lower tuition rates than other Arizona research universities and a 15-to-1 student-to-faculty ratio.\n\nASU Online\nASU Online offers more than 150 undergraduate and graduate degree programs through an online platform. The degree programs delivered online hold the same accreditation as the university's traditional face-to-face programs. ASU Online is headquartered at ASU's SkySong campus in Scottsdale, Arizona. ASU Online was ranked in the Top 4 for Best Online Bachelor's Programs by U.S. News & World Report.\n\nOnline students are taught by the same faculty and receive the same diploma as on-campus students. ASU online programs allow students to learn in highly interactive environments through student collaboration and through technological personalized learning environments.\n\nIn April 2015, ASU Online announced a partnership with edX to form a one of a kind program called the Global Freshman Academy. The program is open to all potential students. The students do not need to submit a high school transcript or GPA to apply for the courses. They only pay for the courses ($600 per credit) after they have passed the course if they want to earn the credits.\n\nAs of spring 2017, more than 25,000 students were enrolled through ASU Online. In June 2014, ASU Online and Starbucks announced a partnership called the Starbucks College Achievement Plan. The Starbucks College Achievement Plan offers all benefits-eligible employees full-tuition coverage when they enroll in any one of ASU Online's undergraduate degree programs.\n\nMayo Clinic School of Medicine, in collaboration with ASU\nIn 2016, Mayo Clinic and ASU formed a new platform for health care education and research: the Mayo Clinic and Arizona State University Alliance for Health Care. Beginning in 2017, Mayo Clinic School of Medicine students in Phoenix and Scottsdale are among the first to earn a certificate in the Science of Health Care Delivery, with the option to earn a master's degree in the Science of Health Care Delivery through ASU.\n\nThunderbird Campus\n\nThunderbird School of Global Management is one of the newest units of \"Arizona State University Knowledge Enterprise.\" The flagship campus was in Glendale, Arizona, at Thunderbird Field No. 1, a former military airfield from which it derives its name, until 2018 when the Thunderbird School relocated to the Downtown area.\n\nBarrett and O'Connor Center\n\nFollowing a nearly 15-year presence in Washington, D.C., through more minor means, ASU opened the Barrett and O'Connor Center in 2018 to solidify the University's contacts with the capital city. The center houses ASU's D.C.-based academic programs, including the Washington Bureau of the Walter Cronkite School of Journalism and Mass Communication, the Sandra Day O\u2019Connor College of Law Rule of Law and Governance program, the Capital Scholars program, and the McCain Institute's Next Generation Leaders program, among many others. In addition to hosting classes and internships on-site, special lectures and seminars taught from the Barrett & O\u2019Connor Washington Center are connected to classrooms in Arizona through video-conferencing technology. The Barrett and O'Connor center is located at 1800 I St NW, Washington, DC 20006, very close to the White House.\n\nASU California Center in Downtown Los Angeles\nASU's California Center is located in Los Angeles at the Herald Examiner Building.  The center offers undergraduate and graduate degree programs, executive education, workshops and seminars.\n\nAcademics\n\nAdmissions\n\nFor fall 2017, ASU admitted 82% of all freshman applicants and is considered a \"more selective\" university by U.S. News & World Report. Average GPA of enrolling freshman was 3.53; the average SAT score was 1216 for critical reading and math combined; and the average ACT composite score was 25.0.\n\nBarrett, The Honors College is ranked among the top honors programs in the nation.  Although there are no set minimum admissions criteria for Barrett College, the average GPA of Fall 2017 incoming freshmen was 3.78, with an average SAT score of 1380 and an average ACT score of 29. The Honors college has 7,236 students, with 719 National Merit Scholars.\n\nASU enrolls 10,268 international students, 14.3% of the total student population. The international student body represents more than 150 nations. The Institute of International Education ranked ASU as the top public university in the U.S. for hosting international students in 2016\u20132017.\n\nAcademic programs\n\nASU offers over 350 majors to undergraduate students, and more than 100 graduate programs leading to numerous masters and doctoral degrees in the liberal arts and sciences, design and arts, engineering, journalism, education, business, law, nursing, public policy, technology, and sustainability. These programs are divided into 16 colleges and schools which are spread across ASU's six campuses. ASU also offers the 4+1 accelerated program, which allows students in their senior year to attain their master's degree the following year. However the 4+1 accelerated program is not associated with all majors, for example in the Mary Lou Fulton Teachers College the 4+1 accelerated program only works with Education Exploratory majors. ASU uses a plus-minus grading system with highest cumulative GPA awarded of 4.0 (at time of graduation). Arizona State University is accredited by the Higher Learning Commission.\n\nRankings\n\nThe 2021 U.S. News & World Report ratings ranked ASU tied for 103rd among universities in the United States and tied for 146th", "flag": 1, "segments": [[3261, 3271]], "strength": 5.5}
{"text": "Art Deco, sometimes referred to as Deco, is a style of visual arts, architecture and design that first appeared in France just before World War I. It influenced the design of buildings, furniture, jewellery, fashion, cars, cinemas, trains, ocean liners, and everyday objects such as radios and vacuum cleaners. It took its name, short for Arts D\u00e9coratifs, from the Exposition internationale des arts d\u00e9coratifs et industriels modernes (International Exhibition of Modern Decorative and Industrial Arts) held in Paris in 1925.\n\nArt Deco combined modern styles with fine craftsmanship and rich materials. During its heyday, it represented luxury, glamour, exuberance, and faith in social and technological progress.\n\nFrom its outset, Art Deco was influenced by the bold geometric forms of Cubism and the Vienna Secession; the bright colours of Fauvism and of the Ballets Russes; the updated craftsmanship of the furniture of the eras of Louis Philippe I and Louis XVI; and the exoticized styles of China and Japan, India, Persia, ancient Egypt and Maya art. It featured rare and expensive materials, such as ebony and ivory, and exquisite craftsmanship. The Empire State Building, Chrysler Building, and other skyscrapers of New York City built during the 1920s and 1930s are monuments to the style.\n\nIn the 1930s, during the Great Depression, Art Deco became more subdued. New materials arrived, including chrome plating, stainless steel and plastic. A sleeker form of the style, called Streamline Moderne, appeared in the 1930s, featuring curving forms and smooth, polished surfaces. Art Deco is one of the first truly international styles, but its dominance ended with the beginning of World War II and the rise of the strictly functional and unadorned styles of modern architecture and the International Style of architecture that followed.\n\nEtymology\nArt Deco took its name, short for arts d\u00e9coratifs, from the Exposition Internationale des Arts D\u00e9coratifs et Industriels Modernes held in Paris in 1925, though the diverse styles that characterised it had already appeared in Paris and Brussels before World War I.\n\nArts d\u00e9coratifs was first used in France in 1858 in the Bulletin de la Soci\u00e9t\u00e9 fran\u00e7aise de photographie. In 1868, the Le Figaro newspaper used the term objets d'art d\u00e9coratifs for objects for stage scenery created for the Th\u00e9\u00e2tre de l'Op\u00e9ra. In 1875, furniture designers, textile, jewellers, glass-workers, and other craftsmen were officially given the status of artists by the French government. In response, the \u00c9cole royale gratuite de dessin (Royal Free School of Design), founded in 1766 under King Louis XVI to train artists and artisans in crafts relating to the fine arts, was renamed the \u00c9cole nationale des arts d\u00e9coratifs (National School of Decorative Arts). It took its present name, ENSAD (\u00c9cole nationale sup\u00e9rieure des arts d\u00e9coratifs), in 1927.\n\nAt the 1925 Exposition, architect Le Corbusier wrote a series of articles about the exhibition for his magazine L'Esprit Nouveau, under the title \"1925 EXPO. ARTS. D\u00c9CO.\", which were combined into a book, L'art d\u00e9coratif d'aujourd'hui (Decorative Art Today). The book was a spirited attack on the excesses of the colourful, lavish objects at the Exposition, and on the idea that practical objects such as furniture should not have any decoration at all; his conclusion was that \"Modern decoration has no decoration\".\n\nThe actual term art d\u00e9co did not appear in print until 1966, in the title of the first modern exhibition on the subject, held by the Museum of Decorative Arts in Paris, Les Ann\u00e9es 25 : Art d\u00e9co, Bauhaus, Stijl, Esprit nouveau, which covered the variety of major styles in the 1920s and 1930s. The term was then used in a 1966 newspaper article by Hillary Gelson in The Times (London, 12 November), describing the different styles at the exhibit.\n\nArt Deco gained currency as a broadly applied stylistic label in 1968 when historian Bevis Hillier published the first major academic book on it, Art Deco of the 20s and 30s. He noted that the term was already being used by art dealers, and cites The Times (2 November 1966) and an essay named Les Arts D\u00e9co in Elle magazine (November 1967) as examples. In 1971, he organized an exhibition at the Minneapolis Institute of Arts, which he details in his book The World of Art Deco.\n\nOrigins\n\nSociety of Decorative Artists (1901\u20131913)\nThe emergence of Art Deco was closely connected with the rise in status of decorative artists, who until late in the 19th century were considered simply as artisans. The term arts d\u00e9coratifs had been invented in 1875, giving the designers of furniture, textiles, and other decoration official status. The Soci\u00e9t\u00e9 des artistes d\u00e9corateurs (Society of Decorative Artists), or SAD, was founded in 1901, and decorative artists were given the same rights of authorship as painters and sculptors. A similar movement developed in Italy. The first international exhibition devoted entirely to the decorative arts, the Esposizione Internazionale d'Arte Decorativa Moderna, was held in Turin in 1902. Several new magazines devoted to decorative arts were founded in Paris, including Arts et d\u00e9coration and L'Art d\u00e9coratif moderne. Decorative arts sections were introduced into the annual salons of the Soci\u00e9te des artistes fran\u00e7ais, and later in the Salon d'Automne. French nationalism also played a part in the resurgence of decorative arts, as French designers felt challenged by the increasing exports of less expensive German furnishings. In 1911, SAD proposed a major new international exposition of decorative arts in 1912. No copies of old styles would be permitted, only modern works. The exhibit was postponed until 1914; and then, because of the war, until 1925, when it gave its name to the whole family of styles known as \"D\u00e9co\".\n\nParisian department stores and fashion designers also played an important part in the rise of Art Deco. Prominent businesses such as silverware firm Christofle, glass designer Ren\u00e9 Lalique, and the jewellers Louis Cartier and Boucheron began designing products in more modern styles. Beginning in 1900, department stores recruited decorative artists to work in their design studios. The decoration of the 1912 Salon d'Automne was entrusted to the department store Printemps, and that year it created its own workshop, Primavera. By 1920 Primavera employed more than 300 artists, whose styles ranged from updated versions of Louis XIV, Louis XVI, and especially Louis Philippe furniture made by Louis S\u00fce and the Primavera workshop, to more modern forms from the workshop of the Au Louvre department store. Other designers, including \u00c9mile-Jacques Ruhlmann and Paul Follot, refused to use mass production, insisting that each piece be made individually. The early Art Deco style featured luxurious and exotic materials such as ebony, ivory and silk, very bright colours and stylized motifs, particularly baskets and bouquets of flowers of all colours, giving a modernist look.\n\nVienna Secession and Wiener Werkst\u00e4tte (1905\u20131911)\nThe architects of the Vienna Secession (formed 1897), especially Josef Hoffmann, had a notable influence on Art Deco. His Stoclet Palace, in Brussels (1905\u20131911), was a prototype of the Art Deco style, featuring geometric volumes, symmetry, straight lines, concrete covered with marble plaques, finely-sculpted ornament, and lavish interiors, including mosaic friezes by Gustav Klimt. Hoffmann was also a founder of the Wiener Werkst\u00e4tte (1903\u20131932), an association of craftsmen and interior designers working in the new style. This became the model for the Compagnie des arts fran\u00e7ais, created in 1919, which brought together Andr\u00e9 Mare, and Louis S\u00fce, the first leading French Art Deco designers and decorators.\n\nNew materials and technologies\nNew materials and technologies, especially reinforced concrete, were key to the development and appearance of Art Deco. The first concrete house was built in 1853 in the Paris suburbs by Fran\u00e7ois Coignet. In 1877 Joseph Monier introduced the idea of strengthening the concrete with a mesh of iron rods in a grill pattern. In 1893 Auguste Perret built the first concrete garage in Paris, then an apartment building, house, then, in 1913, the Th\u00e9\u00e2tre des Champs-\u00c9lys\u00e9es. The theatre was denounced by one critic as the \"Zeppelin of Avenue Montaigne\", an alleged Germanic influence, copied from the Vienna Secession. Thereafter, the majority of Art Deco buildings were made of reinforced concrete, which gave greater freedom of form and less need for reinforcing pillars and columns. Perret was also a pioneer in covering the concrete with ceramic tiles, both for protection and decoration. The architect Le Corbusier first learned the uses of reinforced concrete working as a draftsman in Perret's studio.\n\nOther new technologies that were important to Art Deco were new methods in producing plate glass, which was less expensive and allowed much larger and stronger windows, and for mass-producing aluminium, which was used for building and window frames and later, by Corbusier, Warren McArthur, and others, for lightweight furniture.\n\nTh\u00e9\u00e2tre des Champs-\u00c9lys\u00e9es (1910\u20131913)\n\nThe Th\u00e9\u00e2tre des Champs-\u00c9lys\u00e9es (1910\u20131913), by Auguste Perret, was the first landmark Art Deco building completed in Paris. Previously, reinforced concrete had been used only for industrial and apartment buildings, Perret had built the first modern reinforced-concrete apartment building in Paris on rue Benjamin Franklin in 1903\u201304. Henri Sauvage, another important future Art Deco architect, built another in 1904 at 7, rue Tr\u00e9taigne (1904). From 1908 to 1910, the 21-year-old Le Corbusier worked as a draftsman in Perret's office, learning the techniques of concrete construction. Perret's building had clean rectangular form, geometric decoration and straight lines, the future trademarks of Art Deco. The d\u00e9cor of the theatre was also revolutionary; the fa\u00e7ade was decorated with high reliefs by Antoine Bourdelle, a dome by Maurice Denis, paintings by \u00c9douard Vuillard, and an Art Deco curtain by Ker-Xavier Roussel. The theatre became famous as the venue for many of the first performances of the Ballets Russes. Perret and Sauvage became the leading Art Deco architects in Paris in the 1920s.\n\nSalon d'Automne (1912\u20131913)\n\nAt its birth between 1910 and 1914, Art Deco was an explosion of colours, featuring bright and often clashing hues, frequently in floral designs, presented in furniture upholstery, carpets, screens, wallpaper and fabrics. Many colourful works, including chairs and a table by Maurice Dufr\u00eane and a bright Gobelin carpet by Paul Follot were presented at the 1912 Salon des artistes d\u00e9corateurs. In 1912\u20131913 designer Adrien Karbowsky made a floral chair with a parrot design for the hunting lodge of art collector Jacques Doucet. The furniture designers Louis S\u00fce and Andr\u00e9 Mare made their first appearance at the 1912 exhibit, under the name of the Atelier fran\u00e7ais, combining polychromatic fabrics with exotic and expensive materials, including ebony and ivory. After World War I, they became one of the most prominent French interior design firms, producing the furniture for the first-class salons and cabins of the French transatlantic ocean liners.\n\nThe vivid hues of Art Deco came from many sources, including the exotic set designs by L\u00e9on Bakst for the Ballets Russes, which caused a sensation in Paris just before World War I. Some of the colours were inspired by the earlier Fauvism movement led by Henri Matisse; others by the Orphism of painters such as Sonia Delaunay; others by the movement known as Les Nabis, and in the work of symbolist painter Odilon Redon, who designed fireplace screens and other decorative objects. Bright shades were a feature of the work of fashion designer Paul Poiret, whose work influenced both Art Deco fashion and interior design.\n\nCubism\n\nThe art movement known as Cubism appeared in France between 1907 and 1912, influencing the development of Art Deco. In Art Deco Complete: The Definitive Guide to the Decorative Arts of the 1920s and 1930s Alastair Duncan writes \"Cubism, in some bastardized form or other, became the lingua franca of the era's decorative artists.\" The Cubists, themselves under the influence of Paul C\u00e9zanne, were interested in the simplification of forms to their geometric essentials: the cylinder, the sphere, the cone.\n\nIn 1912, the artists of the Section d'Or exhibited works considerably more accessible to the general public than the analytical Cubism of Picasso and Braque. The Cubist vocabulary was poised to attract fashion, furniture and interior designers.\n\nThe 1912 writings of Andr\u00e9 Vera, Le Nouveau style, published in the journal L'Art d\u00e9coratif, expressed the rejection of Art Nouveau forms (asymmetric, polychrome and picturesque) and called for simplicit\u00e9 volontaire, sym\u00e9trie manifeste, l'ordre et l'harmonie, themes that would eventually become common within Art Deco; though the Deco style was often extremely colourful and often complex.\n\nIn the Art D\u00e9coratif section of the 1912 Salon d'Automne, an architectural installation was exhibited known as La Maison Cubiste. The facade was designed by Raymond Duchamp-Villon. The d\u00e9cor of the house was by Andr\u00e9 Mare. La Maison Cubiste was a furnished installation with a fa\u00e7ade, a staircase, wrought iron banisters, a bedroom, a living room\u2014the Salon Bourgeois, where paintings by Albert Gleizes, Jean Metzinger, Marie Laurencin, Marcel Duchamp, Fernand L\u00e9ger and Roger de La Fresnaye were hung. Thousands of spectators at the salon passed through the full-scale model.\n\nThe fa\u00e7ade of the house, designed by Duchamp-Villon, was not very radical by modern standards; the lintels and pediments had prismatic shapes, but otherwise the fa\u00e7ade resembled an ordinary house of the period. For the two rooms, Mare designed the wallpaper, which featured stylized roses and floral patterns, along with upholstery, furniture and carpets, all with flamboyant and colourful motifs. It was a distinct break from traditional d\u00e9cor. The critic Emile Sedeyn described Mare's work in the magazine Art et D\u00e9coration: \"He does not embarrass himself with simplicity, for he multiplies flowers wherever they can be put. The effect he seeks is obviously one of picturesqueness and gaiety. He achieves it.\" The Cubist element was provided by the paintings. The installation was attacked by some critics as extremely radical, which helped make for its success. This architectural installation was subsequently exhibited at the 1913 Armory Show, New York City, Chicago and Boston. Thanks largely to the exhibition, the term \"Cubist\" began to be applied to anything modern, from women's haircuts to clothing to theater performances.\"\n\nThe Cubist influence continued within Art Deco, even as Deco branched out in many other directions. In 1927, Cubists Joseph Csaky, Jacques Lipchitz, Louis Marcoussis, Henri Laurens, the sculptor Gustave Miklos, and others collaborated in the decoration of a Studio House, rue Saint-James, Neuilly-sur-Seine, designed by the architect Paul Ruaud and owned by the French fashion designer Jacques Doucet, also a collector of Post-Impressionist art by Henri Matisse and Cubist paintings (including Les Demoiselles d'Avignon, which he bought directly from Picasso's studio). Laurens designed the fountain, Csaky designed Doucet's staircase, Lipchitz made the fireplace mantel, and Marcoussis made a Cubist rug.\n\nBesides the Cubist artists, Doucet brought in other Deco interior designers to help in decorating the house, including Pierre Legrain, who was in charge of organizing the decoration, and Paul Iribe, Marcel Coard, Andr\u00e9 Groult, Eileen Gray and Rose Adler to provide furniture. The d\u00e9cor included massive pieces made of macassar ebony, inspired by African art, and furniture covered with Morocco leather, crocodile skin and snakeskin, and patterns taken from African designs.\n\nCubism's adumbrated geometry became coin of the realm in the 1920s. Art Deco's development of Cubism's selective geometry into a wider array of shapes carried Cubism as a pictorial taxonomy to a much broader audience and wider appeal. (Richard Harrison Martin, Metropolitan Museum of Art)\n\nInfluences\n\nArt Deco was not a single style, but a collection of different and sometimes contradictory styles. In architecture, Art Deco was the successor to and reaction against Art Nouveau, a style which flourished in Europe between 1895 and 1900, and also gradually replaced the Beaux-Arts and neoclassical that were predominant in European and American architecture. In 1905 Eug\u00e8ne Grasset wrote and published M\u00e9thode de Composition Ornementale, \u00c9l\u00e9ments Rectilignes, in which he systematically explored the decorative (ornamental) aspects of geometric elements, forms, motifs and their variations, in contrast with (and as a departure from) the undulating Art Nouveau style of Hector Guimard, so popular in Paris a few years earlier. Grasset stressed the principle that various simple geometric shapes like triangles and squares are the basis of all compositional arrangements. The reinforced-concrete buildings of Auguste Perret and Henri Sauvage, and particularly the Th\u00e9\u00e2tre des Champs-\u00c9lys\u00e9es, offered a new form of construction and decoration which was copied worldwide.\n\nIn decoration, many different styles were borrowed and used by Art Deco. They included pre-modern art from around the world and observable at the Mus\u00e9e du Louvre, Mus\u00e9e de l'Homme and the Mus\u00e9e national des Arts d'Afrique et d'Oc\u00e9 exciting roller coaster ride? We have created the hottestanie. There was also popular interest in archaeology due to excavations at Pompeii, Troy, and the tomb of the 18th dynasty Pharaoh Tutankhamun. Artists and designers integrated motifs from ancient Egypt, Africa, Mesopotamia, Greece, Rome, Asia, Mesoamerica and Oceania with Machine Age elements.\n\nOther styles borrowed included Russian Constructivism and Italian Futurism, as well as Orphism, Functionalism, and Modernism in general. Art Deco also used the clashing colours and designs of Fauvism, notably in the work of Henri Matisse and Andr\u00e9 Derain, inspired the designs of art deco textiles, wallpaper, and painted ceramics. It took ideas from the high fashion vocabulary of the period, which featured geometric designs, chevrons, zigzags, and stylized bouquets of flowers. It was influenced by discoveries in Egyptology, and growing interest in the Orient and in African art. From 1925 onwards, it was often inspired by a passion for new machines, such as airships, automobiles and ocean liners, and by 1930 this influence resulted in the style called Streamline Moderne.\n\nStyle of luxury and modernity\n\nArt Deco was associated with both luxury and modernity; it combined very expensive materials and exquisite craftsmanship put into modernistic forms. Nothing was cheap about Art Deco: pieces of furniture included ivory and silver inlays, and pieces of Art Deco jewellery combined diamonds with platinum, jade, coral and other precious materials. The style was used to decorate the first-class salons of ocean liners, deluxe trains, and skyscrapers. It was used around the world to decorate the great movie palaces of the late 1920s and 1930s. Later, after the Great Depression, the style changed and became more sober.\n\nA good example of the luxury style of Art Deco is the boudoir of the fashion designer Jeanne Lanvin, designed by Armand-Albert Rateau (1882\u20131938) made between 1922 and 1925. It was located in her house at 16 rue Barbet de Jouy, in Paris, which was demolished in 1965. The room was reconstructed in the Museum of Decorative Arts in Paris. The walls are covered with moulded lambris below sculpted bas-reliefs in stucco. The alcove is framed with columns of marble on bases and a plinth of sculpted wood. The floor is of white and black marble, and in the cabinets decorative objects are displayed against a background of blue silk. Her bathroom had a tub and washstand made of sienna marble, with a wall of carved stucco and bronze fittings.\n\nBy 1928 the style had become more comfortable, with deep leather club chairs. The study designed by the Paris firm of Alavoine for an American businessman in 1928\u201330, is now in the Brooklyn Museum.\n\nBy the 1930s, the style had been somewhat simplified, but it was still extravagant. In 1932 the decorator Paul Ruaud made the Glass Salon for Suzanne Talbot. It featured a serpentine armchair and two tubular armchairs by Eileen Gray, a floor of mat silvered glass slabs, a panel of abstract patterns in silver and black lacquer, and an assortment of animal skins.\n\nInternational Exhibition of Modern Decorative and Industrial Arts (1925)\n\nThe event that marked the zenith of the style and gave it its name was the International Exhibition of Modern Decorative and Industrial Arts which took place in Paris from April to October in 1925. This was officially sponsored by the French government, and covered a site in Paris of 55 acres, running from the Grand Palais on the right bank to Les Invalides on the left bank, and along the banks of the Seine. The Grand Palais, the largest hall in the city, was filled with exhibits of decorative arts from the participating countries. There were 15,000 exhibitors from twenty different countries, including Austria, Belgium, Czechoslovakia, Denmark, Great Britain, Italy, Japan, the Netherlands, Poland, Spain, Sweden, and the new Soviet Union. Germany was not invited because of tensions after the war; The United States, misunderstanding the purpose of the exhibit, declined to participate. The event was visited by sixteen million people during its seven-month run. The rules of the exhibition required that all work be modern; no historical styles were allowed. The main purpose of the Exhibit was to promote the French manufacturers of luxury furniture, porcelain, glass, metalwork, textiles, and other decorative products. To further promote the products, all the major Paris department stores, and major designers had their own pavil", "flag": 1, "segments": [[4018, 4028]], "strength": 5.5}
{"text": "Antimicrobial resistance (AMR) occurs when microbes evolve mechanisms that protect them from the effects of antimicrobials. Antibiotic resistance is a subset of AMR, that applies specifically to bacteria that become resistant to antibiotics. \n\nInfections due to AMR cause millions of deaths each year. Infections caused by resistant microbes are more difficult to treat, requiring higher doses of antimicrobial drugs, or alternative medications which may prove more toxic. These approaches may also be more expensive. Microbes resistant to multiple antimicrobials are called multidrug resistant (MDR).\n\nAll classes of microbes can evolve resistance. Fungi evolve antifungal resistance. Viruses evolve antiviral resistance. Protozoa evolve antiprotozoal resistance, and bacteria evolve antibiotic resistance. Those bacteria that are considered extensively drug resistant (XDR) or totally drug-resistant (TDR) are sometimes called \"superbugs\". Resistance in bacteria can arise naturally by genetic mutation, or by one species acquiring resistance from another. Resistance can appear spontaneously because of random mutations. However, extended use of antimicrobials appears to encourage selection for mutations which can render antimicrobials ineffective.\n\nThe prevention of antibiotic misuse, which can lead to antibiotic resistance, includes taking antibiotics only when prescribed. Narrow-spectrum antibiotics are preferred over broad-spectrum antibiotics when possible, as effectively and accurately targeting specific organisms is less likely to cause resistance, as well as side effects. For people who take these medications at home, education about proper use is essential. Health care providers can minimize spread of resistant infections by use of proper sanitation and hygiene, including handwashing and disinfecting between patients, and should encourage the same of the patient, visitors, and family members.\n\nRising drug resistance is caused mainly by use of antimicrobials in humans and other animals, and spread of resistant strains between the two. Growing resistance has also been linked to releasing inadequately treated effluents from the pharmaceutical industry, especially in countries where bulk drugs are manufactured. Antibiotics increase selective pressure in bacterial populations, causing vulnerable bacteria to die; this increases the percentage of resistant bacteria which continue growing. Even at very low levels of antibiotic, resistant bacteria can have a growth advantage and grow faster than vulnerable bacteria. As resistance to antibiotics becomes more common there is greater need for alternative treatments. Calls for new antibiotic therapies have been issued, but new drug development is becoming rarer.\n\nAntimicrobial resistance is increasing globally due to increased prescription and dispensing of antibiotic drugs in developing countries. Estimates are that 700,000 to several million deaths result per year and continues to pose a major public health threat worldwide. Each year in the United States, at least 2.8\u00a0million people become infected with bacteria that are resistant to antibiotics and at least 35,000 people die and US$55 billion in increased health care costs and lost productivity. According to World Health Organization (WHO) estimates, 350 million deaths could be caused by AMR by 2050. By then, the yearly death toll will be 10 million, according to a United Nations report.\n\nThere are public calls for global collective action to address the threat that include proposals for international treaties on antimicrobial resistance. Worldwide antibiotic resistance is not completely identified, but poorer countries with weaker healthcare systems are more affected. During the COVID-19 pandemic, action against antimicrobial resistance slowed due to scientists focusing more on SARS-CoV-2 research.\n\nDefinition\n\nThe WHO defines antimicrobial resistance as a microorganism's resistance to an antimicrobial drug that was once able to treat an infection by that microorganism. A person cannot become resistant to antibiotics. Resistance is a property of the microbe, not a person or other organism infected by a microbe.\n\nAntibiotic resistance is a subset of antimicrobial resistance.\u00a0This more specified resistance is linked to pathogenic bacteria and thus broken down into two further subsets, microbiological and clinical. Resistance linked microbiologically is the most common and occurs from genes, mutated or inherited, that allow the bacteria to resist the mechanism associated with certain antibiotics.\u00a0Clinical resistance is shown through the failure of many therapeutic techniques where the bacteria that are normally susceptible to a treatment become resistant after surviving the outcome of the treatment. In both cases of acquired resistance, the bacteria can pass the genetic catalyst for resistance through conjugation, transduction, or transformation.\u00a0This allows the resistance to spread across the same pathogen or even similar bacterial pathogens.\n\nOverview \nWHO report released April 2014 stated, \"this serious threat is no longer a prediction for the future, it is happening right now in every region of the world and has the potential to affect anyone, of any age, in any country. Antibiotic resistance\u2014when bacteria change so antibiotics no longer work in people who need them to treat infections\u2014is now a major threat to public health.\" \n\nGlobal deaths attributable to AMR numbered 1.27 million in 2019. That year, AMR may have contributed to 5 million deaths and one in five people who died due to AMR were children under five years old.\n\nIn 2018, WHO considered antibiotic resistance to be one of the biggest threats to global health, food security and development. Deaths attributable to AMR vary by area:\n\nThe European Centre for Disease Prevention and Control calculated that in 2015 there were 671,689 infections in the EU and European Economic Area caused by antibiotic-resistant bacteria, resulting in 33,110 deaths. Most were acquired in healthcare settings.\n\nCauses \nAntimicrobial resistance is mainly caused by the overuse of antimicrobials. This leads to microbes either evolving a defense against drugs used to treat them, or certain strains of microbes that have a natural resistance to antimicrobials becoming much more prevalent than the ones that are easily defeated with medication.\u00a0 While antimicrobial resistance does occur naturally over time, the use of antimicrobial agents in a variety of settings both within the healthcare industry and outside of has led to antimicrobial resistance becoming increasingly more prevalent.\n\nNatural occurrence \n\nAntimicrobial resistance can evolve naturally due to continued exposure to antimicrobials. Natural selection means that organisms that are able to adapt to their environment, survive, and continue to produce offspring. As a result, the types of microorganisms that are able to survive over time with continued attack by certain antimicrobial agents will naturally become more prevalent in the environment, and those without this resistance will become obsolete.\n\nSome contemporary antibiotic resistances have also evolved naturally before the use of antibiotics or human clinical use of respective antimicrobials. For instance, methicillin-resistance evolved in a pathogen of hedgehogs, possibly as a co-evolutionary adaptation of the pathogen to hedgehogs that are infected by a dermatophyte that naturally produces antibiotics.\n\nOver time, most of the strains of bacteria and infections present will be the type resistant to the antimicrobial agent being used to treat them, making this agent now ineffective to defeat most microbes. With the increased use of antimicrobial agents, there is a speeding up of this natural process.\n\nSelf-medication \nSelf-medication by consumers is defined as \"the taking of medicines on one's own initiative or on another person's suggestion, who is not a certified medical professional\", and it has been identified as one of the primary reasons for the evolution of antimicrobial resistance. In an effort to manage their own illness, patients take the advice of false media sources, friends, and family causing them to take antimicrobials unnecessarily or in excess. Many people resort to this out of necessity, when they have a limited amount of money to see a doctor, or in many developing countries a poorly developed economy and lack of doctors are the cause of self-medication. In these developing countries, governments resort to allowing the sale of antimicrobials as over the counter medications so people could have access to them without having to find or pay to see a medical professional. This increased access makes it extremely easy to obtain antimicrobials without the advice of a physician, and as a result many antimicrobials are taken incorrectly leading to resistant microbial strains. One major example of a place that faces these challenges is India, where in the state of Punjab 73% of the population resorted to treating their minor health issues and chronic illnesses through self-medication.\n\nThe major issue with self-medication is the lack of knowledge of the public on the dangerous effects of antimicrobial resistance, and how they can contribute to it through mistreating or misdiagnosing themselves.\u00a0 In order to determine the public's knowledge and preconceived notions on antibiotic resistance, a major type of antimicrobial resistance, a screening of 3537 articles published in Europe, Asia, and North America was done.\u00a0 Of the 55,225 total people surveyed, 70% had heard of antibiotic resistance previously, but 88% of those people thought it referred to some type of physical change in the body.\u00a0 With so many people around the world with the ability to self-medicate using antibiotics, and a vast majority unaware of what antimicrobial resistance is, it makes the increase of antimicrobial resistance much more likely.\n\nClinical misuse \nClinical misuse by healthcare professionals is another cause leading to increased antimicrobial resistance. Studies done by the CDC show that the indication for treatment of antibiotics, choice of the agent used, and the duration of therapy was incorrect in up to 50% of the cases studied.\u00a0 In another study done in an intensive care unit in a major hospital in France, it was shown that 30% to 60% of prescribed antibiotics were unnecessary. These inappropriate uses of antimicrobial agents promote the evolution of antimicrobial resistance by supporting the bacteria in developing genetic alterations that lead to resistance. In a study done by the American Journal of Infection Control aimed to evaluate physicians\u2019 attitudes and knowledge on antimicrobial resistance in ambulatory settings, only 63% of those surveyed reported antibiotic resistance as a problem in their local practices, while 23% reported the aggressive prescription of antibiotics as necessary to avoid failing to provide adequate care.\u00a0 This demonstrates how a majority of doctors underestimate the impact that their own prescribing habits have on antimicrobial resistance as a whole. It also confirms that some physicians may be overly cautious when it comes to prescribing antibiotics for both medical or legal reasons, even when indication for use for these medications is not always confirmed. This can lead to unnecessary antimicrobial use.\n\nStudies have shown that common misconceptions about the effectiveness and necessity of antibiotics to treat common mild illnesses contribute to their overuse.\n\nPandemics, disinfectants and healthcare systems \nIncreased antibiotic use during the COVID-19 pandemic may exacerbate this global health challenge. Moreover, pandemic burdens on some healthcare systems may contribute to antibiotic-resistant infections. On the other hand, a study suggests that \"increased hand hygiene, decreased international travel, and decreased elective hospital procedures may reduce AMR pathogen selection and spread in the short term\". Disinfectants such as in various forms of use of alcohol-based hand sanitizers, and antiseptic hand wash may also have the potential to increase antimicrobial resistance. According to a study, \"Extensive disinfectant use leads to mutations that induce antimicrobial resistance\".\n\nEnvironmental pollution \nUntreated effluents from pharmaceutical manufacturing industries, hospitals and clinics, and inappropriate disposal of unused or expired medication can expose microbes in the environment to antibiotics and trigger the evolution of resistance.\n\nFood production\n\nLivestock \n\nThe antimicrobial resistance crisis also extends to the food industry, specifically with food producing animals.\u00a0 Antibiotics are fed to livestock to act as growth supplements, and a preventative measure to decrease the likelihood of infections.\u00a0 This results in the transfer of resistant bacterial strains into the food that humans eat, causing potentially fatal transfer of disease.\u00a0 While this practice does result in better yields and meat products, it is a major issue in terms of preventing antimicrobial resistance. Though the evidence linking antimicrobial usage in livestock to antimicrobial resistance is limited, the World Health Organization Advisory Group on Integrated Surveillance of Antimicrobial Resistance strongly recommended the reduction of use of medically important antimicrobials in livestock. Additionally, the Advisory Group stated that such antimicrobials should be expressly prohibited for both growth promotion and disease prevention.\n\nIn a study published by the National Academy of Sciences mapping antimicrobial consumption in livestock globally, it was predicted that in the 228 countries studied, there would be a total 67% increase in consumption of antibiotics by livestock by 2030. reds in the shade: yellow and pink all In some countries such as Brazil, Russia, India, China, and South Africa it is predicted that a 99% increase will occur. Several countries have restricted the use of antibiotics in livestock, including Canada, China, Japan, and the US. These restrictions are sometimes associated with a reduction of the prevalence of antimicrobial resistance in humans.\n\nPesticides \nMost pesticides protect crops against insects and plants, but in some cases antimicrobial pesticides are used to protect against various microorganisms such as bacteria, viruses, fungi, algae, and protozoa. The overuse of many pesticides in an effort to have a higher yield of crops has resulted in many of these microbes evolving a tolerance against these antimicrobial agents. Currently there are over 4000 antimicrobial pesticides registered with the EPA and sold to market, showing the widespread use of these agents. It is estimated that for every single meal a person consumes, 0.3 \u202fg of pesticides is used, as 90% of all pesticide use is used on agriculture. A majority of these products are used to help defend against the spread of infectious diseases, and hopefully protect public health. But out of the large amount of pesticides used, it is also estimated that less than 0.1% of those antimicrobial agents, actually reach their targets. That leaves over 99% of all pesticides used available to contaminate other resources. In soil, air, and water these antimicrobial agents are able to spread, coming in contact with more microorganisms and leading to these microbes evolving mechanisms to tolerate and further resist pesticides.\n\nPrevention\n\nThere have been increasing public calls for global collective action to address the threat, including a proposal for international treaty on antimicrobial resistance. Further detail and attention is still needed in order to recognize and measure trends in resistance on the international level; the idea of a global tracking system has been suggested but implementation has yet to occur. A system of this nature would provide insight to areas of high resistance as well as information necessary for evaluating programs and other changes made to fight or reverse antibiotic resistance.\n\nDuration of antibiotics\nAntibiotic treatment duration should be based on the infection and other health problems a person may have. For many infections once a person has improved there is little evidence that stopping treatment causes more resistance. Some, therefore, feel that stopping early may be reasonable in some cases. Other infections, however, do require long courses regardless of whether a person feels better.\n\nMonitoring and mapping\nThere are multiple national and international monitoring programs for drug-resistant threats, including methicillin-resistant Staphylococcus aureus (MRSA), vancomycin-resistant S. aureus (VRSA), extended spectrum beta-lactamase (ESBL), vancomycin-resistant Enterococcus (VRE), and multidrug-resistant Acinetobacter baumannii (MRAB).\n\nResistanceOpen is an online global map of antimicrobial resistance developed by HealthMap which displays aggregated data on antimicrobial resistance from publicly available and user submitted data. The website can display data for a  radius from a location. Users may submit data from antibiograms for individual hospitals or laboratories. European data is from the EARS-Net (European Antimicrobial Resistance Surveillance Network), part of the ECDC.\n\nResistanceMap is a website by the Center for Disease Dynamics, Economics & Policy and provides data on antimicrobial resistance on a global level.\n\nLimiting antibiotic use \n\nAntibiotic stewardship programmes appear useful in reducing rates of antibiotic resistance. The antibiotic stewardship program will also provide pharmacists with the knowledge to educate patients that antibiotics will not work for a virus.\n\nExcessive antibiotic use has become one of the top contributors to the evolution of antibiotic resistance. Since the beginning of the antibiotic era, antibiotics have been used to treat a wide range of disease. Overuse of antibiotics has become the primary cause of rising levels of antibiotic resistance. The main problem is that doctors are willing to prescribe antibiotics to ill-informed individuals who believe that antibiotics can cure nearly all illnesses, including viral infections like the common cold. In an analysis of drug prescriptions, 36% of individuals with a cold or an upper respiratory infection (both viral in origin) were given prescriptions for antibiotics. These prescriptions accomplished nothing other than increasing the risk of further evolution of antibiotic resistant bacteria. Using antibiotics without prescription is another driving force leading to the overuse of antibiotics to self-treat diseases like the common cold, cough, fever, and dysentery resulting in a epidemic of antibiotic resistance in countries like Bangladesh, risking its spread around the globe. Introducing strict antibiotic stewardship in the outpatient setting may reduce the emerging bacterial resistance.\n\nAt the hospital level \nAntimicrobial stewardship teams in hospitals are encouraging optimal use of antimicrobials. The goals of antimicrobial stewardship are to help practitioners pick the right drug at the right dose and duration of therapy while preventing misuse and minimizing the development of resistance. Stewardship may reduce the length of stay by an average of slightly over 1 day while not increasing the risk of death.\n\nAt the farming level \nIt is established that the use of antibiotics in animal husbandry can give rise to AMR resistances in bacteria found in food animals to the antibiotics being administered (through injections or medicated feeds). For this reason only antimicrobials that are deemed \"not-clinically relevant\" are used in these practices.\n\nRecent studies have shown that the prophylactic use of \"non-priority\" or \"non-clinically relevant\" antimicrobials in feeds can potentially, under certain conditions, lead to co-selection of environmental AMR bacteria with resistance to medically important antibiotics. The possibility for co-selection of AMR resistances in the food chain pipeline may have far-reaching implications for human health.\n\nAt the level of GP \nGiven the volume of care provided in primary care (General Practice), recent strategies have focused on reducing unnecessary antibiotic prescribing in this setting. Simple interventions, such as written information explaining the futility of antibiotics for common infections such as upper respiratory tract infections, have been shown to reduce antibiotic prescribing.\n\nThe prescriber should closely adhere to the five rights of drug administration: the right patient, the right drug, the right dose, the right route, and the right time.\n\nCultures should be taken before treatment when indicated and treatment potentially changed based on the susceptibility report.\n\nAbout a third of antibiotic prescriptions written in outpatient settings in the United States were not appropriate in 2010 and 2011. Doctors in the U.S. wrote 506 annual antibiotic scripts for every 1,000 people, with 353 being medically necessary.\n\nHealth workers and pharmacists can help tackle resistance by: enhancing infection prevention and control; only prescribing and dispensing antibiotics when they are truly needed; prescribing and dispensing the right antibiotic(s) to treat the illness.\n\nAt the individual level \nPeople can help tackle resistance by using antibiotics only when prescribed by a doctor; completing the full prescription, even if they feel better; never sharing antibiotics with others or using leftover prescriptions.\n\nCountry examples\n The Netherlands has the lowest rate of antibiotic prescribing in the OECD, at a rate of 11.4 defined daily doses (DDD) per 1,000 people per day in 2011.\n Germany and Sweden also have lower prescribing rates, with Sweden's rate having been declining since 2007.\n Greece, France and Belgium have high prescribing rates of more than 28 DDD.\n\nWater, sanitation, hygiene \nInfectious disease control through improved water, sanitation and hygiene (WASH) infrastructure needs to be included in the antimicrobial resistance (AMR) agenda. The \"Interagency Coordination Group on Antimicrobial Resistance\" stated in 2018 that \"the spread of pathogens through unsafe water results in a high burden of gastrointestinal disease, increasing even further the need for antibiotic treatment.\" This is particularly a problem in developing countries where the spread of infectious diseases caused by inadequate WASH standards is a major driver of antibiotic demand. Growing usage of antibiotics together with persistent infectious disease levels have led to a dangerous cycle in which reliance on antimicrobials increases while the efficacy of drugs diminishes. The proper use of infrastructure for water, sanitation and hygiene (WASH) can result in a 47\u201372 percent decrease of diarrhea cases treated with antibiotics depending on the type of intervention and its effectiveness. A reduction of the diarrhea disease burden through improved infrastructure would result in large decreases in the number of diarrhea cases treated with antibiotics. This was estimated as ranging from 5 million in Brazil to up to 590\u00a0million in India by the year 2030. The strong link between increased consumption and resistance indicates that this will directly mitigate the accelerating spread of AMR. Sanitation and water for all by 2030 is Goal Number 6 of the Sustainable Development Goals.\n\nAn increase in hand washing compliance by hospital staff results in decreased rates of resistant organisms.\n\nWater supply and sanitation infrastructure in health facilities offer significant co-benefits for combatting AMR, and investment should be increased. There is much room for improvement: WHO and UNICEF estimated in 2015 that globally 38% of health facilities did not have a source of water, nearly 19% had no toilets and 35% had no water and soap or alcohol-based hand rub for handwashing.\n\nIndustrial wastewater treatment \nManufacturers of antimicrobials need to improve the treatment of their wastewater (by using industrial wastewater treatment processes) to reduce the release of residues into the environment.\n\nManagement in animal use\n\nEurope\nIn 1997, European Union health ministers voted to ban avoparcin and four additional antibiotics used to promote animal growth in 1999. In 2006 a ban on the use of antibiotics in European feed, with the exception of two antibiotics in poultry feeds, became effective. In Scandinavia, there is evidence that the ban has led to a lower prevalence of antibiotic resistance in (nonhazardous) animal bacterial populations. As of 2004, several European countries established a decline of antimicrobial resistance in humans through limiting the use of antimicrobials in agriculture and food industries without jeopardizing animal health or economic cost.\n\nUnited States\nThe United States Department of Agriculture (USDA) and the Food and Drug Administration (FDA) collect data on antibiotic use in humans and in a more limited fashion in animals. The FDA first determined in 1977 that there is evidence of emergence of antibiotic-resistant bacterial strains in livestock. The long-established practice of permitting OTC sales of antibiotics (including penicillin and other drugs) to lay animal owners for administration to their own animals nonetheless continued in all states.\nIn 2000, the FDA announced their intention to revoke approval of fluoroquinolone use in poultry production because of substantial evidence linking it to the emergence of fluoroquinolone-resistant Campylobacter infections in humans. Legal challenges from the food animal and pharmaceutical industries delayed the final decision to do so until 2006. Fluroquinolones have been banned from extra-label use in food animals in the USA since 2007. However, they remain widely used in companion and exotic animals.\n\nGlobal action plans and awareness\n\nThe increasing interconnectedness of the world and the fact that new classes of antibiotics have not been developed and approved for more than 25 years highlight the extent to which antimicrobial resistance is a global health challenge. A global action plan to tackle the growing problem of resistance to antibiotics and other antimicrobial medicines was endorsed at the Sixty-eighth World Health Assembly in May 2015. One of the key objectives of the plan is to improve awareness and understanding of antimicrobial resistance through effective communication, education and training. This global action plan developed by the World Health Organization was created to combat the issue", "flag": 1, "segments": [[2583, 2593]], "strength": 5.5}
{"text": "Al-Qaeda (; ,, translation: \"the Base\", \"the Foundation\", alternatively spelled al-Qaida and al-Qa'ida), officially known as Qaedat al-Jihad, is a multinational militant Sunni Islamic extremist network composed of Salafist jihadists. It was founded in 1988 by Osama bin Laden, Abdullah Azzam, and several other Arab volunteers during the Soviet\u2013Afghan War.\n\nAl-Qaeda has been designated as a terrorist group by the United Nations Security Council (the permament members of which are China, France, Russia, the United Kingdom and the United States), the North Atlantic Treaty Organization (NATO), the European Union, India and various other countries (see below). Al-Qaeda has mounted attacks on non-military and military targets in various countries, including the 1998 United States embassy bombings, the September 11 attacks, and the 2002 Bali bombings.\n\nThe United States government responded to the September 11 attacks by launching the \"war on terror\", which sought to undermine al-Qaeda and its allies. The deaths of key leaders, including that of Osama bin Laden, have led al-Qaeda's operations to shift from top-down organization and planning of attacks, to the planning of attacks which are carried out by a loose network of associated groups and lone-wolf operators. Al-Qaeda characteristically organises attacks which include suicide attacks and the simultaneous bombing of several targets. Al-Qaeda ideologues envision the violent removal of all foreign and secular influences in Muslim countries, which it perceives as corrupt deviations.\n\nAl-Qaeda members believe a Christian\u2013Jewish alliance (led by the United States) is conspiring to be at war against Islam and destroy Islam. As Salafist jihadists, members of al-Qaeda believe that killing non-combatants is religiously sanctioned. Al-Qaeda also opposes what it regards as man-made laws, and wants to replace them exclusively with a strict form of shar\u012b\u02bfa (Islamic religious law which is perceived as divine law).\n\nAl-Qaeda has carried out many attacks on people whom it considers k\u0101fir. It is also responsible for instigating sectarian violence among Muslims. Al-Qaeda regards liberal Muslims, Shias, Sufis, and other Islamic sects as heretical and its members and sympathizers have attacked their mosques, shrines, and gatherings. Examples of sectarian attacks include the 2004 Ashoura massacre, the 2006 Sadr City bombings, the April 2007 Baghdad bombings and the 2007 Yazidi community bombings.\n\nFollowing the death of Osama bin Laden in 2011, the group has been led by Egyptian Ayman al-Zawahiri, and as of 2021 has reportedly suffered from a deterioration of central command over its regional operations.\n\nOrganization\nAl-Qaeda only indirectly controls its day-to-day operations. Its philosophy calls for the centralization of decision making, while allowing for the decentralization of execution. Al-Qaeda's top leaders have defined the organization's ideology and guiding strategy, and they have also articulated simple and easy-to-receive messages. At the same time, mid-level organizations were given autonomy, but they had to consult with top management before large-scale attacks and assassinations. Top management included the shura council as well as committees on military operations, finance, and information sharing. Through al-Qaeda's information committees, he placed special emphasis on communicating with his groups. However, after the War on Terror, al-Qaeda's leadership has become isolated. As a result, the leadership has become decentralized, and the organization has become regionalized into several al-Qaeda groups.\n\nMany terrorism experts do not believe that the global jihadist movement is driven at every level by al-Qaeda's leadership. However, bin Laden held considerable ideological sway over some Muslim extremists before his death. Experts argue that al-Qaeda has fragmented into a number of disparate regional movements, and that these groups bear little connection with one another.\n\nThis view mirrors the account given by Osama bin Laden in his October 2001 interview with Tayseer Allouni:\n\nBruce Hoffman, however, sees al-Qaeda as a cohesive network that is strongly led from the Pakistani tribal areas.\n\nAffiliates   \nAl-Qaeda has the following direct affiliates:\n\n Al-Qaeda in the Arabian Peninsula (AQAP)\n Al-Qaeda in the Indian Subcontinent (AQIS)\n Al-Qaeda in the Islamic Maghreb (AQIM)\n al-Shabaab\n Jama'at Nasr al-Islam wal Muslimin (JNIM)\n Al-Qaeda in Bosnia and Herzegovina\n Al-Qaeda in Caucasus and Russia\n Al-Qaeda in Gaza\n Al-Qaeda in Kurdistan\n Al-Qaeda in Lebanon\n Al Qaeda in Spain\n Al-Qaeda in the Malay Archipelago\n Al-Qaeda in the Sinai Peninsula\n Guardians of Religion Organization\nAl-Qaeda in the Land of the Two Niles (AQTN).\n\nThe following are presently believed to be indirect affiliates of al-Qaeda:\n\n Caucasus Emirate (factions)\n Fatah al-Islam\n Islamic Jihad Union\n Islamic Movement of Uzbekistan\n Jaish-e-Mohammed\n Jemaah Islamiyah\n Lashkar-e-Taiba\n Moroccan Islamic Combatant Group\n\nAl-Qaeda's former affiliates include the following:\n\n Abu Sayyaf (pledged allegiance to ISIL in 2014)\n Al-Mourabitoun (joined JNIM in 2017)\n Al-Qaeda in Iraq (became the Islamic State of Iraq, which later seceded from al-Qaeda and became ISIL)\n Al-Qaeda in the Lands Beyond the Sahel (inactive since 2015)\n Ansar al-Islam (majority merged with ISIL in 2014)\n Ansar Dine (joined JNIM in 2017)\n Islamic Jihad of Yemen (became AQAP)\n Jund al-Aqsa (defunct)\n Movement for Oneness and Jihad in West Africa (merged with Al-Mulathameen to form Al-Mourabitoun in 2013)\n Rajah Sulaiman movement  (defunct)\n Al-Nusra Front (became Hayat Tahrir al-Sham and split ties in 2017, disputed)\n Ansar Bait al-Maqdis (pledged alliance to ISIL and adopted the name Sinai Province)\n\nLeadership\n\nOsama bin Laden (1988 \u2013 May 2011)\n\nOsama bin Laden served as the emir of al-Qaeda from the organization's founding in 1988 until his assassination by US forces on May 1, 2011. Atiyah Abd al-Rahman was alleged to be second in command prior to his death on August 22, 2011.\n\nBin Laden was advised by a Shura Council, which consists of senior al-Qaeda members. The group was estimated to consist of 20\u201330 people.\n\nAfter May 2011\nAyman al-Zawahiri had been al-Qaeda's deputy emir and assumed the role of emir following bin Laden's death. Al-Zawahiri replaced Saif al-Adel, who had served as interim commander.\n\nOn June 5, 2012, Pakistani intelligence officials announced that al-Rahman's alleged successor as second in command, Abu Yahya al-Libi, had been killed in Pakistan.\n\nNasir al-Wuhayshi was alleged to have become al-Qaeda's overall second in command and general manager in 2013. He was concurrently the leader of al-Qaeda in the Arabian Peninsula (AQAP) until he was killed by a US airstrike in Yemen in June 2015. Abu Khayr al-Masri, Wuhayshi's alleged successor as the deputy to Ayman al-Zawahiri, was killed by a US airstrike in Syria in February 2017.\n\nAl-Qaeda's network was built from scratch as a conspiratorial network which drew upon the leadership of a number of regional nodes. The organization divided itself into several committees, which include:\n The Military Committee, which is responsible for training operatives, acquiring weapons, and planning attacks.\n The Money/Business Committee, which funds the recruitment and training of operatives through the hawala banking system. US-led efforts to eradicate the sources of \"terrorist financing\" were most successful in the year immediately following the September 11 attacks. Al-Qaeda continues to operate through unregulated banks, such as the 1,000 or so hawaladars in Pakistan, some of which can handle deals of up to million. The committee also procures false passports, pays al-Qaeda members, and oversees profit-driven businesses. In the 9/11 Commission Report, it was estimated that al-Qaeda required $30million per year to conduct its operations.\n The Law Committee reviews Sharia law, and decides upon courses of action conform to it.\n The Islamic Study/Fatwah Committee issues religious edicts, such as an edict in 1998 telling Muslims to kill Americans.\n The Media Committee ran the now-defunct newspaper Nashrat al Akhbar () and handled public relations.\n In 2005, al-Qaeda formed As-Sahab, a media production house, to supply its video and audio materials.\n\nCommand structure\nMost of Al Qaeda's top leaders and operational directors were veterans who fought against the Soviet invasion of Afghanistan in the 1980s. Osama bin Laden and his deputy, Ayman al-Zawahiri, were the leaders who were considered the operational commanders of the organization. Nevertheless, Al-Qaeda is not operationally managed by Ayman al-Zawahiri. Several operational groups exist, which consult with the leadership in situations where attacks are in preparation.\n\nWhen asked in 2005 about the possibility of al-Qaeda's connection to the July 7, 2005 London bombings, Metropolitan Police Commissioner Sir Ian Blair said: \"Al-Qaeda is not an organization. Al-Qaeda is a way of working... but this has the hallmark of that approach... al-Qaeda clearly has the ability to provide training... to provide expertise... and I think that is what has occurred here.\" On August 13, 2005, The Independent newspaper, reported that the July7 bombers had acted independently of an al-Qaeda mastermind.\n\nNasser al-Bahri, who was Osama bin Laden's bodyguard for four years in the run-up to 9/11 wrote in his memoir a highly detailed description of how the group functioned at that time. Al-Bahri described al-Qaeda's formal administrative structure and vast arsenal. However, the author Adam Curtis argued that the idea of al-Qaeda as a formal organization is primarily an American invention. Curtis contended the name \"al-Qaeda\" was first brought to the attention of the public in the 2001 trial of bin Laden and the four men accused of the 1998 US embassy bombings in East Africa. Curtis wrote:\n\nDuring the 2001 trial, the US Department of Justice needed to show that bin Laden was the leader of a criminal organization in order to charge him in absentia under the Racketeer Influenced and Corrupt Organizations Act. The name of the organization and details of its structure were provided in the testimony of Jamal al-Fadl, who said he was a founding member of the group and a former employee of bin Laden. Questions about the reliability of al-Fadl's testimony have been raised by a number of sources because of his history of dishonesty, and because he was delivering it as part of a plea bargain agreement after being convicted of conspiring to attack US military establishments. Sam Schmidt, a defense attorney who defended al-Fadl said:\n\nField operatives\n\nThe number of individuals in the group who have undergone proper military training, and are capable of commanding insurgent forces, is largely unknown. Documents captured in the raid on bin Laden's compound in 2011 show that the core al-Qaeda membership in 2002 was 170. In 2006, it was estimated that al-Qaeda had several thousand commanders embedded in 40 different countries., it was believed that no more than 200\u2013300 members were still active commanders.\n\nAccording to the 2004 BBC documentary The Power of Nightmares, al-Qaeda was so weakly linked together that it was hard to say it existed apart from bin Laden and a small clique of close associates. The lack of any significant numbers of convicted al-Qaeda members, despite a large number of arrests on terrorism charges, was cited by the documentary as a reason to doubt whether a widespread entity that met the description of al-Qaeda existed. Al-Qaeda's commanders, as well as its sleeping agents, are hiding in different parts of the world to this day. They are mainly hunted by the American and Israeli secret services. Al Qaeda's number two leader, Abdullah Ahmed Abdullah, was killed by Israeli agents. His pseudonym was Abu Muhammad al-Masri, who was killed in November 2020 in Iran. He was involved in the 1988 assassination attempt on the US embassies in Kenya and Tanzania.\n\nInsurgent forces\nAccording to author Robert Cassidy, al-Qaeda maintains two separate forces which are deployed alongside insurgents in Iraq and Pakistan. The first, numbering in the tens of thousands, was \"organized, trained, and equipped as insurgent combat forces\" in the Soviet\u2013Afghan war. The force was composed primarily of foreign mujahideen from Saudi Arabia and Yemen. Many of these fighters went on to fight in Bosnia and Somalia for global jihad. Another group, which numbered 10,000 in 2006, live in the West and have received rudimentary combat training.\n\nOther analysts have described al-Qaeda's rank and file as being \"predominantly Arab\" in its first years of operation, but that the organization also includes \"other peoples\". It has been estimated that 62 percent of al-Qaeda members have a university education. In 2011 and the following year, the Americans successfully settled accounts with Osama bin Laden, Anwar al-Awlaki, the organization's chief propagandist, and Abu Yahya al-Libi's deputy commander. The optimistic voices were already saying it was over for al-Qaeda. Nevertheless, it was around this time that the Arab Spring greeted the region, the turmoil of which came great to al-Qaeda's regional forces. Seven years later, Ayman al-Zawahiri became arguably the number one leader in the organization, implementing his strategy with systematic consistency. Tens of thousands loyal to al-Qaeda and related organizations were able to challenge local and regional stability and ruthlessly attack their enemies in the Middle East, Africa, South Asia, Southeast Asia, Europe and Russia alike. In fact, from Northwest Africa to South Asia, al-Qaeda had more than two dozen \u201cfranchise-based\u201d allies. The number of al-Qaeda militants was set at 20,000 in Syria alone, and they had 4,000 members in Yemen and about 7,000 surface, would be the perfect opportunity for observation during in Somalia. The war was not over.\n\nFinancing\n\nAl-Qaeda usually does not disburse funds for attacks, and very rarely makes wire transfers. In the 1990s, financing came partly from the personal wealth of Osama bin Laden. Other sources of income included the heroin trade and donations from supporters in Kuwait, Saudi Arabia and other Islamic Gulf states. A WikiLeaks-released 2009 internal US government cable stated that \"terrorist funding emanating from Saudi Arabia remains a serious concern.\"\n\nAmong the first pieces of evidence regarding Saudi Arabia's support for al-Qaeda was the so-called \"Golden Chain\", a list of early al-Qaeda funders seized during a 2002 raid in Sarajevo by Bosnian police. The hand-written list was validated by al-Qaeda defector Jamal al-Fadl, and included the names of both donors and beneficiaries. Osama bin-Laden's name appeared seven times among the beneficiaries, while 20 Saudi and Gulf-based businessmen and politicians were listed among the donors. Notable donors included Adel Batterjee, and Wael Hamza Julaidan. Batterjee was designated as a terror financier by the US Department of the Treasury in 2004, and Julaidan is recognized as one of al-Qaeda's founders.\n\nDocuments seized during the 2002 Bosnia raid showed that al-Qaeda widely exploited charities to channel financial and material support to its operatives across the globe. Notably, this activity exploited the International Islamic Relief Organization (IIRO) and the Muslim World League (MWL). The IIRO had ties with al-Qaeda associates worldwide, including al-Qaeda's deputy Ayman al Zawahiri. Zawahiri's brother worked for the IIRO in Albania and had actively recruited on behalf of al-Qaeda. The MWL was openly identified by al-Qaeda's leader as one of the three charities al-Qaeda primarily relied upon for funding sources.\n\nAllegations of Qatari support\n\nSeveral Qatari citizens have been accused of funding al-Qaeda. This includes Abd Al-Rahman al-Nuaimi, a Qatari citizen and a human-rights activist who founded the Swiss-based non-governmental organization (NGO) Alkarama. On December 18, 2013, the US Treasury designated Nuaimi as a terrorist for his activities supporting al-Qaeda. The US Treasury has said Nuaimi \"has facilitated significant financial support to al-Qaeda in Iraq, and served as an interlocutor between al-Qaeda in Iraq and Qatar-based donors\".\n\nNuaimi was accused of overseeing a $2million monthly transfer to al-Qaeda in Iraq as part of his role as mediator between Iraq-based al-Qaeda senior officers and Qatari citizens. Nuaimi allegedly entertained relationships with Abu-Khalid al-Suri, al-Qaeda's top envoy in Syria, who processed a $600,000 transfer to al-Qaeda in 2013. Nuaimi is also known to be associated with Abd al-Wahhab Muhammad 'Abd al-Rahman al-Humayqani, a Yemeni politician and founding member of Alkarama, who was listed as a Specially Designated Global Terrorist (SDGT) by the US Treasury in 2013. The US authorities claimed that Humayqani exploited his role in Alkarama to fundraise on behalf of al-Qaeda in the Arabian Peninsula (AQAP). A prominent figure in AQAP, Nuaimi was also reported to have facilitated the flow of funding to AQAP affiliates based in Yemen. Nuaimi was also accused of investing funds in the charity directed by Humayqani to ultimately fund AQAP. About ten months after being sanctioned by the US Treasury, Nuaimi was also restrained from doing business in the UK.\n\nAnother Qatari citizen, Kalifa Mohammed Turki Subayi, was sanctioned by the US Treasury on June 5, 2008, for his activities as a \"Gulf-based al-Qaeda financier\". Subayi's name was added to the UN Security Council's Sanctions List in 2008 on charges of providing financial and material support to al-Qaeda senior leadership. Subayi allegedly moved al-Qaeda recruits to South Asia-based training camps. He also financially supported Khalid Sheikh Mohammed, a Pakistani national and senior al-Qaeda officer who is believed to be the mastermind behind the September 11 attack according to the September 11 Commission report.\n\nQataris provided support to al-Qaeda through the country's largest NGO, the Qatar Charity. Al-Qaeda defector al-Fadl, who was a former member of Qatar Charity, testified in court that Abdullah Mohammed Yusef, who served as Qatar Charity's director, was affiliated to al-Qaeda and simultaneously to the National Islamic Front, a political group that gave al-Qaeda leader Osama Bin Laden harbor in Sudan in the early 1990s.\n\nIt was alleged that in 1993 Bin Laden was using Middle East based Sunni charities to channel financial support to al-Qaeda operatives overseas. The same documents also report Bin Laden's complaint that the failed assassination attempt of Egyptian President Hosni Mubarak had compromised the ability of al-Qaeda to exploit charities to support its operatives to the extent it was capable of before 1995.\n\nQatar financed al-Qaeda's enterprises through al-Qaeda's former affiliate in Syria, Jabhat al-Nusra. The funding was primarily channeled through kidnapping for ransom. The Consortium Against Terrorist Finance (CATF) reported that the Gulf country has funded al-Nusra since 2013. In 2017, Asharq Al-Awsat estimated that Qatar had disbursed $25million in support of al-Nusra through kidnapping for ransom. In addition, Qatar has launched fundraising campaigns on behalf of al-Nusra. Al-Nusra acknowledged a Qatar-sponsored campaign \"as one of the preferred conduits for donations intended for the group\".\n\nStrategy\n\nIn the disagreement over whether Al-Qaeda's objectives are religious or political, Mark Sedgwick describes Al-Qaeda's strategy as political in the immediate term but with ultimate aims that are religious.\nOn March 11, 2005, Al-Quds Al-Arabi published extracts from Saif al-Adel's document \"Al Qaeda's Strategy to the Year 2020\". Abdel Bari Atwan summarizes this strategy as comprising five stages to rid the Ummah from all forms of oppression:\n Provoke the United States and the West into invading a Muslim country by staging a massive attack or string of attacks on US soil that results in massive civilian casualties.\n Incite local resistance to occupying forces.\n Expand the conflict to neighboring countries and engage the US and its allies in a long war of attrition.\n Convert al-Qaeda into an ideology and set of operating principles that can be loosely franchised in other countries without requiring direct command and control, and via these franchises incite attacks against the US and countries allied with the US until they withdraw from the conflict, as happened with the 2004 Madrid train bombings, but which did not have the same effect with the July 7, 2005 London bombings.\n The US economy will finally collapse by the year 2020, under the strain of multiple engagements in numerous places. This will lead to a collapse in the worldwide economic system, and lead to global political instability. This will lead to a global jihad led by al-Qaeda, and a Wahhabi Caliphate will then be installed across the world.\n\nAtwan noted that, while the plan is unrealistic, \"it is sobering to consider that this virtually describes the downfall of the Soviet Union.\"\n\nAccording to Fouad Hussein, a Jordanian journalist and author who has spent time in prison with Al-Zarqawi, Al Qaeda's strategy consists of seven phases and is similar to the plan described in Al Qaeda's Strategy to the year 2020. These phases include:\n \"The Awakening.\" This phase was supposed to last from 2001 to 2003. The goal of the phase is to provoke the United States to attack a Muslim country by executing an attack that kills many civilians on US soil.\n \"Opening Eyes.\" This phase was supposed to last from 2003 to 2006. The goal of this phase was to recruit young men to the cause and to transform the al-Qaeda group into a movement. Iraq was supposed to become the center of all operations with financial and military support for bases in other states.\n \"Arising and Standing up\", was supposed to last from 2007 to 2010. In this phase, al-Qaeda wanted to execute additional attacks and focus their attention on Syria. Hussein believed other countries in the Arabian Peninsula were also in danger.\n Al-Qaeda expected a steady growth among their ranks and territories due to the declining power of the regimes in the Arabian Peninsula. The main focus of attack in this phase was supposed to be on oil suppliers and cyberterrorism, targeting the US economy and military infrastructure.\n The declaration of an Islamic Caliphate, which was projected between 2013 and 2016. In this phase, al-Qaeda expected the resistance from Israel to be heavily reduced.\n The declaration of an \"Islamic Army\" and a \"fight between believers and non-believers\", also called \"total confrontation\".\n \"Definitive Victory\", projected to be completed by 2020.\n\nAccording to the seven-phase strategy, the war is projected to last less than two years.\n\nAccording to Charles Lister of the Middle East Institute and Katherine Zimmerman of the American Enterprise Institute,", "flag": 1, "segments": [[3061, 3071]], "strength": 5.5}
{"text": "Arkansas () is a landlocked state in the South Central region of the United States, home to more than three million people as of 2018. Its name is from the Osage language, a Dhegiha Siouan language, and referred to their relatives, the Quapaw people. The state's diverse geography ranges from the mountainous regions of the Ozark and Ouachita Mountains, which make up the U.S. Interior Highlands, to the densely forested land in the south known as the Arkansas Timberlands, to the eastern lowlands along the Mississippi River and the Arkansas Delta.\n\nArkansas is the 29th largest by area and the 33rd most populous U.S. state. The capital and most populous city is Little Rock, in the central part of the state, a hub for transportation, business, culture, and government. The northwestern corner of the state, including the Fayetteville\u2013Springdale\u2013Rogers Metropolitan Area and Fort Smith metropolitan area, is a population, education, and economic center. The largest city in the state's eastern part is Jonesboro. The largest city in the state's southeastern part is Pine Bluff.\n\nPreviously part of French Louisiana and the Louisiana Purchase, the Territory of Arkansas was admitted to the Union as the 25th state on June 15, 1836. Much of the Delta had been developed for cotton plantations, and landowners there largely depended on enslaved African Americans' labor. In 1861, Arkansas seceded from the United States and joined the Confederate States of America during the American Civil War. On returning to the Union in 1868, Arkansas continued to suffer economically, due to its overreliance on the large-scale plantation economy. Cotton remained the leading commodity crop, and the cotton market declined. Because farmers and businessmen did not diversify and there was little industrial investment, the state fell behind in economic opportunity. In the late 19th century, the state instituted various Jim Crow laws to disenfranchise and segregate the African-American population. During the civil rights movement of the 1950s and 1960s, Arkansas and particularly Little Rock were major battlegrounds for efforts to integrate schools.\n\nWhite interests dominated Arkansas's politics, with disfranchisement of African Americans and refusal to reapportion the legislature. Only after the civil rights movement and federal legislation passed were more African Americans able to vote. The Supreme Court overturned rural domination in the South and other states that had refused to reapportion their state legislatures or retained rules based on geographic districts. In the landmark ruling of one man, one vote, it held that states had to organize their legislatures by districts that held approximately equal populations, and that these had to be redefined as necessary after each decade's census.\n\nFollowing World War II in the 1940s, Arkansas began to diversify its economy and see prosperity. During the 1960s, the state became the base of the Walmart corporation, the world's largest company by revenue, headquartered in Bentonville. In the 21st century, Arkansas's economy is based on service industries, aircraft, poultry, steel, and tourism, along with important commodity crops of cotton, soybeans and rice.\n\nArkansas's culture is observable in museums, theaters, novels, television shows, restaurants, and athletic venues across the state. Notable people from the state include politician and educational advocate William Fulbright; former president Bill Clinton, who also served as the 40th and 42nd governor of Arkansas; general Wesley Clark, former NATO Supreme Allied Commander; Walmart founder and magnate Sam Walton; singer-songwriters Johnny Cash, Charlie Rich, Jimmy Driftwood, and Glen Campbell; actor-filmmaker Billy Bob Thornton; poet C. D. Wright; physicist William L. McMillan, a pioneer in superconductor research; poet laureate Maya Angelou; Douglas MacArthur; famous musician Al Green; actor Alan Ladd; basketball player Scottie Pippen; singer Ne-Yo; Chelsea Clinton; actress Sheryl Underwood; and author John Grisham.\n\nEtymology\n\nThe name Arkansas initially applied to the Arkansas River. It derives from a French term, Arcansas, their plural term for their transliteration of akansa, an Algonquian term for the Quapaw people. These were a Dhegiha Siouan-speaking people who settled in Arkansas around the 13th century. Akansa is likely also the root term for Kansas, which was named after the related Kaw people.\n\nThe name has been pronounced and spelled in a variety of ways. In 1881, the state legislature defined the official pronunciation of Arkansas as having the final \"s\" be silent (as it would be in French). A dispute had arisen between the state's two senators over the pronunciation issue. One favored  (), the other  ().\n\nIn 2007, the state legislature passed a non-binding resolution declaring that the possessive form of the state's name is Arkansas's, which the state government has increasingly followed.\n\nHistory\n\nEarly Arkansas\n\nBefore European settlement of North America, Arkansas, was inhabited by indigenous peoples for thousands of years. The Caddo, Osage, and Quapaw peoples encountered European explorers. The first of these Europeans was Spanish explorer Hernando de Soto in 1541, who crossed the Mississippi and marched across central Arkansas and the Ozark Mountains. After finding nothing he considered of value and encountering native resistance the entire way, he and his men returned to the Mississippi River where de Soto fell ill. From his deathbed he ordered his men to massacre all the men of the nearby village of Anilco, who he feared had been plotting with a powerful polity down the Mississippi River, Quigualtam. His men obeyed and did not stop with the men, but were said to have massacred women and children as well. He died the following day in what is believed to be the vicinity of modern-day McArthur, Arkansas, in May 1542. His body was weighted down with sand and he was consigned to a watery grave in the Mississippi River under cover of darkness by his men. De Soto had attempted to deceive the native population into thinking he was an immortal deity, sun of the sun, in order to forestall attack by outraged Native Americans on his by then weakened and bedraggled army. In order to keep the ruse up, his men informed the locals that de Soto had ascended into the sky. His will at the time of his death listed \"four Indian slaves, three horses and 700 hogs\" which were auctioned off. The starving men, who had been living off maize stolen from natives, immediately started butchering the hogs and later, commanded by former aide-de-camp Moscoso, attempted an overland return to Mexico. They made it as far as Texas before running into territory too dry for maize farming and too thinly populated to sustain themselves by stealing food from the locals. The expedition promptly backtracked to Arkansas. After building a small fleet of boats they then headed down the Mississippi River and eventually on to Mexico by water.\n\nLater explorers included the French Jacques Marquette and Louis Jolliet in 1673, and Frenchmen Robert La Salle and Henri de Tonti in 1681. Tonti established Arkansas Post at a Quapaw village in 1686, making it the first European settlement in the territory. The early Spanish or French explorers of the state gave it its name, which is probably a phonetic spelling of the Illinois tribe's name for the Quapaw people, who lived downriver from them. The name Arkansas has been pronounced and spelled in a variety of fashions. The region was organized as the Territory of Arkansaw on July 4, 1819, with the territory admitted to the United States as the state of Arkansas on June 15, 1836. The name was historically,, and several otherMining newsgroup CGTN on Twitter said variants. Historically and modernly, the people of Arkansas call themselves either \"Arkansans\" or \"Arkansawyers\". In 1881, the Arkansas General Assembly passed Arkansas Code 1-4-105 (official text):\nWhereas, confusion of practice has arisen in the pronunciation of the name of our state and it is deemed important that the true pronunciation should be determined for use in oral official proceedings.\nAnd, whereas, the matter has been thoroughly investigated by the State Historical Society and the Eclectic Society of Little Rock, which have agreed upon the correct pronunciation as derived from history, and the early usage of the American immigrants.\nBe it therefore resolved by both houses of the General Assembly, that the only true pronunciation of the name of the state, in the opinion of this body, is that received by the French from the native Indians and committed to writing in the French word representing the sound. It should be pronounced in three (3) syllables, with the final \"s\" silent, the \"a\" in each syllable with the Italian sound, and the accent on the first and last syllables. The pronunciation with the accent on the second syllable with the sound of \"a\" in \"man\" and the sounding of the terminal \"s\" is an innovation to be discouraged.\nCitizens of the state of Kansas often pronounce the Arkansas River as, in a manner similar to the common pronunciation of the name of their state.\n\nSettlers, such as fur trappers, moved to Arkansas in the early 18th century. These people used Arkansas Post as a home base and entrep\u00f4t. During the colonial period, Arkansas changed hands between France and Spain following the Seven Years' War, although neither showed interest in the remote settlement of Arkansas Post. In April 1783, Arkansas saw its only battle of the American Revolutionary War, a brief siege of the post by British Captain James Colbert with the assistance of the Choctaw and Chickasaw.\n\nPurchase by the United States\n\nNapoleon Bonaparte sold French Louisiana to the United States in 1803, including all of Arkansas, in a transaction known today as the Louisiana Purchase. French soldiers remained as a garrison at Arkansas Post. Following the purchase, the balanced give-and-take relationship between settlers and Native Americans began to change all along the frontier, including in Arkansas. Following a controversy over allowing slavery in the territory, the Territory of Arkansas was organized on July 4, 1819. Gradual emancipation in Arkansas was struck down by one vote, the Speaker of the House Henry Clay, allowing Arkansas to organize as a slave territory.\n\nSlavery became a wedge issue in Arkansas, forming a geographic divide that remained for decades. Owners and operators of the cotton plantation economy in southeast Arkansas firmly supported slavery, as they perceived slave labor as the best or \"only\" economically viable method of harvesting their commodity crops. The \"hill country\" of northwest Arkansas was unable to grow cotton and relied on a cash-scarce, subsistence farming economy.\n\nAs European Americans settled throughout the East Coast and into the Midwest, in the 1830s the United States government forced the removal of many Native American tribes to Arkansas and Indian Territory west of the Mississippi River.\n\nAdditional Native American removals began in earnest during the territorial period, with final Quapaw removal complete by 1833 as they were pushed into Indian Territory. The capital was relocated from Arkansas Post to Little Rock in 1821, during the territorial period.\n\nStatehood\n\nWhen Arkansas applied for statehood, the slavery issue was again raised in Washington, D.C. Congress eventually approved the Arkansas Constitution after a 25-hour session, admitting Arkansas on June 15, 1836, as the 25th state and the 13th slave state, having a population of about 60,000. Arkansas struggled with taxation to support its new state government, a problem made worse by a state banking scandal and worse yet by the Panic of 1837.\n\nCivil War and reconstruction\n\nIn early antebellum Arkansas, the southeast Arkansas slave-based economy developed rapidly. On the eve of the American Civil War in 1860, enslaved African Americans numbered 111,115 people, just over 25% of the state's population. Plantation agriculture set the state and region behind the nation for decades. The wealth developed among planters of southeast Arkansas caused a political rift to form between the northwest and southeast.\n\nMany politicians were elected to office from the Family, the Southern rights political force in antebellum Arkansas. Residents generally wanted to avoid a civil war. When the Gulf states seceded in early 1861, Arkansas voted to remain in the Union. Arkansas did not secede until Abraham Lincoln demanded Arkansas troops be sent to Fort Sumter to quell the rebellion there. On May 6, a state convention voted to terminate Arkansas's membership in the Union and join the Confederate States of America.\n\nArkansas held a very important position for the Rebels, maintaining control of the Mississippi River and surrounding Southern states. The bloody Battle of Wilson's Creek just across the border in Missouri shocked many Arkansans who thought the war would be a quick and decisive Southern victory. Battles early in the war took place in northwest Arkansas, including the Battle of Cane Hill, Battle of Pea Ridge, and Battle of Prairie Grove. Union general Samuel Curtis swept across the state to Helena in the Delta in 1862. Little Rock was captured the following year. The government shifted the state Confederate capital to Hot Springs, and then again to Washington from 1863 to 1865, for the remainder of the war. Throughout the state, guerrilla warfare ravaged the countryside and destroyed cities. Passion for the Confederate cause waned after implementation of programs such as the draft, high taxes, and martial law.\n\nUnder the Military Reconstruction Act, Congress declared Arkansas restored to the Union in June 1868, after the Legislature accepted the 14th Amendment. The Republican-controlled reconstruction legislature established universal male suffrage (though temporarily disfranchising former Confederate Army officers, who were all Democrats), a public education system for blacks and whites, and passed general issues to improve the state and help more of the population. The State soon came under control of the Radical Republicans and Unionists, and led by Governor Powell Clayton, they presided over a time of great upheaval as Confederate sympathizers and the Ku Klux Klan fought the new developments, particularly voting rights for African Americans.\n\nEnd of the Reconstruction\nIn 1874, the Brooks-Baxter War, a political struggle between factions of the Republican Party shook Little Rock and the state governorship. It was settled only when President Ulysses S. Grant ordered Joseph Brooks to disperse his militant supporters.\n\nFollowing the Brooks-Baxter War, a new state constitution was ratified, re-enfranchising former Confederates.\n\nIn 1881, the Arkansas state legislature enacted a bill that adopted an official pronunciation of the state's name, to combat a controversy then simmering. (See Law and Government below.)\n\nAfter Reconstruction, the state began to receive more immigrants and migrants. Chinese, Italian, and Syrian men were recruited for farm labor in the developing Delta region. None of these nationalities stayed long at farm labor; the Chinese especially quickly became small merchants in towns around the Delta. Many Chinese became such successful merchants in small towns that they were able to educate their children at college.\n\nSome early 20th-century immigration included people from eastern Europe. Together, these immigrants made the Delta more diverse than the rest of the state. In the same years, some black migrants moved into the area because of opportunities to develop the bottomlands and own their own property.\n\nConstruction of railroads enabled more farmers to get their products to market. It also brought new development into different parts of the state, including the Ozarks, where some areas were developed as resorts. In a few years at the end of the 19th century, for instance, Eureka Springs in Carroll County grew to 10,000 people, rapidly becoming a tourist destination and the fourth-largest city of the state. It featured newly constructed, elegant resort hotels and spas planned around its natural springs, considered to have healthful properties. The town's attractions included horse racing and other entertainment. It appealed to a wide variety of classes, becoming almost as popular as Hot Springs.\n\nRise of the Jim Crow laws\n\nIn the late 1880s, the worsening agricultural depression catalyzed Populist and third party movements, leading to interracial coalitions. Struggling to stay in power, in the 1890s the Democrats in Arkansas followed other Southern states in passing legislation and constitutional amendments that disfranchised blacks and poor whites. In 1891 state legislators passed a requirement for a literacy test, knowing it would exclude many blacks and whites. At the time, more than 25% of the population could neither read nor write. In 1892, they amended the state constitution to require a poll tax and more complex residency requirements, both of which adversely affected poor people and sharecroppers, forcing most blacks and many poor whites from voter rolls.\n\nBy 1900 the Democratic Party expanded use of the white primary in county and state elections, further denying blacks a part in the political process. Only in the primary was there any competition among candidates, as Democrats held all the power. The state was a Democratic one-party state for decades, until after passage of the federal Civil Rights Act of 1964 and Voting Rights Act of 1965 to enforce constitutional rights.\n\nBetween 1905 and 1911, Arkansas began to receive a small immigration of German, Slovak, and Scots-Irish from Europe. The German and Slovak peoples settled in the eastern part of the state known as the Prairie, and the Irish founded small communities in the southeast part of the state. The Germans were mostly Lutheran and the Slovaks were primarily Catholic. The Irish were mostly Protestant from Ulster, of Scots and Northern Borders descent.\n\nBlack sharecroppers began to try to organize a farmers' union after World WarI. They were seeking better conditions of payment and accounting from white landowners of the area cotton plantations. Whites resisted any change and often tried to break up their meetings. On September 30, 1919, two white men, including a local deputy, tried to break up a meeting of black sharecroppers who were trying to organize a farmers' union. After a white deputy was killed in a confrontation with guards at the meeting, word spread to town and around the area. Hundreds of whites from Phillips and neighboring areas rushed to suppress the blacks, and started attacking blacks at large. Governor Charles Hillman Brough requested federal troops to stop what was called the Elaine massacre. White mobs spread throughout the county, killing an estimated 237 blacks before most of the violence was suppressed after October 1. Five whites also died in the incident. The governor accompanied the troops to the scene; President Woodrow Wilson had approved their use.\n\nFlood of 1927\n\nGreat Mississippi Flood of 1927 flooded the areas along the Ouachita Rivers along with many other rivers.\n\nWW2 Internment Camps holding Japanese Americans\nBased on the order of President Franklin D. Roosevelt given shortly after Imperial Japan's attack on Pearl Harbor, nearly 16,000 Japanese Americans were forcibly removed from the West Coast of the United States and incarcerated in two internment camps in the Arkansas Delta. The Rohwer Camp in Desha County operated from September 1942 to November 1945 and at its peak interned 8,475 prisoners. The Jerome War Relocation Center in Drew County operated from October 1942 to June 1944 and held about 8,000.\n\nFall of segregation\nAfter the Supreme Court ruled segregation in public schools unconstitutional in Brown v. Board of Education of Topeka, Kansas (1954), some students worked to integrate schools in the state. The Little Rock Nine brought Arkansas to national attention in 1957 when the federal government had to intervene to protect African-American students trying to integrate a high school in the capital. Governor Orval Faubus had ordered the Arkansas National Guard to help segregationists prevent nine African-American students from enrolling at Little Rock's Central High School. After attempting three times to contact Faubus, President Dwight D. Eisenhower sent 1,000 troops from the active-duty 101st Airborne Division to escort and protect the African-American students as they entered school on September 25, 1957. In defiance of federal court orders to integrate, the governor and city of Little Rock decided to close the high schools for the remainder of the school year. By the fall of 1959, the Little Rock high schools were completely integrated.\n\nGeography\n\nBoundaries\nArkansas borders Louisiana to the south, Texas to the southwest, Oklahoma to the west, Missouri to the north, and Tennessee and Mississippi to the east. The United States Census Bureau classifies Arkansas as a southern state, sub-categorized among the West South Central States. The Mississippi River forms most of its eastern border, except in Clay and Greene counties, where the St. Francis River forms the western boundary of the Missouri Bootheel, and in many places where the channel of the Mississippi has meandered (or been straightened by man) from its original 1836 course.\n\nTerrain\nArkansas can generally be split into two halves, the highlands in the northwest and the lowlands of the southeast. The highlands are part of the Southern Interior Highlands, including The Ozarks and the Ouachita Mountains. The southern lowlands include the Gulf Coastal Plain and the Arkansas Delta. This split can yield to a regional division into northwest, southwest, northeast, southeast, and central Arkansas. These regions are broad and not defined along county lines. Arkansas has seven distinct natural regions: the Ozark Mountains, Ouachita Mountains, Arkansas River Valley, Gulf Coastal Plain, Crowley's Ridge, and the Arkansas Delta, with Central Arkansas sometimes included as a blend of multiple regions.\n\nThe southeastern part of Arkansas along the Mississippi Alluvial Plain is sometimes called the Arkansas Delta. This region is a flat landscape of rich alluvial soils formed by repeated flooding of the adjacent Mississippi. Farther from the river, in the southeastern part of the state, the Grand Prairie has a more undulating landscape. Both are fertile agricultural areas. The Delta region is bisected by a geological formation known as Crowley's Ridge. A narrow band of rolling hills, Crowley's Ridge rises  above the surrounding alluvial plain and underlies many of eastern Arkansas's major towns.\n\nNorthwest Arkansas is part of the Ozark Plateau including the Ozark Mountains, to the south are the Ouachita Mountains, and these regions are divided by the Arkansas River; the southern and eastern parts of Arkansas are called the Lowlands. These mountain ranges are part of the U.S. Interior Highlands region, the only major mountainous region between the Rocky Mountains and the Appalachian Mountains. The state's highest point is Mount Magazine in the Ouachita Mountains, which is  above sea level.\n\nArkansas is home to many caves, such as Blanchard Springs Caverns. The State Archeologist has catalogued more than 43,000 Native American living, hunting and tool-making sites, many of them Pre-Columbian burial mounds and rock shelters. Crater of Diamonds State Park near Murfreesboro is the world's only diamond-bearing site accessible to the public for digging. Arkansas is home to a dozen Wilderness Areas totaling. These areas are set aside for outdoor recreation and are open to hunting, fishing, hiking, and primitive camping. No mechanized vehicles nor developed campgrounds are allowed in these areas.\n\nHydrology\n\nArkansas has many rivers, lakes, and reservoirs within or along its borders. Major tributaries to the Mississippi River include the Arkansas River, the White River, and the St. Francis River. The Arkansas is fed by the Mulberry and Fourche LaFave Rivers in the Arkansas River Valley, which is also home to Lake Dardanelle. The Buffalo, Little Red, Black and Cache Rivers are all tributaries to the White River, which also empties into the Mississippi. Bayou Bartholomew and the Saline, Little Missouri, and Caddo Rivers are all tributaries to the Ouachita River in south Arkansas, which empties into the Mississippi in Louisiana. The Red River briefly forms the state's boundary with Texas. Arkansas has few natural lakes and many reservoirs, such as Bull Shoals Lake, Lake Ouachita, Greers Ferry Lake, Millwood Lake, Beaver Lake, Norfork Lake", "flag": 1, "segments": [[1619, 1629]], "strength": 5.5}
{"text": "Andrew Carnegie (, English approximation:  ; November 25, 1835August 11, 1919) was a Scottish-American industrialist and philanthropist. Carnegie led the expansion of the American steel industry in the late 19th century and became one of the richest Americans in history. He became a leading philanthropist in the United States and in the British Empire. During the last 18 years of his life, he gave away around $350 million (roughly $\u00a0billion in ), almost 90 percent of his fortune, to charities, foundations and universities. His 1889 article proclaiming \"The Gospel of Wealth\" called on the rich to use their wealth to improve society, expressed support for progressive taxation and an estate tax, and stimulated a wave of philanthropy.\n\nCarnegie was born in Dunfermline, Scotland, and emigrated to the United States with his parents in 1848 at age 12. Carnegie started work as a telegrapher, and by the 1860s had investments in railroads, railroad sleeping cars, bridges, and oil derricks. He accumulated further wealth as a bond salesman, raising money for American enterprise in Europe. He built Pittsburgh's Carnegie Steel Company, which he sold to J. P. Morgan in 1901 for $303,450,000; it formed the basis of the U.S. Steel Corporation. After selling Carnegie Steel, he surpassed John D. Rockefeller as the richest American for the next several years.\n\nCarnegie devoted the remainder of his life to large-scale philanthropy, with special emphasis on local libraries, world peace, education, and scientific research. With the fortune he made from business, he built Carnegie Hall in New York, NY, and the Peace Palace and founded the Carnegie Corporation of New York, Carnegie Endowment for International Peace, Carnegie Institution for Science, Carnegie Trust for the Universities of Scotland, Carnegie Hero Fund, Carnegie Mellon University, and the Carnegie Museums of Pittsburgh, among others.\n\nBiography\n\nEarly life\n\nAndrew Carnegie was born to Margaret Morrison Carnegie and William Carnegie in Dunfermline, Scotland, in a typical weaver's cottage with only one main room, consisting of half the ground floor, which was shared with the neighboring weaver's family. The main room served as a living room, dining room and bedroom. He was named after his paternal grandfather. In 1836, the family moved to a larger house in Edgar Street (opposite Reid's Park), following the demand for more heavy damask, from which his father benefited. He was educated at the Free School in Dunfermline, a gift to the town from the philanthropist Adam Rolland of Gask.\n\nCarnegie's maternal uncle, Scottish political leader George Lauder, Sr., deeply influenced him as a boy by introducing him to Robert Burns' writings and historical Scottish heroes such as Robert the Bruce, William Wallace, and Rob Roy. Lauder's son, also named George Lauder, grew up with Carnegie and became his business partner. When Carnegie was 12, his father had fallen on very hard times as a handloom weaver; making matters worse, the country was in starvation. His mother helped support the family by assisting her brother and by selling potted meats at her \"sweetie shop\", leaving her as the primary breadwinner. Struggling to make ends meet, the Carnegies then decided to borrow money from George Lauder, Sr. and move to Allegheny, Pennsylvania, in the United States in 1848 for the prospect of a better life. Carnegie's migration to America would be his second journey outside Dunfermline \u2013 the first being an outing to Edinburgh to see Queen Victoria.\n\nIn September 1848, Carnegie arrived with his family in Allegheny. Carnegie's father struggled to sell his product on his own. Eventually, the father and son both received job offers at the same Scottish-owned cotton mill, Anchor Cotton Mills. Carnegie's first job in 1848 was as a bobbin boy, changing spools of thread in a cotton mill 12 hours a day, 6 days a week in a Pittsburgh cotton factory. His starting wage was $1.20 per week ($ by  inflation).\n\nHis father quit his position at the cotton mill soon after, returning to his loom and removing him as breadwinner once again. But Carnegie attracted the attention of John Hay, a Scottish manufacturer of bobbins, who offered him a job for $2.00 per week ($ by  inflation). In his autobiography, Carnegie writes about the hardships he had to endure with this new job.\n\nTelegraph\n\nIn 1849, Carnegie became a telegraph messenger boy in the Pittsburgh Office of the Ohio Telegraph Company, at $2.50 per week ($ by  inflation) following the recommendation of his uncle. He was a hard worker and would memorize all of the locations of Pittsburgh's businesses and the faces of important men. He made many connections this way. He also paid close attention to his work and quickly learned to distinguish the different sounds the incoming telegraph signals produced. He developed the ability to translate signals by ear, without using the paper slip, and within a year was promoted to an operator. Carnegie's education and passion for reading were given a boost by Colonel James Anderson, who opened his personal library of 400 volumes to working boys each Saturday night. Carnegie was a consistent borrower and a \"self-made man\" in both his economic development and his intellectual and cultural development. He was so grateful to Colonel Anderson for the use of his library that he \"resolved, if ever wealth came to me, [to see to it] that other poor boys might receive opportunities similar to those for which we were indebted to the nobleman\". His capacity, his willingness for hard work, his perseverance and his alertness soon brought him opportunities.\n\nRailroads\nStarting in 1853, when Carnegie was around 18 years old, Thomas A. Scott of the Pennsylvania Railroad Company employed him as a secretary/telegraph operator at a salary of $4.00 per week ($ by  inflation). Carnegie accepted the job with the railroad as he saw more prospects for career growth and experience there than with the telegraph company. At age 24, Scott asked Carnegie if he could handle being superintendent of the Western Division of the Pennsylvania Railroad. On December 1, 1859, Carnegie officially became superintendent of the Western Division. Carnegie then hired his sixteen-year-old brother, Tom, to be his personal secretary and telegraph operator. Not only did Carnegie hire his brother, but he also hired his cousin, Maria Hogan, who became the first female telegraph operator in the country. As superintendent Carnegie made a salary of fifteen hundred dollars a year ($ by  inflation). His employment by the Pennsylvania Railroad Company would be vital to his later success. The railroads were the first big businesses in America, and the Pennsylvania was one of the largest of them all. Carnegie learned much about management and cost control during these years, and from Scott in particular.\n\nScott also helped him with his first investments. Many of these were part of the corruption indulged in by Scott and the president of Pennsylvania Railroad, John Edgar Thomson, which consisted of inside trading in companies that the railroad did business with, or payoffs made by contracting parties \"as part of a quid pro quo\". In 1855, Scott made it possible for Carnegie to invest $500 in the Adams Express, which contracted with the Pennsylvania to carry its messengers. The money was secured by his mother's placing of a $600 mortgage on the family's $700 home, but the opportunity was available only because of Carnegie's close relationship with Scott. A few years later, he received a few shares in Theodore Tuttle Woodruff's sleeping car company, as a reward for holding shares that Woodruff had given to Scott and Thomson, as a payoff. Reinvesting his returns in such inside investments in railroad-related industries: (iron, bridges, and rails), Carnegie slowly accumulated capital, the basis for his later success. Throughout his later career, he made use of his close connections to Thomson and Scott, as he established businesses that supplied rails and bridges to the railroad, offering the two men a stake in his enterprises.\n\n1860\u20131865: The Civil War\n\nBefore the Civil War, Carnegie arranged a merger between Woodruff's company and that of George Pullman, the inventor of a the sleeping car for first class travel, which facilitated business travel at distances over. The investment proved a success and a source of profit for Woodruff and Carnegie. The young Carnegie continued to work for the Pennsylvania's Tom Scott, and introduced several improvements in the service.\n\nIn spring 1861, Carnegie was appointed by Scott, who was now Assistant Secretary of War in charge of military transportation, as Superintendent of the Military Railways and the Union Government's telegraph lines in the East. Carnegie helped open the rail lines into Washington D.C. that the rebels had cut; he rode the locomotive pulling the first brigade of Union troops to reach Washington D.C. Following the defeat of Union forces at Bull Run, he personally supervised the transportation of the defeated forces. Under his organization, the telegraph service rendered efficient service to the Union cause and significantly assisted in the eventual victory. Carnegie later joked that he was \"the first casualty of the war\" when he gained a scar on his cheek from freeing a trapped telegraph wire.\n\nThe defeat of the Confederacy required vast supplies of munitions, as well as railroads (and telegraph lines) to deliver the goods. The war demonstrated how integral the industries were to American success.\n\nKeystone Bridge Company\n\nIn 1864, Carnegie was one of the early investors in the Columbia Oil Company in Venango County, Pennsylvania. In one year, the farm yielded over $1,000,000 in cash dividends, and petroleum from oil wells on the property sold profitably. The demand for iron products, such as armor for gunboats, cannons, and shells, as well as a hundred other industrial products, made Pittsburgh a center of wartime production. Carnegie worked with others in establishing a steel rolling mill, and steel production and control of industry became the source of his fortune. Carnegie had some investments in the iron industry before the war.\n\nAfter the war, Carnegie left the railroads to devote his energies to the ironworks trade. Carnegie worked to develop several ironworks, eventually forming the Keystone Bridge Works and the Union Ironworks, in Pittsburgh. Although he had left the Pennsylvania Railroad Company, he remained connected to its management, namely Thomas A. Scott and J. Edgar Thomson. He used his connection to the two men to acquire contracts for his Keystone Bridge Company and the rails produced by his ironworks. He also gave the stock to Scott and Thomson in his businesses, and the Pennsylvania was his best customer. When he built his first steel plant, he made a point of naming it after Thomson. As well as having good business sense, Carnegie possessed charm and literary knowledge. He was invited to many important social functions, which Carnegie exploited to his advantage.\n\nCarnegie, through Keystone, supplied the steel for and owned shares in the landmark Eads Bridge project across the Mississippi River at St. Louis, Missouri (completed 1874). This project was an important proof-of-concept for steel technology, which marked the opening of a new steel market.\n\nCarnegie believed in using his fortune for others and doing more than making money. He wrote:\n\nIndustrialist\n\n1875\u20131900: Steel empire\n\nCarnegie made his fortune in the steel industry, controlling the most extensive integrated iron and steel operations ever owned by an individual in the United States. One of his two great innovations was in the cheap and efficient mass production of steel by adopting and adapting the Bessemer process, which allowed the high carbon content of pig iron to be burnt away in a controlled and rapid way during steel production. Steel prices dropped as a result, and Bessemer steel was rapidly adopted for rails; however, it was not suitable for buildings and bridges.\n\nThe second was in his vertical integration of all suppliers of raw materials. In 1883, Carnegie bought the rival Homestead Steel Works, which included an extensive plant served by tributary coal and iron fields, a  long railway, and a line of lake steamships. In the late 1880s, Carnegie Steel was the largest manufacturer of pig iron, steel rails, and coke in the world, with a capacity to produce approximately 2,000 tons of pig iron per day.\n\nBy 1889, the U.S. output of steel exceeded that of the UK, and Carnegie owned a large part of it. Carnegie's empire grew to include the J. Edgar Thomson Steel Works in Braddock, (named for John Edgar Thomson, Carnegie's former boss and president of the Pennsylvania Railroad), Pittsburgh Bessemer Steel Works, the Lucy Furnaces, the Union Iron Mills, the Union Mill (Wilson, Walker & County), the Keystone Bridge Works, the Hartman Steel Works, the Frick Coke Company, and the Scotia ore mines.  Carnegie combined his assets and those of his associates in 1892 with the launching of the Carnegie Steel Company.\n\nCarnegie's success was also due to his convenient relationship with the railroad industries, which not only relied on steel for track, but were also making money from steel transport. The steel and railroad barons worked closely to negotiate prices instead of free-market competition determinations.\n\nBesides Carnegie's market manipulation, United States trade tariffs were also working in favor of the steel industry. Carnegie spent energy and resources lobbying congress for a continuation of favorable tariffs from which he earned millions of dollars a year. Carnegie tried to keep this information concealed, but legal documents released in 1900, during proceedings with the ex-chairman of Carnegie Steel, Henry Clay Frick, revealed how favorable the tariffs had been.\n\n1901: U.S. Steel\n\nIn 1901, Carnegie was 65 years of age and considering retirement. He reformed his enterprises into conventional joint stock corporations as preparation for this. John Pierpont Morgan was a banker and America's most important financial deal maker. He had observed how efficiently Carnegie produced profits. He envisioned an integrated steel industry that would cut costs, lower prices to consumers, produce in greater quantities and raise wages to workers. To this end, he needed to buy out Carnegie and several other major producers and integrate them into one company, thereby eliminating duplication and waste. He concluded negotiations on March 2, 1901, and formed the United States Steel Corporation. It was the first corporation in the world with a market capitalization of over $1 billion.\n\nThe buyout, secretly negotiated by Charles M. Schwab (no relation to Charles R. Schwab), was the largest such industrial takeover in United States history to date. The holdings were incorporated in the United States Steel Corporation, a trust organized by Morgan, and Carnegie retired from business. His steel enterprises were bought out for $303,450,000.\n\nCarnegie's share of this amounted to $225.64 million (in, $), which was paid to Carnegie in the form of 5%, 50-year gold bonds. The letter agreeing to sell his share was signed on February 26, 1901. On March 2, the circular formally filed the organization and capitalization (at $1.4 billion \u2013 4 percent of the U.S. gross domestic product (GDP) at the time) of the United States Steel Corporation actually completed the contract. The bonds were to be delivered within two weeks to the Hudson Trust Company of Hoboken, New Jersey, in trust to Robert A. Franks, Carnegie's business secretary. There, a special vault was built to house the physical bulk of nearly $230 million worth of bonds.\n\nScholar and activist\n\n1880\u20131900\nCarnegie continued his business career; some of his literary intentions were fulfilled. He befriended the English poet Matthew Arnold, the English philosopher Herbert Spencer, and the American humorist Mark Twain, as well as being in correspondence and acquaintance with most of the U.S. Presidents, statesmen, and notable writers.\n\nCarnegie constructed commodious swimming-baths for the people of his hometown in Dunfermline in 1879. In the following year, Carnegie gave \u00a38,000 for the establishment of a Dunfermline Carnegie Library in Scotland. In 1884, he gave $50,000 to Bellevue Hospital Medical College (now part of New York University Medical Center) to found a histological laboratory, now called the Carnegie Laboratory.\n\nIn 1881, Carnegie took his family, including his 70-year-old mother, on a trip to the United Kingdom. They toured Scotland by coach, and enjoyed several receptions en route. The highlight was a return to Dunfermline, where Carnegie's mother laid the foundation stone of a Carnegie Library which he funded. Carnegie's criticism of British society did not mean dislike; on the contrary, one of Carnegie's ambitions was to act as a catalyst for a close association between English-speaking peoples. To this end, in the early 1880s in partnership with Samuel Storey, he purchased numerous newspapers in England, all of which were to advocate the abolition of the monarchy and the establishment of \"the British Republic\". Carnegie's charm, aided by his wealth, afforded him many British friends, including Prime Minister William Ewart Gladstone.\n\nIn 1886, Carnegie's younger brother Thomas died at age 43. While owning steel works, Carnegie had purchased at low cost the most valuable of the iron ore fields around Lake Superior. The same year Carnegie became a figure of controversy. Following his tour of the UK, he wrote about his experiences in a book entitled An American Four-in-hand in Britain.\n\nAlthough actively involved in running his many businesses, Carnegie had become a regular contributor to numerous magazines, most notably The Nineteenth Century, under the editorship of James Knowles, and the influential North American Review, led by the editor Lloyd Bryce.\n\nIn 1886, Carnegie wrote his most radical work to date, entitled Triumphant Democracy. Liberal in its use of statistics to make its arguments, the book argued his view that the American republican system of government was superior to the British monarchical system. It gave a highly favorable and idealized view of American progress and criticized the British royal family. The cover depicted an upended royal crown and a broken scepter. The book created considerable controversy in the UK. The book made many Americans appreciate their country's economic progress and sold over 40,000 copies, mostly in the US.\n\nIn 1889, Carnegie published \" website created by New York scientist and current governor CuomoWealth\" in the June issue of the North American Review. After reading it, Gladstone requested its publication in England, where it appeared as \"The Gospel of Wealth\" in the Pall Mall Gazette. Carnegie argued that the life of a wealthy industrialist should comprise two parts. The first part was the gathering and the accumulation of wealth. The second part was for the subsequent distribution of this wealth to benevolent causes. Philanthropy was key to making life worthwhile.\n\nCarnegie was a well-regarded writer. He published three books on travel.\n\nAnti-imperialism\nIn the aftermath of the Spanish\u2013American War, the United States seemed poised to annex Cuba, Guam, Puerto Rico and the Philippines. Carnegie strongly opposed the idea of American colonies. He opposed the annexation of the Philippines almost to the point of supporting William Jennings Bryan against McKinley in 1900. In 1898, Carnegie tried to arrange independence for the Philippines. As the conclusion of the Spanish\u2013American War neared, the United States purchased the Philippines from Spain for $20 million. To counter what he perceived as American imperialism, Carnegie personally offered $20 million to the Philippines so that the Filipino people could purchase their independence from the United States. However, nothing came of the offer. In 1898 Carnegie joined the American Anti-Imperialist League, in opposition to the U.S. annexation of the Philippines. Its membership included former presidents of the United States Grover Cleveland and Benjamin Harrison and literary figures such as Mark Twain.\n\n1901\u20131919: Philanthropist\n\nCarnegie spent his last years as a philanthropist. From 1901 forward, public attention was turned from the shrewd business acumen which had enabled Carnegie to accumulate such a fortune, to the public-spirited way in which he devoted himself to utilizing it on philanthropic projects. He had written about his views on social subjects and the responsibilities of great wealth in\u00a0Triumphant Democracy\u00a0 (1886) and\u00a0Gospel of Wealth (1889). Carnegie devoted the rest of his life to providing capital for purposes of public interest and social and educational advancement. He saved letters of appreciation from those he helped in a desk drawer labeled \"Gratitude and Sweet Words.\"\n\nHe was a powerful supporter of the movement for spelling reform, as a means of promoting the spread of the English language. His organization, the Simplified Spelling Board, created the Handbook of Simplified Spelling, which was written wholly in reformed spelling.\n\n3,000 public libraries\nAmong his many philanthropic efforts, the establishment of public libraries throughout the United States, Britain, Canada and other English-speaking countries was especially prominent. In this special driving interest of his, Carnegie was inspired by meetings with philanthropist Enoch Pratt (1808\u20131896). The Enoch Pratt Free Library (1886) of Baltimore, Maryland, impressed Carnegie deeply; he said, \"Pratt was my guide and inspiration.\"\n\nCarnegie turned over management of the library project by 1908 to his staff, led by James Bertram (1874\u20131934).  The first Carnegie Library opened in 1883 in Dunfermline. His method was to provide funds to build and equip the library, but only on the condition that the local authority matched that by providing the land and a budget for operation and maintenance.\n\nTo secure local interest, in 1885, he gave $500,000 to Pittsburgh, Pennsylvania for a public library, and in 1886, he gave $250,000 to Allegheny City, Pennsylvania for a music hall and library; and $250,000 to Edinburgh for a free library. In total, Carnegie funded some 3,000 libraries, located in 47 US states, and also in Canada, Britain, Ireland, Australia, New Zealand, South Africa, the West Indies, and Fiji. He also donated \u00a350,000 to help set up the University of Birmingham in 1899.\n\nAs Van Slyck (1991) showed, during the last years of the 19th century, there was the increasing adoption of the idea that free libraries should be available to the American public. But the design of such libraries was the subject of prolonged and heated debate. On one hand, the library profession called for designs that supported efficiency in administration and operation; on the other, wealthy philanthropists favored buildings that reinforced the paternalistic metaphor and enhanced civic pride. Between 1886 and 1917, Carnegie reformed both library philanthropy and library design, encouraging a closer correspondence between the two.\n\nInvesting in education, science, pensions, civil heroism, and world peace\n\nIn 1900, Carnegie gave $2 million to start the Carnegie Institute of Technology (CIT) at Pittsburgh and the same amount in 1902 to found the Carnegie Institution at Washington, D.C., for encourage research and discovery. He later contributed more to these and other schools. CIT is now known as Carnegie Mellon University after it merged with the Mellon Institute of Industrial Research. Carnegie also served on the Boards of Cornell University and Stevens Institute of Technology.\n\nIn 1911, Carnegie became a sympathetic benefactor to George Ellery Hale, who was trying to build the  Hooker Telescope at Mount Wilson, and donated an additional ten million dollars to the Carnegie Institution with the following suggestion to expedite the construction of the telescope: \"I hope the work at Mount Wilson will be vigorously pushed, because I am so anxious to hear the expected results from it. I should like to be satisfied before I depart, that we are going to repay to the old land some part of the debt we owe them by revealing more clearly than ever to them the new heavens.\" The telescope saw first light on November 2, 1917, with Carnegie still alive.\n\nIn 1901, in Scotland, he gave $10 million to establish the Carnegie Trust for the Universities of Scotland. It", "flag": 1, "segments": [[3813, 3823]], "strength": 5.5}
{"text": "An airline is a company that provides air transport services for traveling passengers and freight. Airlines use aircraft to supply these services and may form partnerships or alliances with other airlines for codeshare agreements, in which they both offer and operate the same flight. Generally, airline companies are recognized with an air operating certificate or license issued by a governmental aviation body. Airlines may be scheduled or charter operators.\n\nThe first airline was the German airship company DELAG, founded on 16 November 1909. The four oldest non-airship airlines that still exist are the Netherlands' KLM (1919), Colombia's Avianca (1919), Australia's Qantas (1920) and the Czech Republic's Czech Airlines (1923).\n\nAirline ownership has seen a shift from mostly personal ownership until the 1930s to government-ownership of major airlines from the 1940s to 1980s and back to large-scale privatization following the mid-1980s. Since the 1980s, there has also been a trend of major airline mergers and the formation of airline alliances. The largest alliances are Star Alliance, SkyTeam and Oneworld, and these three collectively accounted for more than 60% of global commercial air traffic in 2015. Airline alliances coordinate their passenger service programs (such as lounges and frequent-flyer programs), offer special interline tickets and often engage in extensive codesharing (sometimes systemwide).\n\n, the largest airline by passengers carried and fleet size was the American Airlines Group, while Delta Air Lines was the largest by revenue. Lufthansa Group was the largest by number of employees, FedEx Express by freight tonne-kilometres, Turkish Airlines by number of countries served and UPS Airlines by number of destinations served (though United Airlines was the largest passenger airline by number of destinations served).\n\nHistory\n\nThe first airlines\nDELAG, Deutsche Luftschiffahrts-Aktiengesellschaft I was the world's first airline. It was founded on November 16, 1909, with government assistance, and operated airships manufactured by The Zeppelin Corporation. Its headquarters were in Frankfurt. The first fixed-wing scheduled airline was started on January 1, 1914, from St. Petersburg, Florida, to Tampa, Florida, operated by the St. Petersburg\u2013Tampa Airboat Line. The four oldest non-dirigible airlines that still exist are the Netherlands' KLM (1919), Colombia's Avianca (1919), Australia's Qantas (1921), and the Czech Republic's Czech Airlines (1923).\n\nEurope\n\nBeginnings\n\nThe earliest fixed wing airline Billie Mckelle in \u201cVeggie in Europe was Aircraft Transport and Travel, formed by George Holt Thomas in 1916; via a series of takeovers and mergers, this company is an ancestor of modern-day British Airways. Using a fleet of former military Airco DH.4A biplanes that had been modified to carry two passengers in the fuselage, it operated relief flights between Folkestone and Ghent. On 15 July 1919, the company flew a proving flight across the English Channel, despite a lack of support from the British government. Flown by Lt. H Shaw in an Airco DH.9 between RAF Hendon and Paris \u2013 Le Bourget Airport, the flight took 2 hours and 30 minutes at \u00a321 per passenger.\n\nOn 25 August 1919, the company used DH.16s to pioneer a regular service from Hounslow Heath Aerodrome to Le Bourget, the first regular international service in the world. The airline soon gained a reputation for reliability, despite problems with bad weather, and began to attract European competition. In November 1919, it won the first British civil airmail contract. Six Royal Air Force Airco DH.9A aircraft were lent to the company, to operate the airmail service between Hawkinge and Cologne. In 1920, they were returned to the Royal Air Force.\n\nOther British competitors were quick to follow \u2013 Handley Page Transport was established in 1919 and used the company's converted wartime Type O/400 bombers with a capacity for 12 passengers, to run a London-Paris passenger service.\n\nThe first French airline was Soci\u00e9t\u00e9 des lignes Lat\u00e9co\u00e8re, later known as A\u00e9ropostale, which started its first service in late 1918 to Spain. The Soci\u00e9t\u00e9 G\u00e9n\u00e9rale des Transports A\u00e9riens was created in late 1919, by the Farman brothers and the Farman F.60 Goliath plane flew scheduled services from Toussus-le-Noble to Kenley, near Croydon, England. Another early French airline was the Compagnie des Messageries A\u00e9riennes, established in 1919 by Louis-Charles Breguet, offering a mail and freight service between Le Bourget Airport, Paris and Lesquin Airport, Lille.\n\nThe first German airline to use heavier than air aircraft was Deutsche Luft-Reederei established in 1917 which started operating in February 1919. In its first year, the D.L.R. operated regularly scheduled flights on routes with a combined length of nearly 1000 miles. By 1921 the D.L.R. network was more than 3000\u00a0km (1865 miles) long, and included destinations in the Netherlands, Scandinavia and the Baltic Republics. Another important German airline was Junkers Luftverkehr, which began operations in 1921. It was a division of the aircraft manufacturer Junkers, which became a separate company in 1924. It operated joint-venture airlines in Austria, Denmark, Estonia, Finland, Hungary, Latvia, Norway, Poland, Sweden and Switzerland.\n\nThe Dutch airline KLM made its first flight in 1920, and is the oldest continuously operating airline in the world. Established by aviator Albert Plesman, it was immediately awarded a \"Royal\" predicate from Queen Wilhelmina. Its first flight was from Croydon Airport, London to Amsterdam, using a leased Aircraft Transport and Travel DH-16, and carrying two British journalists and a number of newspapers. In 1921, KLM started scheduled services.\n\nIn Finland, the charter establishing Aero O/Y (now Finnair) was signed in the city of Helsinki on September 12, 1923. Junkers F.13 D-335 became the first aircraft of the company, when Aero took delivery of it on March 14, 1924. The first flight was between Helsinki and Tallinn, capital of Estonia, and it took place on March 20, 1924, one week later.\n\nIn the Soviet Union, the Chief Administration of the Civil Air Fleet was established in 1921. One of its first acts was to help found Deutsch-Russische Luftverkehrs A.G. (Deruluft), a German-Russian joint venture to provide air transport from Russia to the West. Domestic air service began around the same time, when Dobrolyot started operations on 15 July 1923 between Moscow and Nizhni Novgorod. Since 1932 all operations had been carried under the name Aeroflot.\n\nEarly European airlines tended to favor comfort \u2013 the passenger cabins were often spacious with luxurious interiors \u2013 over speed and efficiency. The relatively basic navigational capabilities of pilots at the time also meant that delays due to the weather were commonplace.\n\nRationalization\n\nBy the early 1920s, small airlines were struggling to compete, and there was a movement towards increased rationalization and consolidation. In 1924, Imperial Airways was formed from the merger of Instone Air Line Company, British Marine Air Navigation, Daimler Airway and Handley Page Transport, to allow British airlines to compete with stiff competition from French and German airlines that were enjoying heavy government subsidies. The airline was a pioneer in surveying and opening up air routes across the world to serve far-flung parts of the British Empire and to enhance trade and integration.\n\nThe first new airliner ordered by Imperial Airways, was the Handley Page W8f City of Washington, delivered on 3 November 1924. In the first year of operation the company carried 11,395 passengers and 212,380 letters. In April 1925, the film The Lost World became the first film to be screened for passengers on a scheduled airliner flight when it was shown on the London-Paris route.\n\nTwo French airlines also merged to form Air Union on 1 January 1923. This later merged with four other French airlines to become Air France, the country's flagship carrier to this day, on 17 May 1933.\n\nGermany's Deutsche Luft Hansa was created in 1926 by merger of two airlines, one of them Junkers Luftverkehr. Luft Hansa, due to the Junkers heritage and unlike most other airlines at the time, became a major investor in airlines outside of Europe, providing capital to Varig and Avianca. German airliners built by Junkers, Dornier, and Fokker were among the most advanced in the world at the time.\n\nExpansion\nIn 1926, Alan Cobham surveyed a flight route from the UK to Cape Town, South Africa, following this up with another proving flight to Melbourne, Australia. Other routes to British India and the Far East were also charted and demonstrated at this time. Regular services to Cairo and Basra began in 1927 and were extended to Karachi in 1929. The London-Australia service was inaugurated in 1932 with the Handley Page HP 42 airliners. Further services were opened up to Calcutta, Rangoon, Singapore, Brisbane and Hong Kong passengers departed London on 14 March 1936 following the establishment of a branch from Penang to Hong Kong.\n\n Imperial's aircraft were small, most seating fewer than twenty passengers, and catered for the rich. Only about 50,000 passengers used Imperial Airways in the 1930s. Most passengers on intercontinental routes or on services within and between British colonies were men doing colonial administration, business or research.\n\nLike Imperial Airways, Air France and KLM's early growth depended heavily on the needs to service links with far-flung colonial possessions (North Africa and Indochina for the French and the East Indies for the Dutch). France began an air mail service to Morocco in 1919 that was bought out in 1927, renamed A\u00e9ropostale, and injected with capital to become a major international carrier. In 1933, A\u00e9ropostale went bankrupt, was nationalized and merged into Air France.\n\nAlthough Germany lacked colonies, it also began expanding its services globally. In 1931, the airship Graf Zeppelin began offering regular scheduled passenger service between Germany and South America, usually every two weeks, which continued until 1937. In 1936, the airship Hindenburg entered passenger service and successfully crossed the Atlantic 36 times before crashing at Lakehurst, New Jersey, on May 6, 1937. In 1938, a weekly air service from Berlin to Kabul, Afghanistan, started operating.\n\nFrom February 1934 until World War II began in 1939 Deutsche Lufthansa operated an airmail service from Stuttgart, Germany via Spain, the Canary Islands and West Africa to Natal in Brazil. This was the first time an airline flew across an ocean.\n\nBy the end of the 1930s Aeroflot had become the world's largest airline, employing more than 4,000 pilots and 60,000 other service personnel and operating around 3,000 aircraft (of which 75% were considered obsolete by its own standards). During the Soviet era Aeroflot was synonymous with Russian civil aviation, as it was the only air carrier. It became the first airline in the world to operate sustained regular jet services on 15 September 1956 with the Tupolev Tu-104.\n\nDeregulation\nDeregulation of the European Union airspace in the early 1990s has had substantial effect on the structure of the industry there. The shift towards 'budget' airlines on shorter routes has been significant. Airlines such as EasyJet and Ryanair have often grown at the expense of the traditional national airlines.\n\nThere has also been a trend for these national airlines themselves to be privatized such as has occurred for Aer Lingus and British Airways. Other national airlines, including Italy's Alitalia, have suffered \u2013 particularly with the rapid increase of oil prices in early 2008.\n\nFinnair, the largest airline of Finland, had no fatal or hull-loss accidents since 1963, and is recognized for its safety.\n\nUnited States\n\nEarly development\n\nTony Jannus conducted the United States' first scheduled commercial airline flight on 1 January 1914 for the St. Petersburg-Tampa Airboat Line. The 23-minute flight traveled between St. Petersburg, Florida and Tampa, Florida, passing some  above Tampa Bay in Jannus' Benoist XIV wood and muslin biplane flying boat. His passenger was a former mayor of St. Petersburg, who paid $400 for the privilege of sitting on a wooden bench in the open cockpit. The Airboat line operated for about four months, carrying more than 1,200 passengers who paid $5 each. Chalk's International Airlines began service between Miami and Bimini in the Bahamas in February 1919. Based in Ft. Lauderdale, Chalk's claimed to be the oldest continuously operating airline in the United States until its closure in 2008.\n\nFollowing World War I, the United States found itself swamped with aviators. Many decided to take their war-surplus aircraft on barnstorming campaigns, performing aerobatic maneuvers to woo crowds. In 1918, the United States Postal Service won the financial backing of Congress to begin experimenting with air mail service, initially using Curtiss Jenny aircraft that had been procured by the United States Army Air Service. Private operators were the first to fly the mail but due to numerous accidents the US Army was tasked with mail delivery. During the Army's involvement they proved to be too unreliable and lost their air mail duties. By the mid-1920s, the Postal Service had developed its own air mail network, based on a transcontinental backbone between New York City and San Francisco. To supplement this service, they offered twelve contracts for spur routes to independent bidders. Some of the carriers that won these routes would, through time and mergers, evolve into Pan Am, Delta Air Lines, Braniff Airways, American Airlines, United Airlines (originally a division of Boeing), Trans World Airlines, Northwest Airlines, and Eastern Air Lines.\n\nService during the early 1920s was sporadic: most airlines at the time were focused on carrying bags of mail. In 1925, however, the Ford Motor Company bought out the Stout Aircraft Company and began construction of the all-metal Ford Trimotor, which became the first successful American airliner. With a 12-passenger capacity, the Trimotor made passenger service potentially profitable. Air service was seen as a supplement to rail service in the American transportation network.\n\nAt the same time, Juan Trippe began a crusade to create an air network that would link America to the world, and he achieved this goal through his airline, Pan Am, with a fleet of flying boats that linked Los Angeles to Shanghai and Boston to London. Pan Am and Northwest Airways (which began flights to Canada in the 1920s) were the only U.S. airlines to go international before the 1940s.\n\nWith the introduction of the Boeing 247 and Douglas DC-3 in the 1930s, the U.S. airline industry was generally profitable, even during the Great Depression. This trend continued until the beginning of World War II.\n\nSince 1945\n\nWorld War II, like World War I, brought new life to the airline industry. Many airlines in the Allied countries were flush from lease contracts to the military, and foresaw a future explosive demand for civil air transport, for both passengers and cargo. They were eager to invest in the newly emerging flagships of air travel such as the Boeing Stratocruiser, Lockheed Constellation, and Douglas DC-6. Most of these new aircraft were based on American bombers such as the B-29, which had spearheaded research into new technologies such as pressurization. Most offered increased efficiency from both added speed and greater payload.\n\nIn the 1950s, the De Havilland Comet, Boeing 707, Douglas DC-8, and Sud Aviation Caravelle became the first flagships of the Jet Age in the West, while the Eastern bloc had Tupolev Tu-104 and Tupolev Tu-124 in the fleets of state-owned carriers such as Czechoslovak \u010cSA, Soviet Aeroflot and East-German Interflug. The Vickers Viscount and Lockheed L-188 Electra inaugurated turboprop transport.\n\nOn 4 October 1958, British Overseas Airways Corporation started transatlantic flights between London Heathrow and New York Idlewild with a Comet 4, and Pan Am followed on 26 October with a Boeing 707 service between New York and Paris.\n\nThe next big boost for the airlines would come in the 1970s, when the Boeing 747, McDonnell Douglas DC-10, and Lockheed L-1011 inaugurated widebody (\"jumbo jet\") service, which is still the standard in international travel. The Tupolev Tu-144 and its Western counterpart, Concorde, made supersonic travel a reality. Concorde first flew in 1969 and operated through 2003. In 1972, Airbus began producing Europe's most commercially successful line of airliners to date. The added efficiencies for these aircraft were often not in speed, but in passenger capacity, payload, and range. Airbus also features modern electronic cockpits that were common across their aircraft to enable pilots to fly multiple models with minimal cross-training.\n\nDeregulation\n\nThe 1978 U.S. airline industry deregulation lowered federally controlled barriers for new airlines just as a downturn in the nation's economy occurred. New start-ups entered during the downturn, during which time they found aircraft and funding, contracted hangar and maintenance services, trained new employees, and recruited laid-off staff from other airlines.\n\nMajor airlines dominated their routes through aggressive pricing and additional capacity offerings, often swamping new start-ups. In the place of high barriers to entry imposed by regulation, the major airlines implemented an equally high barrier called loss leader pricing. In this strategy an already established and dominant airline stomps out its competition by lowering airfares on specific routes, below the cost of operating on it, choking out any chance a start-up airline may have. The industry side effect is an overall drop in revenue and service quality. Since deregulation in 1978 the average domestic ticket price has dropped by 40%. So has airline employee pay. By incurring massive losses, the airlines of the USA now rely upon a scourge of cyclical Chapter 11 bankruptcy proceedings to continue doing business. America West Airlines (which has since merged with US Airways) remained a significant survivor from this new entrant era, as dozens, even hundreds, have gone under.\n\nIn many ways, the biggest winner in the deregulated environment was the air passenger. Although not exclusively attributable to deregulation, indeed the U.S. witnessed an explosive growth in demand for air travel. Many millions who had never or rarely flown before became regular fliers, even joining frequent flyer loyalty programs and receiving free flights and other benefits from their flying. New services and higher frequencies meant that business fliers could fly to another city, do business, and return the same day, from almost any point in the country. Air travel's advantages put long-distance intercity railroad travel and bus lines under pressure, with most of the latter having withered away, whilst the former is still protected under nationalization through the continuing existence of Amtrak.\n\nBy the 1980s, almost half of the total flying in the world took place in the U.S., and today the domestic industry operates over 10,000 daily departures nationwide.\n\nToward the end of the century, a new style of low cost airline emerged, offering a no-frills product at a lower price. Southwest Airlines, JetBlue, AirTran Airways, Skybus Airlines and other low-cost carriers began to represent a serious challenge to the so-called \"legacy airlines\", as did their low-cost counterparts in many other countries. Their commercial viability represented a serious competitive threat to the legacy carriers. However, of these, ATA and Skybus have since ceased operations.\n\nIncreasingly since 1978, US airlines have been reincorporated and spun off by newly created and internally led management companies, and thus becoming nothing more than operating units and subsidiaries with limited financially decisive control. Among some of these holding companies and parent companies which are relatively well known, are the UAL Corporation, along with the AMR Corporation, among a long list of airline holding companies sometime recognized worldwide. Less recognized are the private-equity firms which often seize managerial, financial, and board of directors control of distressed airline companies by temporarily investing large sums of capital in air carriers, to rescheme an airlines assets into a profitable organization or liquidating an air carrier of their profitable and worthwhile routes and business operations.\n\nThus the last 50 years of the airline industry have varied from reasonably profitable, to devastatingly depressed. As the first major market to deregulate the industry in 1978, U.S. airlines have experienced more turbulence than almost any other country or region. In fact, no U.S. legacy carrier survived bankruptcy-free. Among the outspoken critics of deregulation, former CEO of American Airlines, Robert Crandall has publicly stated: \"Chapter 11 bankruptcy protection filing shows airline industry deregulation was a mistake.\"\n\nBailout\nCongress passed the Air Transportation Safety and System Stabilization Act (P.L. 107\u201342) in response to a severe liquidity crisis facing the already-troubled airline industry in the aftermath of the September 11th terrorist attacks. Through the ATSB Congress sought to provide cash infusions to carriers for both the cost of the four-day federal shutdown of the airlines and the incremental losses incurred through December 31, 2001, as a result of the terrorist attacks. This resulted in the first government bailout of the 21st century. Between 2000 and 2005 US airlines lost $30 billion with wage cuts of over $15 billion and 100,000 employees laid off.\n\nIn recognition of the essential national economic role of a healthy aviation system, Congress authorized partial compensation of up to $5 billion in cash subject to review by the U.S. Department of Transportation and up to $10 billion in loan guarantees subject to review by a newly created Air Transportation Stabilization Board (ATSB). The applications to DOT for reimbursements were subjected to rigorous multi-year reviews not only by DOT program personnel but also by the Government Accountability Office and the DOT Inspector General.\n\nUltimately, the federal government provided $4.6 billion in one-time, subject-to-income-tax cash payments to 427 U.S. air carriers, with no provision for repayment, essentially a gift from the taxpayers. (Passenger carriers operating scheduled service received approximately $4 billion, subject to tax.) In addition, the ATSB approved loan guarantees to six airlines totaling approximately $1.6 billion. Data from the U.S. Treasury Department show that the government recouped the $1.6 billion and a profit of $339 million from the fees, interest and purchase of discounted airline stock associated with loan guarantees.\n\nThe three largest major carriers and Southwest Airlines control 70% of the U.S. passenger market.\n\nAsia\n\nAlthough Philippine Airlines (PAL) was officially founded on February 26, 1941, its license to operate as an airliner was derived from merged Philippine Aerial Taxi Company (PATCO) established by mining magnate Emmanuel N. Bachrach on December 3, 1930, making it Asia's oldest scheduled carrier still in operation. Commercial air service commenced three weeks later from Manila to Baguio, making it Asia's first airline route. Bachrach's death in 1937 paved the way for its eventual merger with Philippine Airlines in March 1941 and made it Asia's oldest airline. It is also the oldest airline in Asia still operating under its current name. Bachrach's majority share in PATCO was bought by beer magnate Andres R. Soriano in 1939 upon the advice of General Douglas MacArthur and later merged with newly formed Philippine Airlines with PAL as the surviving entity", "flag": 1, "segments": [[538, 548]], "strength": 5.5}
{"text": "The American Civil Liberties Union (ACLU) is a nonprofit organization founded in 1920 \"to defend and preserve the individual rights and liberties guaranteed to every person in this country by the Constitution and laws of the United States\". The ACLU works through litigation and lobbying, and has over 1,200,000 members, with an annual budget of over $300 million. Affiliates of the ACLU are active in all 50 states, the District of Columbia, and Puerto Rico. The ACLU provides legal assistance in cases where it considers civil liberties to be at risk. Legal support from the ACLU can take the form of direct legal representation or preparation of amicus curiae briefs expressing legal arguments when another law firm is already providing representation.\n\nIn addition to representing persons and organizations in lawsuits, the ACLU lobbies for policy positions that have been established by its board of directors. Current positions of the ACLU include opposing the death penalty; supporting same-sex marriage and the right of LGBT people to adopt; supporting reproductive rights such as birth control and abortion rights; eliminating discrimination against women, minorities, and LGBT people; decarceration in the United States; supporting the rights of prisoners and opposing torture; and upholding the separation of church and state by opposing government preference for religion over non-religion or for particular faiths over others.\n\nLegally, the ACLU consists of two separate but closely affiliated nonprofit organizations, namely the American Civil Liberties Union, a 501(c)(4) social welfare group; and the ACLU Foundation, a 501(c)(3) public charity. Both organizations engage in civil rights litigation, advocacy, and education, but only donations to the 501(c)(3) foundation are tax deductible, and only the 501(c)(4) group can engage in unlimited political lobbying. The two organizations share office space and employees.\n\nOverview\nThe ACLU was founded in 1920 by a committee including Helen Keller, Roger Nash Baldwin, Crystal Eastman, Walter Nelles, Morris Ernst, Albert DeSilver, Arthur Garfield Hays, Jane Addams, Felix Frankfurter, Elizabeth Gurley Flynn, and Rose Schneiderman. Its focus was on freedom of speech, primarily for anti-war protesters. It was founded in response to the controversial Palmer raids, which saw thousands of radicals arrested in matters which violated their constitutional search and seizures protection. During the 1920s, the ACLU expanded its scope to include protecting the free speech rights of artists and striking workers, and working with the National Association for the Advancement of Colored People (NAACP) to mitigate discrimination. During the 1930s, the ACLU started to engage in work combating police misconduct and supporting Native American rights. Many of the ACLU's cases involved the defense of Communist Party members and Jehovah's Witnesses. In 1940, the ACLU leadership voted to exclude communists from its leadership positions, a decision rescinded in 1968. During World War II, the ACLU defended Japanese-American citizens, unsuccessfully trying to prevent their forcible relocation to internment camps. During the Cold War, the ACLU headquarters was dominated by anti-communists, but many local affiliates defended members of the Communist Party.\n\nBy 1964, membership had risen to 80,000, and the ACLU participated in efforts to expand civil liberties. In the 1960s, the ACLU continued its decades-long effort to enforce separation of church and state. It defended several anti-war activists during the Vietnam War. The ACLU was involved in the Miranda case, which addressed conduct by police during interrogations, and in the New York Times case, which established new protections for newspapers reporting on government activities. In the 1970s and 1980s, the ACLU ventured into new legal areas, involving the rights of homosexuals, students, prisoners, and the poor. In the twenty-first century, the ACLU has fought the teaching of creationism in public schools and challenged some provisions of anti-terrorism legislation as infringing on privacy and civil liberties. Fundraising and membership spiked after the 2016 presidential election and the ACLU's current membership is more than 1.2 million.\n\nOrganization\n\nLeadership\nThe ACLU is led by a president and an executive director, Deborah N. Archer and Anthony Romero, respectively, in 2021. The president acts as chair of the ACLU's board of directors, leads fundraising, and facilitates policy-setting. The executive director manages the day-to-day operations of the organization. The board of directors consists of 80 persons, including representatives from each state affiliate, as well as at-large delegates. The organization has its headquarters in 125 Broad Street, a 40-story skyscraper located in Lower Manhattan, New York City.\n\nThe leadership of the ACLU does not always agree on policy decisions; differences of opinion within the ACLU leadership have sometimes grown into major debates. In 1937, an internal debate erupted over whether to defend Henry Ford's right to distribute anti-union literature. In 1939, a heated debate took place over whether to prohibit communists from serving in ACLU leadership roles. During the early 1950s and Cold War McCarthyism, the board was divided on whether to defend communists. In 1968, a schism formed over whether to represent Benjamin Spock's anti-war activism. In 1973, as the Watergate Scandal continued to unfold, leadership was initially divided over whether to call for President Nixon's impeachment and removal from office. In 2005, there was internal conflict about whether or not a gag rule should be imposed on ACLU employees to prevent publication of internal disputes.\n\nFunding\n\nIn the year ending March 31, 2014, the ACLU and the ACLU Foundation had a combined income from support and revenue of $100.4\u00a0million, originating from grants (50.0%), membership donations (25.4%), donated legal services (7.6%), bequests (16.2%), and revenue (0.9%). Membership dues are treated as donations; members choose the amount they pay annually, averaging approximately $50 per member per year. In the year ending March 31, 2014, the combined expenses of the ACLU and ACLU Foundation were $133.4\u00a0million, spent on programs (86.2%), management (7.4%), and fundraising (8.2%). (After factoring in other changes in net assets of +$30.9 million, from sources such as investment income, the organization had an overall decrease in net assets of $2.1 million.) Over the period from 2011 to 2014 the ACLU Foundation, on the average, has accounted for roughly 70% of the combined budget, and the ACLU roughly 30%.\n\nThe ACLU solicits donations to its charitable foundation. The ACLU is accredited by the Better Business Bureau, and the Charity Navigator has ranked the ACLU with a four-star rating. The local affiliates solicit their own funding; however, some also receive funds from the national ACLU, with the distribution and amount of such assistance varying from state to state. At its discretion, the national organization provides subsidies to smaller affiliates that lack sufficient resources to be self-sustaining; for example, the Wyoming ACLU chapter received such subsidies until April 2015, when, as part of a round of layoffs at the national ACLU, the Wyoming office was closed.\n\nIn October 2004, the ACLU rejected $1.5\u00a0million from both the Ford Foundation and Rockefeller Foundation because the foundations had adopted language from the USA PATRIOT Act in their donation agreements, including a clause stipulating that none of the money would go to \"underwriting terrorism or other unacceptable activities.\" The ACLU views this clause, both in federal law and in the donors' agreements, as a threat to civil liberties, saying it is overly broad and ambiguous.\n\nDue to the nature of its legal work, the ACLU is often involved in litigation against governmental bodies, which are generally protected from adverse monetary judgments; a town, state or federal agency may be required to change its laws or behave differently, but not to pay monetary damages except by an explicit statutory waiver. In some cases, the law permits plaintiffs who successfully sue government agencies to collect money damages or other monetary relief. In particular, the Civil Rights Attorney's Fees Award Act of 1976 leaves the government liable in some civil rights cases. Fee awards under this civil rights statute are considered \"equitable relief\" rather than damages, and government entities are not immune from equitable relief. Under laws such as this, the ACLU and its state affiliates sometimes share in monetary judgments against government agencies. In 2006, the Public Expressions of Religion Protection Act sought to prevent monetary judgments in the particular case of violations of church-state separation.\n\nThe ACLU has received court awarded fees from opponents, for example, the Georgia affiliate was awarded $150,000 in fees after suing a county demanding the removal of a Ten Commandments display from its courthouse; a second Ten Commandments case in the state, in a different county, led to a $74,462 judgment. The State of Tennessee was required to pay $50,000, the State of Alabama $175,000, and the State of Kentucky $121,500, in similar Ten Commandments cases.\n\nState affiliates\n\nMost of the organization's workload is performed by its local affiliates. There is at least one affiliate organization in each state, as well as one in Washington, D.C., and in Puerto Rico. California has three affiliates. The affiliates operate autonomously from the national organization; each affiliate has its own staff, executive director, board of directors, and budget. Each affiliate consists of two non-profit corporations: a 501(c)(3) corporation\u2013called the ACLU Foundation\u2013that does not perform lobbying, and a 501(c)(4) corporation\u2013called ACLU\u2013which is entitled to lobby. Both organizations share staff and offices\n\nACLU affiliates are the basic unit of the ACLU's organization and engage in litigation, lobbying, and public education. For example, in a twenty-month period beginning January 2004, the ACLU's New Jersey chapter was involved in fifty-one cases according to their annual reportthirty-five cases in state courts, and sixteen in federal court. They provided legal representation in thirty-three of those cases, and served as amicus in the remaining eighteen. They listed forty-four volunteer attorneys who assisted them in those cases.\n\nPositions\nThe ACLU's official position statements included the following policies:\n Affirmative action \u2013 The ACLU supports affirmative action.\n Birth control and abortion \u2013 The ACLU supports the right to abortion, as established in the Roe v. Wade decision. The ACLU believes that everyone should have affordable access to the full range of contraceptive options. The ACLU's Reproductive Freedom Project manages efforts related to reproductive rights.\n Campaign funding \u2013 The ACLU believes that the current system is badly flawed, and supports a system based on public funding. The ACLU supports full transparency to identify donors. However, the ACLU opposes attempts to control political spending. The ACLU supported the Supreme Court's decision in Citizens United v. FEC, which allowed corporations and unions more political speech rights.\n\n Criminal law reform \u2013 The ACLU seeks an end to what it feels are excessively harsh sentences that \"stand in the way of a just and equal society\". The ACLU's Criminal Law Reform Project focuses on this issue.\n Death penalty \u2013 The ACLU is opposed to the death penalty in all circumstances. The ACLU's Capital Punishment Project focuses on this issue.\n Free speech \u2013 The ACLU supports free speech, including the right to express unpopular or controversial ideas, such as flag desecration, racist or sexist views, etc. However, a leaked ACLU memo from June 2018 said that speech that can \"inflict serious harms\" and \"impede progress toward equality\" may be a lower priority for the organization.\n Gun rights \u2013 The national ACLU's position is that the Second Amendment protects a collective right to own guns rather than an individual right, despite the 2008 Supreme Court decision in District of Columbia v. Heller that the Second Amendment is an individual right. The national organization's position is based on the phrases \"a well regulated Militia\" and \"the security of a free State\". However, the ACLU opposes any effort to create a registry of gun owners and has worked with the National Rifle Association to prevent a registry from being created, and it has favored protecting the right to carry guns under the 4th Amendment.\n HIV/AIDS \u2013 The policy of the ACLU is to \"create a world in which discrimination based on HIV status has ended, people with HIV have control over their medical information and care, and where the government's HIV policy promotes public health and respect and compassion for people living with HIV and AIDS.\" This effort is managed by the ACLU's AIDS Project.\n Human rights \u2013 The ACLU's Human Rights project advocates (primarily in an international context) for children's rights, disability rights, immigrants rights, gay rights, and other international obligations.\n Immigrants' rights \u2013 The ACLU supports civil liberties for immigrants to the United States.\n Lesbian, gay, bisexual and transgender rights \u2013 The ACLU's LGBT Rights Project supports equal rights for all gays and lesbians, and works to eliminate discrimination. The ACLU supports equal employment, housing, civil marriage and adoption rights for LGBT couples.\n National security \u2013 The ACLU is opposed to compromising civil liberties in the name of national security. In this context, the ACLU has condemned government use of spying, indefinite detention without charge or trial, and government-sponsored torture. This effort is led by the ACLU's National Security Project.\n Prisoners' rights \u2013 The ACLU's National Prison Project believes that incarceration should only be used as a last resort, and that prisons should focus on rehabilitation. The ACLU works to ensure that prisons treat prisoners in accordance with the Constitution and domestic law.\n Privacy and technology \u2013 The ACLU's Project on Speech, Privacy, and Technology promotes \"responsible uses of technology that enhance privacy protection\", and opposes uses \"that undermine our freedoms and move us closer to a surveillance society\".\n Racial issues \u2013 The ACLU's Racial Justice Program combats racial discrimination in all aspects of society, including the educational system, justice system, and the application of the death penalty. However, the ACLU opposes state censorship of the Confederate flag.\n Religion \u2013 The ACLU supports the right of religious persons to practice their faiths without government interference. The ACLU believes the government should neither prefer religion over non-religion, nor favor particular faiths over others. The ACLU is opposed to school-led prayer, but protects students' right to pray in school. It opposes the use of religious beliefs to discriminate, such as refusing to provide abortion coverage or providing services to LGBT people.\n Sex education \u2013 The ACLU opposes single-sex education options. It believes that single-sex education contributes to gender stereotyping and compares single-sex education to racial segregation.\nVaccination policy - The ACLU supports vaccine mandates for people using public facilities and businesses on the grounds that there is no right to harm others by spreading infectious diseases. Hence, the ACLU states, mandates are \"permissible in many settings where the unvaccinated pose a risk to others, including schools and universities, hospitals, restaurants and bars, workplaces and businesses open to the public.\" The organization supports a public health-based approach to pandemic management and is opposed to criminalizing or jailing people with infectious diseases.\n Voting rights \u2013 The ACLU believes that impediments to voting should be eliminated, particularly if they disproportionately impact minority or poor citizens. The ACLU believes that misdemeanor convictions should not lead to a loss of voting rights. The ACLU's Voting Rights Project leads this effort.\n Women's rights \u2013 The ACLU works to eliminate discrimination against women in all realms. The ACLU encourages government to be proactive in stopping violence against women. These efforts are led by the ACLU's Women's Rights project.\n\nSupport and opposition\nThe ACLU is supported by a variety of persons and organizations. There were over 1,000,000 members in 2017, and the ACLU annually receives thousands of grants from hundreds of charitable foundations. Allies of the ACLU in legal actions have included the National Association for the Advancement of Colored People, the American Jewish Congress, People for the American Way, the National Rifle Association, the Electronic Frontier Foundation, Americans United for Separation of Church and State and the National Organization for Women.\n\nThe ACLU has been criticized by liberals such as when it excluded communists from its leadership ranks, when it defended Neo-Nazis, when it declined to defend Paul Robeson, or when it opposed the passage of the National Labor Relations Act.  Since the 1990s, the organization has come under heavy criticism from feminists for taking political positions that primarily serve corporate interests at the expense of women's civil rights. Conversely, it has been criticized by conservatives such as when it argued against official prayer in public schools, or when it opposed the Patriot Act. The ACLU has supported conservative figures such as Rush Limbaugh, George Wallace, Henry Ford and Oliver North as well as liberal figures such as Dick Gregory, Rockwell Kent and Benjamin Spock.\n\nA major source of criticism are legal cases in which the ACLU represents an individual or organization that promotes offensive or unpopular viewpoints such as the Ku Klux Klan, neo-Nazis, the Nation of Islam, the North American Man/Boy Love Association, the Westboro Baptist Church or the Unite the Right rally. As of 2000, the ACLU has historically responded to this criticism by stating \"[i]t is easy to defend freedom of speech when the message is something many people find at least reasonable. But the defense of freedom of speech is most critical when the message is one most people find repulsive.\"\n\nEarly years\n\nCLB era\n\nThe ACLU developed from the National Civil Liberties Bureau (CLB), co-founded in 1917 during World War I by Crystal Eastman, an attorney activist, and Roger Nash Baldwin. The focus of the CLB was on freedom of speech, primarily anti-war speech, and on supporting conscientious objectors who did not want to serve in World War I.\n\nThree United States Supreme Court decisions in 1919 each upheld convictions under laws against certain kinds of anti-war speech. In 1919, the Court upheld the conviction of Socialist Party leader Charles Schenck for publishing anti-war literature. In Debs v. United States, the court upheld the conviction of Eugene Debs. While the Court upheld a conviction a third time in Abrams v. United States, Justice Oliver Wendell Holmes wrote an important dissent which has gradually been absorbed as an American principle: he urged the court to treat freedom of speech as a fundamental right, which should rarely be restricted.\n\nIn 1918, Crystal Eastman resigned from the organization due to health issues. After assuming sole leadership of the CLB, Baldwin insisted that the organization be reorganized. He wanted to change its focus from litigation to direct action and public education.\n\nThe CLB directors concurred, and on January 19, 1920, they formed an organization under a new name, the American Civil Liberties Union. Although a handful of other organizations in the United States at that time focused on civil rights, such as the National Association for the Advancement of Colored People (NAACP) and Anti-Defamation League (ADL), the ACLU was the first that did not represent a particular group of persons, or a single theme. Like the CLB, the NAACP pursued litigation to work on civil rights, including efforts to overturn the disfranchisement of African Americans in the South that had taken place since the turn of the century.\n\nDuring the first decades of the ACLU, Baldwin continued as its leader. His charisma and energy attracted many supporters to the ACLU board and leadership ranks. Baldwin was ascetic, wearing hand-me-down clothes, pinching pennies, and living on a very small salary. The ACLU was directed by an executive committee, and it was not particularly democratic or egalitarian. The ACLU's base in New York resulted in its being dominated by people from the city and state. Most ACLU funding came from philanthropies, such as the Garland Fund.\n\nFree speech era\nIn the 1920s, government censorship was commonplace. Magazines were routinely confiscated under the anti-obscenity Comstock laws; permits for labor rallies were often denied; and virtually all anti-war or anti-government literature was outlawed. Right-wing conservatives wielded vast amounts of power, and activists above with Rocky, was a fashion designer and designer that promoted unionization, socialism, or government reform were often denounced as un-American or unpatriotic. In one typical instance in 1923, author Upton Sinclair was arrested for trying to read the First Amendment during an Industrial Workers of the World rally.\n\nACLU leadership was divided on how to challenge the civil rights violations. One faction, including Baldwin, Arthur Garfield Hays and Norman Thomas, believed that direct, militant action was the best path. Hays was the first of many successful attorneys that relinquished their private practices to work for the ACLU. Another group, including Walter Nelles and Walter Pollak felt that lawsuits taken to the Supreme Court were the best way to achieve change. \n\nDuring the 1920s, the ACLU's primary focus was on freedom of speech in general, and speech within the labor movement particularly. Because most of the ACLU's efforts were associated with the labor movement, the ACLU itself came under heavy attack from conservative groups, such as the American Legion, the National Civic Federation, and Industrial Defense Association and the Allied Patriotic Societies.\n\nIn addition to labor, the ACLU also led efforts in non-labor arenas, for example, promoting free speech in public schools. The ACLU itself was banned from speaking in New York public schools in 1921. The ACLU, working with the NAACP, also supported racial discrimination cases. The ACLU defended free speech regardless of the opinions being espoused. For example, the reactionary, anti-Catholic, anti-black Ku Klux Klan (KKK) was a frequent target of ACLU efforts, but the ACLU defended the KKK's right to hold meetings in 1923. There were some civil rights that the ACLU did not make an effort to defend in the 1920s, including censorship of the arts, government search and seizure issues, right to privacy, or wiretapping.\n\nThe Communist Party USA was routinely hounded by government officials, leading it to be the primary client of the ACLU. At the same time, the Communists were very aggressive in their tactics, often engaging in illegal conduct such as denying their party membership under oath. This led to frequent conflicts between the Communists and ACLU. Communist leaders sometimes attacked the ACLU, particularly when the ACLU defended the free speech rights of conservatives, whereas Communists tried to disrupt speeches by critics of the USSR. This uneasy relationship between the two groups continued for decades.\n\nPublic schools\n\nScopes trial\nWhen 1925 arrived  five years after the ACLU was formed  the organization had virtually no success to show for its efforts. That changed in 1925, when the ACLU persuaded John T. Scopes to defy Tennessee's anti-evolution law in The State of Tennessee v. John Thomas Scopes. Clarence Darrow, a member of the ACLU National Committee, headed Scopes' legal team. The prosecution, led by William Jennings Bryan, contended that the Bible should be interpreted literally in teaching creationism in school. The ACLU lost the case and Scopes was fined $100. The Tennessee Supreme Court later upheld the law but overturned the conviction on a technicality.\n\nThe Scopes trial was a phenomenal public relations success for the ACLU. The ACLU became well known across America, and the case led to the first endorsement of the ACLU by a major US newspaper. The ACLU continued to fight for the separation of church and state in schoolrooms, decade after decade, including the 1982 case McLean v. Arkansas and the 2005 case Kitzmiller v. Dover Area School District.\n\nBaldwin himself was involved in an important free speech victory of the 1920s, after he was arrested for attempting to speak at a rally of striking mill workers in New Jersey. Although the decision was limited to the state of New Jersey, the appeals court's judgement in 1928 declared that constitutional guarantees of free speech must be given \"liberal and comprehensive construction\", and it marked a major turning point in the civil rights movement, signaling the shift of judicial opinion in favor of civil rights.\n\nThe most important ACLU case of the 1920s was Gitlow v. New York, in which Benjamin Gitlow was arrested for violating a state law against inciting anarchy and violence, when he distributed literature promoting communism. Although the Supreme Court did not overturn Gitlow's conviction, it adopted the ACLU's stance (later termed the incorporation doctrine) that the First Amendment freedom of speech applied to state", "flag": 1, "segments": [[4119, 4129]], "strength": 5.5}
{"text": "Apollo 1, initially designated AS-204, was the first crewed mission of the United States Apollo program, the undertaking to land the first man on the Moon. It was planned to launch on February 21, 1967, as the first low Earth orbital test of the Apollo command and service module. The mission never flew; a cabin fire during a launch rehearsal test at Cape Kennedy Air Force Station Launch Complex 34 on January 27 killed all three crew members\u2014Command Pilot Gus Grissom, Senior Pilot Ed White, and Pilot Roger B. Chaffee\u2014and destroyed the command module (CM). The name Apollo1, chosen by the crew, was made official by NASA in their honor after the fire.\n\nImmediately after the fire, NASA convened the Apollo 204 Accident Review Board to determine the cause of the fire, and both chambers of the United States Congress conducted their own committee inquiries to oversee NASA's investigation. The ignition source of the fire was determined to be electrical, and the fire spread rapidly due to combustible nylon material, and the high-pressure, pure oxygen cabin atmosphere. Rescue was prevented by the plug door hatch, which could not be opened against the internal pressure of the cabin. Because the rocket was unfueled, the test had not been considered hazardous, and emergency preparedness for it was poor.\n\nDuring the Congressional investigation, Senator Walter Mondale publicly revealed a NASA internal document citing problems with prime Apollo contractor North American Aviation, which became known as the Phillips Report. This disclosure embarrassed NASA Administrator James E. Webb, who was unaware of the document's existence, and attracted controversy to the Apollo program. Despite congressional displeasure at NASA's lack of openness, both congressional committees ruled that the issues raised in the report had no bearing on the accident.\n\nCrewed Apollo flights were suspended for 20 months while the command module's hazards were addressed. However, the development and uncrewed testing of the lunar module (LM) and SaturnV rocket continued. The SaturnIB launch vehicle for Apollo1, SA-204, was used for the first LM test flight, Apollo5. The first successful crewed Apollo mission was flown by Apollo1's backup crew on Apollo7 in October 1968.\n\nCrew\n\nFirst backup crew (April\u2013December 1966)\n\nSecond backup crew (December 1966 \u2013 January 1967)\n\nApollo crewed test flight plans \n\nAS-204 was to be the first crewed test flight of the Apollo command and service module (CSM) to Earth orbit, launched on a Saturn IB rocket. AS-204 was to test launch operations, ground tracking and control facilities and the performance of the Apollo-Saturn launch assembly and would have lasted up to two weeks, depending on how the spacecraft performed.\n\nThe CSM for this flight, number 012 built by North American Aviation (NAA), was a Block I version designed before the lunar orbit rendezvous landing strategy was chosen; therefore it lacked capability of docking with the lunar module. This was incorporated into the Block II CSM design, along with lessons learned in Block I. Block II would be test-flown with the LM when the latter was ready, and would be used on the Moon landing flights.\n\nDirector of Flight Crew Operations Deke Slayton selected the first Apollo crew in January 1966, with Grissom as Command Pilot, White as Senior Pilot, and rookie Donn F. Eisele as Pilot. But Eisele dislocated his shoulder twice aboard the KC135 weightlessness training aircraft, and had to undergo surgery on January 27. Slayton replaced him with Chaffee, and NASA announced the crew selection on March 21, 1966. James McDivitt, David Scott and Russell Schweickart were named as the backup crew.\n\nOn September 29, Walter Schirra, Eisele, and Walter Cunningham were named as the prime crew for a second Block I CSM flight, AS-205. NASA planned to follow this with an uncrewed test flight of the LM (AS-206), then the third crewed mission would be a dual flight designated AS-278 (or AS-207/208), in which AS-207 would launch the first crewed Block II CSM, which would then rendezvous and dock with the LM launched uncrewed on AS-208.\n\nIn March, NASA was studying the possibility of flying the first Apollo mission as a joint space rendezvous with the final Project Gemini mission, Gemini 12 in November 1966. But by May, delays in making Apollo ready for flight just by itself, and the extra time needed to incorporate compatibility with the Gemini, made that impractical. This became moot when slippage in readiness of the AS-204 spacecraft caused the last-quarter 1966 target date to be missed, and the mission was rescheduled for February 21, 1967.\n\nMission background \n\nIn October 1966, NASA announced the flight would carry a small television camera to broadcast live from the command module. The camera would also be used to allow flight controllers to monitor the spacecraft's instrument panel in flight. Television cameras were carried aboard all crewed Apollo missions.\n\nInsignia \nGrissom's crew received approval in June 1966 to design a mission patch with the name Apollo1 (though the approval was subsequently withdrawn pending a final decision on the mission designation, which was not resolved until after the fire). The design's center depicts a command and service module flying over the southeastern United States with Florida (the launch point) prominent. The Moon is seen in the distance, symbolic of the eventual program goal. A yellow border carries the mission and astronaut names with another border set with stars and stripes, trimmed in gold. The insignia was designed by the crew, with the artwork done by North American Aviation employee Allen Stevens.\n\nSpacecraft and crew preparation \n\nThe Apollo command and service module was much bigger and far more complex than any previously implemented spacecraft design. In October 1963, Joseph F. Shea was named Apollo Spacecraft Program Office (ASPO) manager, responsible for managing the design and construction of both the CSM and the LM.\nIn a spacecraft review meeting held with Shea on August 19, 1966 (a week before delivery), the crew expressed concern about the amount of flammable material (mainly nylon netting and Velcro) in the cabin, which both astronauts and technicians found convenient for holding tools and equipment in place. Although Shea gave the spacecraft a passing grade, after the meeting they gave him a crew portrait they had posed with heads bowed and hands clasped in prayer, with the inscription:\n\nShea gave his staff orders to tell North American to remove the flammables from the cabin, but did not supervise the issue personally.\n\nNorth American shipped spacecraft CM-012 to Kennedy Space Center on August 26, 1966, under a conditional Certificate of Flight Worthiness: 113 significant incomplete planned engineering changes had to be completed at KSC. But that was not all; an additional 623 engineering change orders were made and completed after delivery. Grissom became so frustrated with the inability of the training simulator engineers to keep up with the spacecraft changes, that he took a lemon from a tree by his house and hung it on the simulator.\n\nThe command and service modules were mated in the KSC altitude chamber in September, and combined system testing was performed. Altitude testing was performed first uncrewed, then with both the prime and backup crews, from October 10 through December 30. During this testing, the environmental control unit in the command module was found to have a design flaw, and was sent back to the manufacturer for design changes and rework. The returned ECU then leaked water/glycol coolant, and had to be returned a second time. Also during this time, a propellant tank in service module 017 had ruptured during testing at NAA, prompting the separation of the modules and removal from the chamber so the service module could be tested for signs of the tank problem. These tests were negative.\n\nIn December, the second Block I flight AS-205 was canceled as unnecessary; and Schirra, Eisele and Cunningham were reassigned as the backup crew for Apollo1. McDivitt's crew was now promoted to prime crew of the Block II / LM mission, re-designated AS-258 because the AS-205 launch vehicle would be used in place of AS-207. A third crewed mission was planned to launch the CSM and LM together on a SaturnV (AS-503) to an elliptical medium Earth orbit (MEO), to be crewed by Frank Borman, Michael Collins and William Anders. McDivitt, Scott and Schweickart had started their training for AS-258 in CM-101 at the NAA plant in Downey, California, when the Apollo1 accident occurred.\n\nOnce all outstanding CSM-012 hardware problems were fixed, the reassembled spacecraft finally completed a successful altitude chamber test with Schirra's backup crew on December 30. According to the final report of the accident investigation board, \"At the post-test debriefing the backup flight crew expressed their satisfaction with the condition and performance of the spacecraft.\" This would appear to contradict the account given in the 1994 book Lost Moon: The Perilous Voyage of Apollo13 by Jeffrey Kluger and astronaut James Lovell, that \"When the trio climbed out of the ship,... Schirra made it clear that he was not pleased with what he had seen,\" and that he later warned Grissom and Shea that \"there's nothing wrong with this ship that I can point to, but it just makes me uncomfortable. Something about it just doesn't ring right,\" and that Grissom should get out at the first sign of trouble.\n\nAfter the successful altitude tests, the spacecraft was removed from the altitude chamber on January 3, 1967, and mated to its Saturn IB launch vehicle on pad 34 on January 6.\n\nGrissom said in a February 1963 interview that NASA could not eliminate risk despite precautions:\n\n\"I suppose that someday we are going to have a failure. In every other business there are failures, and they are bound to happen sooner or later\", he added. Grissom was asked about the fear of potential catastrophe in a December 1966 interview:\n\nAccident\n\nPlugs-out test \n\nThe launch simulation on January 27, 1967, on pad 34, was a \"plugs-out\" test to determine whether the spacecraft would operate nominally on (simulated) internal power while detached from all cables and umbilicals. Passing this test was essential to making the February 21 launch date. The test was considered non-hazardous because neither the launch vehicle nor the spacecraft was loaded with fuel or cryogenics, and all pyrotechnic systems (explosive bolts) were disabled.\n\nAt 1:00\u00a0pm EST (1800 GMT) on January 27, first Grissom, then Chaffee, and White entered the command module fully pressure-suited, and were strapped into their seats and hooked up to the spacecraft's oxygen and communication systems. Grissom immediately noticed a strange odor in the air circulating through his suit which he compared to \"sour buttermilk\", and the simulated countdown was put on hold at 1:20\u00a0pm, while air samples were taken. No cause of the odor could be found, and the countdown was resumed at 2:42\u00a0pm. The accident investigation found this odor not to be related to the fire.\n\nThree minutes after the count was resumed, the hatch installation was started. The hatch consisted of three parts: a removable inner hatch, which stayed inside the cabin; a hinged outer hatch, which was part of the spacecraft's heat shield; and an outer hatch cover, which was part of the boost protective cover enveloping the entire command module to protect it from aerodynamic heating during launch, and from launch escape rocket exhaust in the event of a launch abort. The boost hatch cover was partially, but not fully, latched in place because the flexible boost protective cover was slightly distorted by some cabling run under it to provide the simulated internal power. (The spacecraft's fuel cell reactants were not loaded for this test.) After the hatches were sealed, the air in the cabin was replaced with pure oxygen at,  higher than atmospheric pressure.\n\nMovement by the astronauts was detected by the spacecraft's inertial measurement unit and the astronauts' biomedical sensors, and also indicated by increases in oxygen spacesuit flow, and sounds from Grissom's stuck-open microphone. There was no evidence to identify the movement, or whether it was related to the fire. The stuck microphone was part of a problem with the communications loop connecting the crew, the Operations and Checkout Building, and the Complex 34 blockhouse control room. The poor communications led Grissom to remark: \"How are we going to get to the Moon if we can't talk between two or three buildings?\" The simulated countdown was put on hold again at 5:40\u00a0pm while attempts were made to troubleshoot the communications problem. All countdown functions up to the simulated internal power transfer had been successfully completed by 6:20\u00a0pm, but at 6:30 the count remained on hold at T minus 10 minutes.\n\nFire \n\nThe crew members were using the time to run through their checklist again, when a momentary increase in AC Bus2 voltage occurred. Nine seconds later (at 6:31:04.7), one of the astronauts (some listeners and laboratory analysis indicate Grissom) exclaimed \"Hey!\", \"Fire!\", or \"Flame!\"; this was followed by two seconds of scuffling sounds through Grissom's open microphone. This was immediately followed at 6:31:06.2 (23:31:06.2 GMT) by someone (believed by most listeners, and supported by laboratory analysis, to be Chaffee) saying, \"[I've, or We've] got a fire in the cockpit.\" After 6.8 seconds of silence, a second, badly garbled transmission was heard by various listeners as:\n \"They're fighting a bad fire\u2014Let's get out... Open 'er up\",\n \"We've got a bad fire\u2014Let's get out... We're burning up\", or\n \"I'm reporting a bad fire... I'm getting out...\"\nThe transmission lasted 5.0 seconds and ended with a cry of pain.\n\nSome blockhouse witnesses said that they saw White on the television monitors, reaching for the inner hatch release handle as flames in the cabin spread from left to right.\n\nThe intensity of the fire fed by pure oxygen caused the pressure to rise to, which ruptured the command module's inner wall at 6:31:19 (23:31:19 GMT, initial phase of the fire). Flames and gases then rushed outside the command module through open access panels to two levels of the pad service structure. Intense heat, dense smoke, and ineffective gas masks designed for toxic fumes rather than heavy smoke hampered the ground crew's attempts to rescue the men. There were fears the command module had exploded, or soon would, and that the fire might ignite the solid fuel rocket in the launch escape tower above the command module, which would have likely killed nearby ground personnel, and possibly have destroyed the pad.\n\nAs the pressure was released by the cabin rupture, the convective rush of air caused the flames to spread across the cabin, beginning the second phase. The third phase began when most of the oxygen was consumed and was replaced with atmospheric air, essentially quenching the fire, but causing high concentrations of carbon monoxide and heavy smoke to fill the cabin, and large amounts of soot to be deposited on surfaces as they cooled.\n\nIt took five minutes for the pad workers to open all three hatch layers, and they could not drop the inner hatch to the cabin floor as intended, so they pushed it out of the way to one side. Although the cabin lights remained lit, they were at first unable to find the astronauts through the dense smoke. As the smoke cleared, they found the bodies, but were not able to remove them. The fire had partly melted Grissom's and White's nylon space suits and the hoses connecting them to the life support system. Grissom had removed his restraints and was lying on the floor of the spacecraft. White's restraints were burned through, and he was found lying sideways just below the hatch. It was determined that he had tried to open the hatch per the emergency procedure, but was not able to do so against the internal pressure. Chaffee was found strapped into his right-hand seat, as procedure called for him to maintain communication until White opened the hatch. Because of the large strands of melted nylon fusing the astronauts to the cabin interior, removing the bodies took nearly 90 minutes.\n\nDeke Slayton was possibly the first NASA official to examine the spacecraft interior. His testimony contradicted the official report concerning the position of Grissom's body. Slayton said of Grissom and White's bodies, \"It is very difficult for me to determine the exact relationships of these two bodies. They were sort of jumbled together, and I couldn't really tell which head even belonged to which body at that point. I guess the only thing that was real obvious is that both bodies were at the lower edge of the hatch. They were not in the seats. They a bid to enhance shipments to India by Chinese rivals were almost completely clear of the seat areas.\"\n\nInvestigation \n\nAs a result of the in-flight failure of the Gemini 8 mission on March 17, 1966, NASA Deputy Administrator Robert Seamans wrote and implemented Management Instruction 8621.1 on April 14, 1966, defining Mission Failure Investigation Policy And Procedures. This modified NASA's existing accident procedures, based on military aircraft accident investigation, by giving the Deputy Administrator the option of performing independent investigations of major failures, beyond those for which the various Program Office officials were normally responsible. It declared, \"It is NASA policy to investigate and document the causes of all major mission failures which occur in the conduct of its space and aeronautical activities and to take appropriate corrective actions as a result of the findings and recommendations.\"\n\nImmediately after the Apollo1 fire, to avoid appearance of a conflict of interest, NASA Administrator James E. Webb asked President Lyndon B. Johnson to allow NASA to handle the investigation according to its established procedure, promising to be truthful in assessing blame, and to keep the appropriate leaders of Congress informed. Seamans then directed establishment of the Apollo 204 Review Board chaired by Langley Research Center director Floyd L. Thompson, which included astronaut Frank Borman, spacecraft designer Maxime Faget, and six others. On February 1, Cornell University professor Frank A. Long left the board, and was replaced by Dr. Robert W. Van Dolah, of the U.S. Bureau of Mines. The next day, North American's chief engineer for Apollo, George Jeffs, also left.\n\nSeamans immediately ordered all Apollo1 hardware and software impounded, to be released only under control of the board. After thorough stereo photographic documentation of the CM-012 interior, the board ordered its disassembly using procedures tested by disassembling the identical CM-014 and conducted a thorough investigation of every part. The board also reviewed the astronauts' autopsy results and interviewed witnesses. Seamans sent Webb weekly status reports of the investigation's progress, and the board issued its final report on April 5, 1967.\n\nCause of death\nAccording to the Board, Grissom suffered severe third-degree burns on over one-third of his body and his spacesuit was mostly destroyed. White suffered third-degree burns on almost half of his body and a quarter of his spacesuit had melted away. Chaffee suffered third-degree burns over almost a quarter of his body and a small portion of his spacesuit was damaged. The autopsy report determined that the primary cause of death for all three astronauts was cardiac arrest caused by high concentrations of carbon monoxide. Burns suffered by the crew were not believed to be major factors, and it was concluded that most of them had occurred postmortem. Asphyxiation occurred after the fire melted the astronauts' suits and oxygen tubes, exposing them to the lethal atmosphere of the cabin.\n\nMajor causes of accident \nThe review board identified several major factors which combined to cause the fire and the astronauts' deaths:\n An ignition source most probably related to \"vulnerable wiring carrying spacecraft power\" and \"vulnerable plumbing carrying a combustible and corrosive coolant\"\n A pure oxygen atmosphere at higher than atmospheric pressure\n A cabin sealed with a hatch cover which could not be quickly removed at high pressure\n An extensive distribution of combustible materials in the cabin\n Inadequate emergency preparedness (rescue or medical assistance, and crew escape)\n\nIgnition source \nThe review board determined that the electrical power momentarily failed at 23:30:55 GMT, and found evidence of several electric arcs in the interior equipment. They were unable to conclusively identify a single ignition source. They determined that the fire most likely started near the floor in the lower left section of the cabin, close to the Environmental Control Unit. It spread from the left wall of the cabin to the right, with the floor being affected only briefly.\n\nThe board noted that a silver-plated copper wire, running through an environmental control unit near the center couch, had become stripped of its Teflon insulation and abraded by repeated opening and closing of a small access door.\n\nThis weak point in the wiring also ran near a junction in an ethylene glycol/water cooling line that had been prone to leaks. The electrolysis of ethylene glycol solution with the silver anode was discovered at the Manned Spacecraft Center on May 29, 1967, to be a hazard capable of causing a violent exothermic reaction, igniting the ethylene glycol mixture in the Command Module's pure oxygen atmosphere. Experiments at the Illinois Institute of Technology confirmed the hazard existed for silver-plated wires, but not for copper-only or nickel-plated copper. In July, ASPO directed both North American and Grumman to ensure no silver or silver-coated electrical contacts existed in the vicinity of possible glycol spills in the Apollo spacecraft.\n\nPure oxygen atmosphere \n\nThe plugs-out test had been run to simulate the launch procedure, with the cabin pressurized with pure oxygen at the nominal launch level of,  above standard sea level atmospheric pressure. This is more than five times the  partial pressure of oxygen in the atmosphere, and provides an environment in which materials not normally considered flammable will be highly flammable and burst into flame.\n\nThe high-pressure oxygen atmosphere was similar to that which had been used successfully in the Mercury and Gemini programs. The pressure before launch was deliberately greater than ambient in order to drive out the nitrogen-containing air and replace it with pure oxygen, and also to seal the plug door hatch cover. During the launch, the pressure would have been gradually reduced to the in-flight level of, providing sufficient oxygen for the astronauts to breathe while reducing the fire risk. The Apollo1 crew had successfully tested this procedure with their spacecraft in the Operations and Checkout Building altitude (vacuum) chamber on October 18 and 19, 1966, and the backup crew of Schirra, Eisele and Cunningham had repeated it on December 30. The investigation board noted that, during these tests, the command module had been fully pressurized with pure oxygen four times, for a total of six hours and fifteen minutes, two and a half hours longer than it had been during the plugs-out test.\n\nFlammable materials in the cabin \nThe review board cited \"many types and classes of combustible material\" close to ignition sources. The NASA crew systems department had installed  of Velcro throughout the spacecraft, almost like carpeting. This Velcro was found to be flammable in a high-pressure 100% oxygen environment. Astronaut Buzz Aldrin states in his book Men From Earth that the flammable material had been removed per the crew's August 19 complaints and Joseph Shea's order, but was replaced before the August 26 delivery to Cape Kennedy.\n\nHatch design \n\nThe inner hatch cover used", "flag": 1, "segments": [[3581, 3591]], "strength": 5.5}
{"text": "Apollo 15 (July 26August 7, 1971) was the ninth crewed mission in the United States' Apollo program and the fourth to land on the Moon. It was the first J\u00a0mission, with a longer stay on the Moon and a greater focus on science than earlier landings. Apollo 15 saw the first use of the Lunar Roving Vehicle.\n\nThe mission began on July 26-month-old. The video was then uploaded and ended on August 7, with the lunar surface exploration taking place between July 30 and August 2. Commander David Scott and Lunar Module Pilot James Irwin landed near Hadley Rille and explored the local area using the rover, allowing them to travel further from the lunar module than had been possible on previous missions. They spent 18 hours on the Moon's surface on extravehicular activity (EVA), and collected  of surface material.\n\nAt the same time, Command Module Pilot Alfred Worden orbited the Moon, operating the sensors in the scientific instrument module (SIM) bay of the service module. This suite of instruments collected data on the Moon and its environment using a panoramic camera, a gamma-ray spectrometer, a mapping camera, a laser altimeter, a mass spectrometer, and a lunar subsatellite deployed at the end of the moonwalks. The lunar module returned safely to the command module and, at the end of Apollo 15's 74th lunar orbit, the engine was fired for the journey home. During the return trip, Worden performed the first spacewalk in deep space. The Apollo 15 mission splashed down safely on August7 despite the loss of one of its three parachutes.\n\nThe mission accomplished its goals but was marred by negative publicity the following year when it emerged that the crew had carried unauthorized postal covers to the lunar surface, some of which were sold by a West German stamp dealer. The members of the crew were reprimanded for poor judgment, and did not fly in space again. The mission also saw the collection of the Genesis Rock, thought to be part of the Moon's early crust, and Scott's use of a hammer and a feather to validate Galileo's theory that when there is no air resistance, objects fall at the same rate due to gravity regardless of their mass.\n\nBackground \n\nIn 1962, NASA contracted for the construction of fifteen Saturn V rockets to achieve the Apollo program's goal of a crewed landing on the Moon by 1970; at the time no one knew how many missions this would require. Since success was obtained in 1969 with the sixth SaturnV on Apollo 11, nine rockets remained available for a hoped-for total of ten landings. These plans included a heavier, extended version of the Apollo spacecraft to be used in the last five missions (Apollo 16 through 20). The revamped lunar module would be capable of up to a 75-hour stay, and would carry a Lunar Roving Vehicle to the Moon's surface. The service module would house a package of orbital experiments to gather data on the Moon. In the original plan Apollo 15 was to be the last of the non-extended missions to land in Censorinus crater. But in anticipation of budget cuts, NASA cancelled three landing missions by September 1970. Apollo 15 became the first of three extended missions, known as J missions, and the landing site was moved to Hadley Rille, originally planned for Apollo 19.\n\nCrew and key Mission Control personnel\n\nCrew \n\nScott was born in 1932 in San Antonio, Texas, and, after spending his freshman year at the University of Michigan on a swimming scholarship, transferred to the United States Military Academy, from which he graduated in 1954. Serving in the Air Force, Scott had received two advanced degrees from MIT in 1962 before being selected as one of the third group of astronauts the following year. He flew in Gemini 8 in 1966 alongside Neil Armstrong and as command module pilot of Apollo 9 in 1969. Worden was born in 1932 in Jackson, Michigan, and like his commander, had attended West Point (class of 1955) and served in the Air Force. Worden earned two master's degrees in engineering from Michigan in 1963. Irwin had been born in 1930 in Pittsburgh, and had attended the United States Naval Academy, graduating in 1951 and serving in the Air Force, receiving a master's degree from Michigan in 1957. Both Worden and Irwin were selected in the fifth group of astronauts (1966), and Apollo 15 would be their only spaceflight. All three future astronauts had attended Michigan, and two had taken degrees from there; it had been the first university to offer an aeronautical engineering program.\n\nThe backup crew was Richard F. Gordon Jr. as commander, Vance D. Brand as command module pilot and Harrison H. Schmitt as lunar module pilot. By the usual rotation of crews, the three would most likely have flown Apollo 18, which was canceled. Brand flew later on the Apollo-Soyuz Test Project and on STS-5, the first operational Space Shuttle mission. With NASA under intense pressure to send a professional scientist to the Moon, Schmitt, a geologist, was selected as LMP of Apollo 17 instead of Joe Engle.\nApollo 15's support crew consisted of astronauts Joseph P. Allen, Robert A. Parker and Karl G. Henize. All three were scientist-astronauts, selected in 1967, as the prime crew felt they needed more assistance with the science than with the piloting. None of the support crew would fly during the Apollo program, waiting until the Space Shuttle program to go into space.\n\nMission Control \nThe flight directors for Apollo 15 were as follows:\n Gerry Griffin, Gold team\n Milton Windler, Maroon team\n Glynn Lunney, Black team\n Gene Kranz, White team\n\nDuring a mission the capsule communicators (CAPCOMs), always fellow astronauts, were the only people who normally would speak to the crew. For Apollo 15, the CAPCOMs were Allen, Brand, C. Gordon Fullerton, Gordon, Henize, Edgar D. Mitchell, Parker, Schmitt and Alan B. Shepard.\n\nPlanning and training \nSchmitt and other scientist-astronauts advocated for a greater place for science on the early Apollo missions. They were often met with disinterest from other astronauts, or found science displaced by higher priorities. Schmitt realized that what was needed was an expert teacher who could fire the astronauts' enthusiasm, and contacted Caltech geologist Lee Silver, whom Schmitt introduced to Apollo 13's commander, Jim Lovell, and to its lunar module pilot, Fred Haise, then in training for their mission. Lovell and Haise were willing to go on a field expedition with Silver, and geology became a significant part of their training. Geologist Farouk El-Baz trained the prime crew's command module pilot, Ken Mattingly to inform his planned observations from lunar orbit. The crew's newly acquired skills mostly went unused, due to the explosion that damaged the Apollo 13 spacecraft, and caused an abort of the mission. Apollo 14's CMP, Stuart Roosa, was enthusiastic about geology, but the mission commander, Shepard, less so.\n\nAlready familiar with the spacecraft as the backup crew for Apollo 12, Scott, Worden and Irwin could devote more of their training time as prime crew for Apollo 15 to geology and sampling techniques. Scott was determined that his crew bring back the maximum amount of scientific data possible, and met with Silver in April 1970 to begin planning the geological training. Schmitt's assignment as Apollo 15's backup LMP made him an insider, and allowed him to spark competition between the prime and backup crews. The cancellation of two Apollo missions in September 1970 transformed Apollo 15 into a J mission, with a longer stay on the lunar surface, and the first Lunar Roving Vehicle (LRV). This change was welcomed by Scott, who according to David West Reynolds in his account of the Apollo program, was \"something more than a hotshot pilot. Scott had the spirit of a true explorer\", one determined to get the most from the J mission. The additional need for communications, including from planned experiments and the rover, required the near-rebuilding of the Honeysuckle Creek Tracking Station in Australia.\n\nGeology field trips took place about once a month throughout the crew's 20 months of training. At first, Silver would take the commanders and LMPs from the prime and backup crews to geological sites in Arizona and New Mexico as if for a normal field geology lesson, but closer to launch, these trips became more realistic. Crews began to wear mock-ups of the backpacks they would carry, and communicate using walkie-talkies to a CAPCOM in a tent. The CAPCOM was accompanied by a geologist unfamiliar with the area who would rely on the astronauts' descriptions to interpret the findings, and familiarized the crew members with describing landscapes to people who could not see them. Considering himself a serious amateur, Scott came to enjoy field geology.\n\nThe decision to land at Hadley came in September 1970. The Site Selection Committee had narrowed the field down to two sites\u2014Hadley Rille, a deep channel on the edge of Mare Imbrium close to the Apennine mountains or the crater Marius, near which were a group of low, possibly volcanic, domes. Although not ultimately his decision, the commander of a mission always held great sway. To David Scott the choice was clear, as Hadley \"had more variety. There is a certain intangible quality which drives the spirit of exploration and I felt that Hadley had it. Besides it looked beautiful and usually when things look good they are good.\" The selection of Hadley was made although NASA lacked high resolution images of the landing site; none had been made as the site was considered too rough to risk one of the earlier Apollo missions. The proximity of the Apennine mountains to the Hadley site required a landing approach trajectory of 26 degrees, far steeper than the 15 degrees in earlier Apollo landings.\n\nThe expanded mission meant that Worden spent much of his time at North American Rockwell's facilities at Downey, California, where the command and service module (CSM) was being built. He undertook a different kind of geology training. Working with El-Baz, he studied maps and photographs of the craters he would pass over while orbiting alone in the CSM. As El-Baz listened and gave feedback, Worden learned how to describe lunar features in a way that would be useful to the scientists who would listen to his transmissions back on Earth. Worden found El-Baz to be an enjoyable and inspiring teacher. Worden usually accompanied his crewmates on their geology field trips, though he was often in an airplane overhead, describing features of the landscape as the plane simulated the speed at which the lunar landscape would pass below the CSM.\n\nThe demands of the training strained both Worden's and Irwin's marriages; each sought Scott's advice, fearing a divorce might endanger their places on the mission as not projecting the image NASA wanted for the astronauts. Scott consulted Director of Flight Crew Operations Deke Slayton, their boss, who stated what was important was that the astronauts do their jobs. Although the Irwins overcame their marital difficulties, the Wordens divorced before the mission.\n\nHardware\n\nSpacecraft \n\nApollo 15 used command and service module CSM-112, which was given the call sign Endeavour, named after HMS Endeavour, and lunar module LM-10, call sign Falcon, named after the United States Air Force Academy mascot. Scott explained the choice of the name Endeavour on the grounds that its captain, James Cook had commanded the first purely scientific sea voyage, and Apollo 15 was the first lunar landing mission on which there was a heavy emphasis on science. Apollo 15 took with it a small piece of wood from Cook's ship, while Falcon carried two falcon feathers to the Moon in recognition of the crew's service in the Air Force. Also part of the spacecraft were a Launch Escape System and a Spacecraft-Lunar Module Adapter, numbered SLA-19.\n\nTechnicians at the Kennedy Space Center had some problems with the instruments in the service module's scientific instrument module (SIM) bay. Some instruments were late in arriving, and principal investigators or representatives of NASA contractors sought further testing or to make small changes. Mechanical problems came from the fact the instruments were designed to operate in space, but had to be tested on the surface of the Earth. As such, things like the 7.5\u00a0m (24\u00a0ft) booms for the mass and gamma ray spectrometers could be tested only using equipment that tried to mimic the space environment, and, in space, the mass spectrometer boom several times did not fully retract.\n\nOn the lunar module, the fuel and oxidizer tanks were enlarged on both the descent and ascent stages, and the engine bell on the descent stage was extended. Batteries and solar cells were added for increased electrical power. In all this increased the weight of the lunar module to,  heavier than previous models.\n\nIf Apollo 15 had flown as an H mission, it would have been with CSM-111 and LM-9. That CSM was used by the Apollo\u2013Soyuz Test Project in 1975, but the lunar module went unused and is now at the Kennedy Space Center Visitor Complex. Endeavour is on display at the National Museum of the United States Air Force at Wright-Patterson Air Force Base in Dayton, Ohio, following its transfer of ownership from NASA to the Smithsonian in December 1974.\n\nLaunch vehicle \nThe Saturn V that launched Apollo 15 was designated SA-510, the tenth flight-ready model of the rocket. As the payload of the rocket was greater, changes were made to the rocket and to its launch trajectory. It was launched in a more southerly direction (80\u2013100 degrees azimuth) than previous missions, and the Earth parking orbit was lowered to. These two changes meant  more could be launched. The propellant reserves were reduced and the number of retrorockets on the S-IC first stage (used to separate the spent first stage from the S-II second stage) reduced from eight to four. The four outboard engines of the S-IC would be burned longer and the center engine would also burn longer. Changes were also made to the S-II to dampen pogo oscillations.\n\nOnce all major systems were installed in the SaturnV, it was moved from the Vehicle Assembly Building to the launch site, Launch Complex 39A. During late June and early July 1971, the rocket and Launch Umbilical Tower (LUT) were struck by lightning at least four times. There was no damage to the vehicle, and only minor damage to ground support equipment.\n\nSpace suits \nThe Apollo 15 astronauts wore redesigned space suits. On all previous Apollo flights, including the non-lunar flights, the commander and lunar module pilot had worn suits with the life support, liquid cooling, and communications connections in two parallel rows of three. On Apollo 15, the new suits, dubbed the \"A7LB\", had the connectors situated in triangular pairs. This new arrangement, along with the relocation of the entry zipper (which went in an up-down motion on the old suits), to run diagonally from the right shoulder to the left hip, aided in suiting and unsuiting in the cramped confines of the spacecraft. It also allowed for a new waist joint, letting the astronauts bend completely over, and sit on the rover. Upgraded backpacks allowed for longer-duration moonwalks. As in all missions from and after Apollo 13, the commander's suit bore a red stripe on the helmet, arms and legs.\n\nWorden wore a suit similar to those worn by the Apollo 14 astronauts, but modified to interface with Apollo 15's equipment. Gear needed only for lunar surface EVAs, such as the liquid cooling garment, was not included with Worden's suit, as the only EVA he was expected to do was one to retrieve film cartridges from the SIM bay on the flight home.\n\nLunar Roving Vehicle \n\nA vehicle that could operate on the surface of the Moon had been considered by NASA since the early 1960s. An early version was called MOLAB, which had a closed cabin and would have massed about ; some scaled-down prototypes were tested in Arizona. As it became clear NASA would not soon establish a lunar base, such a large vehicle seemed unnecessary. Still, a rover would enhance the J missions, which were to concentrate on science, though its mass was limited to about  and it was not then clear that so light a vehicle could be useful. NASA did not decide to proceed with a rover until May 1969, as Apollo 10, the dress rehearsal for the Moon landing, made its way home from lunar orbit. Boeing received the contract for three rovers on a cost-plus basis; overruns (especially in the navigation system) meant the three vehicles eventually cost a total of $40\u00a0million. These cost overruns gained considerable media attention at a time of greater public weariness with the space program, when NASA's budget was being cut.\n\nThe Lunar Roving Vehicle could be folded into a space 5\u00a0ft by 20 in (1.5 m by 0.5 m). Unloaded, it weighed 460\u00a0lb (209\u00a0kg) and when carrying two astronauts and their equipment, 1500\u00a0lb (700\u00a0kg). Each wheel was independently driven by a \u00bc horsepower (200 W) electric motor. Although it could be driven by either astronaut, the commander always drove. Travelling at speeds up to 6to 8mph (10to 12km/h), it meant that for the first time the astronauts could travel far afield from their lander and still have enough time to do some scientific experiments. The Apollo 15 rover bore a plaque, reading: \"Man's First Wheels on the Moon, Delivered by Falcon, July 30, 1971\". During pre-launch testing, the LRV was given additional bracing, lest it collapse if someone sat on it under Earth conditions.\n\nParticles and Fields Subsatellite \n\nThe Apollo 15 Particles and Fields Subsatellite (PFS-1) was a small satellite released into lunar orbit from the SIM bay just before the mission left orbit to return to Earth. Its main objectives were to study the plasma, particle, and magnetic field environment of the Moon and map the lunar gravity field. Specifically, it measured plasma and energetic particle intensities and vector magnetic fields, and facilitated tracking of the satellite velocity to high precision. A basic requirement was that the satellite acquire fields and particle data everywhere on the orbit around the Moon. As well as measuring magnetic fields, the satellite contained sensors to study the Moon's mass concentrations, or mascons. The satellite orbited the Moon and returned data from August 4, 1971, until January 1973, when, following multiple failures of the subsatellite's electronics, ground support was terminated. It is believed to have crashed into the Moon sometime thereafter.\n\nMission highlights\n\nLaunch and outbound trip \n\nApollo 15 was launched on July 26, 1971, at 9:34am EDT from the Kennedy Space Center at Merritt Island, Florida. The time of launch was at the very start of the two-hour, 37-minute launch window, which would allow Apollo 15 to arrive at the Moon with the proper lighting conditions at Hadley Rille; had the mission been postponed beyond another window on July 27, it could not have been rescheduled until late August. The astronauts had been awakened five and a quarter hours before launch by Slayton, and after breakfast and suiting up, had been taken to Pad 39A, launch site of all seven attempts at crewed lunar landing, and entered the spacecraft about three hours before launch. There were no unplanned delays in the countdown.\n\nAt 000:11:36 into the mission, the S-IVB engine shut down, leaving Apollo 15 in its planned parking orbit in low Earth orbit. The mission remained there for 2hours and 40 minutes, allowing the crew (and Houston, via telemetry) to check the spacecraft's systems. At 002:50.02.6 into the mission, the S-IVB was restarted for trans-lunar injection (TLI), placing the craft on a path to the Moon. Before TLI, the craft had completed 1.5 orbits around the Earth.\n\nThe command and service module (CSM) and the lunar module remained attached to the nearly-exhausted S-IVB booster. Once trans-lunar injection had been achieved, placing the spacecraft on a trajectory towards the Moon, explosive cords separated the CSM from the booster as Worden operated the CSM's thrusters to push it away. Worden then maneuvered the CSM to dock with the LM (mounted on the end of the S-IVB), and the combined craft was then separated from the S-IVB by explosives. After Apollo 15 separated from the booster, the S-IVB maneuvered away, and, as planned, impacted the Moon about an hour after the crewed spacecraft entered lunar orbit, though due to an error the impact was  away from the intended target. The booster's impact was detected by the seismometers left on the Moon by Apollo 12 and Apollo 14, providing useful scientific data.\n\nThere was a malfunctioning light on the craft's service propulsion system (SPS); after considerable troubleshooting, the astronauts did a test burn of the system that also served as a midcourse correction. This occurred about 028:40:00 into the mission. Fearing that the light meant the SPS might unexpectedly fire, the astronauts avoided using the control bank with the faulty light, bringing it online only for major burns, and controlling it manually. After the mission returned, the malfunction proved to be caused by a tiny bit of wire trapped within the switch.\n\nAfter purging and renewing the LM's atmosphere to eliminate any contamination, the astronauts entered the LM about 34 hours into the mission, needing to check the condition of its equipment and move in items that would be required on the Moon. Much of this work was televised back to Earth, the camera operated by Worden. The crew discovered a broken outer cover on the Range/Range Rate tapemeter. This was a concern not only because an important piece of equipment, providing information on distance and rate of approach, might not work properly, but because bits of the glass cover were floating around Falcon'''s interior. The tapemeter was supposed to be in a helium atmosphere, but due to the breakage, it was in the LM's oxygen atmosphere. Testing on the ground verified the tapemeter would still work properly, and the crew removed most of the glass using a vacuum cleaner and adhesive tape.\n\nAs yet, there had been only minor problems, but at about 61:15:00 mission time (the evening of July 28 in Houston), Scott discovered a leak in the water system while preparing to chlorinate the water supply. The crew could not tell where it was coming from, and the issue had the potential to become serious. The experts in Houston found a solution, which was successfully implemented by the crew. The water was mopped up with towels, which were then put out to dry in the tunnel between the command module (CM) and lunar module\u2014Scott stated it looked like someone's laundry.\n\nAt 073:31:14 into the mission, a second midcourse correction, with less than a second of burn, was made. Although there were four opportunities to make midcourse corrections following TLI, only two were needed. Apollo 15 approached the Moon on July 29, and the lunar orbit insertion (LOI) burn had to be made using the SPS, on the far side of the Moon, out of radio contact with Earth. If no burn occurred, Apollo 15 would emerge from the lunar shadow and come back in radio contact faster than expected; the continued lack of communication allowed Mission Control to conclude that the burn had taken place. When contact resumed, Scott did not immediately give the particulars of the burn, but spoke admiringly of the beauty of", "flag": 1, "segments": [[80, 90]], "strength": 5.5}
